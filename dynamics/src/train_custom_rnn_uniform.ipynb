{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from custom_rnn_uniform import SequenceModel, Trainer\n",
    "import torch\n",
    "from utils.visualize import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "\n",
    "train = pickle.load(open(root+\"/../datasets/custom_rnn_uniform/train.pickle\", \"rb\"))\n",
    "val = pickle.load(open(root+\"/../datasets/custom_rnn_uniform/val.pickle\", \"rb\"))\n",
    "test = pickle.load(open(root+\"/../datasets/custom_rnn_uniform/test.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1606, 1, 21), (1606, 1, 8), (1606, 21), (1606, 98, 21), (1606, 98, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 1\n",
    "train[\"input_states\"][t].shape, train[\"input_actions\"][t].shape, train[\"intermediate_states\"][t].shape, train[\"output_states\"][t].shape, train[\"output_actions\"][t].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 1, 21), (89, 1, 8), (89, 21), (89, 98, 21), (89, 98, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 1\n",
    "val[\"input_states\"][t].shape, val[\"input_actions\"][t].shape, val[\"intermediate_states\"][t].shape, val[\"output_states\"][t].shape, val[\"output_actions\"][t].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 1, 21), (90, 1, 8), (90, 21), (90, 98, 21), (90, 98, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 1\n",
    "test[\"input_states\"][t].shape, test[\"input_actions\"][t].shape, test[\"intermediate_states\"][t].shape, test[\"output_states\"][t].shape, test[\"output_actions\"][t].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = SequenceModel(state_dim=21, action_dim=8, latent_dim=256, num_recurrent_layers=1, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=seq_model, device=device, learing_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_checkpoint(path=root+\"/../models/custom_rnn_uniform_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 0 -- Train Loss: 0.33280  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1 -- Train Loss: 0.33267  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 2 -- Train Loss: 0.33257  Validation Loss: 0.42838\n",
      "t: 10 EPOCH 3 -- Train Loss: 0.33311  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 4 -- Train Loss: 0.33281  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 5 -- Train Loss: 0.33358  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 6 -- Train Loss: 0.33315  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 7 -- Train Loss: 0.33312  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 8 -- Train Loss: 0.33299  Validation Loss: 0.42953\n",
      "t: 10 EPOCH 9 -- Train Loss: 0.33333  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 10 -- Train Loss: 0.33261  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 11 -- Train Loss: 0.33344  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 12 -- Train Loss: 0.33273  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 13 -- Train Loss: 0.33253  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 14 -- Train Loss: 0.33304  Validation Loss: 0.42897\n",
      "t: 10 EPOCH 15 -- Train Loss: 0.33229  Validation Loss: 0.42874\n",
      "t: 10 EPOCH 16 -- Train Loss: 0.33324  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 17 -- Train Loss: 0.33248  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 18 -- Train Loss: 0.33341  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 19 -- Train Loss: 0.33287  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 20 -- Train Loss: 0.33262  Validation Loss: 0.42914\n",
      "t: 10 EPOCH 21 -- Train Loss: 0.33322  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 22 -- Train Loss: 0.33387  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 23 -- Train Loss: 0.33241  Validation Loss: 0.42940\n",
      "t: 10 EPOCH 24 -- Train Loss: 0.33203  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 25 -- Train Loss: 0.33392  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 26 -- Train Loss: 0.33286  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 27 -- Train Loss: 0.33231  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 28 -- Train Loss: 0.33256  Validation Loss: 0.42901\n",
      "t: 10 EPOCH 29 -- Train Loss: 0.33311  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 30 -- Train Loss: 0.33308  Validation Loss: 0.42935\n",
      "t: 10 EPOCH 31 -- Train Loss: 0.33265  Validation Loss: 0.42998\n",
      "t: 10 EPOCH 32 -- Train Loss: 0.33379  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 33 -- Train Loss: 0.33305  Validation Loss: 0.42930\n",
      "t: 10 EPOCH 34 -- Train Loss: 0.33365  Validation Loss: 0.42853\n",
      "t: 10 EPOCH 35 -- Train Loss: 0.33348  Validation Loss: 0.42897\n",
      "t: 10 EPOCH 36 -- Train Loss: 0.33328  Validation Loss: 0.42930\n",
      "t: 10 EPOCH 37 -- Train Loss: 0.33377  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 38 -- Train Loss: 0.33263  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 39 -- Train Loss: 0.33267  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 40 -- Train Loss: 0.33319  Validation Loss: 0.42878\n",
      "t: 10 EPOCH 41 -- Train Loss: 0.33276  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 42 -- Train Loss: 0.33280  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 43 -- Train Loss: 0.33264  Validation Loss: 0.42944\n",
      "t: 10 EPOCH 44 -- Train Loss: 0.33385  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 45 -- Train Loss: 0.33362  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 46 -- Train Loss: 0.33292  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 47 -- Train Loss: 0.33261  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 48 -- Train Loss: 0.33314  Validation Loss: 0.42893\n",
      "t: 10 EPOCH 49 -- Train Loss: 0.33284  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 50 -- Train Loss: 0.33289  Validation Loss: 0.42939\n",
      "t: 10 EPOCH 51 -- Train Loss: 0.33297  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 52 -- Train Loss: 0.33417  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 53 -- Train Loss: 0.33297  Validation Loss: 0.42859\n",
      "t: 10 EPOCH 54 -- Train Loss: 0.33326  Validation Loss: 0.42866\n",
      "t: 10 EPOCH 55 -- Train Loss: 0.33289  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 56 -- Train Loss: 0.33302  Validation Loss: 0.42933\n",
      "t: 10 EPOCH 57 -- Train Loss: 0.33328  Validation Loss: 0.42800\n",
      "t: 10 EPOCH 58 -- Train Loss: 0.33253  Validation Loss: 0.42873\n",
      "t: 10 EPOCH 59 -- Train Loss: 0.33363  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 60 -- Train Loss: 0.33268  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 61 -- Train Loss: 0.33441  Validation Loss: 0.42918\n",
      "t: 10 EPOCH 62 -- Train Loss: 0.33308  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 63 -- Train Loss: 0.33327  Validation Loss: 0.42960\n",
      "t: 10 EPOCH 64 -- Train Loss: 0.33333  Validation Loss: 0.42934\n",
      "t: 10 EPOCH 65 -- Train Loss: 0.33377  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 66 -- Train Loss: 0.33347  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 67 -- Train Loss: 0.33331  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 68 -- Train Loss: 0.33344  Validation Loss: 0.42858\n",
      "t: 10 EPOCH 69 -- Train Loss: 0.33382  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 70 -- Train Loss: 0.33320  Validation Loss: 0.42909\n",
      "t: 10 EPOCH 71 -- Train Loss: 0.33365  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 72 -- Train Loss: 0.33347  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 73 -- Train Loss: 0.33355  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 74 -- Train Loss: 0.33312  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 75 -- Train Loss: 0.33278  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 76 -- Train Loss: 0.33272  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 77 -- Train Loss: 0.33440  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 78 -- Train Loss: 0.33283  Validation Loss: 0.42923\n",
      "t: 10 EPOCH 79 -- Train Loss: 0.33332  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 80 -- Train Loss: 0.33295  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 81 -- Train Loss: 0.33349  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 82 -- Train Loss: 0.33321  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 83 -- Train Loss: 0.33429  Validation Loss: 0.42848\n",
      "t: 10 EPOCH 84 -- Train Loss: 0.33278  Validation Loss: 0.42939\n",
      "t: 10 EPOCH 85 -- Train Loss: 0.33367  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 86 -- Train Loss: 0.33289  Validation Loss: 0.42880\n",
      "t: 10 EPOCH 87 -- Train Loss: 0.33363  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 88 -- Train Loss: 0.33310  Validation Loss: 0.42897\n",
      "t: 10 EPOCH 89 -- Train Loss: 0.33368  Validation Loss: 0.42942\n",
      "t: 10 EPOCH 90 -- Train Loss: 0.33284  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 91 -- Train Loss: 0.33419  Validation Loss: 0.42936\n",
      "t: 10 EPOCH 92 -- Train Loss: 0.33291  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 93 -- Train Loss: 0.33343  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 94 -- Train Loss: 0.33371  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 95 -- Train Loss: 0.33409  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 96 -- Train Loss: 0.33361  Validation Loss: 0.42882\n",
      "t: 10 EPOCH 97 -- Train Loss: 0.33414  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 98 -- Train Loss: 0.33291  Validation Loss: 0.42864\n",
      "t: 10 EPOCH 99 -- Train Loss: 0.33318  Validation Loss: 0.42940\n",
      "t: 10 EPOCH 100 -- Train Loss: 0.33318  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 101 -- Train Loss: 0.33331  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 102 -- Train Loss: 0.33282  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 103 -- Train Loss: 0.33392  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 104 -- Train Loss: 0.33316  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 105 -- Train Loss: 0.33438  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 106 -- Train Loss: 0.33370  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 107 -- Train Loss: 0.33400  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 108 -- Train Loss: 0.33374  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 109 -- Train Loss: 0.33266  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 110 -- Train Loss: 0.33337  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 111 -- Train Loss: 0.33357  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 112 -- Train Loss: 0.33386  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 113 -- Train Loss: 0.33318  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 114 -- Train Loss: 0.33425  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 115 -- Train Loss: 0.33257  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 116 -- Train Loss: 0.33398  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 117 -- Train Loss: 0.33262  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 118 -- Train Loss: 0.33291  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 119 -- Train Loss: 0.33206  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 120 -- Train Loss: 0.33391  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 121 -- Train Loss: 0.33296  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 122 -- Train Loss: 0.33352  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 123 -- Train Loss: 0.33300  Validation Loss: 0.42929\n",
      "t: 10 EPOCH 124 -- Train Loss: 0.33378  Validation Loss: 0.42940\n",
      "t: 10 EPOCH 125 -- Train Loss: 0.33464  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 126 -- Train Loss: 0.33320  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 127 -- Train Loss: 0.33356  Validation Loss: 0.43070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 128 -- Train Loss: 0.33288  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 129 -- Train Loss: 0.33316  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 130 -- Train Loss: 0.33349  Validation Loss: 0.42921\n",
      "t: 10 EPOCH 131 -- Train Loss: 0.33363  Validation Loss: 0.42839\n",
      "t: 10 EPOCH 132 -- Train Loss: 0.33334  Validation Loss: 0.42925\n",
      "t: 10 EPOCH 133 -- Train Loss: 0.33349  Validation Loss: 0.42905\n",
      "t: 10 EPOCH 134 -- Train Loss: 0.33229  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 135 -- Train Loss: 0.33283  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 136 -- Train Loss: 0.33361  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 137 -- Train Loss: 0.33418  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 138 -- Train Loss: 0.33193  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 139 -- Train Loss: 0.33345  Validation Loss: 0.42892\n",
      "t: 10 EPOCH 140 -- Train Loss: 0.33308  Validation Loss: 0.42954\n",
      "t: 10 EPOCH 141 -- Train Loss: 0.33354  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 142 -- Train Loss: 0.33285  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 143 -- Train Loss: 0.33418  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 144 -- Train Loss: 0.33227  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 145 -- Train Loss: 0.33449  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 146 -- Train Loss: 0.33237  Validation Loss: 0.42931\n",
      "t: 10 EPOCH 147 -- Train Loss: 0.33323  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 148 -- Train Loss: 0.33286  Validation Loss: 0.42856\n",
      "t: 10 EPOCH 149 -- Train Loss: 0.33359  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 150 -- Train Loss: 0.33285  Validation Loss: 0.42848\n",
      "t: 10 EPOCH 151 -- Train Loss: 0.33363  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 152 -- Train Loss: 0.33289  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 153 -- Train Loss: 0.33332  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 154 -- Train Loss: 0.33359  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 155 -- Train Loss: 0.33366  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 156 -- Train Loss: 0.33370  Validation Loss: 0.42821\n",
      "t: 10 EPOCH 157 -- Train Loss: 0.33323  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 158 -- Train Loss: 0.33393  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 159 -- Train Loss: 0.33383  Validation Loss: 0.42920\n",
      "t: 10 EPOCH 160 -- Train Loss: 0.33269  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 161 -- Train Loss: 0.33401  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 162 -- Train Loss: 0.33384  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 163 -- Train Loss: 0.33321  Validation Loss: 0.42913\n",
      "t: 10 EPOCH 164 -- Train Loss: 0.33364  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 165 -- Train Loss: 0.33324  Validation Loss: 0.42852\n",
      "t: 10 EPOCH 166 -- Train Loss: 0.33313  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 167 -- Train Loss: 0.33367  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 168 -- Train Loss: 0.33304  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 169 -- Train Loss: 0.33394  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 170 -- Train Loss: 0.33262  Validation Loss: 0.42934\n",
      "t: 10 EPOCH 171 -- Train Loss: 0.33363  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 172 -- Train Loss: 0.33244  Validation Loss: 0.42936\n",
      "t: 10 EPOCH 173 -- Train Loss: 0.33368  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 174 -- Train Loss: 0.33306  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 175 -- Train Loss: 0.33375  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 176 -- Train Loss: 0.33279  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 177 -- Train Loss: 0.33384  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 178 -- Train Loss: 0.33330  Validation Loss: 0.42901\n",
      "t: 10 EPOCH 179 -- Train Loss: 0.33231  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 180 -- Train Loss: 0.33316  Validation Loss: 0.42905\n",
      "t: 10 EPOCH 181 -- Train Loss: 0.33245  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 182 -- Train Loss: 0.33328  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 183 -- Train Loss: 0.33297  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 184 -- Train Loss: 0.33267  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 185 -- Train Loss: 0.33387  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 186 -- Train Loss: 0.33451  Validation Loss: 0.42906\n",
      "t: 10 EPOCH 187 -- Train Loss: 0.33257  Validation Loss: 0.42891\n",
      "t: 10 EPOCH 188 -- Train Loss: 0.33276  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 189 -- Train Loss: 0.33214  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 190 -- Train Loss: 0.33319  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 191 -- Train Loss: 0.33172  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 192 -- Train Loss: 0.33285  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 193 -- Train Loss: 0.33316  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 194 -- Train Loss: 0.33387  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 195 -- Train Loss: 0.33301  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 196 -- Train Loss: 0.33378  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 197 -- Train Loss: 0.33312  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 198 -- Train Loss: 0.33308  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 199 -- Train Loss: 0.33330  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 200 -- Train Loss: 0.33373  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 201 -- Train Loss: 0.33283  Validation Loss: 0.42918\n",
      "t: 10 EPOCH 202 -- Train Loss: 0.33309  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 203 -- Train Loss: 0.33287  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 204 -- Train Loss: 0.33318  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 205 -- Train Loss: 0.33339  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 206 -- Train Loss: 0.33222  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 207 -- Train Loss: 0.33331  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 208 -- Train Loss: 0.33369  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 209 -- Train Loss: 0.33313  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 210 -- Train Loss: 0.33249  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 211 -- Train Loss: 0.33310  Validation Loss: 0.42882\n",
      "t: 10 EPOCH 212 -- Train Loss: 0.33291  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 213 -- Train Loss: 0.33330  Validation Loss: 0.42954\n",
      "t: 10 EPOCH 214 -- Train Loss: 0.33313  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 215 -- Train Loss: 0.33311  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 216 -- Train Loss: 0.33346  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 217 -- Train Loss: 0.33290  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 218 -- Train Loss: 0.33268  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 219 -- Train Loss: 0.33326  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 220 -- Train Loss: 0.33250  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 221 -- Train Loss: 0.33274  Validation Loss: 0.42945\n",
      "t: 10 EPOCH 222 -- Train Loss: 0.33263  Validation Loss: 0.42954\n",
      "t: 10 EPOCH 223 -- Train Loss: 0.33292  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 224 -- Train Loss: 0.33287  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 225 -- Train Loss: 0.33309  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 226 -- Train Loss: 0.33238  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 227 -- Train Loss: 0.33287  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 228 -- Train Loss: 0.33311  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 229 -- Train Loss: 0.33323  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 230 -- Train Loss: 0.33290  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 231 -- Train Loss: 0.33318  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 232 -- Train Loss: 0.33262  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 233 -- Train Loss: 0.33404  Validation Loss: 0.42966\n",
      "t: 10 EPOCH 234 -- Train Loss: 0.33286  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 235 -- Train Loss: 0.33330  Validation Loss: 0.42909\n",
      "t: 10 EPOCH 236 -- Train Loss: 0.33315  Validation Loss: 0.42953\n",
      "t: 10 EPOCH 237 -- Train Loss: 0.33228  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 238 -- Train Loss: 0.33215  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 239 -- Train Loss: 0.33275  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 240 -- Train Loss: 0.33352  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 241 -- Train Loss: 0.33338  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 242 -- Train Loss: 0.33266  Validation Loss: 0.42929\n",
      "t: 10 EPOCH 243 -- Train Loss: 0.33323  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 244 -- Train Loss: 0.33289  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 245 -- Train Loss: 0.33247  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 246 -- Train Loss: 0.33323  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 247 -- Train Loss: 0.33288  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 248 -- Train Loss: 0.33275  Validation Loss: 0.42918\n",
      "t: 10 EPOCH 249 -- Train Loss: 0.33174  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 250 -- Train Loss: 0.33280  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 251 -- Train Loss: 0.33219  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 252 -- Train Loss: 0.33237  Validation Loss: 0.42859\n",
      "t: 10 EPOCH 253 -- Train Loss: 0.33231  Validation Loss: 0.42937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 254 -- Train Loss: 0.33200  Validation Loss: 0.42951\n",
      "t: 10 EPOCH 255 -- Train Loss: 0.33305  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 256 -- Train Loss: 0.33249  Validation Loss: 0.42963\n",
      "t: 10 EPOCH 257 -- Train Loss: 0.33283  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 258 -- Train Loss: 0.33293  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 259 -- Train Loss: 0.33276  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 260 -- Train Loss: 0.33322  Validation Loss: 0.42865\n",
      "t: 10 EPOCH 261 -- Train Loss: 0.33244  Validation Loss: 0.42921\n",
      "t: 10 EPOCH 262 -- Train Loss: 0.33344  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 263 -- Train Loss: 0.33354  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 264 -- Train Loss: 0.33283  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 265 -- Train Loss: 0.33250  Validation Loss: 0.42916\n",
      "t: 10 EPOCH 266 -- Train Loss: 0.33223  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 267 -- Train Loss: 0.33342  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 268 -- Train Loss: 0.33198  Validation Loss: 0.42926\n",
      "t: 10 EPOCH 269 -- Train Loss: 0.33238  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 270 -- Train Loss: 0.33268  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 271 -- Train Loss: 0.33291  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 272 -- Train Loss: 0.33374  Validation Loss: 0.42907\n",
      "t: 10 EPOCH 273 -- Train Loss: 0.33335  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 274 -- Train Loss: 0.33255  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 275 -- Train Loss: 0.33206  Validation Loss: 0.42953\n",
      "t: 10 EPOCH 276 -- Train Loss: 0.33235  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 277 -- Train Loss: 0.33344  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 278 -- Train Loss: 0.33394  Validation Loss: 0.42939\n",
      "t: 10 EPOCH 279 -- Train Loss: 0.33204  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 280 -- Train Loss: 0.33323  Validation Loss: 0.42955\n",
      "t: 10 EPOCH 281 -- Train Loss: 0.33274  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 282 -- Train Loss: 0.33310  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 283 -- Train Loss: 0.33239  Validation Loss: 0.42940\n",
      "t: 10 EPOCH 284 -- Train Loss: 0.33264  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 285 -- Train Loss: 0.33279  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 286 -- Train Loss: 0.33254  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 287 -- Train Loss: 0.33315  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 288 -- Train Loss: 0.33307  Validation Loss: 0.42879\n",
      "t: 10 EPOCH 289 -- Train Loss: 0.33349  Validation Loss: 0.42884\n",
      "t: 10 EPOCH 290 -- Train Loss: 0.33266  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 291 -- Train Loss: 0.33377  Validation Loss: 0.42846\n",
      "t: 10 EPOCH 292 -- Train Loss: 0.33270  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 293 -- Train Loss: 0.33434  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 294 -- Train Loss: 0.33299  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 295 -- Train Loss: 0.33373  Validation Loss: 0.42855\n",
      "t: 10 EPOCH 296 -- Train Loss: 0.33246  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 297 -- Train Loss: 0.33390  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 298 -- Train Loss: 0.33269  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 299 -- Train Loss: 0.33433  Validation Loss: 0.42821\n",
      "t: 10 EPOCH 300 -- Train Loss: 0.33351  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 301 -- Train Loss: 0.33386  Validation Loss: 0.42831\n",
      "t: 10 EPOCH 302 -- Train Loss: 0.33318  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 303 -- Train Loss: 0.33491  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 304 -- Train Loss: 0.33358  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 305 -- Train Loss: 0.33440  Validation Loss: 0.42825\n",
      "t: 10 EPOCH 306 -- Train Loss: 0.33316  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 307 -- Train Loss: 0.33422  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 308 -- Train Loss: 0.33251  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 309 -- Train Loss: 0.33400  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 310 -- Train Loss: 0.33311  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 311 -- Train Loss: 0.33315  Validation Loss: 0.42790\n",
      "t: 10 EPOCH 312 -- Train Loss: 0.33461  Validation Loss: 0.42917\n",
      "t: 10 EPOCH 313 -- Train Loss: 0.33280  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 314 -- Train Loss: 0.33428  Validation Loss: 0.42942\n",
      "t: 10 EPOCH 315 -- Train Loss: 0.33318  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 316 -- Train Loss: 0.33431  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 317 -- Train Loss: 0.33328  Validation Loss: 0.42910\n",
      "t: 10 EPOCH 318 -- Train Loss: 0.33395  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 319 -- Train Loss: 0.33333  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 320 -- Train Loss: 0.33399  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 321 -- Train Loss: 0.33265  Validation Loss: 0.42906\n",
      "t: 10 EPOCH 322 -- Train Loss: 0.33391  Validation Loss: 0.42856\n",
      "t: 10 EPOCH 323 -- Train Loss: 0.33400  Validation Loss: 0.42904\n",
      "t: 10 EPOCH 324 -- Train Loss: 0.33340  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 325 -- Train Loss: 0.33437  Validation Loss: 0.42855\n",
      "t: 10 EPOCH 326 -- Train Loss: 0.33225  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 327 -- Train Loss: 0.33349  Validation Loss: 0.42975\n",
      "t: 10 EPOCH 328 -- Train Loss: 0.33339  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 329 -- Train Loss: 0.33380  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 330 -- Train Loss: 0.33332  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 331 -- Train Loss: 0.33368  Validation Loss: 0.42857\n",
      "t: 10 EPOCH 332 -- Train Loss: 0.33396  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 333 -- Train Loss: 0.33274  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 334 -- Train Loss: 0.33341  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 335 -- Train Loss: 0.33313  Validation Loss: 0.42831\n",
      "t: 10 EPOCH 336 -- Train Loss: 0.33241  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 337 -- Train Loss: 0.33246  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 338 -- Train Loss: 0.33289  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 339 -- Train Loss: 0.33192  Validation Loss: 0.42862\n",
      "t: 10 EPOCH 340 -- Train Loss: 0.33368  Validation Loss: 0.42963\n",
      "t: 10 EPOCH 341 -- Train Loss: 0.33250  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 342 -- Train Loss: 0.33389  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 343 -- Train Loss: 0.33204  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 344 -- Train Loss: 0.33354  Validation Loss: 0.42811\n",
      "t: 10 EPOCH 345 -- Train Loss: 0.33222  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 346 -- Train Loss: 0.33286  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 347 -- Train Loss: 0.33290  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 348 -- Train Loss: 0.33222  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 349 -- Train Loss: 0.33314  Validation Loss: 0.42947\n",
      "t: 10 EPOCH 350 -- Train Loss: 0.33274  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 351 -- Train Loss: 0.33319  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 352 -- Train Loss: 0.33286  Validation Loss: 0.42924\n",
      "t: 10 EPOCH 353 -- Train Loss: 0.33307  Validation Loss: 0.42930\n",
      "t: 10 EPOCH 354 -- Train Loss: 0.33328  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 355 -- Train Loss: 0.33261  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 356 -- Train Loss: 0.33296  Validation Loss: 0.42878\n",
      "t: 10 EPOCH 357 -- Train Loss: 0.33232  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 358 -- Train Loss: 0.33244  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 359 -- Train Loss: 0.33149  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 360 -- Train Loss: 0.33304  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 361 -- Train Loss: 0.33241  Validation Loss: 0.42930\n",
      "t: 10 EPOCH 362 -- Train Loss: 0.33328  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 363 -- Train Loss: 0.33266  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 364 -- Train Loss: 0.33296  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 365 -- Train Loss: 0.33189  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 366 -- Train Loss: 0.33313  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 367 -- Train Loss: 0.33298  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 368 -- Train Loss: 0.33308  Validation Loss: 0.42894\n",
      "t: 10 EPOCH 369 -- Train Loss: 0.33174  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 370 -- Train Loss: 0.33280  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 371 -- Train Loss: 0.33264  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 372 -- Train Loss: 0.33325  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 373 -- Train Loss: 0.33275  Validation Loss: 0.42894\n",
      "t: 10 EPOCH 374 -- Train Loss: 0.33351  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 375 -- Train Loss: 0.33258  Validation Loss: 0.42854\n",
      "t: 10 EPOCH 376 -- Train Loss: 0.33324  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 377 -- Train Loss: 0.33181  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 378 -- Train Loss: 0.33397  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 379 -- Train Loss: 0.33316  Validation Loss: 0.42942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 380 -- Train Loss: 0.33317  Validation Loss: 0.42894\n",
      "t: 10 EPOCH 381 -- Train Loss: 0.33265  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 382 -- Train Loss: 0.33367  Validation Loss: 0.42850\n",
      "t: 10 EPOCH 383 -- Train Loss: 0.33259  Validation Loss: 0.42938\n",
      "t: 10 EPOCH 384 -- Train Loss: 0.33382  Validation Loss: 0.42939\n",
      "t: 10 EPOCH 385 -- Train Loss: 0.33305  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 386 -- Train Loss: 0.33381  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 387 -- Train Loss: 0.33268  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 388 -- Train Loss: 0.33360  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 389 -- Train Loss: 0.33227  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 390 -- Train Loss: 0.33393  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 391 -- Train Loss: 0.33216  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 392 -- Train Loss: 0.33274  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 393 -- Train Loss: 0.33301  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 394 -- Train Loss: 0.33285  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 395 -- Train Loss: 0.33302  Validation Loss: 0.42841\n",
      "t: 10 EPOCH 396 -- Train Loss: 0.33319  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 397 -- Train Loss: 0.33310  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 398 -- Train Loss: 0.33233  Validation Loss: 0.42866\n",
      "t: 10 EPOCH 399 -- Train Loss: 0.33291  Validation Loss: 0.42935\n",
      "t: 10 EPOCH 400 -- Train Loss: 0.33324  Validation Loss: 0.42864\n",
      "t: 10 EPOCH 401 -- Train Loss: 0.33363  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 402 -- Train Loss: 0.33397  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 403 -- Train Loss: 0.33240  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 404 -- Train Loss: 0.33245  Validation Loss: 0.42919\n",
      "t: 10 EPOCH 405 -- Train Loss: 0.33248  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 406 -- Train Loss: 0.33325  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 407 -- Train Loss: 0.33300  Validation Loss: 0.42864\n",
      "t: 10 EPOCH 408 -- Train Loss: 0.33319  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 409 -- Train Loss: 0.33258  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 410 -- Train Loss: 0.33200  Validation Loss: 0.42975\n",
      "t: 10 EPOCH 411 -- Train Loss: 0.33371  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 412 -- Train Loss: 0.33254  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 413 -- Train Loss: 0.33313  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 414 -- Train Loss: 0.33279  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 415 -- Train Loss: 0.33274  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 416 -- Train Loss: 0.33196  Validation Loss: 0.42902\n",
      "t: 10 EPOCH 417 -- Train Loss: 0.33312  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 418 -- Train Loss: 0.33268  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 419 -- Train Loss: 0.33299  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 420 -- Train Loss: 0.33304  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 421 -- Train Loss: 0.33369  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 422 -- Train Loss: 0.33262  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 423 -- Train Loss: 0.33291  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 424 -- Train Loss: 0.33257  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 425 -- Train Loss: 0.33298  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 426 -- Train Loss: 0.33290  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 427 -- Train Loss: 0.33317  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 428 -- Train Loss: 0.33294  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 429 -- Train Loss: 0.33336  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 430 -- Train Loss: 0.33322  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 431 -- Train Loss: 0.33330  Validation Loss: 0.42909\n",
      "t: 10 EPOCH 432 -- Train Loss: 0.33313  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 433 -- Train Loss: 0.33327  Validation Loss: 0.42912\n",
      "t: 10 EPOCH 434 -- Train Loss: 0.33293  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 435 -- Train Loss: 0.33263  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 436 -- Train Loss: 0.33320  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 437 -- Train Loss: 0.33267  Validation Loss: 0.42881\n",
      "t: 10 EPOCH 438 -- Train Loss: 0.33287  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 439 -- Train Loss: 0.33297  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 440 -- Train Loss: 0.33259  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 441 -- Train Loss: 0.33264  Validation Loss: 0.42821\n",
      "t: 10 EPOCH 442 -- Train Loss: 0.33227  Validation Loss: 0.42929\n",
      "t: 10 EPOCH 443 -- Train Loss: 0.33291  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 444 -- Train Loss: 0.33291  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 445 -- Train Loss: 0.33282  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 446 -- Train Loss: 0.33372  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 447 -- Train Loss: 0.33286  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 448 -- Train Loss: 0.33309  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 449 -- Train Loss: 0.33302  Validation Loss: 0.42927\n",
      "t: 10 EPOCH 450 -- Train Loss: 0.33351  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 451 -- Train Loss: 0.33245  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 452 -- Train Loss: 0.33323  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 453 -- Train Loss: 0.33194  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 454 -- Train Loss: 0.33292  Validation Loss: 0.42892\n",
      "t: 10 EPOCH 455 -- Train Loss: 0.33301  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 456 -- Train Loss: 0.33244  Validation Loss: 0.42914\n",
      "t: 10 EPOCH 457 -- Train Loss: 0.33192  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 458 -- Train Loss: 0.33274  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 459 -- Train Loss: 0.33219  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 460 -- Train Loss: 0.33261  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 461 -- Train Loss: 0.33223  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 462 -- Train Loss: 0.33302  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 463 -- Train Loss: 0.33254  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 464 -- Train Loss: 0.33311  Validation Loss: 0.42895\n",
      "t: 10 EPOCH 465 -- Train Loss: 0.33190  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 466 -- Train Loss: 0.33198  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 467 -- Train Loss: 0.33218  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 468 -- Train Loss: 0.33181  Validation Loss: 0.42966\n",
      "t: 10 EPOCH 469 -- Train Loss: 0.33306  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 470 -- Train Loss: 0.33180  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 471 -- Train Loss: 0.33217  Validation Loss: 0.42892\n",
      "t: 10 EPOCH 472 -- Train Loss: 0.33269  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 473 -- Train Loss: 0.33257  Validation Loss: 0.42945\n",
      "t: 10 EPOCH 474 -- Train Loss: 0.33277  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 475 -- Train Loss: 0.33265  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 476 -- Train Loss: 0.33205  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 477 -- Train Loss: 0.33341  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 478 -- Train Loss: 0.33299  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 479 -- Train Loss: 0.33383  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 480 -- Train Loss: 0.33286  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 481 -- Train Loss: 0.33274  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 482 -- Train Loss: 0.33215  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 483 -- Train Loss: 0.33336  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 484 -- Train Loss: 0.33244  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 485 -- Train Loss: 0.33320  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 486 -- Train Loss: 0.33276  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 487 -- Train Loss: 0.33262  Validation Loss: 0.42890\n",
      "t: 10 EPOCH 488 -- Train Loss: 0.33248  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 489 -- Train Loss: 0.33327  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 490 -- Train Loss: 0.33256  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 491 -- Train Loss: 0.33258  Validation Loss: 0.42914\n",
      "t: 10 EPOCH 492 -- Train Loss: 0.33244  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 493 -- Train Loss: 0.33273  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 494 -- Train Loss: 0.33246  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 495 -- Train Loss: 0.33330  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 496 -- Train Loss: 0.33372  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 497 -- Train Loss: 0.33235  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 498 -- Train Loss: 0.33196  Validation Loss: 0.42936\n",
      "t: 10 EPOCH 499 -- Train Loss: 0.33286  Validation Loss: 0.42942\n",
      "t: 10 EPOCH 500 -- Train Loss: 0.33321  Validation Loss: 0.42974\n",
      "t: 10 EPOCH 501 -- Train Loss: 0.33172  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 502 -- Train Loss: 0.33358  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 503 -- Train Loss: 0.33326  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 504 -- Train Loss: 0.33309  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 505 -- Train Loss: 0.33315  Validation Loss: 0.43051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 506 -- Train Loss: 0.33310  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 507 -- Train Loss: 0.33223  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 508 -- Train Loss: 0.33278  Validation Loss: 0.42894\n",
      "t: 10 EPOCH 509 -- Train Loss: 0.33175  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 510 -- Train Loss: 0.33282  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 511 -- Train Loss: 0.33260  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 512 -- Train Loss: 0.33353  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 513 -- Train Loss: 0.33213  Validation Loss: 0.43001\n",
      "t: 10 EPOCH 514 -- Train Loss: 0.33344  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 515 -- Train Loss: 0.33278  Validation Loss: 0.42887\n",
      "t: 10 EPOCH 516 -- Train Loss: 0.33329  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 517 -- Train Loss: 0.33294  Validation Loss: 0.42962\n",
      "t: 10 EPOCH 518 -- Train Loss: 0.33322  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 519 -- Train Loss: 0.33245  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 520 -- Train Loss: 0.33254  Validation Loss: 0.42898\n",
      "t: 10 EPOCH 521 -- Train Loss: 0.33371  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 522 -- Train Loss: 0.33356  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 523 -- Train Loss: 0.33264  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 524 -- Train Loss: 0.33333  Validation Loss: 0.42944\n",
      "t: 10 EPOCH 525 -- Train Loss: 0.33259  Validation Loss: 0.42837\n",
      "t: 10 EPOCH 526 -- Train Loss: 0.33253  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 527 -- Train Loss: 0.33328  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 528 -- Train Loss: 0.33335  Validation Loss: 0.42931\n",
      "t: 10 EPOCH 529 -- Train Loss: 0.33303  Validation Loss: 0.42934\n",
      "t: 10 EPOCH 530 -- Train Loss: 0.33238  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 531 -- Train Loss: 0.33294  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 532 -- Train Loss: 0.33278  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 533 -- Train Loss: 0.33253  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 534 -- Train Loss: 0.33259  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 535 -- Train Loss: 0.33283  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 536 -- Train Loss: 0.33279  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 537 -- Train Loss: 0.33373  Validation Loss: 0.42903\n",
      "t: 10 EPOCH 538 -- Train Loss: 0.33301  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 539 -- Train Loss: 0.33201  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 540 -- Train Loss: 0.33280  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 541 -- Train Loss: 0.33286  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 542 -- Train Loss: 0.33322  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 543 -- Train Loss: 0.33255  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 544 -- Train Loss: 0.33245  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 545 -- Train Loss: 0.33191  Validation Loss: 0.42878\n",
      "t: 10 EPOCH 546 -- Train Loss: 0.33375  Validation Loss: 0.42892\n",
      "t: 10 EPOCH 547 -- Train Loss: 0.33225  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 548 -- Train Loss: 0.33352  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 549 -- Train Loss: 0.33319  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 550 -- Train Loss: 0.33353  Validation Loss: 0.42867\n",
      "t: 10 EPOCH 551 -- Train Loss: 0.33289  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 552 -- Train Loss: 0.33352  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 553 -- Train Loss: 0.33262  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 554 -- Train Loss: 0.33236  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 555 -- Train Loss: 0.33226  Validation Loss: 0.42926\n",
      "t: 10 EPOCH 556 -- Train Loss: 0.33312  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 557 -- Train Loss: 0.33278  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 558 -- Train Loss: 0.33291  Validation Loss: 0.42871\n",
      "t: 10 EPOCH 559 -- Train Loss: 0.33272  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 560 -- Train Loss: 0.33170  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 561 -- Train Loss: 0.33258  Validation Loss: 0.42973\n",
      "t: 10 EPOCH 562 -- Train Loss: 0.33258  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 563 -- Train Loss: 0.33216  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 564 -- Train Loss: 0.33262  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 565 -- Train Loss: 0.33295  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 566 -- Train Loss: 0.33261  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 567 -- Train Loss: 0.33291  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 568 -- Train Loss: 0.33203  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 569 -- Train Loss: 0.33245  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 570 -- Train Loss: 0.33258  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 571 -- Train Loss: 0.33312  Validation Loss: 0.42876\n",
      "t: 10 EPOCH 572 -- Train Loss: 0.33286  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 573 -- Train Loss: 0.33232  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 574 -- Train Loss: 0.33196  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 575 -- Train Loss: 0.33298  Validation Loss: 0.42901\n",
      "t: 10 EPOCH 576 -- Train Loss: 0.33302  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 577 -- Train Loss: 0.33252  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 578 -- Train Loss: 0.33292  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 579 -- Train Loss: 0.33274  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 580 -- Train Loss: 0.33342  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 581 -- Train Loss: 0.33303  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 582 -- Train Loss: 0.33268  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 583 -- Train Loss: 0.33341  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 584 -- Train Loss: 0.33260  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 585 -- Train Loss: 0.33275  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 586 -- Train Loss: 0.33339  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 587 -- Train Loss: 0.33288  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 588 -- Train Loss: 0.33245  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 589 -- Train Loss: 0.33218  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 590 -- Train Loss: 0.33222  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 591 -- Train Loss: 0.33294  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 592 -- Train Loss: 0.33200  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 593 -- Train Loss: 0.33246  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 594 -- Train Loss: 0.33225  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 595 -- Train Loss: 0.33298  Validation Loss: 0.42891\n",
      "t: 10 EPOCH 596 -- Train Loss: 0.33249  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 597 -- Train Loss: 0.33340  Validation Loss: 0.42973\n",
      "t: 10 EPOCH 598 -- Train Loss: 0.33287  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 599 -- Train Loss: 0.33330  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 600 -- Train Loss: 0.33313  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 601 -- Train Loss: 0.33276  Validation Loss: 0.42898\n",
      "t: 10 EPOCH 602 -- Train Loss: 0.33338  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 603 -- Train Loss: 0.33359  Validation Loss: 0.42897\n",
      "t: 10 EPOCH 604 -- Train Loss: 0.33349  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 605 -- Train Loss: 0.33285  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 606 -- Train Loss: 0.33324  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 607 -- Train Loss: 0.33305  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 608 -- Train Loss: 0.33239  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 609 -- Train Loss: 0.33368  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 610 -- Train Loss: 0.33250  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 611 -- Train Loss: 0.33291  Validation Loss: 0.42937\n",
      "t: 10 EPOCH 612 -- Train Loss: 0.33212  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 613 -- Train Loss: 0.33231  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 614 -- Train Loss: 0.33337  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 615 -- Train Loss: 0.33241  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 616 -- Train Loss: 0.33223  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 617 -- Train Loss: 0.33220  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 618 -- Train Loss: 0.33249  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 619 -- Train Loss: 0.33262  Validation Loss: 0.42853\n",
      "t: 10 EPOCH 620 -- Train Loss: 0.33303  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 621 -- Train Loss: 0.33265  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 622 -- Train Loss: 0.33255  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 623 -- Train Loss: 0.33230  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 624 -- Train Loss: 0.33203  Validation Loss: 0.42875\n",
      "t: 10 EPOCH 625 -- Train Loss: 0.33276  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 626 -- Train Loss: 0.33308  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 627 -- Train Loss: 0.33263  Validation Loss: 0.42951\n",
      "t: 10 EPOCH 628 -- Train Loss: 0.33300  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 629 -- Train Loss: 0.33350  Validation Loss: 0.42896\n",
      "t: 10 EPOCH 630 -- Train Loss: 0.33229  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 631 -- Train Loss: 0.33268  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 632 -- Train Loss: 0.33272  Validation Loss: 0.43034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 633 -- Train Loss: 0.33276  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 634 -- Train Loss: 0.33164  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 635 -- Train Loss: 0.33346  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 636 -- Train Loss: 0.33302  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 637 -- Train Loss: 0.33231  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 638 -- Train Loss: 0.33261  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 639 -- Train Loss: 0.33283  Validation Loss: 0.42916\n",
      "t: 10 EPOCH 640 -- Train Loss: 0.33209  Validation Loss: 0.42966\n",
      "t: 10 EPOCH 641 -- Train Loss: 0.33324  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 642 -- Train Loss: 0.33336  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 643 -- Train Loss: 0.33307  Validation Loss: 0.42865\n",
      "t: 10 EPOCH 644 -- Train Loss: 0.33226  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 645 -- Train Loss: 0.33219  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 646 -- Train Loss: 0.33309  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 647 -- Train Loss: 0.33286  Validation Loss: 0.42962\n",
      "t: 10 EPOCH 648 -- Train Loss: 0.33266  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 649 -- Train Loss: 0.33299  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 650 -- Train Loss: 0.33246  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 651 -- Train Loss: 0.33333  Validation Loss: 0.42850\n",
      "t: 10 EPOCH 652 -- Train Loss: 0.33178  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 653 -- Train Loss: 0.33279  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 654 -- Train Loss: 0.33281  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 655 -- Train Loss: 0.33245  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 656 -- Train Loss: 0.33220  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 657 -- Train Loss: 0.33264  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 658 -- Train Loss: 0.33247  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 659 -- Train Loss: 0.33291  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 660 -- Train Loss: 0.33369  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 661 -- Train Loss: 0.33266  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 662 -- Train Loss: 0.33281  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 663 -- Train Loss: 0.33342  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 664 -- Train Loss: 0.33294  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 665 -- Train Loss: 0.33403  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 666 -- Train Loss: 0.33288  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 667 -- Train Loss: 0.33200  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 668 -- Train Loss: 0.33294  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 669 -- Train Loss: 0.33349  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 670 -- Train Loss: 0.33243  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 671 -- Train Loss: 0.33362  Validation Loss: 0.42898\n",
      "t: 10 EPOCH 672 -- Train Loss: 0.33275  Validation Loss: 0.42887\n",
      "t: 10 EPOCH 673 -- Train Loss: 0.33330  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 674 -- Train Loss: 0.33263  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 675 -- Train Loss: 0.33271  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 676 -- Train Loss: 0.33264  Validation Loss: 0.42931\n",
      "t: 10 EPOCH 677 -- Train Loss: 0.33409  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 678 -- Train Loss: 0.33260  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 679 -- Train Loss: 0.33337  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 680 -- Train Loss: 0.33208  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 681 -- Train Loss: 0.33300  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 682 -- Train Loss: 0.33232  Validation Loss: 0.42939\n",
      "t: 10 EPOCH 683 -- Train Loss: 0.33331  Validation Loss: 0.42927\n",
      "t: 10 EPOCH 684 -- Train Loss: 0.33213  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 685 -- Train Loss: 0.33230  Validation Loss: 0.42963\n",
      "t: 10 EPOCH 686 -- Train Loss: 0.33239  Validation Loss: 0.42870\n",
      "t: 10 EPOCH 687 -- Train Loss: 0.33294  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 688 -- Train Loss: 0.33290  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 689 -- Train Loss: 0.33330  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 690 -- Train Loss: 0.33321  Validation Loss: 0.42895\n",
      "t: 10 EPOCH 691 -- Train Loss: 0.33348  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 692 -- Train Loss: 0.33294  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 693 -- Train Loss: 0.33286  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 694 -- Train Loss: 0.33396  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 695 -- Train Loss: 0.33247  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 696 -- Train Loss: 0.33276  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 697 -- Train Loss: 0.33229  Validation Loss: 0.42891\n",
      "t: 10 EPOCH 698 -- Train Loss: 0.33331  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 699 -- Train Loss: 0.33216  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 700 -- Train Loss: 0.33336  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 701 -- Train Loss: 0.33242  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 702 -- Train Loss: 0.33275  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 703 -- Train Loss: 0.33289  Validation Loss: 0.42902\n",
      "t: 10 EPOCH 704 -- Train Loss: 0.33257  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 705 -- Train Loss: 0.33212  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 706 -- Train Loss: 0.33296  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 707 -- Train Loss: 0.33313  Validation Loss: 0.42864\n",
      "t: 10 EPOCH 708 -- Train Loss: 0.33230  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 709 -- Train Loss: 0.33270  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 710 -- Train Loss: 0.33341  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 711 -- Train Loss: 0.33257  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 712 -- Train Loss: 0.33335  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 713 -- Train Loss: 0.33162  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 714 -- Train Loss: 0.33188  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 715 -- Train Loss: 0.33254  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 716 -- Train Loss: 0.33331  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 717 -- Train Loss: 0.33174  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 718 -- Train Loss: 0.33291  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 719 -- Train Loss: 0.33212  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 720 -- Train Loss: 0.33248  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 721 -- Train Loss: 0.33323  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 722 -- Train Loss: 0.33360  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 723 -- Train Loss: 0.33288  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 724 -- Train Loss: 0.33292  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 725 -- Train Loss: 0.33227  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 726 -- Train Loss: 0.33266  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 727 -- Train Loss: 0.33159  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 728 -- Train Loss: 0.33200  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 729 -- Train Loss: 0.33255  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 730 -- Train Loss: 0.33212  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 731 -- Train Loss: 0.33211  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 732 -- Train Loss: 0.33257  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 733 -- Train Loss: 0.33291  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 734 -- Train Loss: 0.33290  Validation Loss: 0.42826\n",
      "t: 10 EPOCH 735 -- Train Loss: 0.33277  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 736 -- Train Loss: 0.33201  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 737 -- Train Loss: 0.33260  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 738 -- Train Loss: 0.33239  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 739 -- Train Loss: 0.33280  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 740 -- Train Loss: 0.33289  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 741 -- Train Loss: 0.33283  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 742 -- Train Loss: 0.33193  Validation Loss: 0.42874\n",
      "t: 10 EPOCH 743 -- Train Loss: 0.33341  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 744 -- Train Loss: 0.33250  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 745 -- Train Loss: 0.33175  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 746 -- Train Loss: 0.33239  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 747 -- Train Loss: 0.33359  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 748 -- Train Loss: 0.33304  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 749 -- Train Loss: 0.33308  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 750 -- Train Loss: 0.33291  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 751 -- Train Loss: 0.33349  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 752 -- Train Loss: 0.33209  Validation Loss: 0.42888\n",
      "t: 10 EPOCH 753 -- Train Loss: 0.33201  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 754 -- Train Loss: 0.33269  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 755 -- Train Loss: 0.33274  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 756 -- Train Loss: 0.33328  Validation Loss: 0.42963\n",
      "t: 10 EPOCH 757 -- Train Loss: 0.33092  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 758 -- Train Loss: 0.33295  Validation Loss: 0.42942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 759 -- Train Loss: 0.33312  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 760 -- Train Loss: 0.33220  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 761 -- Train Loss: 0.33308  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 762 -- Train Loss: 0.33150  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 763 -- Train Loss: 0.33287  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 764 -- Train Loss: 0.33236  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 765 -- Train Loss: 0.33245  Validation Loss: 0.42925\n",
      "t: 10 EPOCH 766 -- Train Loss: 0.33262  Validation Loss: 0.42960\n",
      "t: 10 EPOCH 767 -- Train Loss: 0.33117  Validation Loss: 0.42975\n",
      "t: 10 EPOCH 768 -- Train Loss: 0.33231  Validation Loss: 0.42918\n",
      "t: 10 EPOCH 769 -- Train Loss: 0.33246  Validation Loss: 0.42942\n",
      "t: 10 EPOCH 770 -- Train Loss: 0.33205  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 771 -- Train Loss: 0.33241  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 772 -- Train Loss: 0.33197  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 773 -- Train Loss: 0.33348  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 774 -- Train Loss: 0.33143  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 775 -- Train Loss: 0.33254  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 776 -- Train Loss: 0.33276  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 777 -- Train Loss: 0.33254  Validation Loss: 0.42904\n",
      "t: 10 EPOCH 778 -- Train Loss: 0.33207  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 779 -- Train Loss: 0.33298  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 780 -- Train Loss: 0.33218  Validation Loss: 0.42928\n",
      "t: 10 EPOCH 781 -- Train Loss: 0.33324  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 782 -- Train Loss: 0.33158  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 783 -- Train Loss: 0.33249  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 784 -- Train Loss: 0.33197  Validation Loss: 0.42910\n",
      "t: 10 EPOCH 785 -- Train Loss: 0.33228  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 786 -- Train Loss: 0.33248  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 787 -- Train Loss: 0.33218  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 788 -- Train Loss: 0.33277  Validation Loss: 0.42888\n",
      "t: 10 EPOCH 789 -- Train Loss: 0.33226  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 790 -- Train Loss: 0.33185  Validation Loss: 0.42944\n",
      "t: 10 EPOCH 791 -- Train Loss: 0.33228  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 792 -- Train Loss: 0.33288  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 793 -- Train Loss: 0.33203  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 794 -- Train Loss: 0.33286  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 795 -- Train Loss: 0.33219  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 796 -- Train Loss: 0.33321  Validation Loss: 0.42955\n",
      "t: 10 EPOCH 797 -- Train Loss: 0.33236  Validation Loss: 0.42951\n",
      "t: 10 EPOCH 798 -- Train Loss: 0.33197  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 799 -- Train Loss: 0.33195  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 800 -- Train Loss: 0.33288  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 801 -- Train Loss: 0.33178  Validation Loss: 0.43001\n",
      "t: 10 EPOCH 802 -- Train Loss: 0.33193  Validation Loss: 0.42904\n",
      "t: 10 EPOCH 803 -- Train Loss: 0.33277  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 804 -- Train Loss: 0.33250  Validation Loss: 0.42887\n",
      "t: 10 EPOCH 805 -- Train Loss: 0.33190  Validation Loss: 0.42880\n",
      "t: 10 EPOCH 806 -- Train Loss: 0.33314  Validation Loss: 0.42937\n",
      "t: 10 EPOCH 807 -- Train Loss: 0.33260  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 808 -- Train Loss: 0.33223  Validation Loss: 0.42925\n",
      "t: 10 EPOCH 809 -- Train Loss: 0.33247  Validation Loss: 0.42930\n",
      "t: 10 EPOCH 810 -- Train Loss: 0.33320  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 811 -- Train Loss: 0.33290  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 812 -- Train Loss: 0.33266  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 813 -- Train Loss: 0.33255  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 814 -- Train Loss: 0.33301  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 815 -- Train Loss: 0.33302  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 816 -- Train Loss: 0.33353  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 817 -- Train Loss: 0.33247  Validation Loss: 0.42954\n",
      "t: 10 EPOCH 818 -- Train Loss: 0.33304  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 819 -- Train Loss: 0.33273  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 820 -- Train Loss: 0.33335  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 821 -- Train Loss: 0.33182  Validation Loss: 0.42876\n",
      "t: 10 EPOCH 822 -- Train Loss: 0.33229  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 823 -- Train Loss: 0.33113  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 824 -- Train Loss: 0.33196  Validation Loss: 0.42840\n",
      "t: 10 EPOCH 825 -- Train Loss: 0.33299  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 826 -- Train Loss: 0.33270  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 827 -- Train Loss: 0.33280  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 828 -- Train Loss: 0.33247  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 829 -- Train Loss: 0.33306  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 830 -- Train Loss: 0.33220  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 831 -- Train Loss: 0.33280  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 832 -- Train Loss: 0.33218  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 833 -- Train Loss: 0.33325  Validation Loss: 0.42893\n",
      "t: 10 EPOCH 834 -- Train Loss: 0.33187  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 835 -- Train Loss: 0.33221  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 836 -- Train Loss: 0.33327  Validation Loss: 0.42948\n",
      "t: 10 EPOCH 837 -- Train Loss: 0.33266  Validation Loss: 0.42904\n",
      "t: 10 EPOCH 838 -- Train Loss: 0.33365  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 839 -- Train Loss: 0.33275  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 840 -- Train Loss: 0.33272  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 841 -- Train Loss: 0.33317  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 842 -- Train Loss: 0.33220  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 843 -- Train Loss: 0.33229  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 844 -- Train Loss: 0.33238  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 845 -- Train Loss: 0.33313  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 846 -- Train Loss: 0.33301  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 847 -- Train Loss: 0.33332  Validation Loss: 0.42915\n",
      "t: 10 EPOCH 848 -- Train Loss: 0.33257  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 849 -- Train Loss: 0.33247  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 850 -- Train Loss: 0.33290  Validation Loss: 0.42923\n",
      "t: 10 EPOCH 851 -- Train Loss: 0.33233  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 852 -- Train Loss: 0.33151  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 853 -- Train Loss: 0.33262  Validation Loss: 0.42963\n",
      "t: 10 EPOCH 854 -- Train Loss: 0.33312  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 855 -- Train Loss: 0.33334  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 856 -- Train Loss: 0.33225  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 857 -- Train Loss: 0.33375  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 858 -- Train Loss: 0.33270  Validation Loss: 0.42937\n",
      "t: 10 EPOCH 859 -- Train Loss: 0.33282  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 860 -- Train Loss: 0.33169  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 861 -- Train Loss: 0.33235  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 862 -- Train Loss: 0.33156  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 863 -- Train Loss: 0.33293  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 864 -- Train Loss: 0.33228  Validation Loss: 0.42934\n",
      "t: 10 EPOCH 865 -- Train Loss: 0.33338  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 866 -- Train Loss: 0.33222  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 867 -- Train Loss: 0.33212  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 868 -- Train Loss: 0.33264  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 869 -- Train Loss: 0.33252  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 870 -- Train Loss: 0.33357  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 871 -- Train Loss: 0.33165  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 872 -- Train Loss: 0.33253  Validation Loss: 0.42891\n",
      "t: 10 EPOCH 873 -- Train Loss: 0.33251  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 874 -- Train Loss: 0.33236  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 875 -- Train Loss: 0.33335  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 876 -- Train Loss: 0.33408  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 877 -- Train Loss: 0.33249  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 878 -- Train Loss: 0.33213  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 879 -- Train Loss: 0.33267  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 880 -- Train Loss: 0.33276  Validation Loss: 0.42903\n",
      "t: 10 EPOCH 881 -- Train Loss: 0.33230  Validation Loss: 0.42938\n",
      "t: 10 EPOCH 882 -- Train Loss: 0.33220  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 883 -- Train Loss: 0.33312  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 884 -- Train Loss: 0.33344  Validation Loss: 0.42953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 885 -- Train Loss: 0.33317  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 886 -- Train Loss: 0.33234  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 887 -- Train Loss: 0.33317  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 888 -- Train Loss: 0.33274  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 889 -- Train Loss: 0.33320  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 890 -- Train Loss: 0.33151  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 891 -- Train Loss: 0.33205  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 892 -- Train Loss: 0.33287  Validation Loss: 0.42933\n",
      "t: 10 EPOCH 893 -- Train Loss: 0.33326  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 894 -- Train Loss: 0.33273  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 895 -- Train Loss: 0.33234  Validation Loss: 0.42837\n",
      "t: 10 EPOCH 896 -- Train Loss: 0.33135  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 897 -- Train Loss: 0.33296  Validation Loss: 0.42882\n",
      "t: 10 EPOCH 898 -- Train Loss: 0.33214  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 899 -- Train Loss: 0.33363  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 900 -- Train Loss: 0.33200  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 901 -- Train Loss: 0.33319  Validation Loss: 0.42938\n",
      "t: 10 EPOCH 902 -- Train Loss: 0.33246  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 903 -- Train Loss: 0.33274  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 904 -- Train Loss: 0.33207  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 905 -- Train Loss: 0.33230  Validation Loss: 0.42954\n",
      "t: 10 EPOCH 906 -- Train Loss: 0.33150  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 907 -- Train Loss: 0.33316  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 908 -- Train Loss: 0.33110  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 909 -- Train Loss: 0.33266  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 910 -- Train Loss: 0.33169  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 911 -- Train Loss: 0.33376  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 912 -- Train Loss: 0.33170  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 913 -- Train Loss: 0.33238  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 914 -- Train Loss: 0.33221  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 915 -- Train Loss: 0.33319  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 916 -- Train Loss: 0.33128  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 917 -- Train Loss: 0.33357  Validation Loss: 0.42896\n",
      "t: 10 EPOCH 918 -- Train Loss: 0.33215  Validation Loss: 0.42918\n",
      "t: 10 EPOCH 919 -- Train Loss: 0.33259  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 920 -- Train Loss: 0.33254  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 921 -- Train Loss: 0.33417  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 922 -- Train Loss: 0.33152  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 923 -- Train Loss: 0.33394  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 924 -- Train Loss: 0.33180  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 925 -- Train Loss: 0.33301  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 926 -- Train Loss: 0.33249  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 927 -- Train Loss: 0.33295  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 928 -- Train Loss: 0.33252  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 929 -- Train Loss: 0.33342  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 930 -- Train Loss: 0.33277  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 931 -- Train Loss: 0.33239  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 932 -- Train Loss: 0.33255  Validation Loss: 0.42887\n",
      "t: 10 EPOCH 933 -- Train Loss: 0.33191  Validation Loss: 0.42853\n",
      "t: 10 EPOCH 934 -- Train Loss: 0.33282  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 935 -- Train Loss: 0.33252  Validation Loss: 0.42893\n",
      "t: 10 EPOCH 936 -- Train Loss: 0.33212  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 937 -- Train Loss: 0.33282  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 938 -- Train Loss: 0.33209  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 939 -- Train Loss: 0.33302  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 940 -- Train Loss: 0.33393  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 941 -- Train Loss: 0.33270  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 942 -- Train Loss: 0.33277  Validation Loss: 0.42925\n",
      "t: 10 EPOCH 943 -- Train Loss: 0.33281  Validation Loss: 0.42880\n",
      "t: 10 EPOCH 944 -- Train Loss: 0.33310  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 945 -- Train Loss: 0.33311  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 946 -- Train Loss: 0.33221  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 947 -- Train Loss: 0.33234  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 948 -- Train Loss: 0.33256  Validation Loss: 0.42901\n",
      "t: 10 EPOCH 949 -- Train Loss: 0.33264  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 950 -- Train Loss: 0.33339  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 951 -- Train Loss: 0.33292  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 952 -- Train Loss: 0.33303  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 953 -- Train Loss: 0.33233  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 954 -- Train Loss: 0.33236  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 955 -- Train Loss: 0.33302  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 956 -- Train Loss: 0.33296  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 957 -- Train Loss: 0.33298  Validation Loss: 0.42894\n",
      "t: 10 EPOCH 958 -- Train Loss: 0.33220  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 959 -- Train Loss: 0.33233  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 960 -- Train Loss: 0.33175  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 961 -- Train Loss: 0.33328  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 962 -- Train Loss: 0.33233  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 963 -- Train Loss: 0.33212  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 964 -- Train Loss: 0.33162  Validation Loss: 0.42816\n",
      "t: 10 EPOCH 965 -- Train Loss: 0.33242  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 966 -- Train Loss: 0.33297  Validation Loss: 0.42906\n",
      "t: 10 EPOCH 967 -- Train Loss: 0.33223  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 968 -- Train Loss: 0.33308  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 969 -- Train Loss: 0.33255  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 970 -- Train Loss: 0.33246  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 971 -- Train Loss: 0.33234  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 972 -- Train Loss: 0.33300  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 973 -- Train Loss: 0.33256  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 974 -- Train Loss: 0.33267  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 975 -- Train Loss: 0.33198  Validation Loss: 0.42960\n",
      "t: 10 EPOCH 976 -- Train Loss: 0.33294  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 977 -- Train Loss: 0.33154  Validation Loss: 0.42955\n",
      "t: 10 EPOCH 978 -- Train Loss: 0.33317  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 979 -- Train Loss: 0.33232  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 980 -- Train Loss: 0.33147  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 981 -- Train Loss: 0.33268  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 982 -- Train Loss: 0.33357  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 983 -- Train Loss: 0.33193  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 984 -- Train Loss: 0.33277  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 985 -- Train Loss: 0.33221  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 986 -- Train Loss: 0.33336  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 987 -- Train Loss: 0.33264  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 988 -- Train Loss: 0.33229  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 989 -- Train Loss: 0.33281  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 990 -- Train Loss: 0.33288  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 991 -- Train Loss: 0.33334  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 992 -- Train Loss: 0.33230  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 993 -- Train Loss: 0.33249  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 994 -- Train Loss: 0.33106  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 995 -- Train Loss: 0.33319  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 996 -- Train Loss: 0.33145  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 997 -- Train Loss: 0.33224  Validation Loss: 0.42885\n",
      "t: 10 EPOCH 998 -- Train Loss: 0.33109  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 999 -- Train Loss: 0.33255  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 1000 -- Train Loss: 0.33255  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 1001 -- Train Loss: 0.33280  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 1002 -- Train Loss: 0.33197  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 1003 -- Train Loss: 0.33268  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 1004 -- Train Loss: 0.33179  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 1005 -- Train Loss: 0.33206  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 1006 -- Train Loss: 0.33189  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 1007 -- Train Loss: 0.33198  Validation Loss: 0.42862\n",
      "t: 10 EPOCH 1008 -- Train Loss: 0.33187  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 1009 -- Train Loss: 0.33287  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 1010 -- Train Loss: 0.33200  Validation Loss: 0.42952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1011 -- Train Loss: 0.33230  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 1012 -- Train Loss: 0.33218  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 1013 -- Train Loss: 0.33281  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 1014 -- Train Loss: 0.33183  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 1015 -- Train Loss: 0.33224  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 1016 -- Train Loss: 0.33203  Validation Loss: 0.42940\n",
      "t: 10 EPOCH 1017 -- Train Loss: 0.33243  Validation Loss: 0.42923\n",
      "t: 10 EPOCH 1018 -- Train Loss: 0.33247  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 1019 -- Train Loss: 0.33221  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 1020 -- Train Loss: 0.33212  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 1021 -- Train Loss: 0.33246  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 1022 -- Train Loss: 0.33229  Validation Loss: 0.42966\n",
      "t: 10 EPOCH 1023 -- Train Loss: 0.33201  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 1024 -- Train Loss: 0.33205  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 1025 -- Train Loss: 0.33341  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 1026 -- Train Loss: 0.33255  Validation Loss: 0.42888\n",
      "t: 10 EPOCH 1027 -- Train Loss: 0.33277  Validation Loss: 0.42939\n",
      "t: 10 EPOCH 1028 -- Train Loss: 0.33282  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 1029 -- Train Loss: 0.33178  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 1030 -- Train Loss: 0.33250  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 1031 -- Train Loss: 0.33245  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 1032 -- Train Loss: 0.33232  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 1033 -- Train Loss: 0.33235  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 1034 -- Train Loss: 0.33215  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1035 -- Train Loss: 0.33234  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 1036 -- Train Loss: 0.33222  Validation Loss: 0.42892\n",
      "t: 10 EPOCH 1037 -- Train Loss: 0.33233  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 1038 -- Train Loss: 0.33266  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 1039 -- Train Loss: 0.33274  Validation Loss: 0.42945\n",
      "t: 10 EPOCH 1040 -- Train Loss: 0.33232  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 1041 -- Train Loss: 0.33224  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 1042 -- Train Loss: 0.33148  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 1043 -- Train Loss: 0.33187  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1044 -- Train Loss: 0.33232  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 1045 -- Train Loss: 0.33335  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 1046 -- Train Loss: 0.33209  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 1047 -- Train Loss: 0.33279  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 1048 -- Train Loss: 0.33269  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 1049 -- Train Loss: 0.33202  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 1050 -- Train Loss: 0.33270  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 1051 -- Train Loss: 0.33226  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 1052 -- Train Loss: 0.33235  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 1053 -- Train Loss: 0.33228  Validation Loss: 0.42947\n",
      "t: 10 EPOCH 1054 -- Train Loss: 0.33232  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 1055 -- Train Loss: 0.33281  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 1056 -- Train Loss: 0.33260  Validation Loss: 0.42911\n",
      "t: 10 EPOCH 1057 -- Train Loss: 0.33301  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 1058 -- Train Loss: 0.33189  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 1059 -- Train Loss: 0.33273  Validation Loss: 0.42921\n",
      "t: 10 EPOCH 1060 -- Train Loss: 0.33237  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 1061 -- Train Loss: 0.33233  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 1062 -- Train Loss: 0.33232  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 1063 -- Train Loss: 0.33184  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 1064 -- Train Loss: 0.33240  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 1065 -- Train Loss: 0.33221  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 1066 -- Train Loss: 0.33322  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 1067 -- Train Loss: 0.33287  Validation Loss: 0.42916\n",
      "t: 10 EPOCH 1068 -- Train Loss: 0.33202  Validation Loss: 0.42917\n",
      "t: 10 EPOCH 1069 -- Train Loss: 0.33373  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 1070 -- Train Loss: 0.33214  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 1071 -- Train Loss: 0.33287  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 1072 -- Train Loss: 0.33175  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 1073 -- Train Loss: 0.33305  Validation Loss: 0.42960\n",
      "t: 10 EPOCH 1074 -- Train Loss: 0.33186  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 1075 -- Train Loss: 0.33277  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 1076 -- Train Loss: 0.33229  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1077 -- Train Loss: 0.33283  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 1078 -- Train Loss: 0.33269  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 1079 -- Train Loss: 0.33221  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 1080 -- Train Loss: 0.33269  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 1081 -- Train Loss: 0.33245  Validation Loss: 0.42933\n",
      "t: 10 EPOCH 1082 -- Train Loss: 0.33250  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 1083 -- Train Loss: 0.33193  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1084 -- Train Loss: 0.33205  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 1085 -- Train Loss: 0.33221  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 1086 -- Train Loss: 0.33290  Validation Loss: 0.42951\n",
      "t: 10 EPOCH 1087 -- Train Loss: 0.33270  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 1088 -- Train Loss: 0.33218  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 1089 -- Train Loss: 0.33277  Validation Loss: 0.42925\n",
      "t: 10 EPOCH 1090 -- Train Loss: 0.33236  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 1091 -- Train Loss: 0.33330  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 1092 -- Train Loss: 0.33215  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 1093 -- Train Loss: 0.33285  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 1094 -- Train Loss: 0.33255  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 1095 -- Train Loss: 0.33262  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 1096 -- Train Loss: 0.33191  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 1097 -- Train Loss: 0.33300  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 1098 -- Train Loss: 0.33257  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 1099 -- Train Loss: 0.33208  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 1100 -- Train Loss: 0.33184  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 1101 -- Train Loss: 0.33386  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 1102 -- Train Loss: 0.33278  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 1103 -- Train Loss: 0.33335  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1104 -- Train Loss: 0.33228  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 1105 -- Train Loss: 0.33267  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 1106 -- Train Loss: 0.33239  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 1107 -- Train Loss: 0.33274  Validation Loss: 0.42955\n",
      "t: 10 EPOCH 1108 -- Train Loss: 0.33251  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 1109 -- Train Loss: 0.33197  Validation Loss: 0.43001\n",
      "t: 10 EPOCH 1110 -- Train Loss: 0.33247  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1111 -- Train Loss: 0.33238  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 1112 -- Train Loss: 0.33187  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 1113 -- Train Loss: 0.33264  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 1114 -- Train Loss: 0.33243  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 1115 -- Train Loss: 0.33202  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 1116 -- Train Loss: 0.33145  Validation Loss: 0.42842\n",
      "t: 10 EPOCH 1117 -- Train Loss: 0.33280  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 1118 -- Train Loss: 0.33104  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 1119 -- Train Loss: 0.33224  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 1120 -- Train Loss: 0.33233  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 1121 -- Train Loss: 0.33353  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 1122 -- Train Loss: 0.33199  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 1123 -- Train Loss: 0.33311  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 1124 -- Train Loss: 0.33147  Validation Loss: 0.42855\n",
      "t: 10 EPOCH 1125 -- Train Loss: 0.33314  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1126 -- Train Loss: 0.33258  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 1127 -- Train Loss: 0.33238  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 1128 -- Train Loss: 0.33166  Validation Loss: 0.42942\n",
      "t: 10 EPOCH 1129 -- Train Loss: 0.33323  Validation Loss: 0.42998\n",
      "t: 10 EPOCH 1130 -- Train Loss: 0.33299  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1131 -- Train Loss: 0.33323  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1132 -- Train Loss: 0.33190  Validation Loss: 0.42888\n",
      "t: 10 EPOCH 1133 -- Train Loss: 0.33274  Validation Loss: 0.42929\n",
      "t: 10 EPOCH 1134 -- Train Loss: 0.33263  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 1135 -- Train Loss: 0.33282  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 1136 -- Train Loss: 0.33274  Validation Loss: 0.42998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1137 -- Train Loss: 0.33221  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 1138 -- Train Loss: 0.33195  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 1139 -- Train Loss: 0.33293  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 1140 -- Train Loss: 0.33289  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 1141 -- Train Loss: 0.33230  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1142 -- Train Loss: 0.33175  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 1143 -- Train Loss: 0.33318  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 1144 -- Train Loss: 0.33175  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 1145 -- Train Loss: 0.33279  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 1146 -- Train Loss: 0.33204  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 1147 -- Train Loss: 0.33286  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 1148 -- Train Loss: 0.33256  Validation Loss: 0.42898\n",
      "t: 10 EPOCH 1149 -- Train Loss: 0.33310  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 1150 -- Train Loss: 0.33127  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 1151 -- Train Loss: 0.33283  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 1152 -- Train Loss: 0.33270  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 1153 -- Train Loss: 0.33268  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 1154 -- Train Loss: 0.33311  Validation Loss: 0.42935\n",
      "t: 10 EPOCH 1155 -- Train Loss: 0.33244  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 1156 -- Train Loss: 0.33249  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 1157 -- Train Loss: 0.33286  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 1158 -- Train Loss: 0.33303  Validation Loss: 0.42954\n",
      "t: 10 EPOCH 1159 -- Train Loss: 0.33248  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 1160 -- Train Loss: 0.33266  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 1161 -- Train Loss: 0.33187  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 1162 -- Train Loss: 0.33424  Validation Loss: 0.42945\n",
      "t: 10 EPOCH 1163 -- Train Loss: 0.33225  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 1164 -- Train Loss: 0.33324  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 1165 -- Train Loss: 0.33218  Validation Loss: 0.42914\n",
      "t: 10 EPOCH 1166 -- Train Loss: 0.33367  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 1167 -- Train Loss: 0.33255  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 1168 -- Train Loss: 0.33294  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1169 -- Train Loss: 0.33261  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 1170 -- Train Loss: 0.33229  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 1171 -- Train Loss: 0.33268  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 1172 -- Train Loss: 0.33308  Validation Loss: 0.42883\n",
      "t: 10 EPOCH 1173 -- Train Loss: 0.33186  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 1174 -- Train Loss: 0.33223  Validation Loss: 0.42877\n",
      "t: 10 EPOCH 1175 -- Train Loss: 0.33314  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 1176 -- Train Loss: 0.33159  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 1177 -- Train Loss: 0.33249  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 1178 -- Train Loss: 0.33248  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 1179 -- Train Loss: 0.33243  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 1180 -- Train Loss: 0.33234  Validation Loss: 0.42962\n",
      "t: 10 EPOCH 1181 -- Train Loss: 0.33258  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 1182 -- Train Loss: 0.33189  Validation Loss: 0.42821\n",
      "t: 10 EPOCH 1183 -- Train Loss: 0.33314  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 1184 -- Train Loss: 0.33141  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1185 -- Train Loss: 0.33283  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 1186 -- Train Loss: 0.33189  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 1187 -- Train Loss: 0.33241  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 1188 -- Train Loss: 0.33313  Validation Loss: 0.42920\n",
      "t: 10 EPOCH 1189 -- Train Loss: 0.33187  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 1190 -- Train Loss: 0.33199  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 1191 -- Train Loss: 0.33241  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 1192 -- Train Loss: 0.33279  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 1193 -- Train Loss: 0.33224  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 1194 -- Train Loss: 0.33240  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 1195 -- Train Loss: 0.33139  Validation Loss: 0.42935\n",
      "t: 10 EPOCH 1196 -- Train Loss: 0.33269  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 1197 -- Train Loss: 0.33183  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 1198 -- Train Loss: 0.33205  Validation Loss: 0.42946\n",
      "t: 10 EPOCH 1199 -- Train Loss: 0.33256  Validation Loss: 0.42906\n",
      "t: 10 EPOCH 1200 -- Train Loss: 0.33175  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 1201 -- Train Loss: 0.33183  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 1202 -- Train Loss: 0.33169  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 1203 -- Train Loss: 0.33191  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 1204 -- Train Loss: 0.33235  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1205 -- Train Loss: 0.33175  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 1206 -- Train Loss: 0.33138  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 1207 -- Train Loss: 0.33207  Validation Loss: 0.42924\n",
      "t: 10 EPOCH 1208 -- Train Loss: 0.33220  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 1209 -- Train Loss: 0.33275  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 1210 -- Train Loss: 0.33241  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 1211 -- Train Loss: 0.33168  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 1212 -- Train Loss: 0.33251  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1213 -- Train Loss: 0.33281  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 1214 -- Train Loss: 0.33104  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 1215 -- Train Loss: 0.33173  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 1216 -- Train Loss: 0.33166  Validation Loss: 0.42860\n",
      "t: 10 EPOCH 1217 -- Train Loss: 0.33195  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 1218 -- Train Loss: 0.33193  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 1219 -- Train Loss: 0.33303  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1220 -- Train Loss: 0.33201  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 1221 -- Train Loss: 0.33267  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 1222 -- Train Loss: 0.33173  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 1223 -- Train Loss: 0.33168  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 1224 -- Train Loss: 0.33130  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 1225 -- Train Loss: 0.33131  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1226 -- Train Loss: 0.33155  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 1227 -- Train Loss: 0.33109  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 1228 -- Train Loss: 0.33093  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 1229 -- Train Loss: 0.33257  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 1230 -- Train Loss: 0.33235  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 1231 -- Train Loss: 0.33152  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 1232 -- Train Loss: 0.33183  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 1233 -- Train Loss: 0.33190  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1234 -- Train Loss: 0.33159  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 1235 -- Train Loss: 0.33205  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 1236 -- Train Loss: 0.33222  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 1237 -- Train Loss: 0.33193  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 1238 -- Train Loss: 0.33173  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 1239 -- Train Loss: 0.33200  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 1240 -- Train Loss: 0.33248  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 1241 -- Train Loss: 0.33204  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 1242 -- Train Loss: 0.33246  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 1243 -- Train Loss: 0.33153  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1244 -- Train Loss: 0.33146  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 1245 -- Train Loss: 0.33190  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 1246 -- Train Loss: 0.33130  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 1247 -- Train Loss: 0.33201  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 1248 -- Train Loss: 0.33223  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1249 -- Train Loss: 0.33201  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 1250 -- Train Loss: 0.33218  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 1251 -- Train Loss: 0.33131  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 1252 -- Train Loss: 0.33186  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 1253 -- Train Loss: 0.33202  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 1254 -- Train Loss: 0.33192  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 1255 -- Train Loss: 0.33246  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 1256 -- Train Loss: 0.33185  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 1257 -- Train Loss: 0.33305  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1258 -- Train Loss: 0.33250  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 1259 -- Train Loss: 0.33121  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 1260 -- Train Loss: 0.33252  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1261 -- Train Loss: 0.33190  Validation Loss: 0.42838\n",
      "t: 10 EPOCH 1262 -- Train Loss: 0.33253  Validation Loss: 0.43121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1263 -- Train Loss: 0.33276  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 1264 -- Train Loss: 0.33260  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 1265 -- Train Loss: 0.33211  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 1266 -- Train Loss: 0.33321  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 1267 -- Train Loss: 0.33234  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 1268 -- Train Loss: 0.33206  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 1269 -- Train Loss: 0.33243  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 1270 -- Train Loss: 0.33269  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 1271 -- Train Loss: 0.33179  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 1272 -- Train Loss: 0.33305  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 1273 -- Train Loss: 0.33079  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 1274 -- Train Loss: 0.33268  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 1275 -- Train Loss: 0.33293  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 1276 -- Train Loss: 0.33246  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 1277 -- Train Loss: 0.33210  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 1278 -- Train Loss: 0.33233  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 1279 -- Train Loss: 0.33191  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 1280 -- Train Loss: 0.33199  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 1281 -- Train Loss: 0.33193  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1282 -- Train Loss: 0.33246  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 1283 -- Train Loss: 0.33150  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 1284 -- Train Loss: 0.33281  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 1285 -- Train Loss: 0.33195  Validation Loss: 0.42900\n",
      "t: 10 EPOCH 1286 -- Train Loss: 0.33190  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1287 -- Train Loss: 0.33286  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 1288 -- Train Loss: 0.33228  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1289 -- Train Loss: 0.33235  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 1290 -- Train Loss: 0.33177  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 1291 -- Train Loss: 0.33264  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1292 -- Train Loss: 0.33193  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 1293 -- Train Loss: 0.33260  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 1294 -- Train Loss: 0.33282  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 1295 -- Train Loss: 0.33312  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 1296 -- Train Loss: 0.33190  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 1297 -- Train Loss: 0.33224  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 1298 -- Train Loss: 0.33341  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 1299 -- Train Loss: 0.33230  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 1300 -- Train Loss: 0.33266  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 1301 -- Train Loss: 0.33297  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 1302 -- Train Loss: 0.33261  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1303 -- Train Loss: 0.33168  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 1304 -- Train Loss: 0.33233  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 1305 -- Train Loss: 0.33184  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 1306 -- Train Loss: 0.33307  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 1307 -- Train Loss: 0.33341  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 1308 -- Train Loss: 0.33209  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 1309 -- Train Loss: 0.33167  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 1310 -- Train Loss: 0.33278  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 1311 -- Train Loss: 0.33164  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 1312 -- Train Loss: 0.33203  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 1313 -- Train Loss: 0.33212  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1314 -- Train Loss: 0.33276  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 1315 -- Train Loss: 0.33306  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 1316 -- Train Loss: 0.33181  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 1317 -- Train Loss: 0.33350  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 1318 -- Train Loss: 0.33220  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 1319 -- Train Loss: 0.33242  Validation Loss: 0.42810\n",
      "t: 10 EPOCH 1320 -- Train Loss: 0.33147  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1321 -- Train Loss: 0.33351  Validation Loss: 0.42951\n",
      "t: 10 EPOCH 1322 -- Train Loss: 0.33163  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 1323 -- Train Loss: 0.33336  Validation Loss: 0.42898\n",
      "t: 10 EPOCH 1324 -- Train Loss: 0.33168  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 1325 -- Train Loss: 0.33251  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 1326 -- Train Loss: 0.33242  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 1327 -- Train Loss: 0.33310  Validation Loss: 0.42960\n",
      "t: 10 EPOCH 1328 -- Train Loss: 0.33246  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 1329 -- Train Loss: 0.33353  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 1330 -- Train Loss: 0.33213  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 1331 -- Train Loss: 0.33300  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 1332 -- Train Loss: 0.33274  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 1333 -- Train Loss: 0.33195  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 1334 -- Train Loss: 0.33280  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 1335 -- Train Loss: 0.33292  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 1336 -- Train Loss: 0.33308  Validation Loss: 0.42962\n",
      "t: 10 EPOCH 1337 -- Train Loss: 0.33224  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 1338 -- Train Loss: 0.33226  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 1339 -- Train Loss: 0.33216  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 1340 -- Train Loss: 0.33160  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 1341 -- Train Loss: 0.33277  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 1342 -- Train Loss: 0.33216  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 1343 -- Train Loss: 0.33230  Validation Loss: 0.42907\n",
      "t: 10 EPOCH 1344 -- Train Loss: 0.33237  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 1345 -- Train Loss: 0.33269  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 1346 -- Train Loss: 0.33181  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 1347 -- Train Loss: 0.33151  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1348 -- Train Loss: 0.33275  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1349 -- Train Loss: 0.33196  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 1350 -- Train Loss: 0.33273  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 1351 -- Train Loss: 0.33248  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 1352 -- Train Loss: 0.33181  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 1353 -- Train Loss: 0.33185  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 1354 -- Train Loss: 0.33270  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 1355 -- Train Loss: 0.33295  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 1356 -- Train Loss: 0.33221  Validation Loss: 0.42935\n",
      "t: 10 EPOCH 1357 -- Train Loss: 0.33204  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 1358 -- Train Loss: 0.33122  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 1359 -- Train Loss: 0.33316  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 1360 -- Train Loss: 0.33260  Validation Loss: 0.42966\n",
      "t: 10 EPOCH 1361 -- Train Loss: 0.33074  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 1362 -- Train Loss: 0.33254  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 1363 -- Train Loss: 0.33178  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1364 -- Train Loss: 0.33287  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 1365 -- Train Loss: 0.33197  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 1366 -- Train Loss: 0.33148  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 1367 -- Train Loss: 0.33239  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 1368 -- Train Loss: 0.33226  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 1369 -- Train Loss: 0.33184  Validation Loss: 0.42837\n",
      "t: 10 EPOCH 1370 -- Train Loss: 0.33271  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 1371 -- Train Loss: 0.33193  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 1372 -- Train Loss: 0.33161  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 1373 -- Train Loss: 0.33171  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1374 -- Train Loss: 0.33195  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 1375 -- Train Loss: 0.33095  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 1376 -- Train Loss: 0.33297  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 1377 -- Train Loss: 0.33197  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 1378 -- Train Loss: 0.33248  Validation Loss: 0.42975\n",
      "t: 10 EPOCH 1379 -- Train Loss: 0.33155  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 1380 -- Train Loss: 0.33217  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 1381 -- Train Loss: 0.33272  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1382 -- Train Loss: 0.33138  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 1383 -- Train Loss: 0.33252  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 1384 -- Train Loss: 0.33210  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 1385 -- Train Loss: 0.33187  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 1386 -- Train Loss: 0.33254  Validation Loss: 0.42925\n",
      "t: 10 EPOCH 1387 -- Train Loss: 0.33261  Validation Loss: 0.43099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1388 -- Train Loss: 0.33234  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 1389 -- Train Loss: 0.33201  Validation Loss: 0.42942\n",
      "t: 10 EPOCH 1390 -- Train Loss: 0.33190  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 1391 -- Train Loss: 0.33268  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 1392 -- Train Loss: 0.33179  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 1393 -- Train Loss: 0.33213  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 1394 -- Train Loss: 0.33149  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 1395 -- Train Loss: 0.33192  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 1396 -- Train Loss: 0.33116  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 1397 -- Train Loss: 0.33244  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 1398 -- Train Loss: 0.33199  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 1399 -- Train Loss: 0.33226  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 1400 -- Train Loss: 0.33226  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 1401 -- Train Loss: 0.33214  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 1402 -- Train Loss: 0.33264  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 1403 -- Train Loss: 0.33242  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 1404 -- Train Loss: 0.33230  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 1405 -- Train Loss: 0.33246  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 1406 -- Train Loss: 0.33207  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 1407 -- Train Loss: 0.33180  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 1408 -- Train Loss: 0.33231  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 1409 -- Train Loss: 0.33282  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 1410 -- Train Loss: 0.33217  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 1411 -- Train Loss: 0.33255  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 1412 -- Train Loss: 0.33205  Validation Loss: 0.42929\n",
      "t: 10 EPOCH 1413 -- Train Loss: 0.33106  Validation Loss: 0.42881\n",
      "t: 10 EPOCH 1414 -- Train Loss: 0.33282  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 1415 -- Train Loss: 0.33301  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 1416 -- Train Loss: 0.33202  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 1417 -- Train Loss: 0.33166  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 1418 -- Train Loss: 0.33271  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 1419 -- Train Loss: 0.33179  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 1420 -- Train Loss: 0.33236  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 1421 -- Train Loss: 0.33249  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 1422 -- Train Loss: 0.33267  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1423 -- Train Loss: 0.33208  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 1424 -- Train Loss: 0.33357  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1425 -- Train Loss: 0.33185  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 1426 -- Train Loss: 0.33346  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 1427 -- Train Loss: 0.33221  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1428 -- Train Loss: 0.33275  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 1429 -- Train Loss: 0.33239  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 1430 -- Train Loss: 0.33231  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 1431 -- Train Loss: 0.33199  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 1432 -- Train Loss: 0.33232  Validation Loss: 0.42937\n",
      "t: 10 EPOCH 1433 -- Train Loss: 0.33163  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 1434 -- Train Loss: 0.33240  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 1435 -- Train Loss: 0.33315  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 1436 -- Train Loss: 0.33327  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 1437 -- Train Loss: 0.33233  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 1438 -- Train Loss: 0.33270  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 1439 -- Train Loss: 0.33205  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 1440 -- Train Loss: 0.33324  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 1441 -- Train Loss: 0.33239  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 1442 -- Train Loss: 0.33305  Validation Loss: 0.42915\n",
      "t: 10 EPOCH 1443 -- Train Loss: 0.33189  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 1444 -- Train Loss: 0.33216  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 1445 -- Train Loss: 0.33203  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 1446 -- Train Loss: 0.33337  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 1447 -- Train Loss: 0.33306  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 1448 -- Train Loss: 0.33250  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 1449 -- Train Loss: 0.33203  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 1450 -- Train Loss: 0.33280  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 1451 -- Train Loss: 0.33161  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 1452 -- Train Loss: 0.33283  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 1453 -- Train Loss: 0.33155  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 1454 -- Train Loss: 0.33298  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 1455 -- Train Loss: 0.33239  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 1456 -- Train Loss: 0.33273  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 1457 -- Train Loss: 0.33244  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 1458 -- Train Loss: 0.33242  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 1459 -- Train Loss: 0.33266  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 1460 -- Train Loss: 0.33221  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1461 -- Train Loss: 0.33265  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 1462 -- Train Loss: 0.33267  Validation Loss: 0.42960\n",
      "t: 10 EPOCH 1463 -- Train Loss: 0.33278  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 1464 -- Train Loss: 0.33223  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 1465 -- Train Loss: 0.33312  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 1466 -- Train Loss: 0.33235  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 1467 -- Train Loss: 0.33297  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 1468 -- Train Loss: 0.33242  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 1469 -- Train Loss: 0.33250  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 1470 -- Train Loss: 0.33254  Validation Loss: 0.42920\n",
      "t: 10 EPOCH 1471 -- Train Loss: 0.33269  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 1472 -- Train Loss: 0.33185  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 1473 -- Train Loss: 0.33256  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 1474 -- Train Loss: 0.33253  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 1475 -- Train Loss: 0.33274  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 1476 -- Train Loss: 0.33130  Validation Loss: 0.42889\n",
      "t: 10 EPOCH 1477 -- Train Loss: 0.33171  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 1478 -- Train Loss: 0.33162  Validation Loss: 0.42897\n",
      "t: 10 EPOCH 1479 -- Train Loss: 0.33230  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 1480 -- Train Loss: 0.33210  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 1481 -- Train Loss: 0.33262  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 1482 -- Train Loss: 0.33156  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 1483 -- Train Loss: 0.33242  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 1484 -- Train Loss: 0.33182  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 1485 -- Train Loss: 0.33232  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 1486 -- Train Loss: 0.33236  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 1487 -- Train Loss: 0.33193  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 1488 -- Train Loss: 0.33242  Validation Loss: 0.42921\n",
      "t: 10 EPOCH 1489 -- Train Loss: 0.33128  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 1490 -- Train Loss: 0.33255  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 1491 -- Train Loss: 0.33222  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 1492 -- Train Loss: 0.33304  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 1493 -- Train Loss: 0.33222  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 1494 -- Train Loss: 0.33245  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 1495 -- Train Loss: 0.33236  Validation Loss: 0.42948\n",
      "t: 10 EPOCH 1496 -- Train Loss: 0.33224  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 1497 -- Train Loss: 0.33189  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 1498 -- Train Loss: 0.33255  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 1499 -- Train Loss: 0.33157  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 1500 -- Train Loss: 0.33261  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 1501 -- Train Loss: 0.33192  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 1502 -- Train Loss: 0.33171  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 1503 -- Train Loss: 0.33242  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 1504 -- Train Loss: 0.33236  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 1505 -- Train Loss: 0.33195  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 1506 -- Train Loss: 0.33208  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 1507 -- Train Loss: 0.33205  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 1508 -- Train Loss: 0.33192  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 1509 -- Train Loss: 0.33183  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 1510 -- Train Loss: 0.33179  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 1511 -- Train Loss: 0.33217  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 1512 -- Train Loss: 0.33247  Validation Loss: 0.43092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1513 -- Train Loss: 0.33239  Validation Loss: 0.42951\n",
      "t: 10 EPOCH 1514 -- Train Loss: 0.33309  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 1515 -- Train Loss: 0.33115  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 1516 -- Train Loss: 0.33192  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 1517 -- Train Loss: 0.33178  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 1518 -- Train Loss: 0.33235  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 1519 -- Train Loss: 0.33205  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1520 -- Train Loss: 0.33238  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 1521 -- Train Loss: 0.33239  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 1522 -- Train Loss: 0.33166  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 1523 -- Train Loss: 0.33200  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 1524 -- Train Loss: 0.33195  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 1525 -- Train Loss: 0.33278  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 1526 -- Train Loss: 0.33171  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1527 -- Train Loss: 0.33239  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 1528 -- Train Loss: 0.33170  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 1529 -- Train Loss: 0.33381  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 1530 -- Train Loss: 0.33172  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 1531 -- Train Loss: 0.33264  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 1532 -- Train Loss: 0.33238  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 1533 -- Train Loss: 0.33232  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 1534 -- Train Loss: 0.33145  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 1535 -- Train Loss: 0.33216  Validation Loss: 0.42928\n",
      "t: 10 EPOCH 1536 -- Train Loss: 0.33249  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1537 -- Train Loss: 0.33253  Validation Loss: 0.42904\n",
      "t: 10 EPOCH 1538 -- Train Loss: 0.33152  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 1539 -- Train Loss: 0.33204  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 1540 -- Train Loss: 0.33212  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 1541 -- Train Loss: 0.33138  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 1542 -- Train Loss: 0.33124  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 1543 -- Train Loss: 0.33171  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 1544 -- Train Loss: 0.33217  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 1545 -- Train Loss: 0.33204  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 1546 -- Train Loss: 0.33119  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 1547 -- Train Loss: 0.33223  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 1548 -- Train Loss: 0.33186  Validation Loss: 0.42864\n",
      "t: 10 EPOCH 1549 -- Train Loss: 0.33227  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 1550 -- Train Loss: 0.33241  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 1551 -- Train Loss: 0.33219  Validation Loss: 0.42868\n",
      "t: 10 EPOCH 1552 -- Train Loss: 0.33234  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 1553 -- Train Loss: 0.33169  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 1554 -- Train Loss: 0.33241  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 1555 -- Train Loss: 0.33236  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 1556 -- Train Loss: 0.33229  Validation Loss: 0.42937\n",
      "t: 10 EPOCH 1557 -- Train Loss: 0.33231  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 1558 -- Train Loss: 0.33134  Validation Loss: 0.42915\n",
      "t: 10 EPOCH 1559 -- Train Loss: 0.33253  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 1560 -- Train Loss: 0.33140  Validation Loss: 0.42936\n",
      "t: 10 EPOCH 1561 -- Train Loss: 0.33223  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 1562 -- Train Loss: 0.33177  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 1563 -- Train Loss: 0.33255  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 1564 -- Train Loss: 0.33214  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 1565 -- Train Loss: 0.33258  Validation Loss: 0.42842\n",
      "t: 10 EPOCH 1566 -- Train Loss: 0.33268  Validation Loss: 0.42962\n",
      "t: 10 EPOCH 1567 -- Train Loss: 0.33292  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 1568 -- Train Loss: 0.33187  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 1569 -- Train Loss: 0.33148  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 1570 -- Train Loss: 0.33226  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 1571 -- Train Loss: 0.33206  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 1572 -- Train Loss: 0.33181  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 1573 -- Train Loss: 0.33220  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 1574 -- Train Loss: 0.33310  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 1575 -- Train Loss: 0.33110  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 1576 -- Train Loss: 0.33277  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 1577 -- Train Loss: 0.33171  Validation Loss: 0.42877\n",
      "t: 10 EPOCH 1578 -- Train Loss: 0.33178  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 1579 -- Train Loss: 0.33201  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 1580 -- Train Loss: 0.33198  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 1581 -- Train Loss: 0.33170  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 1582 -- Train Loss: 0.33203  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 1583 -- Train Loss: 0.33128  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 1584 -- Train Loss: 0.33172  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 1585 -- Train Loss: 0.33221  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 1586 -- Train Loss: 0.33236  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 1587 -- Train Loss: 0.33195  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 1588 -- Train Loss: 0.33089  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 1589 -- Train Loss: 0.33219  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 1590 -- Train Loss: 0.33211  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1591 -- Train Loss: 0.33218  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 1592 -- Train Loss: 0.33232  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 1593 -- Train Loss: 0.33193  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 1594 -- Train Loss: 0.33156  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 1595 -- Train Loss: 0.33091  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 1596 -- Train Loss: 0.33039  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 1597 -- Train Loss: 0.33137  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 1598 -- Train Loss: 0.33238  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 1599 -- Train Loss: 0.33237  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 1600 -- Train Loss: 0.33216  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1601 -- Train Loss: 0.33146  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 1602 -- Train Loss: 0.33218  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 1603 -- Train Loss: 0.33196  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 1604 -- Train Loss: 0.33217  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 1605 -- Train Loss: 0.33235  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 1606 -- Train Loss: 0.33171  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 1607 -- Train Loss: 0.33182  Validation Loss: 0.42945\n",
      "t: 10 EPOCH 1608 -- Train Loss: 0.33279  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 1609 -- Train Loss: 0.33170  Validation Loss: 0.42882\n",
      "t: 10 EPOCH 1610 -- Train Loss: 0.33114  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 1611 -- Train Loss: 0.33161  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 1612 -- Train Loss: 0.33229  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 1613 -- Train Loss: 0.33207  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 1614 -- Train Loss: 0.33145  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 1615 -- Train Loss: 0.33147  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 1616 -- Train Loss: 0.33192  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 1617 -- Train Loss: 0.33093  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 1618 -- Train Loss: 0.33110  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 1619 -- Train Loss: 0.33207  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 1620 -- Train Loss: 0.33135  Validation Loss: 0.42998\n",
      "t: 10 EPOCH 1621 -- Train Loss: 0.33164  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 1622 -- Train Loss: 0.33163  Validation Loss: 0.42909\n",
      "t: 10 EPOCH 1623 -- Train Loss: 0.33111  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1624 -- Train Loss: 0.33260  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 1625 -- Train Loss: 0.33226  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 1626 -- Train Loss: 0.33102  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 1627 -- Train Loss: 0.33129  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1628 -- Train Loss: 0.33260  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 1629 -- Train Loss: 0.33161  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 1630 -- Train Loss: 0.33313  Validation Loss: 0.42893\n",
      "t: 10 EPOCH 1631 -- Train Loss: 0.33145  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 1632 -- Train Loss: 0.33220  Validation Loss: 0.42974\n",
      "t: 10 EPOCH 1633 -- Train Loss: 0.33074  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 1634 -- Train Loss: 0.33248  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 1635 -- Train Loss: 0.33144  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 1636 -- Train Loss: 0.33142  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 1637 -- Train Loss: 0.33127  Validation Loss: 0.43061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1638 -- Train Loss: 0.33227  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1639 -- Train Loss: 0.33200  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 1640 -- Train Loss: 0.33270  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 1641 -- Train Loss: 0.33238  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 1642 -- Train Loss: 0.33284  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 1643 -- Train Loss: 0.33247  Validation Loss: 0.42892\n",
      "t: 10 EPOCH 1644 -- Train Loss: 0.33189  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 1645 -- Train Loss: 0.33211  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 1646 -- Train Loss: 0.33176  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 1647 -- Train Loss: 0.33234  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 1648 -- Train Loss: 0.33236  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 1649 -- Train Loss: 0.33196  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1650 -- Train Loss: 0.33095  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 1651 -- Train Loss: 0.33334  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 1652 -- Train Loss: 0.33278  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 1653 -- Train Loss: 0.33205  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 1654 -- Train Loss: 0.33150  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 1655 -- Train Loss: 0.33200  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 1656 -- Train Loss: 0.33104  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 1657 -- Train Loss: 0.33205  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 1658 -- Train Loss: 0.33098  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 1659 -- Train Loss: 0.33223  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 1660 -- Train Loss: 0.33149  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 1661 -- Train Loss: 0.33232  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1662 -- Train Loss: 0.33215  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1663 -- Train Loss: 0.33269  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 1664 -- Train Loss: 0.33250  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 1665 -- Train Loss: 0.33297  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 1666 -- Train Loss: 0.33124  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 1667 -- Train Loss: 0.33237  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 1668 -- Train Loss: 0.33236  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 1669 -- Train Loss: 0.33236  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 1670 -- Train Loss: 0.33163  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 1671 -- Train Loss: 0.33247  Validation Loss: 0.42921\n",
      "t: 10 EPOCH 1672 -- Train Loss: 0.33159  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1673 -- Train Loss: 0.33169  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1674 -- Train Loss: 0.33177  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 1675 -- Train Loss: 0.33171  Validation Loss: 0.42926\n",
      "t: 10 EPOCH 1676 -- Train Loss: 0.33168  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 1677 -- Train Loss: 0.33163  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 1678 -- Train Loss: 0.33242  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 1679 -- Train Loss: 0.33145  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 1680 -- Train Loss: 0.33240  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 1681 -- Train Loss: 0.33183  Validation Loss: 0.42888\n",
      "t: 10 EPOCH 1682 -- Train Loss: 0.33126  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 1683 -- Train Loss: 0.33282  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 1684 -- Train Loss: 0.33246  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 1685 -- Train Loss: 0.33167  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 1686 -- Train Loss: 0.33163  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 1687 -- Train Loss: 0.33224  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 1688 -- Train Loss: 0.33272  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 1689 -- Train Loss: 0.33238  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 1690 -- Train Loss: 0.33185  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 1691 -- Train Loss: 0.33311  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 1692 -- Train Loss: 0.33157  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 1693 -- Train Loss: 0.33269  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 1694 -- Train Loss: 0.33225  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 1695 -- Train Loss: 0.33170  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 1696 -- Train Loss: 0.33112  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 1697 -- Train Loss: 0.33231  Validation Loss: 0.42973\n",
      "t: 10 EPOCH 1698 -- Train Loss: 0.33145  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 1699 -- Train Loss: 0.33144  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 1700 -- Train Loss: 0.33172  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 1701 -- Train Loss: 0.33129  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 1702 -- Train Loss: 0.33178  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 1703 -- Train Loss: 0.33190  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 1704 -- Train Loss: 0.33089  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 1705 -- Train Loss: 0.33180  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 1706 -- Train Loss: 0.33292  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 1707 -- Train Loss: 0.33152  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 1708 -- Train Loss: 0.33212  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 1709 -- Train Loss: 0.33156  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 1710 -- Train Loss: 0.33219  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 1711 -- Train Loss: 0.33187  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 1712 -- Train Loss: 0.33256  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 1713 -- Train Loss: 0.33155  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 1714 -- Train Loss: 0.33160  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 1715 -- Train Loss: 0.33130  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 1716 -- Train Loss: 0.33115  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 1717 -- Train Loss: 0.33206  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 1718 -- Train Loss: 0.33243  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 1719 -- Train Loss: 0.33168  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 1720 -- Train Loss: 0.33172  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 1721 -- Train Loss: 0.33203  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 1722 -- Train Loss: 0.33174  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1723 -- Train Loss: 0.33197  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 1724 -- Train Loss: 0.33242  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 1725 -- Train Loss: 0.33179  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 1726 -- Train Loss: 0.33213  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 1727 -- Train Loss: 0.33175  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 1728 -- Train Loss: 0.33210  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 1729 -- Train Loss: 0.33160  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 1730 -- Train Loss: 0.33086  Validation Loss: 0.42973\n",
      "t: 10 EPOCH 1731 -- Train Loss: 0.33267  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 1732 -- Train Loss: 0.33071  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 1733 -- Train Loss: 0.33187  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 1734 -- Train Loss: 0.33108  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1735 -- Train Loss: 0.33256  Validation Loss: 0.42923\n",
      "t: 10 EPOCH 1736 -- Train Loss: 0.33249  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 1737 -- Train Loss: 0.33142  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 1738 -- Train Loss: 0.33147  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 1739 -- Train Loss: 0.33254  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 1740 -- Train Loss: 0.33208  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 1741 -- Train Loss: 0.33283  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 1742 -- Train Loss: 0.33150  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 1743 -- Train Loss: 0.33263  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 1744 -- Train Loss: 0.33157  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 1745 -- Train Loss: 0.33251  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 1746 -- Train Loss: 0.33195  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 1747 -- Train Loss: 0.33308  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 1748 -- Train Loss: 0.33123  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 1749 -- Train Loss: 0.33195  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 1750 -- Train Loss: 0.33153  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 1751 -- Train Loss: 0.33280  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 1752 -- Train Loss: 0.33146  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 1753 -- Train Loss: 0.33259  Validation Loss: 0.42912\n",
      "t: 10 EPOCH 1754 -- Train Loss: 0.33167  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 1755 -- Train Loss: 0.33230  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 1756 -- Train Loss: 0.33260  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 1757 -- Train Loss: 0.33291  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 1758 -- Train Loss: 0.33190  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 1759 -- Train Loss: 0.33271  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 1760 -- Train Loss: 0.33274  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 1761 -- Train Loss: 0.33232  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1762 -- Train Loss: 0.33130  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 1763 -- Train Loss: 0.33222  Validation Loss: 0.43002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1764 -- Train Loss: 0.33171  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 1765 -- Train Loss: 0.33261  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 1766 -- Train Loss: 0.33147  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 1767 -- Train Loss: 0.33215  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 1768 -- Train Loss: 0.33107  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 1769 -- Train Loss: 0.33281  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 1770 -- Train Loss: 0.33134  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 1771 -- Train Loss: 0.33271  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 1772 -- Train Loss: 0.33197  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 1773 -- Train Loss: 0.33256  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 1774 -- Train Loss: 0.33141  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 1775 -- Train Loss: 0.33265  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 1776 -- Train Loss: 0.33250  Validation Loss: 0.42944\n",
      "t: 10 EPOCH 1777 -- Train Loss: 0.33309  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1778 -- Train Loss: 0.33211  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 1779 -- Train Loss: 0.33283  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 1780 -- Train Loss: 0.33194  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 1781 -- Train Loss: 0.33251  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 1782 -- Train Loss: 0.33204  Validation Loss: 0.42884\n",
      "t: 10 EPOCH 1783 -- Train Loss: 0.33220  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 1784 -- Train Loss: 0.33239  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 1785 -- Train Loss: 0.33157  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 1786 -- Train Loss: 0.33256  Validation Loss: 0.42940\n",
      "t: 10 EPOCH 1787 -- Train Loss: 0.33190  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 1788 -- Train Loss: 0.33221  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 1789 -- Train Loss: 0.33229  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 1790 -- Train Loss: 0.33201  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1791 -- Train Loss: 0.33113  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 1792 -- Train Loss: 0.33279  Validation Loss: 0.43001\n",
      "t: 10 EPOCH 1793 -- Train Loss: 0.33170  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 1794 -- Train Loss: 0.33250  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 1795 -- Train Loss: 0.33172  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 1796 -- Train Loss: 0.33289  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 1797 -- Train Loss: 0.33276  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1798 -- Train Loss: 0.33173  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 1799 -- Train Loss: 0.33171  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 1800 -- Train Loss: 0.33214  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 1801 -- Train Loss: 0.33199  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 1802 -- Train Loss: 0.33143  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 1803 -- Train Loss: 0.33240  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 1804 -- Train Loss: 0.33153  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 1805 -- Train Loss: 0.33132  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 1806 -- Train Loss: 0.33176  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 1807 -- Train Loss: 0.33295  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 1808 -- Train Loss: 0.33126  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 1809 -- Train Loss: 0.33180  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 1810 -- Train Loss: 0.33161  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1811 -- Train Loss: 0.33192  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 1812 -- Train Loss: 0.33080  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 1813 -- Train Loss: 0.33225  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 1814 -- Train Loss: 0.33165  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 1815 -- Train Loss: 0.33221  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 1816 -- Train Loss: 0.33125  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1817 -- Train Loss: 0.33084  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 1818 -- Train Loss: 0.33132  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 1819 -- Train Loss: 0.33225  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 1820 -- Train Loss: 0.33120  Validation Loss: 0.42921\n",
      "t: 10 EPOCH 1821 -- Train Loss: 0.33107  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 1822 -- Train Loss: 0.33161  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 1823 -- Train Loss: 0.33239  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1824 -- Train Loss: 0.33185  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 1825 -- Train Loss: 0.33099  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 1826 -- Train Loss: 0.33150  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 1827 -- Train Loss: 0.33180  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 1828 -- Train Loss: 0.33192  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 1829 -- Train Loss: 0.33063  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 1830 -- Train Loss: 0.33150  Validation Loss: 0.42933\n",
      "t: 10 EPOCH 1831 -- Train Loss: 0.33213  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 1832 -- Train Loss: 0.33113  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 1833 -- Train Loss: 0.33259  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1834 -- Train Loss: 0.33115  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 1835 -- Train Loss: 0.33136  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 1836 -- Train Loss: 0.33109  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 1837 -- Train Loss: 0.33090  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 1838 -- Train Loss: 0.33183  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 1839 -- Train Loss: 0.33126  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 1840 -- Train Loss: 0.33174  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 1841 -- Train Loss: 0.33193  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 1842 -- Train Loss: 0.33209  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 1843 -- Train Loss: 0.33173  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 1844 -- Train Loss: 0.33224  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 1845 -- Train Loss: 0.33092  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 1846 -- Train Loss: 0.33138  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 1847 -- Train Loss: 0.33129  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 1848 -- Train Loss: 0.33145  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 1849 -- Train Loss: 0.33182  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 1850 -- Train Loss: 0.33110  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 1851 -- Train Loss: 0.33170  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 1852 -- Train Loss: 0.33131  Validation Loss: 0.42865\n",
      "t: 10 EPOCH 1853 -- Train Loss: 0.33080  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 1854 -- Train Loss: 0.33125  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1855 -- Train Loss: 0.33175  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 1856 -- Train Loss: 0.33110  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 1857 -- Train Loss: 0.33192  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1858 -- Train Loss: 0.33152  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 1859 -- Train Loss: 0.33224  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 1860 -- Train Loss: 0.33056  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 1861 -- Train Loss: 0.33116  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 1862 -- Train Loss: 0.33124  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 1863 -- Train Loss: 0.33167  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 1864 -- Train Loss: 0.33101  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 1865 -- Train Loss: 0.33185  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 1866 -- Train Loss: 0.33180  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 1867 -- Train Loss: 0.33089  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 1868 -- Train Loss: 0.33253  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1869 -- Train Loss: 0.33059  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 1870 -- Train Loss: 0.33125  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 1871 -- Train Loss: 0.33216  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 1872 -- Train Loss: 0.33276  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 1873 -- Train Loss: 0.33228  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 1874 -- Train Loss: 0.33191  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 1875 -- Train Loss: 0.33109  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 1876 -- Train Loss: 0.33196  Validation Loss: 0.42998\n",
      "t: 10 EPOCH 1877 -- Train Loss: 0.33198  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 1878 -- Train Loss: 0.33237  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 1879 -- Train Loss: 0.33157  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 1880 -- Train Loss: 0.33264  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 1881 -- Train Loss: 0.33184  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 1882 -- Train Loss: 0.33200  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 1883 -- Train Loss: 0.33264  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 1884 -- Train Loss: 0.33189  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 1885 -- Train Loss: 0.33080  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 1886 -- Train Loss: 0.33215  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 1887 -- Train Loss: 0.33260  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 1888 -- Train Loss: 0.33275  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 1889 -- Train Loss: 0.33303  Validation Loss: 0.43036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 1890 -- Train Loss: 0.33131  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 1891 -- Train Loss: 0.33269  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 1892 -- Train Loss: 0.33240  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 1893 -- Train Loss: 0.33206  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 1894 -- Train Loss: 0.33131  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 1895 -- Train Loss: 0.33250  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 1896 -- Train Loss: 0.33267  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 1897 -- Train Loss: 0.33261  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 1898 -- Train Loss: 0.33312  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 1899 -- Train Loss: 0.33237  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 1900 -- Train Loss: 0.33228  Validation Loss: 0.42955\n",
      "t: 10 EPOCH 1901 -- Train Loss: 0.33197  Validation Loss: 0.42896\n",
      "t: 10 EPOCH 1902 -- Train Loss: 0.33233  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 1903 -- Train Loss: 0.33223  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 1904 -- Train Loss: 0.33153  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 1905 -- Train Loss: 0.33302  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 1906 -- Train Loss: 0.33159  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 1907 -- Train Loss: 0.33314  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 1908 -- Train Loss: 0.33193  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 1909 -- Train Loss: 0.33313  Validation Loss: 0.42972\n",
      "t: 10 EPOCH 1910 -- Train Loss: 0.33158  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 1911 -- Train Loss: 0.33198  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 1912 -- Train Loss: 0.33181  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 1913 -- Train Loss: 0.33154  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 1914 -- Train Loss: 0.33163  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 1915 -- Train Loss: 0.33137  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 1916 -- Train Loss: 0.33194  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 1917 -- Train Loss: 0.33144  Validation Loss: 0.42918\n",
      "t: 10 EPOCH 1918 -- Train Loss: 0.33109  Validation Loss: 0.42913\n",
      "t: 10 EPOCH 1919 -- Train Loss: 0.33188  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 1920 -- Train Loss: 0.33208  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 1921 -- Train Loss: 0.33176  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 1922 -- Train Loss: 0.33225  Validation Loss: 0.42915\n",
      "t: 10 EPOCH 1923 -- Train Loss: 0.33212  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 1924 -- Train Loss: 0.33180  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 1925 -- Train Loss: 0.33139  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 1926 -- Train Loss: 0.33170  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 1927 -- Train Loss: 0.33265  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 1928 -- Train Loss: 0.33198  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 1929 -- Train Loss: 0.33313  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 1930 -- Train Loss: 0.33176  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 1931 -- Train Loss: 0.33255  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1932 -- Train Loss: 0.33167  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 1933 -- Train Loss: 0.33252  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 1934 -- Train Loss: 0.33219  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 1935 -- Train Loss: 0.33162  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1936 -- Train Loss: 0.33241  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 1937 -- Train Loss: 0.33318  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 1938 -- Train Loss: 0.33178  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 1939 -- Train Loss: 0.33255  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1940 -- Train Loss: 0.33159  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 1941 -- Train Loss: 0.33186  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 1942 -- Train Loss: 0.33201  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 1943 -- Train Loss: 0.33240  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 1944 -- Train Loss: 0.33219  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 1945 -- Train Loss: 0.33276  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 1946 -- Train Loss: 0.33273  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 1947 -- Train Loss: 0.33143  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 1948 -- Train Loss: 0.33183  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 1949 -- Train Loss: 0.33219  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1950 -- Train Loss: 0.33162  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 1951 -- Train Loss: 0.33139  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1952 -- Train Loss: 0.33173  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 1953 -- Train Loss: 0.33204  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 1954 -- Train Loss: 0.33146  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 1955 -- Train Loss: 0.33209  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 1956 -- Train Loss: 0.33287  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 1957 -- Train Loss: 0.33213  Validation Loss: 0.42956\n",
      "t: 10 EPOCH 1958 -- Train Loss: 0.33233  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 1959 -- Train Loss: 0.33158  Validation Loss: 0.42955\n",
      "t: 10 EPOCH 1960 -- Train Loss: 0.33220  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 1961 -- Train Loss: 0.33146  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 1962 -- Train Loss: 0.33107  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 1963 -- Train Loss: 0.33176  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 1964 -- Train Loss: 0.33144  Validation Loss: 0.42866\n",
      "t: 10 EPOCH 1965 -- Train Loss: 0.33139  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 1966 -- Train Loss: 0.33140  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 1967 -- Train Loss: 0.33224  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 1968 -- Train Loss: 0.33221  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 1969 -- Train Loss: 0.33158  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 1970 -- Train Loss: 0.33235  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 1971 -- Train Loss: 0.33102  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 1972 -- Train Loss: 0.33141  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 1973 -- Train Loss: 0.33077  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 1974 -- Train Loss: 0.33192  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 1975 -- Train Loss: 0.33167  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 1976 -- Train Loss: 0.33149  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 1977 -- Train Loss: 0.33210  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 1978 -- Train Loss: 0.33173  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 1979 -- Train Loss: 0.33151  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 1980 -- Train Loss: 0.33197  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 1981 -- Train Loss: 0.33082  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 1982 -- Train Loss: 0.33206  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 1983 -- Train Loss: 0.33122  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 1984 -- Train Loss: 0.33176  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 1985 -- Train Loss: 0.33173  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 1986 -- Train Loss: 0.33117  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 1987 -- Train Loss: 0.33163  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 1988 -- Train Loss: 0.33223  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 1989 -- Train Loss: 0.33271  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 1990 -- Train Loss: 0.33243  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 1991 -- Train Loss: 0.33184  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 1992 -- Train Loss: 0.33235  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 1993 -- Train Loss: 0.33091  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 1994 -- Train Loss: 0.33230  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 1995 -- Train Loss: 0.33136  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 1996 -- Train Loss: 0.33138  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 1997 -- Train Loss: 0.33155  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 1998 -- Train Loss: 0.33166  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 1999 -- Train Loss: 0.33243  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 2000 -- Train Loss: 0.33278  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 2001 -- Train Loss: 0.33164  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2002 -- Train Loss: 0.33155  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 2003 -- Train Loss: 0.33175  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 2004 -- Train Loss: 0.33142  Validation Loss: 0.42971\n",
      "t: 10 EPOCH 2005 -- Train Loss: 0.33203  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 2006 -- Train Loss: 0.33215  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 2007 -- Train Loss: 0.33242  Validation Loss: 0.42908\n",
      "t: 10 EPOCH 2008 -- Train Loss: 0.33219  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 2009 -- Train Loss: 0.33212  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 2010 -- Train Loss: 0.33180  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 2011 -- Train Loss: 0.33219  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 2012 -- Train Loss: 0.33216  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 2013 -- Train Loss: 0.33238  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 2014 -- Train Loss: 0.33153  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 2015 -- Train Loss: 0.33220  Validation Loss: 0.43013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2016 -- Train Loss: 0.33142  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 2017 -- Train Loss: 0.33237  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2018 -- Train Loss: 0.33174  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 2019 -- Train Loss: 0.33223  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 2020 -- Train Loss: 0.33123  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2021 -- Train Loss: 0.33142  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 2022 -- Train Loss: 0.33144  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 2023 -- Train Loss: 0.33216  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 2024 -- Train Loss: 0.33215  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2025 -- Train Loss: 0.33191  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 2026 -- Train Loss: 0.33202  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 2027 -- Train Loss: 0.33159  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 2028 -- Train Loss: 0.33199  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2029 -- Train Loss: 0.33227  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 2030 -- Train Loss: 0.33094  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 2031 -- Train Loss: 0.33206  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 2032 -- Train Loss: 0.33083  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 2033 -- Train Loss: 0.33214  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 2034 -- Train Loss: 0.33141  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2035 -- Train Loss: 0.33151  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 2036 -- Train Loss: 0.33240  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 2037 -- Train Loss: 0.33182  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2038 -- Train Loss: 0.33244  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 2039 -- Train Loss: 0.33124  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 2040 -- Train Loss: 0.33130  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 2041 -- Train Loss: 0.33185  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 2042 -- Train Loss: 0.33144  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 2043 -- Train Loss: 0.33204  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 2044 -- Train Loss: 0.33124  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 2045 -- Train Loss: 0.33188  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 2046 -- Train Loss: 0.33178  Validation Loss: 0.42881\n",
      "t: 10 EPOCH 2047 -- Train Loss: 0.33173  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 2048 -- Train Loss: 0.33166  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 2049 -- Train Loss: 0.33123  Validation Loss: 0.42923\n",
      "t: 10 EPOCH 2050 -- Train Loss: 0.33189  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 2051 -- Train Loss: 0.33147  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 2052 -- Train Loss: 0.33208  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 2053 -- Train Loss: 0.33103  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 2054 -- Train Loss: 0.33145  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 2055 -- Train Loss: 0.33123  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 2056 -- Train Loss: 0.33207  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2057 -- Train Loss: 0.33131  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 2058 -- Train Loss: 0.33235  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 2059 -- Train Loss: 0.33158  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 2060 -- Train Loss: 0.33137  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 2061 -- Train Loss: 0.33103  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 2062 -- Train Loss: 0.33153  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2063 -- Train Loss: 0.33084  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2064 -- Train Loss: 0.33181  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 2065 -- Train Loss: 0.33098  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 2066 -- Train Loss: 0.33148  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 2067 -- Train Loss: 0.33185  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 2068 -- Train Loss: 0.33115  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 2069 -- Train Loss: 0.33172  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 2070 -- Train Loss: 0.33186  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2071 -- Train Loss: 0.33182  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 2072 -- Train Loss: 0.33176  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 2073 -- Train Loss: 0.33173  Validation Loss: 0.42934\n",
      "t: 10 EPOCH 2074 -- Train Loss: 0.33122  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2075 -- Train Loss: 0.33044  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 2076 -- Train Loss: 0.33112  Validation Loss: 0.42932\n",
      "t: 10 EPOCH 2077 -- Train Loss: 0.33119  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 2078 -- Train Loss: 0.33151  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2079 -- Train Loss: 0.33168  Validation Loss: 0.42914\n",
      "t: 10 EPOCH 2080 -- Train Loss: 0.33076  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 2081 -- Train Loss: 0.33164  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2082 -- Train Loss: 0.33174  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2083 -- Train Loss: 0.33208  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 2084 -- Train Loss: 0.33197  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2085 -- Train Loss: 0.33168  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 2086 -- Train Loss: 0.33223  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 2087 -- Train Loss: 0.33122  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 2088 -- Train Loss: 0.33239  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 2089 -- Train Loss: 0.33278  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 2090 -- Train Loss: 0.33157  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 2091 -- Train Loss: 0.33185  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 2092 -- Train Loss: 0.33103  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 2093 -- Train Loss: 0.33163  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 2094 -- Train Loss: 0.33200  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 2095 -- Train Loss: 0.33152  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 2096 -- Train Loss: 0.33104  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 2097 -- Train Loss: 0.33220  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 2098 -- Train Loss: 0.33110  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 2099 -- Train Loss: 0.33188  Validation Loss: 0.42894\n",
      "t: 10 EPOCH 2100 -- Train Loss: 0.33108  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 2101 -- Train Loss: 0.33115  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 2102 -- Train Loss: 0.33254  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 2103 -- Train Loss: 0.33135  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 2104 -- Train Loss: 0.33144  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 2105 -- Train Loss: 0.33118  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 2106 -- Train Loss: 0.33167  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 2107 -- Train Loss: 0.33161  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 2108 -- Train Loss: 0.33142  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 2109 -- Train Loss: 0.33264  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 2110 -- Train Loss: 0.33090  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 2111 -- Train Loss: 0.33200  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 2112 -- Train Loss: 0.33158  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 2113 -- Train Loss: 0.33142  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 2114 -- Train Loss: 0.33136  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 2115 -- Train Loss: 0.33245  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 2116 -- Train Loss: 0.33159  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 2117 -- Train Loss: 0.33108  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 2118 -- Train Loss: 0.33166  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 2119 -- Train Loss: 0.33248  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2120 -- Train Loss: 0.33156  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 2121 -- Train Loss: 0.33250  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 2122 -- Train Loss: 0.33163  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 2123 -- Train Loss: 0.33189  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 2124 -- Train Loss: 0.33124  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 2125 -- Train Loss: 0.33160  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2126 -- Train Loss: 0.33245  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 2127 -- Train Loss: 0.33219  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 2128 -- Train Loss: 0.33219  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 2129 -- Train Loss: 0.33086  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2130 -- Train Loss: 0.33173  Validation Loss: 0.42974\n",
      "t: 10 EPOCH 2131 -- Train Loss: 0.33215  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 2132 -- Train Loss: 0.33158  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 2133 -- Train Loss: 0.33171  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 2134 -- Train Loss: 0.33246  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 2135 -- Train Loss: 0.33104  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 2136 -- Train Loss: 0.33240  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 2137 -- Train Loss: 0.33166  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 2138 -- Train Loss: 0.33158  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 2139 -- Train Loss: 0.33206  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2140 -- Train Loss: 0.33119  Validation Loss: 0.43057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2141 -- Train Loss: 0.33219  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 2142 -- Train Loss: 0.33237  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 2143 -- Train Loss: 0.33174  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2144 -- Train Loss: 0.33231  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2145 -- Train Loss: 0.33182  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 2146 -- Train Loss: 0.33137  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 2147 -- Train Loss: 0.33189  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 2148 -- Train Loss: 0.33219  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 2149 -- Train Loss: 0.33166  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 2150 -- Train Loss: 0.33125  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 2151 -- Train Loss: 0.33127  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 2152 -- Train Loss: 0.33228  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 2153 -- Train Loss: 0.33096  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 2154 -- Train Loss: 0.33284  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 2155 -- Train Loss: 0.33043  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 2156 -- Train Loss: 0.33218  Validation Loss: 0.42937\n",
      "t: 10 EPOCH 2157 -- Train Loss: 0.33179  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2158 -- Train Loss: 0.33208  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 2159 -- Train Loss: 0.33163  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2160 -- Train Loss: 0.33234  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2161 -- Train Loss: 0.33163  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 2162 -- Train Loss: 0.33109  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2163 -- Train Loss: 0.33127  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 2164 -- Train Loss: 0.33127  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 2165 -- Train Loss: 0.33170  Validation Loss: 0.42934\n",
      "t: 10 EPOCH 2166 -- Train Loss: 0.33185  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 2167 -- Train Loss: 0.33131  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 2168 -- Train Loss: 0.33028  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 2169 -- Train Loss: 0.33085  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 2170 -- Train Loss: 0.33107  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 2171 -- Train Loss: 0.33105  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2172 -- Train Loss: 0.33158  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 2173 -- Train Loss: 0.33215  Validation Loss: 0.42919\n",
      "t: 10 EPOCH 2174 -- Train Loss: 0.33143  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 2175 -- Train Loss: 0.33124  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 2176 -- Train Loss: 0.33133  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 2177 -- Train Loss: 0.33098  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 2178 -- Train Loss: 0.33166  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 2179 -- Train Loss: 0.33092  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 2180 -- Train Loss: 0.33213  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 2181 -- Train Loss: 0.33093  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 2182 -- Train Loss: 0.33186  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2183 -- Train Loss: 0.33098  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 2184 -- Train Loss: 0.33173  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 2185 -- Train Loss: 0.33162  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 2186 -- Train Loss: 0.33206  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 2187 -- Train Loss: 0.33205  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 2188 -- Train Loss: 0.33201  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2189 -- Train Loss: 0.33099  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 2190 -- Train Loss: 0.33143  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2191 -- Train Loss: 0.33238  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 2192 -- Train Loss: 0.33115  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 2193 -- Train Loss: 0.33212  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 2194 -- Train Loss: 0.33133  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2195 -- Train Loss: 0.33209  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 2196 -- Train Loss: 0.33140  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 2197 -- Train Loss: 0.33146  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 2198 -- Train Loss: 0.33169  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 2199 -- Train Loss: 0.33181  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 2200 -- Train Loss: 0.33183  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 2201 -- Train Loss: 0.33138  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 2202 -- Train Loss: 0.33124  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 2203 -- Train Loss: 0.33170  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2204 -- Train Loss: 0.33163  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 2205 -- Train Loss: 0.33210  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2206 -- Train Loss: 0.33141  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 2207 -- Train Loss: 0.33093  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2208 -- Train Loss: 0.33130  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 2209 -- Train Loss: 0.33103  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 2210 -- Train Loss: 0.33175  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 2211 -- Train Loss: 0.33230  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 2212 -- Train Loss: 0.33143  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 2213 -- Train Loss: 0.33138  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2214 -- Train Loss: 0.33205  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 2215 -- Train Loss: 0.33116  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2216 -- Train Loss: 0.33135  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 2217 -- Train Loss: 0.33172  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 2218 -- Train Loss: 0.33121  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 2219 -- Train Loss: 0.33221  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 2220 -- Train Loss: 0.33163  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 2221 -- Train Loss: 0.33202  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 2222 -- Train Loss: 0.33130  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 2223 -- Train Loss: 0.33242  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2224 -- Train Loss: 0.33116  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 2225 -- Train Loss: 0.33230  Validation Loss: 0.42912\n",
      "t: 10 EPOCH 2226 -- Train Loss: 0.33065  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 2227 -- Train Loss: 0.33129  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 2228 -- Train Loss: 0.33196  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 2229 -- Train Loss: 0.33162  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 2230 -- Train Loss: 0.33157  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 2231 -- Train Loss: 0.33235  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 2232 -- Train Loss: 0.33084  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2233 -- Train Loss: 0.33132  Validation Loss: 0.42925\n",
      "t: 10 EPOCH 2234 -- Train Loss: 0.33190  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 2235 -- Train Loss: 0.33150  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 2236 -- Train Loss: 0.33091  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 2237 -- Train Loss: 0.33116  Validation Loss: 0.42939\n",
      "t: 10 EPOCH 2238 -- Train Loss: 0.33166  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 2239 -- Train Loss: 0.33210  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 2240 -- Train Loss: 0.33173  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 2241 -- Train Loss: 0.33109  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 2242 -- Train Loss: 0.33190  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 2243 -- Train Loss: 0.33053  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 2244 -- Train Loss: 0.33226  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 2245 -- Train Loss: 0.33188  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 2246 -- Train Loss: 0.33258  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 2247 -- Train Loss: 0.33166  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 2248 -- Train Loss: 0.33160  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 2249 -- Train Loss: 0.33135  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 2250 -- Train Loss: 0.33155  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 2251 -- Train Loss: 0.33216  Validation Loss: 0.42924\n",
      "t: 10 EPOCH 2252 -- Train Loss: 0.33210  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 2253 -- Train Loss: 0.33061  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 2254 -- Train Loss: 0.33229  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 2255 -- Train Loss: 0.33150  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 2256 -- Train Loss: 0.33090  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 2257 -- Train Loss: 0.33135  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 2258 -- Train Loss: 0.33124  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 2259 -- Train Loss: 0.33143  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2260 -- Train Loss: 0.33154  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 2261 -- Train Loss: 0.33054  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 2262 -- Train Loss: 0.33144  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 2263 -- Train Loss: 0.33113  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 2264 -- Train Loss: 0.33170  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 2265 -- Train Loss: 0.33218  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 2266 -- Train Loss: 0.33193  Validation Loss: 0.43228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2267 -- Train Loss: 0.33133  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2268 -- Train Loss: 0.33192  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 2269 -- Train Loss: 0.33176  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 2270 -- Train Loss: 0.33176  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2271 -- Train Loss: 0.33187  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2272 -- Train Loss: 0.33106  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 2273 -- Train Loss: 0.33173  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2274 -- Train Loss: 0.33179  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 2275 -- Train Loss: 0.33228  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 2276 -- Train Loss: 0.33202  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 2277 -- Train Loss: 0.33172  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 2278 -- Train Loss: 0.33173  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 2279 -- Train Loss: 0.33099  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 2280 -- Train Loss: 0.33040  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 2281 -- Train Loss: 0.33115  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 2282 -- Train Loss: 0.33139  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2283 -- Train Loss: 0.33072  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 2284 -- Train Loss: 0.33067  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2285 -- Train Loss: 0.33101  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 2286 -- Train Loss: 0.33175  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 2287 -- Train Loss: 0.33138  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2288 -- Train Loss: 0.33238  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 2289 -- Train Loss: 0.33134  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2290 -- Train Loss: 0.33140  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 2291 -- Train Loss: 0.33157  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2292 -- Train Loss: 0.33089  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 2293 -- Train Loss: 0.33185  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 2294 -- Train Loss: 0.33046  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 2295 -- Train Loss: 0.33235  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2296 -- Train Loss: 0.32980  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 2297 -- Train Loss: 0.33189  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 2298 -- Train Loss: 0.33096  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 2299 -- Train Loss: 0.33138  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2300 -- Train Loss: 0.33174  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 2301 -- Train Loss: 0.33194  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 2302 -- Train Loss: 0.33252  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 2303 -- Train Loss: 0.33200  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 2304 -- Train Loss: 0.33185  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 2305 -- Train Loss: 0.33164  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 2306 -- Train Loss: 0.33067  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2307 -- Train Loss: 0.33192  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 2308 -- Train Loss: 0.33173  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 2309 -- Train Loss: 0.33072  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 2310 -- Train Loss: 0.33138  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2311 -- Train Loss: 0.33138  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 2312 -- Train Loss: 0.33151  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 2313 -- Train Loss: 0.33058  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 2314 -- Train Loss: 0.33131  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 2315 -- Train Loss: 0.33180  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2316 -- Train Loss: 0.33162  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 2317 -- Train Loss: 0.33165  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 2318 -- Train Loss: 0.33183  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 2319 -- Train Loss: 0.33135  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 2320 -- Train Loss: 0.33127  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 2321 -- Train Loss: 0.33109  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 2322 -- Train Loss: 0.33167  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 2323 -- Train Loss: 0.33183  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 2324 -- Train Loss: 0.33208  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 2325 -- Train Loss: 0.33119  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 2326 -- Train Loss: 0.33084  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 2327 -- Train Loss: 0.33099  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 2328 -- Train Loss: 0.33253  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 2329 -- Train Loss: 0.33137  Validation Loss: 0.42973\n",
      "t: 10 EPOCH 2330 -- Train Loss: 0.33186  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 2331 -- Train Loss: 0.33188  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 2332 -- Train Loss: 0.33093  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 2333 -- Train Loss: 0.33156  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2334 -- Train Loss: 0.33244  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 2335 -- Train Loss: 0.33163  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 2336 -- Train Loss: 0.33221  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 2337 -- Train Loss: 0.33234  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 2338 -- Train Loss: 0.33115  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 2339 -- Train Loss: 0.33128  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 2340 -- Train Loss: 0.33215  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 2341 -- Train Loss: 0.33160  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 2342 -- Train Loss: 0.33151  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 2343 -- Train Loss: 0.33178  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 2344 -- Train Loss: 0.33174  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 2345 -- Train Loss: 0.33098  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 2346 -- Train Loss: 0.33225  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 2347 -- Train Loss: 0.33135  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 2348 -- Train Loss: 0.33169  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2349 -- Train Loss: 0.33127  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 2350 -- Train Loss: 0.33202  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 2351 -- Train Loss: 0.33093  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 2352 -- Train Loss: 0.33152  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 2353 -- Train Loss: 0.33218  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 2354 -- Train Loss: 0.33167  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 2355 -- Train Loss: 0.33171  Validation Loss: 0.42938\n",
      "t: 10 EPOCH 2356 -- Train Loss: 0.33159  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 2357 -- Train Loss: 0.33231  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 2358 -- Train Loss: 0.33184  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 2359 -- Train Loss: 0.33139  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 2360 -- Train Loss: 0.33244  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 2361 -- Train Loss: 0.33081  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 2362 -- Train Loss: 0.33136  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 2363 -- Train Loss: 0.33116  Validation Loss: 0.42920\n",
      "t: 10 EPOCH 2364 -- Train Loss: 0.33215  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 2365 -- Train Loss: 0.33123  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 2366 -- Train Loss: 0.33315  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2367 -- Train Loss: 0.33124  Validation Loss: 0.42990\n",
      "t: 10 EPOCH 2368 -- Train Loss: 0.33225  Validation Loss: 0.42903\n",
      "t: 10 EPOCH 2369 -- Train Loss: 0.33139  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 2370 -- Train Loss: 0.33216  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2371 -- Train Loss: 0.33053  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 2372 -- Train Loss: 0.33212  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 2373 -- Train Loss: 0.33099  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 2374 -- Train Loss: 0.33195  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 2375 -- Train Loss: 0.33125  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2376 -- Train Loss: 0.33110  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 2377 -- Train Loss: 0.33205  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 2378 -- Train Loss: 0.33173  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 2379 -- Train Loss: 0.33167  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 2380 -- Train Loss: 0.33148  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 2381 -- Train Loss: 0.33147  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 2382 -- Train Loss: 0.33105  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 2383 -- Train Loss: 0.33109  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2384 -- Train Loss: 0.33154  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2385 -- Train Loss: 0.33139  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 2386 -- Train Loss: 0.33109  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 2387 -- Train Loss: 0.33155  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 2388 -- Train Loss: 0.33169  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 2389 -- Train Loss: 0.33089  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 2390 -- Train Loss: 0.33120  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2391 -- Train Loss: 0.33104  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 2392 -- Train Loss: 0.33219  Validation Loss: 0.42998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2393 -- Train Loss: 0.33049  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 2394 -- Train Loss: 0.33220  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 2395 -- Train Loss: 0.33162  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 2396 -- Train Loss: 0.33163  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 2397 -- Train Loss: 0.33094  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 2398 -- Train Loss: 0.33123  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 2399 -- Train Loss: 0.33133  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 2400 -- Train Loss: 0.33123  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 2401 -- Train Loss: 0.33172  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2402 -- Train Loss: 0.33157  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 2403 -- Train Loss: 0.33190  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2404 -- Train Loss: 0.33124  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 2405 -- Train Loss: 0.33253  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 2406 -- Train Loss: 0.33139  Validation Loss: 0.43023\n",
      "t: 10 EPOCH 2407 -- Train Loss: 0.33106  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 2408 -- Train Loss: 0.33107  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2409 -- Train Loss: 0.33170  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 2410 -- Train Loss: 0.33141  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 2411 -- Train Loss: 0.33134  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2412 -- Train Loss: 0.33175  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 2413 -- Train Loss: 0.33256  Validation Loss: 0.43001\n",
      "t: 10 EPOCH 2414 -- Train Loss: 0.33222  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 2415 -- Train Loss: 0.33143  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 2416 -- Train Loss: 0.33033  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 2417 -- Train Loss: 0.33134  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 2418 -- Train Loss: 0.33058  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 2419 -- Train Loss: 0.33202  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 2420 -- Train Loss: 0.33188  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 2421 -- Train Loss: 0.33152  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2422 -- Train Loss: 0.33105  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 2423 -- Train Loss: 0.33050  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 2424 -- Train Loss: 0.33175  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 2425 -- Train Loss: 0.33149  Validation Loss: 0.42948\n",
      "t: 10 EPOCH 2426 -- Train Loss: 0.33133  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 2427 -- Train Loss: 0.33137  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 2428 -- Train Loss: 0.33104  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2429 -- Train Loss: 0.33180  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 2430 -- Train Loss: 0.33193  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 2431 -- Train Loss: 0.33182  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 2432 -- Train Loss: 0.33122  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 2433 -- Train Loss: 0.33216  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 2434 -- Train Loss: 0.33103  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 2435 -- Train Loss: 0.33174  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 2436 -- Train Loss: 0.33265  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2437 -- Train Loss: 0.33140  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 2438 -- Train Loss: 0.33218  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 2439 -- Train Loss: 0.33191  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 2440 -- Train Loss: 0.33255  Validation Loss: 0.42963\n",
      "t: 10 EPOCH 2441 -- Train Loss: 0.33165  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 2442 -- Train Loss: 0.33117  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 2443 -- Train Loss: 0.33161  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 2444 -- Train Loss: 0.33107  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 2445 -- Train Loss: 0.33121  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 2446 -- Train Loss: 0.33199  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 2447 -- Train Loss: 0.33107  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 2448 -- Train Loss: 0.33147  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 2449 -- Train Loss: 0.33164  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 2450 -- Train Loss: 0.33134  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 2451 -- Train Loss: 0.33196  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 2452 -- Train Loss: 0.33144  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 2453 -- Train Loss: 0.33166  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 2454 -- Train Loss: 0.33171  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 2455 -- Train Loss: 0.33162  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 2456 -- Train Loss: 0.33147  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 2457 -- Train Loss: 0.33185  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 2458 -- Train Loss: 0.33198  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 2459 -- Train Loss: 0.33204  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 2460 -- Train Loss: 0.33284  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 2461 -- Train Loss: 0.33135  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 2462 -- Train Loss: 0.33132  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 2463 -- Train Loss: 0.33225  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 2464 -- Train Loss: 0.33234  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2465 -- Train Loss: 0.33152  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2466 -- Train Loss: 0.33178  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 2467 -- Train Loss: 0.33098  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2468 -- Train Loss: 0.33218  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 2469 -- Train Loss: 0.33105  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 2470 -- Train Loss: 0.33250  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 2471 -- Train Loss: 0.33063  Validation Loss: 0.42966\n",
      "t: 10 EPOCH 2472 -- Train Loss: 0.33152  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2473 -- Train Loss: 0.33130  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 2474 -- Train Loss: 0.33149  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 2475 -- Train Loss: 0.33149  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 2476 -- Train Loss: 0.33127  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 2477 -- Train Loss: 0.33210  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 2478 -- Train Loss: 0.33065  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 2479 -- Train Loss: 0.33208  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2480 -- Train Loss: 0.33047  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2481 -- Train Loss: 0.33144  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 2482 -- Train Loss: 0.33043  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 2483 -- Train Loss: 0.33173  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 2484 -- Train Loss: 0.33147  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2485 -- Train Loss: 0.33161  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 2486 -- Train Loss: 0.33127  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 2487 -- Train Loss: 0.33040  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 2488 -- Train Loss: 0.33120  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 2489 -- Train Loss: 0.33108  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 2490 -- Train Loss: 0.33119  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 2491 -- Train Loss: 0.33066  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 2492 -- Train Loss: 0.33149  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 2493 -- Train Loss: 0.33133  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 2494 -- Train Loss: 0.33134  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2495 -- Train Loss: 0.33039  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 2496 -- Train Loss: 0.33174  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 2497 -- Train Loss: 0.33094  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 2498 -- Train Loss: 0.33118  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2499 -- Train Loss: 0.33077  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 2500 -- Train Loss: 0.33082  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 2501 -- Train Loss: 0.33130  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 2502 -- Train Loss: 0.33080  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 2503 -- Train Loss: 0.33085  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 2504 -- Train Loss: 0.33012  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 2505 -- Train Loss: 0.33024  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 2506 -- Train Loss: 0.33080  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 2507 -- Train Loss: 0.33087  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 2508 -- Train Loss: 0.33044  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 2509 -- Train Loss: 0.33142  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 2510 -- Train Loss: 0.33206  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2511 -- Train Loss: 0.33117  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 2512 -- Train Loss: 0.33132  Validation Loss: 0.42930\n",
      "t: 10 EPOCH 2513 -- Train Loss: 0.33055  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 2514 -- Train Loss: 0.33125  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 2515 -- Train Loss: 0.33125  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 2516 -- Train Loss: 0.33154  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 2517 -- Train Loss: 0.33082  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 2518 -- Train Loss: 0.33226  Validation Loss: 0.43158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2519 -- Train Loss: 0.33128  Validation Loss: 0.42941\n",
      "t: 10 EPOCH 2520 -- Train Loss: 0.33213  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 2521 -- Train Loss: 0.33156  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 2522 -- Train Loss: 0.33108  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 2523 -- Train Loss: 0.33112  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 2524 -- Train Loss: 0.33117  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 2525 -- Train Loss: 0.33040  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 2526 -- Train Loss: 0.33093  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 2527 -- Train Loss: 0.33098  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 2528 -- Train Loss: 0.33034  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2529 -- Train Loss: 0.33148  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 2530 -- Train Loss: 0.33044  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 2531 -- Train Loss: 0.33159  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 2532 -- Train Loss: 0.33101  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 2533 -- Train Loss: 0.33122  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 2534 -- Train Loss: 0.33111  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 2535 -- Train Loss: 0.33171  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 2536 -- Train Loss: 0.33121  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 2537 -- Train Loss: 0.33235  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 2538 -- Train Loss: 0.33095  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 2539 -- Train Loss: 0.33079  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 2540 -- Train Loss: 0.33169  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 2541 -- Train Loss: 0.33195  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 2542 -- Train Loss: 0.33198  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 2543 -- Train Loss: 0.33175  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 2544 -- Train Loss: 0.33150  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 2545 -- Train Loss: 0.33079  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 2546 -- Train Loss: 0.33136  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 2547 -- Train Loss: 0.33215  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 2548 -- Train Loss: 0.33199  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 2549 -- Train Loss: 0.33088  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 2550 -- Train Loss: 0.33189  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2551 -- Train Loss: 0.33108  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 2552 -- Train Loss: 0.33095  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 2553 -- Train Loss: 0.33215  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 2554 -- Train Loss: 0.33087  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 2555 -- Train Loss: 0.33211  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2556 -- Train Loss: 0.33162  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2557 -- Train Loss: 0.33194  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 2558 -- Train Loss: 0.33096  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2559 -- Train Loss: 0.33166  Validation Loss: 0.42907\n",
      "t: 10 EPOCH 2560 -- Train Loss: 0.33140  Validation Loss: 0.42964\n",
      "t: 10 EPOCH 2561 -- Train Loss: 0.33224  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 2562 -- Train Loss: 0.33157  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 2563 -- Train Loss: 0.33134  Validation Loss: 0.42908\n",
      "t: 10 EPOCH 2564 -- Train Loss: 0.33127  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2565 -- Train Loss: 0.33178  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 2566 -- Train Loss: 0.33168  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 2567 -- Train Loss: 0.33172  Validation Loss: 0.42965\n",
      "t: 10 EPOCH 2568 -- Train Loss: 0.33186  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 2569 -- Train Loss: 0.33137  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 2570 -- Train Loss: 0.33266  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 2571 -- Train Loss: 0.33157  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 2572 -- Train Loss: 0.33251  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2573 -- Train Loss: 0.33202  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 2574 -- Train Loss: 0.33212  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 2575 -- Train Loss: 0.33167  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 2576 -- Train Loss: 0.33170  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 2577 -- Train Loss: 0.33202  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 2578 -- Train Loss: 0.33227  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 2579 -- Train Loss: 0.33243  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 2580 -- Train Loss: 0.33203  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2581 -- Train Loss: 0.33137  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 2582 -- Train Loss: 0.33147  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 2583 -- Train Loss: 0.33113  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 2584 -- Train Loss: 0.33116  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 2585 -- Train Loss: 0.33257  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 2586 -- Train Loss: 0.33227  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 2587 -- Train Loss: 0.33192  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 2588 -- Train Loss: 0.33107  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 2589 -- Train Loss: 0.33112  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2590 -- Train Loss: 0.33039  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 2591 -- Train Loss: 0.33174  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 2592 -- Train Loss: 0.33117  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 2593 -- Train Loss: 0.33249  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 2594 -- Train Loss: 0.33065  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 2595 -- Train Loss: 0.33119  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 2596 -- Train Loss: 0.33094  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 2597 -- Train Loss: 0.33223  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 2598 -- Train Loss: 0.33066  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 2599 -- Train Loss: 0.33187  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 2600 -- Train Loss: 0.33114  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 2601 -- Train Loss: 0.33190  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 2602 -- Train Loss: 0.33102  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 2603 -- Train Loss: 0.33026  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 2604 -- Train Loss: 0.33162  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2605 -- Train Loss: 0.33133  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 2606 -- Train Loss: 0.33108  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 2607 -- Train Loss: 0.33152  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 2608 -- Train Loss: 0.33161  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2609 -- Train Loss: 0.33146  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 2610 -- Train Loss: 0.33102  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 2611 -- Train Loss: 0.33131  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 2612 -- Train Loss: 0.33123  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2613 -- Train Loss: 0.33079  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 2614 -- Train Loss: 0.33249  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 2615 -- Train Loss: 0.33114  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 2616 -- Train Loss: 0.33142  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 2617 -- Train Loss: 0.33198  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2618 -- Train Loss: 0.33107  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 2619 -- Train Loss: 0.33081  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2620 -- Train Loss: 0.33068  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2621 -- Train Loss: 0.33056  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 2622 -- Train Loss: 0.33076  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 2623 -- Train Loss: 0.33084  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 2624 -- Train Loss: 0.33129  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 2625 -- Train Loss: 0.33169  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 2626 -- Train Loss: 0.33122  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 2627 -- Train Loss: 0.33055  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 2628 -- Train Loss: 0.33133  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 2629 -- Train Loss: 0.33138  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 2630 -- Train Loss: 0.33170  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 2631 -- Train Loss: 0.33096  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2632 -- Train Loss: 0.33085  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 2633 -- Train Loss: 0.33064  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 2634 -- Train Loss: 0.33123  Validation Loss: 0.42922\n",
      "t: 10 EPOCH 2635 -- Train Loss: 0.33037  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 2636 -- Train Loss: 0.33234  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 2637 -- Train Loss: 0.33008  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 2638 -- Train Loss: 0.33190  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 2639 -- Train Loss: 0.33116  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2640 -- Train Loss: 0.33201  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 2641 -- Train Loss: 0.33092  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 2642 -- Train Loss: 0.33158  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 2643 -- Train Loss: 0.33066  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 2644 -- Train Loss: 0.33110  Validation Loss: 0.43225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2645 -- Train Loss: 0.33134  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2646 -- Train Loss: 0.33050  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 2647 -- Train Loss: 0.33100  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 2648 -- Train Loss: 0.32986  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2649 -- Train Loss: 0.33092  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 2650 -- Train Loss: 0.33091  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 2651 -- Train Loss: 0.33132  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 2652 -- Train Loss: 0.33064  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 2653 -- Train Loss: 0.33135  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 2654 -- Train Loss: 0.33023  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 2655 -- Train Loss: 0.33079  Validation Loss: 0.42979\n",
      "t: 10 EPOCH 2656 -- Train Loss: 0.33132  Validation Loss: 0.42953\n",
      "t: 10 EPOCH 2657 -- Train Loss: 0.33089  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 2658 -- Train Loss: 0.33151  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2659 -- Train Loss: 0.33096  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 2660 -- Train Loss: 0.33203  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 2661 -- Train Loss: 0.33016  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 2662 -- Train Loss: 0.33131  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 2663 -- Train Loss: 0.33125  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 2664 -- Train Loss: 0.33124  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 2665 -- Train Loss: 0.33032  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 2666 -- Train Loss: 0.33123  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 2667 -- Train Loss: 0.33158  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2668 -- Train Loss: 0.33064  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 2669 -- Train Loss: 0.33114  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 2670 -- Train Loss: 0.33116  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 2671 -- Train Loss: 0.33020  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 2672 -- Train Loss: 0.33060  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 2673 -- Train Loss: 0.33147  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 2674 -- Train Loss: 0.33129  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 2675 -- Train Loss: 0.33080  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 2676 -- Train Loss: 0.33132  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2677 -- Train Loss: 0.33218  Validation Loss: 0.42989\n",
      "t: 10 EPOCH 2678 -- Train Loss: 0.33155  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 2679 -- Train Loss: 0.33133  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 2680 -- Train Loss: 0.33053  Validation Loss: 0.42913\n",
      "t: 10 EPOCH 2681 -- Train Loss: 0.33147  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2682 -- Train Loss: 0.33176  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2683 -- Train Loss: 0.33101  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 2684 -- Train Loss: 0.33102  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 2685 -- Train Loss: 0.33090  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 2686 -- Train Loss: 0.33101  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2687 -- Train Loss: 0.33043  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 2688 -- Train Loss: 0.33131  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 2689 -- Train Loss: 0.33174  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 2690 -- Train Loss: 0.33213  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2691 -- Train Loss: 0.33171  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 2692 -- Train Loss: 0.33164  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 2693 -- Train Loss: 0.33143  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 2694 -- Train Loss: 0.33161  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2695 -- Train Loss: 0.33085  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 2696 -- Train Loss: 0.33178  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 2697 -- Train Loss: 0.33162  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 2698 -- Train Loss: 0.33165  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 2699 -- Train Loss: 0.33122  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 2700 -- Train Loss: 0.33137  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 2701 -- Train Loss: 0.33090  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2702 -- Train Loss: 0.33109  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 2703 -- Train Loss: 0.33225  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 2704 -- Train Loss: 0.33152  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 2705 -- Train Loss: 0.33224  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 2706 -- Train Loss: 0.33180  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 2707 -- Train Loss: 0.33136  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 2708 -- Train Loss: 0.33125  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 2709 -- Train Loss: 0.33128  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 2710 -- Train Loss: 0.33131  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 2711 -- Train Loss: 0.33081  Validation Loss: 0.42973\n",
      "t: 10 EPOCH 2712 -- Train Loss: 0.33213  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 2713 -- Train Loss: 0.33140  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 2714 -- Train Loss: 0.33125  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 2715 -- Train Loss: 0.33085  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 2716 -- Train Loss: 0.33164  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2717 -- Train Loss: 0.32998  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 2718 -- Train Loss: 0.33187  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 2719 -- Train Loss: 0.33141  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 2720 -- Train Loss: 0.33170  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 2721 -- Train Loss: 0.33080  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 2722 -- Train Loss: 0.33103  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 2723 -- Train Loss: 0.33082  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 2724 -- Train Loss: 0.33149  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 2725 -- Train Loss: 0.33186  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 2726 -- Train Loss: 0.33113  Validation Loss: 0.42947\n",
      "t: 10 EPOCH 2727 -- Train Loss: 0.33120  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 2728 -- Train Loss: 0.33184  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2729 -- Train Loss: 0.33128  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2730 -- Train Loss: 0.33185  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 2731 -- Train Loss: 0.33109  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 2732 -- Train Loss: 0.33205  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2733 -- Train Loss: 0.33043  Validation Loss: 0.42929\n",
      "t: 10 EPOCH 2734 -- Train Loss: 0.33069  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 2735 -- Train Loss: 0.33094  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 2736 -- Train Loss: 0.33112  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 2737 -- Train Loss: 0.33143  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2738 -- Train Loss: 0.33107  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 2739 -- Train Loss: 0.33129  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 2740 -- Train Loss: 0.33125  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 2741 -- Train Loss: 0.33128  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 2742 -- Train Loss: 0.33106  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 2743 -- Train Loss: 0.33176  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 2744 -- Train Loss: 0.33102  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 2745 -- Train Loss: 0.33127  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 2746 -- Train Loss: 0.33159  Validation Loss: 0.42981\n",
      "t: 10 EPOCH 2747 -- Train Loss: 0.33132  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 2748 -- Train Loss: 0.33058  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 2749 -- Train Loss: 0.33115  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 2750 -- Train Loss: 0.33137  Validation Loss: 0.42890\n",
      "t: 10 EPOCH 2751 -- Train Loss: 0.33055  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2752 -- Train Loss: 0.33150  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 2753 -- Train Loss: 0.33156  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 2754 -- Train Loss: 0.33176  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2755 -- Train Loss: 0.33061  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 2756 -- Train Loss: 0.33159  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 2757 -- Train Loss: 0.33159  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2758 -- Train Loss: 0.33060  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 2759 -- Train Loss: 0.33111  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 2760 -- Train Loss: 0.33111  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 2761 -- Train Loss: 0.33110  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 2762 -- Train Loss: 0.33085  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 2763 -- Train Loss: 0.33164  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 2764 -- Train Loss: 0.33111  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 2765 -- Train Loss: 0.33153  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 2766 -- Train Loss: 0.33144  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 2767 -- Train Loss: 0.33219  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 2768 -- Train Loss: 0.33073  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2769 -- Train Loss: 0.33172  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 2770 -- Train Loss: 0.33196  Validation Loss: 0.42950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2771 -- Train Loss: 0.33096  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 2772 -- Train Loss: 0.33176  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 2773 -- Train Loss: 0.33108  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 2774 -- Train Loss: 0.33155  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 2775 -- Train Loss: 0.32968  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 2776 -- Train Loss: 0.33136  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 2777 -- Train Loss: 0.33174  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 2778 -- Train Loss: 0.33003  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 2779 -- Train Loss: 0.33096  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 2780 -- Train Loss: 0.33116  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 2781 -- Train Loss: 0.33193  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 2782 -- Train Loss: 0.33038  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 2783 -- Train Loss: 0.33031  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 2784 -- Train Loss: 0.33157  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 2785 -- Train Loss: 0.33043  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 2786 -- Train Loss: 0.33034  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2787 -- Train Loss: 0.33192  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 2788 -- Train Loss: 0.33117  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 2789 -- Train Loss: 0.33198  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 2790 -- Train Loss: 0.32956  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 2791 -- Train Loss: 0.33120  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 2792 -- Train Loss: 0.33135  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 2793 -- Train Loss: 0.33160  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2794 -- Train Loss: 0.33108  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 2795 -- Train Loss: 0.33175  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 2796 -- Train Loss: 0.33064  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 2797 -- Train Loss: 0.33134  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 2798 -- Train Loss: 0.33093  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 2799 -- Train Loss: 0.33105  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 2800 -- Train Loss: 0.33140  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 2801 -- Train Loss: 0.33204  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 2802 -- Train Loss: 0.33046  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 2803 -- Train Loss: 0.33090  Validation Loss: 0.43036\n",
      "t: 10 EPOCH 2804 -- Train Loss: 0.33126  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 2805 -- Train Loss: 0.33176  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2806 -- Train Loss: 0.33107  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 2807 -- Train Loss: 0.33149  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 2808 -- Train Loss: 0.33046  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 2809 -- Train Loss: 0.33161  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 2810 -- Train Loss: 0.33092  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 2811 -- Train Loss: 0.33205  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 2812 -- Train Loss: 0.33094  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 2813 -- Train Loss: 0.33123  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 2814 -- Train Loss: 0.33203  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 2815 -- Train Loss: 0.33201  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 2816 -- Train Loss: 0.33018  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2817 -- Train Loss: 0.33218  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 2818 -- Train Loss: 0.33085  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 2819 -- Train Loss: 0.33201  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 2820 -- Train Loss: 0.33132  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 2821 -- Train Loss: 0.33138  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 2822 -- Train Loss: 0.33116  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 2823 -- Train Loss: 0.33207  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2824 -- Train Loss: 0.33082  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 2825 -- Train Loss: 0.33052  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2826 -- Train Loss: 0.33062  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 2827 -- Train Loss: 0.33135  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 2828 -- Train Loss: 0.33063  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 2829 -- Train Loss: 0.33166  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2830 -- Train Loss: 0.33194  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 2831 -- Train Loss: 0.33183  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 2832 -- Train Loss: 0.33159  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 2833 -- Train Loss: 0.33152  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 2834 -- Train Loss: 0.33090  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 2835 -- Train Loss: 0.33088  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 2836 -- Train Loss: 0.33099  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 2837 -- Train Loss: 0.33081  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 2838 -- Train Loss: 0.33065  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 2839 -- Train Loss: 0.33220  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 2840 -- Train Loss: 0.33088  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 2841 -- Train Loss: 0.33037  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 2842 -- Train Loss: 0.33127  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 2843 -- Train Loss: 0.33113  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 2844 -- Train Loss: 0.33106  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 2845 -- Train Loss: 0.33114  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 2846 -- Train Loss: 0.33110  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 2847 -- Train Loss: 0.33155  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 2848 -- Train Loss: 0.33171  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 2849 -- Train Loss: 0.33039  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 2850 -- Train Loss: 0.33146  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 2851 -- Train Loss: 0.33129  Validation Loss: 0.43013\n",
      "t: 10 EPOCH 2852 -- Train Loss: 0.33002  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 2853 -- Train Loss: 0.33196  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 2854 -- Train Loss: 0.33131  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2855 -- Train Loss: 0.33129  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 2856 -- Train Loss: 0.33110  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 2857 -- Train Loss: 0.33153  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 2858 -- Train Loss: 0.33121  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 2859 -- Train Loss: 0.33065  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 2860 -- Train Loss: 0.33111  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 2861 -- Train Loss: 0.33062  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 2862 -- Train Loss: 0.33126  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 2863 -- Train Loss: 0.33175  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 2864 -- Train Loss: 0.33070  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 2865 -- Train Loss: 0.33126  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2866 -- Train Loss: 0.33053  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 2867 -- Train Loss: 0.33115  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 2868 -- Train Loss: 0.33011  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 2869 -- Train Loss: 0.33034  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 2870 -- Train Loss: 0.33146  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2871 -- Train Loss: 0.33055  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 2872 -- Train Loss: 0.33152  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 2873 -- Train Loss: 0.32993  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 2874 -- Train Loss: 0.33016  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 2875 -- Train Loss: 0.32988  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 2876 -- Train Loss: 0.33051  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 2877 -- Train Loss: 0.33079  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 2878 -- Train Loss: 0.33165  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 2879 -- Train Loss: 0.33069  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 2880 -- Train Loss: 0.33135  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 2881 -- Train Loss: 0.33203  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 2882 -- Train Loss: 0.33115  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2883 -- Train Loss: 0.33045  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 2884 -- Train Loss: 0.33167  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 2885 -- Train Loss: 0.33083  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 2886 -- Train Loss: 0.33083  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 2887 -- Train Loss: 0.33028  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 2888 -- Train Loss: 0.33119  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 2889 -- Train Loss: 0.33084  Validation Loss: 0.42999\n",
      "t: 10 EPOCH 2890 -- Train Loss: 0.33108  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2891 -- Train Loss: 0.33056  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 2892 -- Train Loss: 0.33218  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 2893 -- Train Loss: 0.33093  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 2894 -- Train Loss: 0.33106  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 2895 -- Train Loss: 0.33070  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2896 -- Train Loss: 0.33083  Validation Loss: 0.43167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 2897 -- Train Loss: 0.33105  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 2898 -- Train Loss: 0.33140  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 2899 -- Train Loss: 0.33074  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 2900 -- Train Loss: 0.33120  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 2901 -- Train Loss: 0.33061  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 2902 -- Train Loss: 0.33171  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2903 -- Train Loss: 0.33145  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 2904 -- Train Loss: 0.33105  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 2905 -- Train Loss: 0.33122  Validation Loss: 0.42996\n",
      "t: 10 EPOCH 2906 -- Train Loss: 0.33101  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 2907 -- Train Loss: 0.33187  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2908 -- Train Loss: 0.33077  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 2909 -- Train Loss: 0.33077  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 2910 -- Train Loss: 0.33102  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 2911 -- Train Loss: 0.33183  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 2912 -- Train Loss: 0.33134  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 2913 -- Train Loss: 0.33200  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 2914 -- Train Loss: 0.33148  Validation Loss: 0.42988\n",
      "t: 10 EPOCH 2915 -- Train Loss: 0.33172  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 2916 -- Train Loss: 0.33080  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 2917 -- Train Loss: 0.33119  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 2918 -- Train Loss: 0.33125  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 2919 -- Train Loss: 0.33111  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 2920 -- Train Loss: 0.33143  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 2921 -- Train Loss: 0.33119  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 2922 -- Train Loss: 0.33099  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 2923 -- Train Loss: 0.33115  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 2924 -- Train Loss: 0.33073  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2925 -- Train Loss: 0.33141  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 2926 -- Train Loss: 0.33098  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 2927 -- Train Loss: 0.33069  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 2928 -- Train Loss: 0.33128  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 2929 -- Train Loss: 0.33152  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 2930 -- Train Loss: 0.33001  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 2931 -- Train Loss: 0.33161  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 2932 -- Train Loss: 0.33011  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 2933 -- Train Loss: 0.33143  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 2934 -- Train Loss: 0.33121  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2935 -- Train Loss: 0.33051  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 2936 -- Train Loss: 0.33080  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 2937 -- Train Loss: 0.33000  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 2938 -- Train Loss: 0.33045  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 2939 -- Train Loss: 0.33188  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 2940 -- Train Loss: 0.33172  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 2941 -- Train Loss: 0.33066  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 2942 -- Train Loss: 0.33086  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 2943 -- Train Loss: 0.33152  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 2944 -- Train Loss: 0.33151  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 2945 -- Train Loss: 0.33160  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 2946 -- Train Loss: 0.33125  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 2947 -- Train Loss: 0.33141  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 2948 -- Train Loss: 0.33123  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 2949 -- Train Loss: 0.33154  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 2950 -- Train Loss: 0.33147  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 2951 -- Train Loss: 0.33035  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 2952 -- Train Loss: 0.33182  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 2953 -- Train Loss: 0.33159  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 2954 -- Train Loss: 0.33130  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2955 -- Train Loss: 0.33086  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 2956 -- Train Loss: 0.33140  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 2957 -- Train Loss: 0.33138  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 2958 -- Train Loss: 0.33075  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 2959 -- Train Loss: 0.33150  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 2960 -- Train Loss: 0.33084  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 2961 -- Train Loss: 0.33147  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 2962 -- Train Loss: 0.33109  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 2963 -- Train Loss: 0.33107  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 2964 -- Train Loss: 0.33066  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 2965 -- Train Loss: 0.33091  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 2966 -- Train Loss: 0.33056  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 2967 -- Train Loss: 0.33095  Validation Loss: 0.42958\n",
      "t: 10 EPOCH 2968 -- Train Loss: 0.33044  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 2969 -- Train Loss: 0.33099  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 2970 -- Train Loss: 0.33140  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2971 -- Train Loss: 0.33058  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 2972 -- Train Loss: 0.33077  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 2973 -- Train Loss: 0.33032  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 2974 -- Train Loss: 0.33059  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 2975 -- Train Loss: 0.33031  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 2976 -- Train Loss: 0.33144  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 2977 -- Train Loss: 0.33169  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 2978 -- Train Loss: 0.33063  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 2979 -- Train Loss: 0.33081  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 2980 -- Train Loss: 0.33066  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 2981 -- Train Loss: 0.33153  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 2982 -- Train Loss: 0.33078  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 2983 -- Train Loss: 0.33141  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 2984 -- Train Loss: 0.33135  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 2985 -- Train Loss: 0.33016  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 2986 -- Train Loss: 0.33118  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 2987 -- Train Loss: 0.33150  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 2988 -- Train Loss: 0.33199  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 2989 -- Train Loss: 0.33091  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 2990 -- Train Loss: 0.33085  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 2991 -- Train Loss: 0.33148  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 2992 -- Train Loss: 0.33104  Validation Loss: 0.42962\n",
      "t: 10 EPOCH 2993 -- Train Loss: 0.33087  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 2994 -- Train Loss: 0.33008  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 2995 -- Train Loss: 0.33158  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 2996 -- Train Loss: 0.33111  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 2997 -- Train Loss: 0.33109  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 2998 -- Train Loss: 0.33040  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 2999 -- Train Loss: 0.33025  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 3000 -- Train Loss: 0.33070  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 3001 -- Train Loss: 0.33068  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 3002 -- Train Loss: 0.33126  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 3003 -- Train Loss: 0.33083  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 3004 -- Train Loss: 0.32989  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 3005 -- Train Loss: 0.33168  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 3006 -- Train Loss: 0.33008  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 3007 -- Train Loss: 0.33059  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 3008 -- Train Loss: 0.33096  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 3009 -- Train Loss: 0.33064  Validation Loss: 0.43006\n",
      "t: 10 EPOCH 3010 -- Train Loss: 0.33105  Validation Loss: 0.42957\n",
      "t: 10 EPOCH 3011 -- Train Loss: 0.32998  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 3012 -- Train Loss: 0.33035  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 3013 -- Train Loss: 0.33056  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 3014 -- Train Loss: 0.33106  Validation Loss: 0.42961\n",
      "t: 10 EPOCH 3015 -- Train Loss: 0.33147  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 3016 -- Train Loss: 0.33025  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 3017 -- Train Loss: 0.33131  Validation Loss: 0.43050\n",
      "t: 10 EPOCH 3018 -- Train Loss: 0.33013  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 3019 -- Train Loss: 0.33096  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 3020 -- Train Loss: 0.33083  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 3021 -- Train Loss: 0.33172  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 3022 -- Train Loss: 0.33082  Validation Loss: 0.42990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3023 -- Train Loss: 0.33131  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 3024 -- Train Loss: 0.33076  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 3025 -- Train Loss: 0.33053  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 3026 -- Train Loss: 0.33055  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3027 -- Train Loss: 0.33107  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 3028 -- Train Loss: 0.33096  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 3029 -- Train Loss: 0.33036  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 3030 -- Train Loss: 0.33035  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 3031 -- Train Loss: 0.33205  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 3032 -- Train Loss: 0.33117  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 3033 -- Train Loss: 0.33055  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 3034 -- Train Loss: 0.33030  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 3035 -- Train Loss: 0.33130  Validation Loss: 0.42885\n",
      "t: 10 EPOCH 3036 -- Train Loss: 0.33038  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 3037 -- Train Loss: 0.33100  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 3038 -- Train Loss: 0.33112  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3039 -- Train Loss: 0.33077  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 3040 -- Train Loss: 0.33036  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 3041 -- Train Loss: 0.33049  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 3042 -- Train Loss: 0.33074  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 3043 -- Train Loss: 0.32993  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3044 -- Train Loss: 0.33035  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 3045 -- Train Loss: 0.33064  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 3046 -- Train Loss: 0.33058  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 3047 -- Train Loss: 0.33032  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 3048 -- Train Loss: 0.33071  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 3049 -- Train Loss: 0.33110  Validation Loss: 0.42783\n",
      "t: 10 EPOCH 3050 -- Train Loss: 0.33066  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 3051 -- Train Loss: 0.33146  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3052 -- Train Loss: 0.33055  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3053 -- Train Loss: 0.33107  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 3054 -- Train Loss: 0.33112  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3055 -- Train Loss: 0.33074  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 3056 -- Train Loss: 0.33075  Validation Loss: 0.42948\n",
      "t: 10 EPOCH 3057 -- Train Loss: 0.33151  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 3058 -- Train Loss: 0.33074  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 3059 -- Train Loss: 0.32996  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 3060 -- Train Loss: 0.33061  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 3061 -- Train Loss: 0.33100  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 3062 -- Train Loss: 0.33079  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 3063 -- Train Loss: 0.33132  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 3064 -- Train Loss: 0.33135  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 3065 -- Train Loss: 0.33166  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3066 -- Train Loss: 0.33033  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 3067 -- Train Loss: 0.33156  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 3068 -- Train Loss: 0.33034  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 3069 -- Train Loss: 0.33125  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 3070 -- Train Loss: 0.33049  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 3071 -- Train Loss: 0.33083  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 3072 -- Train Loss: 0.33088  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 3073 -- Train Loss: 0.33205  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 3074 -- Train Loss: 0.33135  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3075 -- Train Loss: 0.33069  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 3076 -- Train Loss: 0.33146  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 3077 -- Train Loss: 0.33200  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 3078 -- Train Loss: 0.33111  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 3079 -- Train Loss: 0.33107  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 3080 -- Train Loss: 0.33116  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 3081 -- Train Loss: 0.33044  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3082 -- Train Loss: 0.33082  Validation Loss: 0.42901\n",
      "t: 10 EPOCH 3083 -- Train Loss: 0.33042  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 3084 -- Train Loss: 0.33093  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 3085 -- Train Loss: 0.33154  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 3086 -- Train Loss: 0.33070  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3087 -- Train Loss: 0.33034  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 3088 -- Train Loss: 0.33034  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 3089 -- Train Loss: 0.33102  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 3090 -- Train Loss: 0.33187  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 3091 -- Train Loss: 0.33101  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 3092 -- Train Loss: 0.33122  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 3093 -- Train Loss: 0.33153  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 3094 -- Train Loss: 0.33074  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 3095 -- Train Loss: 0.33134  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 3096 -- Train Loss: 0.33066  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 3097 -- Train Loss: 0.33104  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3098 -- Train Loss: 0.33144  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 3099 -- Train Loss: 0.33138  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 3100 -- Train Loss: 0.33190  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 3101 -- Train Loss: 0.33155  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3102 -- Train Loss: 0.33142  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3103 -- Train Loss: 0.33163  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 3104 -- Train Loss: 0.33110  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 3105 -- Train Loss: 0.33149  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 3106 -- Train Loss: 0.33172  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 3107 -- Train Loss: 0.33187  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 3108 -- Train Loss: 0.33144  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 3109 -- Train Loss: 0.33055  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 3110 -- Train Loss: 0.33109  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 3111 -- Train Loss: 0.32941  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 3112 -- Train Loss: 0.33081  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 3113 -- Train Loss: 0.33076  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 3114 -- Train Loss: 0.33171  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 3115 -- Train Loss: 0.33080  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 3116 -- Train Loss: 0.33129  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 3117 -- Train Loss: 0.33079  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 3118 -- Train Loss: 0.33125  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3119 -- Train Loss: 0.33092  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 3120 -- Train Loss: 0.33013  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 3121 -- Train Loss: 0.33171  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 3122 -- Train Loss: 0.33128  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 3123 -- Train Loss: 0.33107  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 3124 -- Train Loss: 0.33157  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 3125 -- Train Loss: 0.33101  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 3126 -- Train Loss: 0.33075  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 3127 -- Train Loss: 0.33077  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 3128 -- Train Loss: 0.33090  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 3129 -- Train Loss: 0.33139  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3130 -- Train Loss: 0.33128  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 3131 -- Train Loss: 0.33138  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 3132 -- Train Loss: 0.33113  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 3133 -- Train Loss: 0.33047  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 3134 -- Train Loss: 0.33071  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 3135 -- Train Loss: 0.33118  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 3136 -- Train Loss: 0.33145  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 3137 -- Train Loss: 0.33087  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 3138 -- Train Loss: 0.33102  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 3139 -- Train Loss: 0.33103  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 3140 -- Train Loss: 0.33144  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 3141 -- Train Loss: 0.33028  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 3142 -- Train Loss: 0.33121  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 3143 -- Train Loss: 0.33204  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3144 -- Train Loss: 0.33081  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 3145 -- Train Loss: 0.32995  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 3146 -- Train Loss: 0.33127  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 3147 -- Train Loss: 0.33159  Validation Loss: 0.43197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3148 -- Train Loss: 0.33074  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 3149 -- Train Loss: 0.33128  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 3150 -- Train Loss: 0.33065  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 3151 -- Train Loss: 0.33108  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 3152 -- Train Loss: 0.33117  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 3153 -- Train Loss: 0.33167  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 3154 -- Train Loss: 0.33076  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 3155 -- Train Loss: 0.33125  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 3156 -- Train Loss: 0.33061  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 3157 -- Train Loss: 0.33184  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 3158 -- Train Loss: 0.33036  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 3159 -- Train Loss: 0.33105  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 3160 -- Train Loss: 0.33051  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 3161 -- Train Loss: 0.33104  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 3162 -- Train Loss: 0.33105  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 3163 -- Train Loss: 0.33061  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 3164 -- Train Loss: 0.33041  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 3165 -- Train Loss: 0.33084  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 3166 -- Train Loss: 0.33152  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 3167 -- Train Loss: 0.33137  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3168 -- Train Loss: 0.33132  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3169 -- Train Loss: 0.33159  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 3170 -- Train Loss: 0.33062  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 3171 -- Train Loss: 0.33142  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 3172 -- Train Loss: 0.33102  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 3173 -- Train Loss: 0.33120  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 3174 -- Train Loss: 0.33057  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 3175 -- Train Loss: 0.33107  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3176 -- Train Loss: 0.33087  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 3177 -- Train Loss: 0.33062  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 3178 -- Train Loss: 0.33035  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3179 -- Train Loss: 0.33115  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 3180 -- Train Loss: 0.33150  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 3181 -- Train Loss: 0.33060  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 3182 -- Train Loss: 0.33103  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 3183 -- Train Loss: 0.33061  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3184 -- Train Loss: 0.33130  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 3185 -- Train Loss: 0.33073  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 3186 -- Train Loss: 0.33178  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 3187 -- Train Loss: 0.33024  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 3188 -- Train Loss: 0.33148  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 3189 -- Train Loss: 0.33016  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 3190 -- Train Loss: 0.33067  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 3191 -- Train Loss: 0.33114  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 3192 -- Train Loss: 0.33056  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 3193 -- Train Loss: 0.33014  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 3194 -- Train Loss: 0.33138  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 3195 -- Train Loss: 0.33064  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 3196 -- Train Loss: 0.33100  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 3197 -- Train Loss: 0.33078  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 3198 -- Train Loss: 0.33082  Validation Loss: 0.42940\n",
      "t: 10 EPOCH 3199 -- Train Loss: 0.32956  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 3200 -- Train Loss: 0.33030  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 3201 -- Train Loss: 0.33042  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 3202 -- Train Loss: 0.33098  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 3203 -- Train Loss: 0.33095  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 3204 -- Train Loss: 0.33048  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 3205 -- Train Loss: 0.33139  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 3206 -- Train Loss: 0.33103  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3207 -- Train Loss: 0.33008  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3208 -- Train Loss: 0.33107  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 3209 -- Train Loss: 0.33031  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 3210 -- Train Loss: 0.33134  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 3211 -- Train Loss: 0.33111  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 3212 -- Train Loss: 0.33099  Validation Loss: 0.43009\n",
      "t: 10 EPOCH 3213 -- Train Loss: 0.33115  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 3214 -- Train Loss: 0.33031  Validation Loss: 0.42893\n",
      "t: 10 EPOCH 3215 -- Train Loss: 0.33107  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 3216 -- Train Loss: 0.33101  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 3217 -- Train Loss: 0.33102  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3218 -- Train Loss: 0.32988  Validation Loss: 0.42918\n",
      "t: 10 EPOCH 3219 -- Train Loss: 0.32988  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 3220 -- Train Loss: 0.33077  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 3221 -- Train Loss: 0.33137  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 3222 -- Train Loss: 0.33025  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 3223 -- Train Loss: 0.33157  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 3224 -- Train Loss: 0.33067  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 3225 -- Train Loss: 0.33116  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 3226 -- Train Loss: 0.33037  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 3227 -- Train Loss: 0.33080  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 3228 -- Train Loss: 0.33053  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 3229 -- Train Loss: 0.33191  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 3230 -- Train Loss: 0.33114  Validation Loss: 0.42933\n",
      "t: 10 EPOCH 3231 -- Train Loss: 0.33108  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 3232 -- Train Loss: 0.33131  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 3233 -- Train Loss: 0.33083  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 3234 -- Train Loss: 0.33126  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 3235 -- Train Loss: 0.33070  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 3236 -- Train Loss: 0.33045  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3237 -- Train Loss: 0.33097  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3238 -- Train Loss: 0.33109  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 3239 -- Train Loss: 0.33043  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3240 -- Train Loss: 0.33123  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 3241 -- Train Loss: 0.33120  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 3242 -- Train Loss: 0.33152  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 3243 -- Train Loss: 0.33021  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 3244 -- Train Loss: 0.33019  Validation Loss: 0.42950\n",
      "t: 10 EPOCH 3245 -- Train Loss: 0.33051  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 3246 -- Train Loss: 0.33007  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 3247 -- Train Loss: 0.33113  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3248 -- Train Loss: 0.33111  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 3249 -- Train Loss: 0.33121  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 3250 -- Train Loss: 0.33159  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 3251 -- Train Loss: 0.33113  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 3252 -- Train Loss: 0.32989  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3253 -- Train Loss: 0.33106  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 3254 -- Train Loss: 0.33118  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 3255 -- Train Loss: 0.32959  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 3256 -- Train Loss: 0.32980  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 3257 -- Train Loss: 0.33033  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 3258 -- Train Loss: 0.33162  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3259 -- Train Loss: 0.33069  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 3260 -- Train Loss: 0.33087  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 3261 -- Train Loss: 0.33009  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3262 -- Train Loss: 0.32974  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 3263 -- Train Loss: 0.33103  Validation Loss: 0.42931\n",
      "t: 10 EPOCH 3264 -- Train Loss: 0.33099  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3265 -- Train Loss: 0.33119  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 3266 -- Train Loss: 0.32979  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 3267 -- Train Loss: 0.33045  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3268 -- Train Loss: 0.33053  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 3269 -- Train Loss: 0.33025  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 3270 -- Train Loss: 0.33001  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 3271 -- Train Loss: 0.33152  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 3272 -- Train Loss: 0.33123  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3273 -- Train Loss: 0.33114  Validation Loss: 0.43104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3274 -- Train Loss: 0.32980  Validation Loss: 0.42948\n",
      "t: 10 EPOCH 3275 -- Train Loss: 0.33093  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 3276 -- Train Loss: 0.33098  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 3277 -- Train Loss: 0.33032  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 3278 -- Train Loss: 0.33108  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 3279 -- Train Loss: 0.33072  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 3280 -- Train Loss: 0.33116  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3281 -- Train Loss: 0.33097  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 3282 -- Train Loss: 0.33084  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 3283 -- Train Loss: 0.33057  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 3284 -- Train Loss: 0.33142  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 3285 -- Train Loss: 0.33031  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 3286 -- Train Loss: 0.33098  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 3287 -- Train Loss: 0.32985  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 3288 -- Train Loss: 0.33011  Validation Loss: 0.42993\n",
      "t: 10 EPOCH 3289 -- Train Loss: 0.33030  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 3290 -- Train Loss: 0.33000  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3291 -- Train Loss: 0.33110  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 3292 -- Train Loss: 0.33017  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 3293 -- Train Loss: 0.33067  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 3294 -- Train Loss: 0.33123  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 3295 -- Train Loss: 0.33100  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3296 -- Train Loss: 0.32972  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3297 -- Train Loss: 0.33155  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3298 -- Train Loss: 0.33020  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 3299 -- Train Loss: 0.33052  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 3300 -- Train Loss: 0.32995  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3301 -- Train Loss: 0.33096  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 3302 -- Train Loss: 0.33044  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 3303 -- Train Loss: 0.33084  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 3304 -- Train Loss: 0.33001  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 3305 -- Train Loss: 0.33130  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 3306 -- Train Loss: 0.33022  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 3307 -- Train Loss: 0.33119  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 3308 -- Train Loss: 0.33076  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 3309 -- Train Loss: 0.33119  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 3310 -- Train Loss: 0.33123  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 3311 -- Train Loss: 0.33089  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 3312 -- Train Loss: 0.33033  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 3313 -- Train Loss: 0.33050  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3314 -- Train Loss: 0.33051  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 3315 -- Train Loss: 0.33132  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 3316 -- Train Loss: 0.33089  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 3317 -- Train Loss: 0.32933  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 3318 -- Train Loss: 0.33114  Validation Loss: 0.42994\n",
      "t: 10 EPOCH 3319 -- Train Loss: 0.33057  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 3320 -- Train Loss: 0.33063  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 3321 -- Train Loss: 0.33026  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 3322 -- Train Loss: 0.32975  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 3323 -- Train Loss: 0.33077  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 3324 -- Train Loss: 0.33142  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 3325 -- Train Loss: 0.33019  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 3326 -- Train Loss: 0.33078  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 3327 -- Train Loss: 0.33064  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 3328 -- Train Loss: 0.33016  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 3329 -- Train Loss: 0.33029  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 3330 -- Train Loss: 0.33084  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 3331 -- Train Loss: 0.33109  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 3332 -- Train Loss: 0.33078  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 3333 -- Train Loss: 0.32993  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3334 -- Train Loss: 0.33011  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 3335 -- Train Loss: 0.33010  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 3336 -- Train Loss: 0.33081  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 3337 -- Train Loss: 0.33077  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 3338 -- Train Loss: 0.33056  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 3339 -- Train Loss: 0.33104  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 3340 -- Train Loss: 0.33017  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 3341 -- Train Loss: 0.33161  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 3342 -- Train Loss: 0.33056  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 3343 -- Train Loss: 0.33120  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 3344 -- Train Loss: 0.33116  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 3345 -- Train Loss: 0.33055  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 3346 -- Train Loss: 0.33159  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 3347 -- Train Loss: 0.33010  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 3348 -- Train Loss: 0.33065  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 3349 -- Train Loss: 0.32962  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 3350 -- Train Loss: 0.33127  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 3351 -- Train Loss: 0.33111  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 3352 -- Train Loss: 0.33106  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 3353 -- Train Loss: 0.33071  Validation Loss: 0.42933\n",
      "t: 10 EPOCH 3354 -- Train Loss: 0.33118  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 3355 -- Train Loss: 0.33065  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 3356 -- Train Loss: 0.33104  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 3357 -- Train Loss: 0.33050  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 3358 -- Train Loss: 0.33077  Validation Loss: 0.43015\n",
      "t: 10 EPOCH 3359 -- Train Loss: 0.33104  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 3360 -- Train Loss: 0.33099  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 3361 -- Train Loss: 0.33072  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 3362 -- Train Loss: 0.33062  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 3363 -- Train Loss: 0.33094  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3364 -- Train Loss: 0.33069  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 3365 -- Train Loss: 0.33017  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 3366 -- Train Loss: 0.33113  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 3367 -- Train Loss: 0.32982  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 3368 -- Train Loss: 0.33048  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 3369 -- Train Loss: 0.32996  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 3370 -- Train Loss: 0.33042  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 3371 -- Train Loss: 0.33112  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 3372 -- Train Loss: 0.33084  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 3373 -- Train Loss: 0.33073  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 3374 -- Train Loss: 0.33035  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 3375 -- Train Loss: 0.33078  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 3376 -- Train Loss: 0.33010  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 3377 -- Train Loss: 0.33029  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 3378 -- Train Loss: 0.32977  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 3379 -- Train Loss: 0.33186  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 3380 -- Train Loss: 0.33017  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 3381 -- Train Loss: 0.33146  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 3382 -- Train Loss: 0.32923  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 3383 -- Train Loss: 0.33008  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3384 -- Train Loss: 0.33035  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 3385 -- Train Loss: 0.33076  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 3386 -- Train Loss: 0.33028  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 3387 -- Train Loss: 0.33077  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 3388 -- Train Loss: 0.32929  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 3389 -- Train Loss: 0.33017  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 3390 -- Train Loss: 0.33129  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 3391 -- Train Loss: 0.33081  Validation Loss: 0.42952\n",
      "t: 10 EPOCH 3392 -- Train Loss: 0.33145  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3393 -- Train Loss: 0.33023  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 3394 -- Train Loss: 0.33102  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 3395 -- Train Loss: 0.33043  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 3396 -- Train Loss: 0.32970  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3397 -- Train Loss: 0.33056  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 3398 -- Train Loss: 0.33001  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 3399 -- Train Loss: 0.32999  Validation Loss: 0.43045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3400 -- Train Loss: 0.33034  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 3401 -- Train Loss: 0.32952  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 3402 -- Train Loss: 0.33035  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 3403 -- Train Loss: 0.32987  Validation Loss: 0.43007\n",
      "t: 10 EPOCH 3404 -- Train Loss: 0.33034  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 3405 -- Train Loss: 0.33021  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 3406 -- Train Loss: 0.33125  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 3407 -- Train Loss: 0.33072  Validation Loss: 0.43020\n",
      "t: 10 EPOCH 3408 -- Train Loss: 0.33037  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 3409 -- Train Loss: 0.32996  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 3410 -- Train Loss: 0.33114  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 3411 -- Train Loss: 0.33120  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 3412 -- Train Loss: 0.32989  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 3413 -- Train Loss: 0.33026  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3414 -- Train Loss: 0.33199  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 3415 -- Train Loss: 0.33064  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 3416 -- Train Loss: 0.33122  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 3417 -- Train Loss: 0.33003  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 3418 -- Train Loss: 0.33101  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 3419 -- Train Loss: 0.32985  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 3420 -- Train Loss: 0.33128  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 3421 -- Train Loss: 0.32971  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 3422 -- Train Loss: 0.33211  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 3423 -- Train Loss: 0.33050  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 3424 -- Train Loss: 0.33086  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3425 -- Train Loss: 0.32960  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 3426 -- Train Loss: 0.33157  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 3427 -- Train Loss: 0.33117  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 3428 -- Train Loss: 0.33198  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 3429 -- Train Loss: 0.33099  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 3430 -- Train Loss: 0.33102  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 3431 -- Train Loss: 0.32997  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 3432 -- Train Loss: 0.33184  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 3433 -- Train Loss: 0.33155  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 3434 -- Train Loss: 0.33177  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 3435 -- Train Loss: 0.32993  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 3436 -- Train Loss: 0.33187  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 3437 -- Train Loss: 0.33020  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 3438 -- Train Loss: 0.33089  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 3439 -- Train Loss: 0.33151  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 3440 -- Train Loss: 0.33115  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 3441 -- Train Loss: 0.33058  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 3442 -- Train Loss: 0.33089  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 3443 -- Train Loss: 0.33113  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 3444 -- Train Loss: 0.33086  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 3445 -- Train Loss: 0.33153  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 3446 -- Train Loss: 0.33052  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 3447 -- Train Loss: 0.33084  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 3448 -- Train Loss: 0.33084  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 3449 -- Train Loss: 0.33060  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 3450 -- Train Loss: 0.33115  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 3451 -- Train Loss: 0.33141  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 3452 -- Train Loss: 0.33015  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 3453 -- Train Loss: 0.33048  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 3454 -- Train Loss: 0.33045  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 3455 -- Train Loss: 0.33154  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 3456 -- Train Loss: 0.33000  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 3457 -- Train Loss: 0.33099  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 3458 -- Train Loss: 0.32989  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 3459 -- Train Loss: 0.33078  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 3460 -- Train Loss: 0.33056  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 3461 -- Train Loss: 0.33064  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 3462 -- Train Loss: 0.33045  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 3463 -- Train Loss: 0.33092  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 3464 -- Train Loss: 0.33004  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 3465 -- Train Loss: 0.32974  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 3466 -- Train Loss: 0.33028  Validation Loss: 0.42986\n",
      "t: 10 EPOCH 3467 -- Train Loss: 0.33158  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 3468 -- Train Loss: 0.33064  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 3469 -- Train Loss: 0.33043  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 3470 -- Train Loss: 0.33091  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 3471 -- Train Loss: 0.32972  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 3472 -- Train Loss: 0.33112  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 3473 -- Train Loss: 0.33035  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 3474 -- Train Loss: 0.33070  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 3475 -- Train Loss: 0.33048  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3476 -- Train Loss: 0.33083  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 3477 -- Train Loss: 0.33053  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 3478 -- Train Loss: 0.33098  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 3479 -- Train Loss: 0.33062  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 3480 -- Train Loss: 0.33033  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 3481 -- Train Loss: 0.32982  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 3482 -- Train Loss: 0.32977  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 3483 -- Train Loss: 0.33004  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 3484 -- Train Loss: 0.32994  Validation Loss: 0.43026\n",
      "t: 10 EPOCH 3485 -- Train Loss: 0.33034  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3486 -- Train Loss: 0.32956  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 3487 -- Train Loss: 0.33056  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 3488 -- Train Loss: 0.33118  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 3489 -- Train Loss: 0.33057  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 3490 -- Train Loss: 0.32983  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 3491 -- Train Loss: 0.32994  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 3492 -- Train Loss: 0.33038  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3493 -- Train Loss: 0.33103  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 3494 -- Train Loss: 0.33017  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 3495 -- Train Loss: 0.32919  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 3496 -- Train Loss: 0.33052  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 3497 -- Train Loss: 0.33010  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 3498 -- Train Loss: 0.33032  Validation Loss: 0.43002\n",
      "t: 10 EPOCH 3499 -- Train Loss: 0.33066  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3500 -- Train Loss: 0.33045  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 3501 -- Train Loss: 0.33051  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 3502 -- Train Loss: 0.33045  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 3503 -- Train Loss: 0.33088  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 3504 -- Train Loss: 0.33059  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 3505 -- Train Loss: 0.33158  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 3506 -- Train Loss: 0.33070  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 3507 -- Train Loss: 0.33034  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 3508 -- Train Loss: 0.32977  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 3509 -- Train Loss: 0.33159  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 3510 -- Train Loss: 0.32968  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 3511 -- Train Loss: 0.33017  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 3512 -- Train Loss: 0.33053  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 3513 -- Train Loss: 0.33066  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 3514 -- Train Loss: 0.33055  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 3515 -- Train Loss: 0.33087  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 3516 -- Train Loss: 0.32941  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 3517 -- Train Loss: 0.33045  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 3518 -- Train Loss: 0.32955  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 3519 -- Train Loss: 0.33064  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 3520 -- Train Loss: 0.33082  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 3521 -- Train Loss: 0.33100  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 3522 -- Train Loss: 0.32986  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 3523 -- Train Loss: 0.33121  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 3524 -- Train Loss: 0.33087  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 3525 -- Train Loss: 0.33064  Validation Loss: 0.43177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3526 -- Train Loss: 0.33002  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 3527 -- Train Loss: 0.33119  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 3528 -- Train Loss: 0.33020  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 3529 -- Train Loss: 0.33051  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 3530 -- Train Loss: 0.32905  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 3531 -- Train Loss: 0.33150  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 3532 -- Train Loss: 0.32933  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 3533 -- Train Loss: 0.33158  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 3534 -- Train Loss: 0.32871  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 3535 -- Train Loss: 0.33078  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 3536 -- Train Loss: 0.33068  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 3537 -- Train Loss: 0.33037  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 3538 -- Train Loss: 0.33029  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 3539 -- Train Loss: 0.33057  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 3540 -- Train Loss: 0.32990  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 3541 -- Train Loss: 0.33020  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 3542 -- Train Loss: 0.33012  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 3543 -- Train Loss: 0.33117  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 3544 -- Train Loss: 0.33081  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 3545 -- Train Loss: 0.33099  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 3546 -- Train Loss: 0.33036  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 3547 -- Train Loss: 0.33137  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 3548 -- Train Loss: 0.32972  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 3549 -- Train Loss: 0.33153  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 3550 -- Train Loss: 0.33014  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 3551 -- Train Loss: 0.33160  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3552 -- Train Loss: 0.32957  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 3553 -- Train Loss: 0.33127  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 3554 -- Train Loss: 0.33044  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 3555 -- Train Loss: 0.33121  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 3556 -- Train Loss: 0.33057  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 3557 -- Train Loss: 0.33085  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 3558 -- Train Loss: 0.33099  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 3559 -- Train Loss: 0.33060  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 3560 -- Train Loss: 0.33040  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 3561 -- Train Loss: 0.33179  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 3562 -- Train Loss: 0.33007  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 3563 -- Train Loss: 0.33070  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 3564 -- Train Loss: 0.33087  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 3565 -- Train Loss: 0.33143  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 3566 -- Train Loss: 0.33105  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 3567 -- Train Loss: 0.33135  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 3568 -- Train Loss: 0.33056  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 3569 -- Train Loss: 0.33198  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 3570 -- Train Loss: 0.33130  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 3571 -- Train Loss: 0.33146  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 3572 -- Train Loss: 0.33049  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3573 -- Train Loss: 0.33082  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 3574 -- Train Loss: 0.33067  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 3575 -- Train Loss: 0.33165  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 3576 -- Train Loss: 0.33063  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 3577 -- Train Loss: 0.33049  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 3578 -- Train Loss: 0.33163  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 3579 -- Train Loss: 0.33037  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 3580 -- Train Loss: 0.33123  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3581 -- Train Loss: 0.33085  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 3582 -- Train Loss: 0.33075  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 3583 -- Train Loss: 0.33076  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 3584 -- Train Loss: 0.32996  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 3585 -- Train Loss: 0.33139  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 3586 -- Train Loss: 0.33159  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 3587 -- Train Loss: 0.33012  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 3588 -- Train Loss: 0.33118  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 3589 -- Train Loss: 0.33093  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 3590 -- Train Loss: 0.33136  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 3591 -- Train Loss: 0.33084  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 3592 -- Train Loss: 0.33044  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 3593 -- Train Loss: 0.33099  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 3594 -- Train Loss: 0.33083  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 3595 -- Train Loss: 0.33063  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 3596 -- Train Loss: 0.33042  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 3597 -- Train Loss: 0.32980  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 3598 -- Train Loss: 0.33061  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 3599 -- Train Loss: 0.33062  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 3600 -- Train Loss: 0.33056  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 3601 -- Train Loss: 0.33112  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 3602 -- Train Loss: 0.33133  Validation Loss: 0.42995\n",
      "t: 10 EPOCH 3603 -- Train Loss: 0.33159  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 3604 -- Train Loss: 0.33090  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 3605 -- Train Loss: 0.33065  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 3606 -- Train Loss: 0.33148  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 3607 -- Train Loss: 0.32964  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 3608 -- Train Loss: 0.33119  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 3609 -- Train Loss: 0.33051  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3610 -- Train Loss: 0.32989  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 3611 -- Train Loss: 0.33153  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 3612 -- Train Loss: 0.33088  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 3613 -- Train Loss: 0.33064  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 3614 -- Train Loss: 0.33040  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3615 -- Train Loss: 0.33001  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3616 -- Train Loss: 0.33022  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 3617 -- Train Loss: 0.33085  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 3618 -- Train Loss: 0.33122  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 3619 -- Train Loss: 0.33095  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 3620 -- Train Loss: 0.33005  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 3621 -- Train Loss: 0.33068  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 3622 -- Train Loss: 0.33073  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 3623 -- Train Loss: 0.33019  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3624 -- Train Loss: 0.33086  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3625 -- Train Loss: 0.32997  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 3626 -- Train Loss: 0.33091  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 3627 -- Train Loss: 0.33044  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 3628 -- Train Loss: 0.33103  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 3629 -- Train Loss: 0.33024  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 3630 -- Train Loss: 0.33027  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 3631 -- Train Loss: 0.33037  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 3632 -- Train Loss: 0.33009  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 3633 -- Train Loss: 0.33092  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 3634 -- Train Loss: 0.33033  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 3635 -- Train Loss: 0.33066  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 3636 -- Train Loss: 0.33095  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3637 -- Train Loss: 0.32952  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 3638 -- Train Loss: 0.33093  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 3639 -- Train Loss: 0.33058  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 3640 -- Train Loss: 0.33039  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3641 -- Train Loss: 0.32954  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 3642 -- Train Loss: 0.33086  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 3643 -- Train Loss: 0.33033  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 3644 -- Train Loss: 0.33032  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 3645 -- Train Loss: 0.33026  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 3646 -- Train Loss: 0.33120  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3647 -- Train Loss: 0.32925  Validation Loss: 0.43021\n",
      "t: 10 EPOCH 3648 -- Train Loss: 0.32992  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 3649 -- Train Loss: 0.33077  Validation Loss: 0.43018\n",
      "t: 10 EPOCH 3650 -- Train Loss: 0.33041  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 3651 -- Train Loss: 0.33110  Validation Loss: 0.43195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3652 -- Train Loss: 0.32943  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 3653 -- Train Loss: 0.32999  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 3654 -- Train Loss: 0.32894  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 3655 -- Train Loss: 0.33045  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3656 -- Train Loss: 0.33010  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 3657 -- Train Loss: 0.33082  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 3658 -- Train Loss: 0.33024  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 3659 -- Train Loss: 0.33009  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 3660 -- Train Loss: 0.33069  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 3661 -- Train Loss: 0.32990  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 3662 -- Train Loss: 0.33041  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 3663 -- Train Loss: 0.33016  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 3664 -- Train Loss: 0.33022  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 3665 -- Train Loss: 0.33016  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 3666 -- Train Loss: 0.32998  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 3667 -- Train Loss: 0.33028  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 3668 -- Train Loss: 0.33043  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 3669 -- Train Loss: 0.33030  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 3670 -- Train Loss: 0.32961  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 3671 -- Train Loss: 0.33017  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 3672 -- Train Loss: 0.33031  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 3673 -- Train Loss: 0.33021  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 3674 -- Train Loss: 0.33090  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 3675 -- Train Loss: 0.33034  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 3676 -- Train Loss: 0.33087  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 3677 -- Train Loss: 0.32996  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 3678 -- Train Loss: 0.33020  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 3679 -- Train Loss: 0.33050  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 3680 -- Train Loss: 0.33073  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 3681 -- Train Loss: 0.33024  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 3682 -- Train Loss: 0.32985  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 3683 -- Train Loss: 0.33028  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 3684 -- Train Loss: 0.33111  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 3685 -- Train Loss: 0.32926  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 3686 -- Train Loss: 0.33055  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 3687 -- Train Loss: 0.33028  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 3688 -- Train Loss: 0.33056  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 3689 -- Train Loss: 0.33117  Validation Loss: 0.42937\n",
      "t: 10 EPOCH 3690 -- Train Loss: 0.33063  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 3691 -- Train Loss: 0.32981  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3692 -- Train Loss: 0.33051  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3693 -- Train Loss: 0.33023  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3694 -- Train Loss: 0.33090  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3695 -- Train Loss: 0.33053  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 3696 -- Train Loss: 0.32985  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 3697 -- Train Loss: 0.33036  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 3698 -- Train Loss: 0.33030  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 3699 -- Train Loss: 0.32998  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 3700 -- Train Loss: 0.33129  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 3701 -- Train Loss: 0.33056  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 3702 -- Train Loss: 0.33023  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 3703 -- Train Loss: 0.33072  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 3704 -- Train Loss: 0.33051  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 3705 -- Train Loss: 0.33019  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 3706 -- Train Loss: 0.33029  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 3707 -- Train Loss: 0.33032  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 3708 -- Train Loss: 0.33078  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 3709 -- Train Loss: 0.33067  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 3710 -- Train Loss: 0.33050  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 3711 -- Train Loss: 0.33159  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 3712 -- Train Loss: 0.32986  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3713 -- Train Loss: 0.33068  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 3714 -- Train Loss: 0.33030  Validation Loss: 0.43014\n",
      "t: 10 EPOCH 3715 -- Train Loss: 0.32988  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 3716 -- Train Loss: 0.32953  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 3717 -- Train Loss: 0.32968  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 3718 -- Train Loss: 0.33070  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3719 -- Train Loss: 0.32968  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 3720 -- Train Loss: 0.33043  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 3721 -- Train Loss: 0.33098  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 3722 -- Train Loss: 0.33052  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 3723 -- Train Loss: 0.33093  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 3724 -- Train Loss: 0.33068  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 3725 -- Train Loss: 0.32965  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 3726 -- Train Loss: 0.33036  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 3727 -- Train Loss: 0.33019  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3728 -- Train Loss: 0.33015  Validation Loss: 0.42978\n",
      "t: 10 EPOCH 3729 -- Train Loss: 0.32955  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 3730 -- Train Loss: 0.33045  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 3731 -- Train Loss: 0.32941  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 3732 -- Train Loss: 0.33056  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 3733 -- Train Loss: 0.33082  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 3734 -- Train Loss: 0.33020  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 3735 -- Train Loss: 0.33044  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3736 -- Train Loss: 0.32989  Validation Loss: 0.42945\n",
      "t: 10 EPOCH 3737 -- Train Loss: 0.33003  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 3738 -- Train Loss: 0.33005  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 3739 -- Train Loss: 0.33045  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 3740 -- Train Loss: 0.33015  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 3741 -- Train Loss: 0.33033  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 3742 -- Train Loss: 0.33129  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 3743 -- Train Loss: 0.33003  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 3744 -- Train Loss: 0.33000  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 3745 -- Train Loss: 0.33075  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 3746 -- Train Loss: 0.33042  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3747 -- Train Loss: 0.33015  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 3748 -- Train Loss: 0.32998  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 3749 -- Train Loss: 0.32952  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 3750 -- Train Loss: 0.32974  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 3751 -- Train Loss: 0.32962  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 3752 -- Train Loss: 0.33068  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 3753 -- Train Loss: 0.32994  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 3754 -- Train Loss: 0.33163  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 3755 -- Train Loss: 0.33050  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 3756 -- Train Loss: 0.33068  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 3757 -- Train Loss: 0.33078  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 3758 -- Train Loss: 0.33033  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 3759 -- Train Loss: 0.33015  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 3760 -- Train Loss: 0.32988  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 3761 -- Train Loss: 0.32922  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 3762 -- Train Loss: 0.32997  Validation Loss: 0.42917\n",
      "t: 10 EPOCH 3763 -- Train Loss: 0.33025  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3764 -- Train Loss: 0.33010  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 3765 -- Train Loss: 0.32983  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 3766 -- Train Loss: 0.33002  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 3767 -- Train Loss: 0.33030  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3768 -- Train Loss: 0.33087  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 3769 -- Train Loss: 0.33072  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 3770 -- Train Loss: 0.33072  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 3771 -- Train Loss: 0.33138  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 3772 -- Train Loss: 0.33055  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 3773 -- Train Loss: 0.33020  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 3774 -- Train Loss: 0.32992  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3775 -- Train Loss: 0.33075  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 3776 -- Train Loss: 0.33110  Validation Loss: 0.43175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3777 -- Train Loss: 0.33053  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3778 -- Train Loss: 0.32995  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 3779 -- Train Loss: 0.33135  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 3780 -- Train Loss: 0.33009  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 3781 -- Train Loss: 0.33107  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 3782 -- Train Loss: 0.33006  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 3783 -- Train Loss: 0.33071  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 3784 -- Train Loss: 0.33002  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 3785 -- Train Loss: 0.32994  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 3786 -- Train Loss: 0.33101  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 3787 -- Train Loss: 0.33124  Validation Loss: 0.42928\n",
      "t: 10 EPOCH 3788 -- Train Loss: 0.33064  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 3789 -- Train Loss: 0.33080  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 3790 -- Train Loss: 0.32972  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 3791 -- Train Loss: 0.33075  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 3792 -- Train Loss: 0.32931  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 3793 -- Train Loss: 0.33076  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 3794 -- Train Loss: 0.32972  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3795 -- Train Loss: 0.33108  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3796 -- Train Loss: 0.33124  Validation Loss: 0.43022\n",
      "t: 10 EPOCH 3797 -- Train Loss: 0.33043  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 3798 -- Train Loss: 0.33052  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 3799 -- Train Loss: 0.33090  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 3800 -- Train Loss: 0.33067  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3801 -- Train Loss: 0.32972  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 3802 -- Train Loss: 0.32933  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 3803 -- Train Loss: 0.33082  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 3804 -- Train Loss: 0.33096  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 3805 -- Train Loss: 0.33009  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 3806 -- Train Loss: 0.33052  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 3807 -- Train Loss: 0.33034  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 3808 -- Train Loss: 0.33007  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 3809 -- Train Loss: 0.32958  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 3810 -- Train Loss: 0.33092  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 3811 -- Train Loss: 0.32989  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 3812 -- Train Loss: 0.33047  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 3813 -- Train Loss: 0.33049  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3814 -- Train Loss: 0.33143  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 3815 -- Train Loss: 0.33130  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 3816 -- Train Loss: 0.33090  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 3817 -- Train Loss: 0.33000  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 3818 -- Train Loss: 0.33023  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 3819 -- Train Loss: 0.33123  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 3820 -- Train Loss: 0.33060  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 3821 -- Train Loss: 0.33137  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 3822 -- Train Loss: 0.33043  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 3823 -- Train Loss: 0.32993  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 3824 -- Train Loss: 0.33131  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 3825 -- Train Loss: 0.33088  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 3826 -- Train Loss: 0.33110  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 3827 -- Train Loss: 0.32975  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 3828 -- Train Loss: 0.33053  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 3829 -- Train Loss: 0.32969  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 3830 -- Train Loss: 0.33048  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 3831 -- Train Loss: 0.33052  Validation Loss: 0.42959\n",
      "t: 10 EPOCH 3832 -- Train Loss: 0.33035  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 3833 -- Train Loss: 0.32999  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 3834 -- Train Loss: 0.33072  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3835 -- Train Loss: 0.32993  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 3836 -- Train Loss: 0.33053  Validation Loss: 0.42954\n",
      "t: 10 EPOCH 3837 -- Train Loss: 0.33083  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 3838 -- Train Loss: 0.32954  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 3839 -- Train Loss: 0.33073  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 3840 -- Train Loss: 0.32934  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 3841 -- Train Loss: 0.33056  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 3842 -- Train Loss: 0.32929  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 3843 -- Train Loss: 0.33013  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 3844 -- Train Loss: 0.32980  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 3845 -- Train Loss: 0.33013  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 3846 -- Train Loss: 0.33008  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 3847 -- Train Loss: 0.33043  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3848 -- Train Loss: 0.33045  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 3849 -- Train Loss: 0.33037  Validation Loss: 0.42998\n",
      "t: 10 EPOCH 3850 -- Train Loss: 0.32933  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 3851 -- Train Loss: 0.33047  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 3852 -- Train Loss: 0.33034  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 3853 -- Train Loss: 0.33012  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 3854 -- Train Loss: 0.33076  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 3855 -- Train Loss: 0.33060  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3856 -- Train Loss: 0.33107  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 3857 -- Train Loss: 0.32967  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 3858 -- Train Loss: 0.32996  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 3859 -- Train Loss: 0.33014  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 3860 -- Train Loss: 0.32989  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 3861 -- Train Loss: 0.33101  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 3862 -- Train Loss: 0.33038  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 3863 -- Train Loss: 0.33034  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3864 -- Train Loss: 0.33065  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 3865 -- Train Loss: 0.32987  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 3866 -- Train Loss: 0.33064  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 3867 -- Train Loss: 0.33054  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 3868 -- Train Loss: 0.33058  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 3869 -- Train Loss: 0.33014  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 3870 -- Train Loss: 0.33083  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 3871 -- Train Loss: 0.33008  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 3872 -- Train Loss: 0.32975  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 3873 -- Train Loss: 0.33060  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 3874 -- Train Loss: 0.32989  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 3875 -- Train Loss: 0.32972  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 3876 -- Train Loss: 0.32930  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 3877 -- Train Loss: 0.33040  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 3878 -- Train Loss: 0.32949  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 3879 -- Train Loss: 0.33001  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 3880 -- Train Loss: 0.32922  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3881 -- Train Loss: 0.33083  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 3882 -- Train Loss: 0.33118  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 3883 -- Train Loss: 0.32901  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 3884 -- Train Loss: 0.33041  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 3885 -- Train Loss: 0.32950  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 3886 -- Train Loss: 0.32979  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 3887 -- Train Loss: 0.33053  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 3888 -- Train Loss: 0.32978  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 3889 -- Train Loss: 0.32960  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 3890 -- Train Loss: 0.33027  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 3891 -- Train Loss: 0.33064  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 3892 -- Train Loss: 0.32994  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 3893 -- Train Loss: 0.33068  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 3894 -- Train Loss: 0.32936  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 3895 -- Train Loss: 0.33059  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 3896 -- Train Loss: 0.33041  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 3897 -- Train Loss: 0.33004  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 3898 -- Train Loss: 0.32983  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 3899 -- Train Loss: 0.33109  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 3900 -- Train Loss: 0.33019  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 3901 -- Train Loss: 0.33013  Validation Loss: 0.43099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 3902 -- Train Loss: 0.33030  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 3903 -- Train Loss: 0.33037  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 3904 -- Train Loss: 0.33001  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 3905 -- Train Loss: 0.33104  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 3906 -- Train Loss: 0.33043  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 3907 -- Train Loss: 0.33073  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 3908 -- Train Loss: 0.33153  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 3909 -- Train Loss: 0.33045  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 3910 -- Train Loss: 0.33058  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 3911 -- Train Loss: 0.32997  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 3912 -- Train Loss: 0.32976  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 3913 -- Train Loss: 0.33045  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 3914 -- Train Loss: 0.33046  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 3915 -- Train Loss: 0.33081  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 3916 -- Train Loss: 0.33044  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 3917 -- Train Loss: 0.33098  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 3918 -- Train Loss: 0.33056  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 3919 -- Train Loss: 0.33090  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 3920 -- Train Loss: 0.33030  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 3921 -- Train Loss: 0.33091  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 3922 -- Train Loss: 0.32957  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 3923 -- Train Loss: 0.33017  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 3924 -- Train Loss: 0.33032  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 3925 -- Train Loss: 0.33022  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 3926 -- Train Loss: 0.32977  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 3927 -- Train Loss: 0.33049  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3928 -- Train Loss: 0.32955  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 3929 -- Train Loss: 0.33071  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 3930 -- Train Loss: 0.33021  Validation Loss: 0.42980\n",
      "t: 10 EPOCH 3931 -- Train Loss: 0.33009  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 3932 -- Train Loss: 0.32914  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3933 -- Train Loss: 0.33136  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3934 -- Train Loss: 0.32977  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 3935 -- Train Loss: 0.33102  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 3936 -- Train Loss: 0.33060  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 3937 -- Train Loss: 0.32964  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 3938 -- Train Loss: 0.33007  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 3939 -- Train Loss: 0.33056  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 3940 -- Train Loss: 0.32958  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3941 -- Train Loss: 0.33080  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 3942 -- Train Loss: 0.33008  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 3943 -- Train Loss: 0.33074  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 3944 -- Train Loss: 0.33022  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 3945 -- Train Loss: 0.32998  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 3946 -- Train Loss: 0.33006  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 3947 -- Train Loss: 0.33038  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 3948 -- Train Loss: 0.33008  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 3949 -- Train Loss: 0.32975  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 3950 -- Train Loss: 0.33033  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 3951 -- Train Loss: 0.33056  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 3952 -- Train Loss: 0.33074  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 3953 -- Train Loss: 0.33094  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 3954 -- Train Loss: 0.33003  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 3955 -- Train Loss: 0.33027  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 3956 -- Train Loss: 0.32962  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 3957 -- Train Loss: 0.33093  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 3958 -- Train Loss: 0.32966  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 3959 -- Train Loss: 0.32951  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 3960 -- Train Loss: 0.33061  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 3961 -- Train Loss: 0.32965  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 3962 -- Train Loss: 0.33001  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 3963 -- Train Loss: 0.33032  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 3964 -- Train Loss: 0.33079  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 3965 -- Train Loss: 0.33030  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 3966 -- Train Loss: 0.33006  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 3967 -- Train Loss: 0.33020  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 3968 -- Train Loss: 0.33029  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 3969 -- Train Loss: 0.33031  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 3970 -- Train Loss: 0.33047  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 3971 -- Train Loss: 0.33088  Validation Loss: 0.42943\n",
      "t: 10 EPOCH 3972 -- Train Loss: 0.33020  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 3973 -- Train Loss: 0.33122  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 3974 -- Train Loss: 0.33044  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 3975 -- Train Loss: 0.33070  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 3976 -- Train Loss: 0.32997  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 3977 -- Train Loss: 0.32992  Validation Loss: 0.43001\n",
      "t: 10 EPOCH 3978 -- Train Loss: 0.32950  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 3979 -- Train Loss: 0.33113  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 3980 -- Train Loss: 0.32944  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 3981 -- Train Loss: 0.33038  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 3982 -- Train Loss: 0.32918  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 3983 -- Train Loss: 0.33111  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 3984 -- Train Loss: 0.32990  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 3985 -- Train Loss: 0.33041  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 3986 -- Train Loss: 0.33014  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 3987 -- Train Loss: 0.32983  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 3988 -- Train Loss: 0.32996  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 3989 -- Train Loss: 0.32991  Validation Loss: 0.42982\n",
      "t: 10 EPOCH 3990 -- Train Loss: 0.32988  Validation Loss: 0.43060\n",
      "t: 10 EPOCH 3991 -- Train Loss: 0.33053  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 3992 -- Train Loss: 0.33117  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 3993 -- Train Loss: 0.32953  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 3994 -- Train Loss: 0.32990  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 3995 -- Train Loss: 0.33021  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 3996 -- Train Loss: 0.33082  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 3997 -- Train Loss: 0.33037  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 3998 -- Train Loss: 0.33032  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 3999 -- Train Loss: 0.32944  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 4000 -- Train Loss: 0.33006  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 4001 -- Train Loss: 0.32978  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 4002 -- Train Loss: 0.33011  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 4003 -- Train Loss: 0.33025  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 4004 -- Train Loss: 0.33070  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 4005 -- Train Loss: 0.33034  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 4006 -- Train Loss: 0.33066  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 4007 -- Train Loss: 0.33067  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 4008 -- Train Loss: 0.33012  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 4009 -- Train Loss: 0.33030  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 4010 -- Train Loss: 0.32946  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4011 -- Train Loss: 0.32965  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 4012 -- Train Loss: 0.33066  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 4013 -- Train Loss: 0.33044  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 4014 -- Train Loss: 0.33057  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 4015 -- Train Loss: 0.33051  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 4016 -- Train Loss: 0.33098  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 4017 -- Train Loss: 0.33079  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 4018 -- Train Loss: 0.33050  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 4019 -- Train Loss: 0.33083  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 4020 -- Train Loss: 0.33031  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 4021 -- Train Loss: 0.33062  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 4022 -- Train Loss: 0.33052  Validation Loss: 0.43034\n",
      "t: 10 EPOCH 4023 -- Train Loss: 0.33066  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 4024 -- Train Loss: 0.33037  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 4025 -- Train Loss: 0.33029  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 4026 -- Train Loss: 0.33073  Validation Loss: 0.42992\n",
      "t: 10 EPOCH 4027 -- Train Loss: 0.32996  Validation Loss: 0.43173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4028 -- Train Loss: 0.33097  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 4029 -- Train Loss: 0.33021  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 4030 -- Train Loss: 0.33073  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 4031 -- Train Loss: 0.33105  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 4032 -- Train Loss: 0.33071  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4033 -- Train Loss: 0.33011  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 4034 -- Train Loss: 0.33018  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 4035 -- Train Loss: 0.33098  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 4036 -- Train Loss: 0.33035  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 4037 -- Train Loss: 0.33047  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 4038 -- Train Loss: 0.32875  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 4039 -- Train Loss: 0.33133  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 4040 -- Train Loss: 0.32969  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 4041 -- Train Loss: 0.33088  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4042 -- Train Loss: 0.32982  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 4043 -- Train Loss: 0.32971  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 4044 -- Train Loss: 0.32953  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4045 -- Train Loss: 0.33012  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 4046 -- Train Loss: 0.33009  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 4047 -- Train Loss: 0.32982  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 4048 -- Train Loss: 0.33066  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 4049 -- Train Loss: 0.32970  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 4050 -- Train Loss: 0.33003  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 4051 -- Train Loss: 0.33072  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 4052 -- Train Loss: 0.32974  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 4053 -- Train Loss: 0.32999  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 4054 -- Train Loss: 0.33027  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 4055 -- Train Loss: 0.33004  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 4056 -- Train Loss: 0.33041  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 4057 -- Train Loss: 0.32992  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4058 -- Train Loss: 0.33035  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 4059 -- Train Loss: 0.33049  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 4060 -- Train Loss: 0.32922  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4061 -- Train Loss: 0.33033  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 4062 -- Train Loss: 0.33035  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 4063 -- Train Loss: 0.33046  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 4064 -- Train Loss: 0.32916  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 4065 -- Train Loss: 0.32900  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 4066 -- Train Loss: 0.33009  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 4067 -- Train Loss: 0.32900  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 4068 -- Train Loss: 0.32971  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 4069 -- Train Loss: 0.33042  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 4070 -- Train Loss: 0.33057  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 4071 -- Train Loss: 0.32956  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 4072 -- Train Loss: 0.33060  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 4073 -- Train Loss: 0.33003  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 4074 -- Train Loss: 0.33038  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 4075 -- Train Loss: 0.32972  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 4076 -- Train Loss: 0.32971  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 4077 -- Train Loss: 0.33039  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4078 -- Train Loss: 0.33042  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 4079 -- Train Loss: 0.33026  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4080 -- Train Loss: 0.33058  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 4081 -- Train Loss: 0.33023  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 4082 -- Train Loss: 0.32970  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4083 -- Train Loss: 0.33009  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 4084 -- Train Loss: 0.32989  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 4085 -- Train Loss: 0.33104  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 4086 -- Train Loss: 0.33010  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 4087 -- Train Loss: 0.32976  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4088 -- Train Loss: 0.32986  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 4089 -- Train Loss: 0.33058  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 4090 -- Train Loss: 0.32968  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 4091 -- Train Loss: 0.32949  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 4092 -- Train Loss: 0.33025  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 4093 -- Train Loss: 0.33095  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 4094 -- Train Loss: 0.33018  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 4095 -- Train Loss: 0.32901  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 4096 -- Train Loss: 0.32960  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 4097 -- Train Loss: 0.32984  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 4098 -- Train Loss: 0.33016  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4099 -- Train Loss: 0.33053  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 4100 -- Train Loss: 0.32902  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 4101 -- Train Loss: 0.33047  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 4102 -- Train Loss: 0.32962  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 4103 -- Train Loss: 0.33053  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 4104 -- Train Loss: 0.33058  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 4105 -- Train Loss: 0.32976  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4106 -- Train Loss: 0.33070  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 4107 -- Train Loss: 0.32986  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 4108 -- Train Loss: 0.33094  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 4109 -- Train Loss: 0.33033  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4110 -- Train Loss: 0.33018  Validation Loss: 0.42930\n",
      "t: 10 EPOCH 4111 -- Train Loss: 0.32998  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 4112 -- Train Loss: 0.33054  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 4113 -- Train Loss: 0.33011  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 4114 -- Train Loss: 0.32976  Validation Loss: 0.43046\n",
      "t: 10 EPOCH 4115 -- Train Loss: 0.32977  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 4116 -- Train Loss: 0.33061  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4117 -- Train Loss: 0.33027  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 4118 -- Train Loss: 0.32990  Validation Loss: 0.42968\n",
      "t: 10 EPOCH 4119 -- Train Loss: 0.33039  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4120 -- Train Loss: 0.33026  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 4121 -- Train Loss: 0.33079  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 4122 -- Train Loss: 0.33024  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 4123 -- Train Loss: 0.33111  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 4124 -- Train Loss: 0.33030  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 4125 -- Train Loss: 0.33037  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 4126 -- Train Loss: 0.33028  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 4127 -- Train Loss: 0.33004  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 4128 -- Train Loss: 0.33033  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 4129 -- Train Loss: 0.33091  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 4130 -- Train Loss: 0.33016  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 4131 -- Train Loss: 0.32972  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4132 -- Train Loss: 0.32965  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4133 -- Train Loss: 0.32910  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 4134 -- Train Loss: 0.33062  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 4135 -- Train Loss: 0.32997  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4136 -- Train Loss: 0.32962  Validation Loss: 0.42960\n",
      "t: 10 EPOCH 4137 -- Train Loss: 0.33071  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 4138 -- Train Loss: 0.33020  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 4139 -- Train Loss: 0.33035  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 4140 -- Train Loss: 0.33036  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 4141 -- Train Loss: 0.32983  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 4142 -- Train Loss: 0.33054  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 4143 -- Train Loss: 0.32984  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 4144 -- Train Loss: 0.32961  Validation Loss: 0.43048\n",
      "t: 10 EPOCH 4145 -- Train Loss: 0.32973  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 4146 -- Train Loss: 0.32957  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4147 -- Train Loss: 0.33109  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 4148 -- Train Loss: 0.33024  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4149 -- Train Loss: 0.32949  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 4150 -- Train Loss: 0.33079  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 4151 -- Train Loss: 0.32931  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 4152 -- Train Loss: 0.32955  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 4153 -- Train Loss: 0.32985  Validation Loss: 0.43371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4154 -- Train Loss: 0.33079  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 4155 -- Train Loss: 0.32981  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 4156 -- Train Loss: 0.33032  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 4157 -- Train Loss: 0.32957  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 4158 -- Train Loss: 0.33001  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 4159 -- Train Loss: 0.32951  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 4160 -- Train Loss: 0.32978  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 4161 -- Train Loss: 0.32952  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 4162 -- Train Loss: 0.33087  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 4163 -- Train Loss: 0.33001  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 4164 -- Train Loss: 0.33068  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 4165 -- Train Loss: 0.32921  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 4166 -- Train Loss: 0.33036  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 4167 -- Train Loss: 0.32976  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 4168 -- Train Loss: 0.32945  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 4169 -- Train Loss: 0.32876  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 4170 -- Train Loss: 0.33019  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 4171 -- Train Loss: 0.32943  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 4172 -- Train Loss: 0.32964  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 4173 -- Train Loss: 0.32974  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 4174 -- Train Loss: 0.32953  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 4175 -- Train Loss: 0.33005  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 4176 -- Train Loss: 0.32933  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 4177 -- Train Loss: 0.32957  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 4178 -- Train Loss: 0.32958  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 4179 -- Train Loss: 0.32863  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 4180 -- Train Loss: 0.32987  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 4181 -- Train Loss: 0.32922  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 4182 -- Train Loss: 0.33007  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 4183 -- Train Loss: 0.33056  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 4184 -- Train Loss: 0.33076  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 4185 -- Train Loss: 0.32831  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 4186 -- Train Loss: 0.33026  Validation Loss: 0.43017\n",
      "t: 10 EPOCH 4187 -- Train Loss: 0.32994  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 4188 -- Train Loss: 0.33004  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 4189 -- Train Loss: 0.32911  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 4190 -- Train Loss: 0.33031  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 4191 -- Train Loss: 0.32988  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4192 -- Train Loss: 0.33050  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 4193 -- Train Loss: 0.32916  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 4194 -- Train Loss: 0.33000  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 4195 -- Train Loss: 0.32992  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 4196 -- Train Loss: 0.32925  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 4197 -- Train Loss: 0.33025  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 4198 -- Train Loss: 0.32997  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 4199 -- Train Loss: 0.33003  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 4200 -- Train Loss: 0.32951  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 4201 -- Train Loss: 0.32964  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 4202 -- Train Loss: 0.33003  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4203 -- Train Loss: 0.32990  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 4204 -- Train Loss: 0.32924  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 4205 -- Train Loss: 0.33009  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 4206 -- Train Loss: 0.32877  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 4207 -- Train Loss: 0.32980  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 4208 -- Train Loss: 0.32972  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 4209 -- Train Loss: 0.32962  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 4210 -- Train Loss: 0.32956  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 4211 -- Train Loss: 0.33005  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 4212 -- Train Loss: 0.32954  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 4213 -- Train Loss: 0.33078  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 4214 -- Train Loss: 0.32973  Validation Loss: 0.42916\n",
      "t: 10 EPOCH 4215 -- Train Loss: 0.32862  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 4216 -- Train Loss: 0.32952  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4217 -- Train Loss: 0.33028  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 4218 -- Train Loss: 0.33026  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 4219 -- Train Loss: 0.32897  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 4220 -- Train Loss: 0.32978  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4221 -- Train Loss: 0.33010  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 4222 -- Train Loss: 0.32894  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 4223 -- Train Loss: 0.32964  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 4224 -- Train Loss: 0.32979  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 4225 -- Train Loss: 0.33031  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 4226 -- Train Loss: 0.33061  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 4227 -- Train Loss: 0.33113  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 4228 -- Train Loss: 0.32951  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 4229 -- Train Loss: 0.33055  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 4230 -- Train Loss: 0.32941  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 4231 -- Train Loss: 0.33052  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 4232 -- Train Loss: 0.32967  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 4233 -- Train Loss: 0.33090  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 4234 -- Train Loss: 0.32978  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 4235 -- Train Loss: 0.33008  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4236 -- Train Loss: 0.33072  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 4237 -- Train Loss: 0.32990  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 4238 -- Train Loss: 0.32953  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4239 -- Train Loss: 0.33067  Validation Loss: 0.42970\n",
      "t: 10 EPOCH 4240 -- Train Loss: 0.33034  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 4241 -- Train Loss: 0.33042  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4242 -- Train Loss: 0.32997  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4243 -- Train Loss: 0.33039  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 4244 -- Train Loss: 0.33019  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 4245 -- Train Loss: 0.33070  Validation Loss: 0.43049\n",
      "t: 10 EPOCH 4246 -- Train Loss: 0.33080  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 4247 -- Train Loss: 0.33073  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 4248 -- Train Loss: 0.33016  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 4249 -- Train Loss: 0.32989  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 4250 -- Train Loss: 0.32994  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 4251 -- Train Loss: 0.33173  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 4252 -- Train Loss: 0.33039  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 4253 -- Train Loss: 0.33028  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 4254 -- Train Loss: 0.32911  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 4255 -- Train Loss: 0.33055  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 4256 -- Train Loss: 0.32994  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 4257 -- Train Loss: 0.33109  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 4258 -- Train Loss: 0.33040  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4259 -- Train Loss: 0.33143  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 4260 -- Train Loss: 0.33040  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 4261 -- Train Loss: 0.33125  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4262 -- Train Loss: 0.32941  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 4263 -- Train Loss: 0.33056  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 4264 -- Train Loss: 0.33033  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 4265 -- Train Loss: 0.33135  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 4266 -- Train Loss: 0.33026  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4267 -- Train Loss: 0.33040  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 4268 -- Train Loss: 0.32983  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 4269 -- Train Loss: 0.33204  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 4270 -- Train Loss: 0.32980  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 4271 -- Train Loss: 0.33202  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 4272 -- Train Loss: 0.33026  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4273 -- Train Loss: 0.33067  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 4274 -- Train Loss: 0.32967  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 4275 -- Train Loss: 0.33022  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 4276 -- Train Loss: 0.33069  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 4277 -- Train Loss: 0.33023  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 4278 -- Train Loss: 0.33020  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 4279 -- Train Loss: 0.33050  Validation Loss: 0.43239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4280 -- Train Loss: 0.33015  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 4281 -- Train Loss: 0.33019  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 4282 -- Train Loss: 0.33066  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 4283 -- Train Loss: 0.32980  Validation Loss: 0.43004\n",
      "t: 10 EPOCH 4284 -- Train Loss: 0.33036  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 4285 -- Train Loss: 0.32939  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 4286 -- Train Loss: 0.33105  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4287 -- Train Loss: 0.32996  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 4288 -- Train Loss: 0.33042  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 4289 -- Train Loss: 0.33036  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 4290 -- Train Loss: 0.33087  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 4291 -- Train Loss: 0.32909  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 4292 -- Train Loss: 0.33008  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 4293 -- Train Loss: 0.33010  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 4294 -- Train Loss: 0.32997  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 4295 -- Train Loss: 0.33015  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 4296 -- Train Loss: 0.33072  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 4297 -- Train Loss: 0.33010  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 4298 -- Train Loss: 0.33027  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 4299 -- Train Loss: 0.33036  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4300 -- Train Loss: 0.33080  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 4301 -- Train Loss: 0.33010  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 4302 -- Train Loss: 0.32996  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 4303 -- Train Loss: 0.32963  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 4304 -- Train Loss: 0.32929  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 4305 -- Train Loss: 0.32983  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 4306 -- Train Loss: 0.33099  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 4307 -- Train Loss: 0.32948  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 4308 -- Train Loss: 0.32967  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 4309 -- Train Loss: 0.32991  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 4310 -- Train Loss: 0.32976  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 4311 -- Train Loss: 0.32993  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 4312 -- Train Loss: 0.33033  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 4313 -- Train Loss: 0.32975  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 4314 -- Train Loss: 0.32978  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 4315 -- Train Loss: 0.32982  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 4316 -- Train Loss: 0.32979  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 4317 -- Train Loss: 0.32953  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 4318 -- Train Loss: 0.32984  Validation Loss: 0.42997\n",
      "t: 10 EPOCH 4319 -- Train Loss: 0.32937  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 4320 -- Train Loss: 0.32966  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 4321 -- Train Loss: 0.33041  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 4322 -- Train Loss: 0.33010  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 4323 -- Train Loss: 0.33013  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 4324 -- Train Loss: 0.33011  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 4325 -- Train Loss: 0.33065  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 4326 -- Train Loss: 0.32914  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 4327 -- Train Loss: 0.33035  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 4328 -- Train Loss: 0.32996  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 4329 -- Train Loss: 0.32980  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 4330 -- Train Loss: 0.33029  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4331 -- Train Loss: 0.32925  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 4332 -- Train Loss: 0.32966  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 4333 -- Train Loss: 0.32957  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 4334 -- Train Loss: 0.33023  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 4335 -- Train Loss: 0.32993  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 4336 -- Train Loss: 0.33026  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 4337 -- Train Loss: 0.32962  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4338 -- Train Loss: 0.32949  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 4339 -- Train Loss: 0.33040  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 4340 -- Train Loss: 0.32979  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 4341 -- Train Loss: 0.33014  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 4342 -- Train Loss: 0.32983  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 4343 -- Train Loss: 0.32941  Validation Loss: 0.43074\n",
      "t: 10 EPOCH 4344 -- Train Loss: 0.32998  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4345 -- Train Loss: 0.32960  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 4346 -- Train Loss: 0.33058  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4347 -- Train Loss: 0.33078  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 4348 -- Train Loss: 0.32997  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4349 -- Train Loss: 0.32938  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 4350 -- Train Loss: 0.32980  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 4351 -- Train Loss: 0.32978  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 4352 -- Train Loss: 0.32937  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 4353 -- Train Loss: 0.33031  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 4354 -- Train Loss: 0.32946  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 4355 -- Train Loss: 0.32996  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 4356 -- Train Loss: 0.32945  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 4357 -- Train Loss: 0.32986  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 4358 -- Train Loss: 0.32887  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 4359 -- Train Loss: 0.33025  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 4360 -- Train Loss: 0.33069  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 4361 -- Train Loss: 0.32965  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 4362 -- Train Loss: 0.32930  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 4363 -- Train Loss: 0.32949  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 4364 -- Train Loss: 0.32986  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 4365 -- Train Loss: 0.33024  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 4366 -- Train Loss: 0.32902  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 4367 -- Train Loss: 0.33004  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 4368 -- Train Loss: 0.32999  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 4369 -- Train Loss: 0.32952  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 4370 -- Train Loss: 0.32969  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 4371 -- Train Loss: 0.32970  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 4372 -- Train Loss: 0.32916  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4373 -- Train Loss: 0.32868  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4374 -- Train Loss: 0.32930  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 4375 -- Train Loss: 0.32975  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4376 -- Train Loss: 0.33030  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4377 -- Train Loss: 0.32908  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 4378 -- Train Loss: 0.33053  Validation Loss: 0.42985\n",
      "t: 10 EPOCH 4379 -- Train Loss: 0.32959  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 4380 -- Train Loss: 0.32916  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 4381 -- Train Loss: 0.33038  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 4382 -- Train Loss: 0.32911  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 4383 -- Train Loss: 0.32968  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 4384 -- Train Loss: 0.32923  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 4385 -- Train Loss: 0.32940  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4386 -- Train Loss: 0.32980  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 4387 -- Train Loss: 0.33066  Validation Loss: 0.42953\n",
      "t: 10 EPOCH 4388 -- Train Loss: 0.32948  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 4389 -- Train Loss: 0.32972  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 4390 -- Train Loss: 0.32996  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 4391 -- Train Loss: 0.32937  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 4392 -- Train Loss: 0.32981  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 4393 -- Train Loss: 0.32992  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 4394 -- Train Loss: 0.32959  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 4395 -- Train Loss: 0.32949  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4396 -- Train Loss: 0.32990  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 4397 -- Train Loss: 0.32895  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 4398 -- Train Loss: 0.32908  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 4399 -- Train Loss: 0.32886  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 4400 -- Train Loss: 0.32992  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 4401 -- Train Loss: 0.32837  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 4402 -- Train Loss: 0.33004  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 4403 -- Train Loss: 0.32878  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4404 -- Train Loss: 0.33046  Validation Loss: 0.43070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4405 -- Train Loss: 0.32872  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 4406 -- Train Loss: 0.32920  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 4407 -- Train Loss: 0.32951  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 4408 -- Train Loss: 0.33031  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 4409 -- Train Loss: 0.32954  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 4410 -- Train Loss: 0.32984  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 4411 -- Train Loss: 0.33053  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 4412 -- Train Loss: 0.32933  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 4413 -- Train Loss: 0.32987  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 4414 -- Train Loss: 0.32862  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 4415 -- Train Loss: 0.32848  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 4416 -- Train Loss: 0.32951  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4417 -- Train Loss: 0.33031  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 4418 -- Train Loss: 0.32990  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 4419 -- Train Loss: 0.32965  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 4420 -- Train Loss: 0.32942  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 4421 -- Train Loss: 0.32986  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 4422 -- Train Loss: 0.32909  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4423 -- Train Loss: 0.32975  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 4424 -- Train Loss: 0.33032  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 4425 -- Train Loss: 0.32998  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 4426 -- Train Loss: 0.32980  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 4427 -- Train Loss: 0.33032  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 4428 -- Train Loss: 0.33034  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 4429 -- Train Loss: 0.33006  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4430 -- Train Loss: 0.33037  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 4431 -- Train Loss: 0.33006  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 4432 -- Train Loss: 0.33007  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 4433 -- Train Loss: 0.32981  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 4434 -- Train Loss: 0.33017  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 4435 -- Train Loss: 0.32953  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 4436 -- Train Loss: 0.33056  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 4437 -- Train Loss: 0.32971  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 4438 -- Train Loss: 0.32999  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 4439 -- Train Loss: 0.32948  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4440 -- Train Loss: 0.32893  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 4441 -- Train Loss: 0.33038  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 4442 -- Train Loss: 0.33125  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 4443 -- Train Loss: 0.33034  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 4444 -- Train Loss: 0.33017  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 4445 -- Train Loss: 0.33063  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 4446 -- Train Loss: 0.32936  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 4447 -- Train Loss: 0.33083  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 4448 -- Train Loss: 0.33009  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 4449 -- Train Loss: 0.33165  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4450 -- Train Loss: 0.33023  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 4451 -- Train Loss: 0.33096  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 4452 -- Train Loss: 0.32996  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 4453 -- Train Loss: 0.33142  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 4454 -- Train Loss: 0.33071  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 4455 -- Train Loss: 0.33106  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 4456 -- Train Loss: 0.33014  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4457 -- Train Loss: 0.33053  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 4458 -- Train Loss: 0.33060  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 4459 -- Train Loss: 0.32972  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 4460 -- Train Loss: 0.32999  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 4461 -- Train Loss: 0.32963  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 4462 -- Train Loss: 0.33048  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 4463 -- Train Loss: 0.32992  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 4464 -- Train Loss: 0.33050  Validation Loss: 0.43044\n",
      "t: 10 EPOCH 4465 -- Train Loss: 0.32995  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 4466 -- Train Loss: 0.32997  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 4467 -- Train Loss: 0.32972  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 4468 -- Train Loss: 0.33088  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4469 -- Train Loss: 0.32918  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 4470 -- Train Loss: 0.33029  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 4471 -- Train Loss: 0.32911  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 4472 -- Train Loss: 0.33078  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 4473 -- Train Loss: 0.32997  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 4474 -- Train Loss: 0.33109  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 4475 -- Train Loss: 0.32932  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 4476 -- Train Loss: 0.32944  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 4477 -- Train Loss: 0.32982  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 4478 -- Train Loss: 0.33066  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4479 -- Train Loss: 0.33032  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 4480 -- Train Loss: 0.33055  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 4481 -- Train Loss: 0.32956  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 4482 -- Train Loss: 0.33018  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4483 -- Train Loss: 0.33020  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 4484 -- Train Loss: 0.32951  Validation Loss: 0.43056\n",
      "t: 10 EPOCH 4485 -- Train Loss: 0.33000  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4486 -- Train Loss: 0.33053  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 4487 -- Train Loss: 0.33002  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 4488 -- Train Loss: 0.32931  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 4489 -- Train Loss: 0.33038  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 4490 -- Train Loss: 0.33044  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 4491 -- Train Loss: 0.32977  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 4492 -- Train Loss: 0.32900  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 4493 -- Train Loss: 0.32970  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 4494 -- Train Loss: 0.32983  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 4495 -- Train Loss: 0.32956  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 4496 -- Train Loss: 0.32935  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 4497 -- Train Loss: 0.32967  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 4498 -- Train Loss: 0.32925  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 4499 -- Train Loss: 0.32968  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 4500 -- Train Loss: 0.33047  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 4501 -- Train Loss: 0.33006  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 4502 -- Train Loss: 0.32865  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 4503 -- Train Loss: 0.33034  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 4504 -- Train Loss: 0.32927  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 4505 -- Train Loss: 0.32996  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 4506 -- Train Loss: 0.33009  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 4507 -- Train Loss: 0.33022  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 4508 -- Train Loss: 0.32971  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 4509 -- Train Loss: 0.33026  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 4510 -- Train Loss: 0.32978  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4511 -- Train Loss: 0.33030  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 4512 -- Train Loss: 0.32963  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 4513 -- Train Loss: 0.32944  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 4514 -- Train Loss: 0.32990  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 4515 -- Train Loss: 0.33021  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 4516 -- Train Loss: 0.33025  Validation Loss: 0.42949\n",
      "t: 10 EPOCH 4517 -- Train Loss: 0.33002  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 4518 -- Train Loss: 0.32960  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 4519 -- Train Loss: 0.33046  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 4520 -- Train Loss: 0.33039  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 4521 -- Train Loss: 0.33020  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4522 -- Train Loss: 0.33007  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 4523 -- Train Loss: 0.32989  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4524 -- Train Loss: 0.33011  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 4525 -- Train Loss: 0.33015  Validation Loss: 0.42977\n",
      "t: 10 EPOCH 4526 -- Train Loss: 0.32964  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 4527 -- Train Loss: 0.33018  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 4528 -- Train Loss: 0.32949  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 4529 -- Train Loss: 0.33042  Validation Loss: 0.43069\n",
      "t: 10 EPOCH 4530 -- Train Loss: 0.33065  Validation Loss: 0.43125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4531 -- Train Loss: 0.33014  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 4532 -- Train Loss: 0.33029  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 4533 -- Train Loss: 0.33050  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 4534 -- Train Loss: 0.32988  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 4535 -- Train Loss: 0.32965  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4536 -- Train Loss: 0.32977  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 4537 -- Train Loss: 0.32977  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 4538 -- Train Loss: 0.33015  Validation Loss: 0.42984\n",
      "t: 10 EPOCH 4539 -- Train Loss: 0.32931  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 4540 -- Train Loss: 0.33001  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4541 -- Train Loss: 0.32907  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 4542 -- Train Loss: 0.32967  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 4543 -- Train Loss: 0.33013  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 4544 -- Train Loss: 0.33018  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 4545 -- Train Loss: 0.32870  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 4546 -- Train Loss: 0.33035  Validation Loss: 0.42974\n",
      "t: 10 EPOCH 4547 -- Train Loss: 0.33088  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 4548 -- Train Loss: 0.32947  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 4549 -- Train Loss: 0.32982  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 4550 -- Train Loss: 0.32977  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 4551 -- Train Loss: 0.32957  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 4552 -- Train Loss: 0.32955  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 4553 -- Train Loss: 0.33004  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 4554 -- Train Loss: 0.32938  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4555 -- Train Loss: 0.32909  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 4556 -- Train Loss: 0.32963  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4557 -- Train Loss: 0.33029  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 4558 -- Train Loss: 0.32915  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 4559 -- Train Loss: 0.33046  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4560 -- Train Loss: 0.32994  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 4561 -- Train Loss: 0.32923  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 4562 -- Train Loss: 0.32958  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 4563 -- Train Loss: 0.32923  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 4564 -- Train Loss: 0.32978  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 4565 -- Train Loss: 0.32951  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 4566 -- Train Loss: 0.32940  Validation Loss: 0.42969\n",
      "t: 10 EPOCH 4567 -- Train Loss: 0.32998  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4568 -- Train Loss: 0.32940  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 4569 -- Train Loss: 0.32934  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 4570 -- Train Loss: 0.32916  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 4571 -- Train Loss: 0.33032  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 4572 -- Train Loss: 0.32931  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 4573 -- Train Loss: 0.32934  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 4574 -- Train Loss: 0.32984  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 4575 -- Train Loss: 0.32960  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 4576 -- Train Loss: 0.33004  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 4577 -- Train Loss: 0.33005  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 4578 -- Train Loss: 0.33036  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 4579 -- Train Loss: 0.32958  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 4580 -- Train Loss: 0.33019  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4581 -- Train Loss: 0.32966  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 4582 -- Train Loss: 0.32980  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4583 -- Train Loss: 0.32892  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4584 -- Train Loss: 0.32910  Validation Loss: 0.43099\n",
      "t: 10 EPOCH 4585 -- Train Loss: 0.32902  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 4586 -- Train Loss: 0.32939  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4587 -- Train Loss: 0.33006  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 4588 -- Train Loss: 0.33016  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 4589 -- Train Loss: 0.32906  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4590 -- Train Loss: 0.33033  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 4591 -- Train Loss: 0.33032  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 4592 -- Train Loss: 0.32951  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 4593 -- Train Loss: 0.32978  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 4594 -- Train Loss: 0.32982  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 4595 -- Train Loss: 0.33023  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 4596 -- Train Loss: 0.32876  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 4597 -- Train Loss: 0.32935  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 4598 -- Train Loss: 0.32898  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 4599 -- Train Loss: 0.32958  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 4600 -- Train Loss: 0.32952  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 4601 -- Train Loss: 0.32993  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 4602 -- Train Loss: 0.32930  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 4603 -- Train Loss: 0.32945  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 4604 -- Train Loss: 0.32997  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 4605 -- Train Loss: 0.32949  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 4606 -- Train Loss: 0.32891  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 4607 -- Train Loss: 0.32976  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 4608 -- Train Loss: 0.32904  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4609 -- Train Loss: 0.33007  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4610 -- Train Loss: 0.32929  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 4611 -- Train Loss: 0.33017  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 4612 -- Train Loss: 0.32873  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 4613 -- Train Loss: 0.33076  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 4614 -- Train Loss: 0.32898  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 4615 -- Train Loss: 0.33015  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 4616 -- Train Loss: 0.32948  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 4617 -- Train Loss: 0.33024  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 4618 -- Train Loss: 0.32934  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 4619 -- Train Loss: 0.33074  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4620 -- Train Loss: 0.32909  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 4621 -- Train Loss: 0.32881  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 4622 -- Train Loss: 0.32961  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4623 -- Train Loss: 0.33024  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 4624 -- Train Loss: 0.32949  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 4625 -- Train Loss: 0.32975  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 4626 -- Train Loss: 0.32872  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 4627 -- Train Loss: 0.33099  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 4628 -- Train Loss: 0.32966  Validation Loss: 0.43087\n",
      "t: 10 EPOCH 4629 -- Train Loss: 0.33011  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4630 -- Train Loss: 0.32923  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 4631 -- Train Loss: 0.33054  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 4632 -- Train Loss: 0.32864  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 4633 -- Train Loss: 0.32991  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 4634 -- Train Loss: 0.33030  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 4635 -- Train Loss: 0.33085  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 4636 -- Train Loss: 0.32971  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 4637 -- Train Loss: 0.32967  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 4638 -- Train Loss: 0.33000  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 4639 -- Train Loss: 0.32905  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 4640 -- Train Loss: 0.33006  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 4641 -- Train Loss: 0.32929  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 4642 -- Train Loss: 0.32939  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 4643 -- Train Loss: 0.32982  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4644 -- Train Loss: 0.32972  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4645 -- Train Loss: 0.33039  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 4646 -- Train Loss: 0.32967  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 4647 -- Train Loss: 0.33062  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 4648 -- Train Loss: 0.32957  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 4649 -- Train Loss: 0.33016  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 4650 -- Train Loss: 0.32965  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 4651 -- Train Loss: 0.32993  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 4652 -- Train Loss: 0.33027  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 4653 -- Train Loss: 0.33023  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 4654 -- Train Loss: 0.32985  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 4655 -- Train Loss: 0.33052  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 4656 -- Train Loss: 0.32869  Validation Loss: 0.43274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4657 -- Train Loss: 0.33094  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 4658 -- Train Loss: 0.32966  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 4659 -- Train Loss: 0.33094  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 4660 -- Train Loss: 0.32936  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 4661 -- Train Loss: 0.33062  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 4662 -- Train Loss: 0.32873  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 4663 -- Train Loss: 0.32980  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 4664 -- Train Loss: 0.33037  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 4665 -- Train Loss: 0.32918  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 4666 -- Train Loss: 0.32938  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 4667 -- Train Loss: 0.33003  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 4668 -- Train Loss: 0.33075  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4669 -- Train Loss: 0.33036  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 4670 -- Train Loss: 0.33003  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 4671 -- Train Loss: 0.32872  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4672 -- Train Loss: 0.32988  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 4673 -- Train Loss: 0.33021  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 4674 -- Train Loss: 0.32991  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 4675 -- Train Loss: 0.32964  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 4676 -- Train Loss: 0.32969  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 4677 -- Train Loss: 0.32863  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4678 -- Train Loss: 0.32914  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 4679 -- Train Loss: 0.32940  Validation Loss: 0.43068\n",
      "t: 10 EPOCH 4680 -- Train Loss: 0.33029  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 4681 -- Train Loss: 0.32890  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4682 -- Train Loss: 0.33039  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4683 -- Train Loss: 0.32845  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 4684 -- Train Loss: 0.32965  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 4685 -- Train Loss: 0.32964  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4686 -- Train Loss: 0.33013  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 4687 -- Train Loss: 0.33035  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 4688 -- Train Loss: 0.33034  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 4689 -- Train Loss: 0.33035  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 4690 -- Train Loss: 0.32917  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 4691 -- Train Loss: 0.32922  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 4692 -- Train Loss: 0.32947  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 4693 -- Train Loss: 0.32921  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 4694 -- Train Loss: 0.33000  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 4695 -- Train Loss: 0.32895  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 4696 -- Train Loss: 0.33091  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 4697 -- Train Loss: 0.32969  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 4698 -- Train Loss: 0.33008  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 4699 -- Train Loss: 0.32926  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 4700 -- Train Loss: 0.32947  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 4701 -- Train Loss: 0.32938  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 4702 -- Train Loss: 0.32990  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4703 -- Train Loss: 0.32908  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4704 -- Train Loss: 0.32918  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 4705 -- Train Loss: 0.32852  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 4706 -- Train Loss: 0.32941  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 4707 -- Train Loss: 0.32972  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 4708 -- Train Loss: 0.32940  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 4709 -- Train Loss: 0.33010  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 4710 -- Train Loss: 0.32953  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 4711 -- Train Loss: 0.32963  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 4712 -- Train Loss: 0.32984  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 4713 -- Train Loss: 0.32965  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 4714 -- Train Loss: 0.32936  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 4715 -- Train Loss: 0.33022  Validation Loss: 0.43030\n",
      "t: 10 EPOCH 4716 -- Train Loss: 0.32883  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 4717 -- Train Loss: 0.33087  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 4718 -- Train Loss: 0.33000  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 4719 -- Train Loss: 0.32940  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 4720 -- Train Loss: 0.32930  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 4721 -- Train Loss: 0.33011  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 4722 -- Train Loss: 0.32959  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 4723 -- Train Loss: 0.32957  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 4724 -- Train Loss: 0.33057  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 4725 -- Train Loss: 0.32957  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4726 -- Train Loss: 0.32969  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 4727 -- Train Loss: 0.33009  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4728 -- Train Loss: 0.32910  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 4729 -- Train Loss: 0.32968  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4730 -- Train Loss: 0.32937  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 4731 -- Train Loss: 0.32927  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 4732 -- Train Loss: 0.32886  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 4733 -- Train Loss: 0.33029  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 4734 -- Train Loss: 0.32954  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 4735 -- Train Loss: 0.32920  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 4736 -- Train Loss: 0.32862  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4737 -- Train Loss: 0.32907  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 4738 -- Train Loss: 0.32943  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 4739 -- Train Loss: 0.33040  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 4740 -- Train Loss: 0.32848  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 4741 -- Train Loss: 0.33000  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 4742 -- Train Loss: 0.32986  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 4743 -- Train Loss: 0.32960  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 4744 -- Train Loss: 0.33003  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 4745 -- Train Loss: 0.33045  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 4746 -- Train Loss: 0.32994  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 4747 -- Train Loss: 0.33028  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 4748 -- Train Loss: 0.33016  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 4749 -- Train Loss: 0.32955  Validation Loss: 0.43032\n",
      "t: 10 EPOCH 4750 -- Train Loss: 0.32944  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4751 -- Train Loss: 0.32982  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 4752 -- Train Loss: 0.32948  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 4753 -- Train Loss: 0.32952  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 4754 -- Train Loss: 0.32951  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 4755 -- Train Loss: 0.32981  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 4756 -- Train Loss: 0.32974  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 4757 -- Train Loss: 0.32902  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 4758 -- Train Loss: 0.32992  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4759 -- Train Loss: 0.32942  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 4760 -- Train Loss: 0.32942  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 4761 -- Train Loss: 0.32934  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 4762 -- Train Loss: 0.33083  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 4763 -- Train Loss: 0.32946  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4764 -- Train Loss: 0.32943  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 4765 -- Train Loss: 0.32896  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 4766 -- Train Loss: 0.33094  Validation Loss: 0.43008\n",
      "t: 10 EPOCH 4767 -- Train Loss: 0.32956  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 4768 -- Train Loss: 0.32946  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 4769 -- Train Loss: 0.33017  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 4770 -- Train Loss: 0.32889  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 4771 -- Train Loss: 0.32985  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 4772 -- Train Loss: 0.32942  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 4773 -- Train Loss: 0.33065  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 4774 -- Train Loss: 0.33023  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 4775 -- Train Loss: 0.32866  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 4776 -- Train Loss: 0.32945  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 4777 -- Train Loss: 0.32959  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 4778 -- Train Loss: 0.32990  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 4779 -- Train Loss: 0.32978  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 4780 -- Train Loss: 0.32861  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4781 -- Train Loss: 0.32995  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 4782 -- Train Loss: 0.32900  Validation Loss: 0.43170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4783 -- Train Loss: 0.32973  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4784 -- Train Loss: 0.32900  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 4785 -- Train Loss: 0.32924  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 4786 -- Train Loss: 0.32868  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4787 -- Train Loss: 0.33006  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 4788 -- Train Loss: 0.32846  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 4789 -- Train Loss: 0.32997  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 4790 -- Train Loss: 0.32953  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 4791 -- Train Loss: 0.33020  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4792 -- Train Loss: 0.32974  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 4793 -- Train Loss: 0.32939  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 4794 -- Train Loss: 0.32959  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 4795 -- Train Loss: 0.32901  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 4796 -- Train Loss: 0.32968  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 4797 -- Train Loss: 0.32999  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4798 -- Train Loss: 0.32971  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 4799 -- Train Loss: 0.32996  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 4800 -- Train Loss: 0.33001  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 4801 -- Train Loss: 0.32960  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 4802 -- Train Loss: 0.32895  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 4803 -- Train Loss: 0.32932  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 4804 -- Train Loss: 0.32956  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 4805 -- Train Loss: 0.32972  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 4806 -- Train Loss: 0.32905  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 4807 -- Train Loss: 0.32943  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 4808 -- Train Loss: 0.32954  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 4809 -- Train Loss: 0.33010  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 4810 -- Train Loss: 0.32955  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 4811 -- Train Loss: 0.32941  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 4812 -- Train Loss: 0.32887  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4813 -- Train Loss: 0.33018  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 4814 -- Train Loss: 0.32954  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 4815 -- Train Loss: 0.32965  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 4816 -- Train Loss: 0.32927  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 4817 -- Train Loss: 0.32907  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 4818 -- Train Loss: 0.32946  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 4819 -- Train Loss: 0.33072  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 4820 -- Train Loss: 0.32994  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 4821 -- Train Loss: 0.32983  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 4822 -- Train Loss: 0.32948  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 4823 -- Train Loss: 0.32977  Validation Loss: 0.43064\n",
      "t: 10 EPOCH 4824 -- Train Loss: 0.32959  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 4825 -- Train Loss: 0.32980  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 4826 -- Train Loss: 0.32949  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 4827 -- Train Loss: 0.32996  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 4828 -- Train Loss: 0.32963  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 4829 -- Train Loss: 0.32937  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 4830 -- Train Loss: 0.33016  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 4831 -- Train Loss: 0.32920  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 4832 -- Train Loss: 0.32997  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 4833 -- Train Loss: 0.32944  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4834 -- Train Loss: 0.33016  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 4835 -- Train Loss: 0.32960  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 4836 -- Train Loss: 0.32961  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 4837 -- Train Loss: 0.32925  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 4838 -- Train Loss: 0.32914  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 4839 -- Train Loss: 0.32944  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 4840 -- Train Loss: 0.32999  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 4841 -- Train Loss: 0.32878  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 4842 -- Train Loss: 0.32987  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 4843 -- Train Loss: 0.32917  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 4844 -- Train Loss: 0.32952  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 4845 -- Train Loss: 0.32926  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 4846 -- Train Loss: 0.33026  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 4847 -- Train Loss: 0.32819  Validation Loss: 0.43059\n",
      "t: 10 EPOCH 4848 -- Train Loss: 0.32984  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 4849 -- Train Loss: 0.32897  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4850 -- Train Loss: 0.33064  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 4851 -- Train Loss: 0.32940  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 4852 -- Train Loss: 0.33010  Validation Loss: 0.43025\n",
      "t: 10 EPOCH 4853 -- Train Loss: 0.32841  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 4854 -- Train Loss: 0.32999  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 4855 -- Train Loss: 0.32985  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 4856 -- Train Loss: 0.32947  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 4857 -- Train Loss: 0.32947  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 4858 -- Train Loss: 0.32941  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 4859 -- Train Loss: 0.32913  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 4860 -- Train Loss: 0.32857  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 4861 -- Train Loss: 0.32972  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 4862 -- Train Loss: 0.32936  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 4863 -- Train Loss: 0.33002  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 4864 -- Train Loss: 0.32944  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4865 -- Train Loss: 0.32930  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 4866 -- Train Loss: 0.32974  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 4867 -- Train Loss: 0.32915  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 4868 -- Train Loss: 0.32928  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4869 -- Train Loss: 0.32865  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 4870 -- Train Loss: 0.32917  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 4871 -- Train Loss: 0.32907  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 4872 -- Train Loss: 0.33026  Validation Loss: 0.43027\n",
      "t: 10 EPOCH 4873 -- Train Loss: 0.32975  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 4874 -- Train Loss: 0.32989  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 4875 -- Train Loss: 0.32879  Validation Loss: 0.43011\n",
      "t: 10 EPOCH 4876 -- Train Loss: 0.32864  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 4877 -- Train Loss: 0.32853  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 4878 -- Train Loss: 0.32923  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 4879 -- Train Loss: 0.32974  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 4880 -- Train Loss: 0.32893  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 4881 -- Train Loss: 0.32993  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 4882 -- Train Loss: 0.32869  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 4883 -- Train Loss: 0.32884  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 4884 -- Train Loss: 0.32973  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 4885 -- Train Loss: 0.32999  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 4886 -- Train Loss: 0.32963  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 4887 -- Train Loss: 0.32947  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 4888 -- Train Loss: 0.32899  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 4889 -- Train Loss: 0.32908  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 4890 -- Train Loss: 0.32912  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 4891 -- Train Loss: 0.32942  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 4892 -- Train Loss: 0.32962  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 4893 -- Train Loss: 0.32855  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 4894 -- Train Loss: 0.32892  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 4895 -- Train Loss: 0.32902  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 4896 -- Train Loss: 0.32961  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 4897 -- Train Loss: 0.32956  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 4898 -- Train Loss: 0.32942  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 4899 -- Train Loss: 0.32845  Validation Loss: 0.42933\n",
      "t: 10 EPOCH 4900 -- Train Loss: 0.32946  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 4901 -- Train Loss: 0.32969  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 4902 -- Train Loss: 0.32918  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 4903 -- Train Loss: 0.32873  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 4904 -- Train Loss: 0.32909  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 4905 -- Train Loss: 0.32976  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 4906 -- Train Loss: 0.32985  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 4907 -- Train Loss: 0.32840  Validation Loss: 0.43165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 4908 -- Train Loss: 0.32996  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 4909 -- Train Loss: 0.32939  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 4910 -- Train Loss: 0.32880  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 4911 -- Train Loss: 0.33010  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 4912 -- Train Loss: 0.32932  Validation Loss: 0.42974\n",
      "t: 10 EPOCH 4913 -- Train Loss: 0.32972  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 4914 -- Train Loss: 0.32930  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 4915 -- Train Loss: 0.33083  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 4916 -- Train Loss: 0.33031  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 4917 -- Train Loss: 0.32936  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 4918 -- Train Loss: 0.32951  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4919 -- Train Loss: 0.32986  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 4920 -- Train Loss: 0.32933  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 4921 -- Train Loss: 0.33025  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 4922 -- Train Loss: 0.32937  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 4923 -- Train Loss: 0.32951  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 4924 -- Train Loss: 0.33013  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 4925 -- Train Loss: 0.32946  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 4926 -- Train Loss: 0.33074  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 4927 -- Train Loss: 0.33041  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 4928 -- Train Loss: 0.32916  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 4929 -- Train Loss: 0.32933  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 4930 -- Train Loss: 0.32909  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 4931 -- Train Loss: 0.33073  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 4932 -- Train Loss: 0.33077  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4933 -- Train Loss: 0.32963  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 4934 -- Train Loss: 0.32997  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 4935 -- Train Loss: 0.33036  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 4936 -- Train Loss: 0.32937  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 4937 -- Train Loss: 0.32875  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 4938 -- Train Loss: 0.32983  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 4939 -- Train Loss: 0.32919  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 4940 -- Train Loss: 0.32909  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 4941 -- Train Loss: 0.32899  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 4942 -- Train Loss: 0.32976  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 4943 -- Train Loss: 0.32899  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 4944 -- Train Loss: 0.33043  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 4945 -- Train Loss: 0.32890  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 4946 -- Train Loss: 0.33078  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 4947 -- Train Loss: 0.32866  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 4948 -- Train Loss: 0.33048  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 4949 -- Train Loss: 0.33029  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 4950 -- Train Loss: 0.33016  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 4951 -- Train Loss: 0.32820  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 4952 -- Train Loss: 0.33009  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 4953 -- Train Loss: 0.33031  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 4954 -- Train Loss: 0.32908  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 4955 -- Train Loss: 0.32934  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 4956 -- Train Loss: 0.33007  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 4957 -- Train Loss: 0.32924  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 4958 -- Train Loss: 0.32913  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 4959 -- Train Loss: 0.32991  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 4960 -- Train Loss: 0.32954  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 4961 -- Train Loss: 0.32943  Validation Loss: 0.43072\n",
      "t: 10 EPOCH 4962 -- Train Loss: 0.33018  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 4963 -- Train Loss: 0.32984  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 4964 -- Train Loss: 0.32972  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 4965 -- Train Loss: 0.32949  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 4966 -- Train Loss: 0.32939  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 4967 -- Train Loss: 0.32949  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 4968 -- Train Loss: 0.32878  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 4969 -- Train Loss: 0.32899  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 4970 -- Train Loss: 0.32949  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 4971 -- Train Loss: 0.32884  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 4972 -- Train Loss: 0.32949  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 4973 -- Train Loss: 0.32961  Validation Loss: 0.43005\n",
      "t: 10 EPOCH 4974 -- Train Loss: 0.32943  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 4975 -- Train Loss: 0.32925  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 4976 -- Train Loss: 0.32867  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 4977 -- Train Loss: 0.32933  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 4978 -- Train Loss: 0.32940  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 4979 -- Train Loss: 0.32911  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 4980 -- Train Loss: 0.32956  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 4981 -- Train Loss: 0.32980  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 4982 -- Train Loss: 0.32946  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 4983 -- Train Loss: 0.32953  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 4984 -- Train Loss: 0.33003  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 4985 -- Train Loss: 0.32933  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 4986 -- Train Loss: 0.32925  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 4987 -- Train Loss: 0.32921  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 4988 -- Train Loss: 0.32902  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 4989 -- Train Loss: 0.32938  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 4990 -- Train Loss: 0.33050  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 4991 -- Train Loss: 0.32892  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 4992 -- Train Loss: 0.32994  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 4993 -- Train Loss: 0.32880  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 4994 -- Train Loss: 0.32960  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 4995 -- Train Loss: 0.32876  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 4996 -- Train Loss: 0.32904  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 4997 -- Train Loss: 0.32990  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 4998 -- Train Loss: 0.32928  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 4999 -- Train Loss: 0.32931  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 5000 -- Train Loss: 0.32911  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5001 -- Train Loss: 0.32913  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 5002 -- Train Loss: 0.32892  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5003 -- Train Loss: 0.32818  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5004 -- Train Loss: 0.32872  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 5005 -- Train Loss: 0.32935  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 5006 -- Train Loss: 0.32888  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5007 -- Train Loss: 0.32929  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 5008 -- Train Loss: 0.32884  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 5009 -- Train Loss: 0.32971  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 5010 -- Train Loss: 0.32865  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 5011 -- Train Loss: 0.32843  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 5012 -- Train Loss: 0.33008  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 5013 -- Train Loss: 0.32888  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 5014 -- Train Loss: 0.33010  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 5015 -- Train Loss: 0.32889  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 5016 -- Train Loss: 0.32943  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 5017 -- Train Loss: 0.32920  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 5018 -- Train Loss: 0.32900  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 5019 -- Train Loss: 0.32939  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 5020 -- Train Loss: 0.32928  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 5021 -- Train Loss: 0.33029  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 5022 -- Train Loss: 0.32906  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5023 -- Train Loss: 0.32867  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 5024 -- Train Loss: 0.32970  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 5025 -- Train Loss: 0.32916  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 5026 -- Train Loss: 0.32932  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 5027 -- Train Loss: 0.32944  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 5028 -- Train Loss: 0.32882  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 5029 -- Train Loss: 0.32799  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5030 -- Train Loss: 0.32960  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5031 -- Train Loss: 0.32886  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5032 -- Train Loss: 0.32944  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 5033 -- Train Loss: 0.32919  Validation Loss: 0.43172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5034 -- Train Loss: 0.32915  Validation Loss: 0.42955\n",
      "t: 10 EPOCH 5035 -- Train Loss: 0.32873  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 5036 -- Train Loss: 0.32971  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5037 -- Train Loss: 0.32920  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 5038 -- Train Loss: 0.32946  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 5039 -- Train Loss: 0.32989  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 5040 -- Train Loss: 0.32919  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 5041 -- Train Loss: 0.33029  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 5042 -- Train Loss: 0.32964  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 5043 -- Train Loss: 0.32918  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 5044 -- Train Loss: 0.32767  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 5045 -- Train Loss: 0.33035  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 5046 -- Train Loss: 0.32883  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 5047 -- Train Loss: 0.32972  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 5048 -- Train Loss: 0.32938  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 5049 -- Train Loss: 0.32912  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 5050 -- Train Loss: 0.32942  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5051 -- Train Loss: 0.32936  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 5052 -- Train Loss: 0.32984  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 5053 -- Train Loss: 0.32920  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 5054 -- Train Loss: 0.32997  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 5055 -- Train Loss: 0.32995  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 5056 -- Train Loss: 0.33058  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5057 -- Train Loss: 0.32920  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 5058 -- Train Loss: 0.33003  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 5059 -- Train Loss: 0.32980  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 5060 -- Train Loss: 0.32985  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 5061 -- Train Loss: 0.32981  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 5062 -- Train Loss: 0.33028  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 5063 -- Train Loss: 0.33022  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 5064 -- Train Loss: 0.33007  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 5065 -- Train Loss: 0.32994  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 5066 -- Train Loss: 0.33047  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 5067 -- Train Loss: 0.33006  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 5068 -- Train Loss: 0.33054  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 5069 -- Train Loss: 0.33011  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 5070 -- Train Loss: 0.32974  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 5071 -- Train Loss: 0.33002  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 5072 -- Train Loss: 0.32998  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 5073 -- Train Loss: 0.33103  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 5074 -- Train Loss: 0.32981  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 5075 -- Train Loss: 0.32940  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 5076 -- Train Loss: 0.33030  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 5077 -- Train Loss: 0.32951  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5078 -- Train Loss: 0.32953  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 5079 -- Train Loss: 0.32920  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5080 -- Train Loss: 0.33013  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 5081 -- Train Loss: 0.32863  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 5082 -- Train Loss: 0.32958  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 5083 -- Train Loss: 0.32894  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 5084 -- Train Loss: 0.32952  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 5085 -- Train Loss: 0.32933  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 5086 -- Train Loss: 0.32979  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 5087 -- Train Loss: 0.32927  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 5088 -- Train Loss: 0.32911  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 5089 -- Train Loss: 0.32928  Validation Loss: 0.43073\n",
      "t: 10 EPOCH 5090 -- Train Loss: 0.32954  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 5091 -- Train Loss: 0.32924  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 5092 -- Train Loss: 0.33010  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5093 -- Train Loss: 0.32902  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5094 -- Train Loss: 0.32922  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5095 -- Train Loss: 0.32963  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 5096 -- Train Loss: 0.32956  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 5097 -- Train Loss: 0.32913  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5098 -- Train Loss: 0.32987  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 5099 -- Train Loss: 0.32918  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 5100 -- Train Loss: 0.33017  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5101 -- Train Loss: 0.32901  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 5102 -- Train Loss: 0.32896  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 5103 -- Train Loss: 0.32822  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 5104 -- Train Loss: 0.32955  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 5105 -- Train Loss: 0.33030  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 5106 -- Train Loss: 0.32906  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5107 -- Train Loss: 0.32992  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 5108 -- Train Loss: 0.32941  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 5109 -- Train Loss: 0.32953  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 5110 -- Train Loss: 0.32872  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 5111 -- Train Loss: 0.32905  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 5112 -- Train Loss: 0.32879  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5113 -- Train Loss: 0.32926  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 5114 -- Train Loss: 0.32826  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 5115 -- Train Loss: 0.32950  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 5116 -- Train Loss: 0.32999  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 5117 -- Train Loss: 0.32951  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 5118 -- Train Loss: 0.32913  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 5119 -- Train Loss: 0.32911  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 5120 -- Train Loss: 0.32931  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 5121 -- Train Loss: 0.32894  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 5122 -- Train Loss: 0.32980  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 5123 -- Train Loss: 0.32897  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 5124 -- Train Loss: 0.32984  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 5125 -- Train Loss: 0.32926  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5126 -- Train Loss: 0.32911  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 5127 -- Train Loss: 0.32979  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 5128 -- Train Loss: 0.33013  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 5129 -- Train Loss: 0.32781  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 5130 -- Train Loss: 0.32953  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 5131 -- Train Loss: 0.32935  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5132 -- Train Loss: 0.32894  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5133 -- Train Loss: 0.32948  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 5134 -- Train Loss: 0.32861  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 5135 -- Train Loss: 0.32847  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 5136 -- Train Loss: 0.32905  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 5137 -- Train Loss: 0.32965  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 5138 -- Train Loss: 0.32952  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 5139 -- Train Loss: 0.32916  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 5140 -- Train Loss: 0.32843  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 5141 -- Train Loss: 0.32904  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 5142 -- Train Loss: 0.32950  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 5143 -- Train Loss: 0.32974  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 5144 -- Train Loss: 0.32892  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 5145 -- Train Loss: 0.32993  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 5146 -- Train Loss: 0.32881  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 5147 -- Train Loss: 0.32925  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 5148 -- Train Loss: 0.32931  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 5149 -- Train Loss: 0.32921  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5150 -- Train Loss: 0.32918  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 5151 -- Train Loss: 0.32922  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 5152 -- Train Loss: 0.32928  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 5153 -- Train Loss: 0.32905  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 5154 -- Train Loss: 0.32942  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 5155 -- Train Loss: 0.32998  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 5156 -- Train Loss: 0.32986  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 5157 -- Train Loss: 0.32907  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 5158 -- Train Loss: 0.32904  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 5159 -- Train Loss: 0.33003  Validation Loss: 0.43292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5160 -- Train Loss: 0.32951  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 5161 -- Train Loss: 0.32937  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 5162 -- Train Loss: 0.32913  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 5163 -- Train Loss: 0.32970  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 5164 -- Train Loss: 0.32860  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5165 -- Train Loss: 0.32971  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 5166 -- Train Loss: 0.32913  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 5167 -- Train Loss: 0.32970  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 5168 -- Train Loss: 0.32906  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 5169 -- Train Loss: 0.32993  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 5170 -- Train Loss: 0.32914  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 5171 -- Train Loss: 0.32964  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 5172 -- Train Loss: 0.33002  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 5173 -- Train Loss: 0.32965  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 5174 -- Train Loss: 0.32894  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 5175 -- Train Loss: 0.33003  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 5176 -- Train Loss: 0.32900  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 5177 -- Train Loss: 0.32981  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5178 -- Train Loss: 0.32975  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 5179 -- Train Loss: 0.32985  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 5180 -- Train Loss: 0.32947  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5181 -- Train Loss: 0.33012  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 5182 -- Train Loss: 0.32874  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 5183 -- Train Loss: 0.32988  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 5184 -- Train Loss: 0.32946  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5185 -- Train Loss: 0.33084  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 5186 -- Train Loss: 0.32942  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 5187 -- Train Loss: 0.33032  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 5188 -- Train Loss: 0.32926  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 5189 -- Train Loss: 0.32980  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 5190 -- Train Loss: 0.32925  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 5191 -- Train Loss: 0.32982  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5192 -- Train Loss: 0.32936  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 5193 -- Train Loss: 0.32982  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 5194 -- Train Loss: 0.32966  Validation Loss: 0.42967\n",
      "t: 10 EPOCH 5195 -- Train Loss: 0.32937  Validation Loss: 0.43000\n",
      "t: 10 EPOCH 5196 -- Train Loss: 0.32915  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 5197 -- Train Loss: 0.32965  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 5198 -- Train Loss: 0.33022  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 5199 -- Train Loss: 0.33002  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 5200 -- Train Loss: 0.32996  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 5201 -- Train Loss: 0.32890  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 5202 -- Train Loss: 0.32992  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 5203 -- Train Loss: 0.32965  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 5204 -- Train Loss: 0.32907  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 5205 -- Train Loss: 0.32901  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 5206 -- Train Loss: 0.32980  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5207 -- Train Loss: 0.32963  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 5208 -- Train Loss: 0.32904  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 5209 -- Train Loss: 0.32944  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 5210 -- Train Loss: 0.33040  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5211 -- Train Loss: 0.32918  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5212 -- Train Loss: 0.32965  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 5213 -- Train Loss: 0.32880  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 5214 -- Train Loss: 0.32878  Validation Loss: 0.43035\n",
      "t: 10 EPOCH 5215 -- Train Loss: 0.32901  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 5216 -- Train Loss: 0.33077  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 5217 -- Train Loss: 0.32846  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 5218 -- Train Loss: 0.32978  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 5219 -- Train Loss: 0.32980  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 5220 -- Train Loss: 0.33003  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 5221 -- Train Loss: 0.32957  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 5222 -- Train Loss: 0.32956  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 5223 -- Train Loss: 0.32879  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5224 -- Train Loss: 0.33008  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 5225 -- Train Loss: 0.32863  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5226 -- Train Loss: 0.32814  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 5227 -- Train Loss: 0.32975  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 5228 -- Train Loss: 0.32859  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 5229 -- Train Loss: 0.32954  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 5230 -- Train Loss: 0.32842  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5231 -- Train Loss: 0.32912  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 5232 -- Train Loss: 0.32841  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 5233 -- Train Loss: 0.32996  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 5234 -- Train Loss: 0.32945  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 5235 -- Train Loss: 0.32970  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 5236 -- Train Loss: 0.32905  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 5237 -- Train Loss: 0.32963  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 5238 -- Train Loss: 0.32916  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 5239 -- Train Loss: 0.32960  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 5240 -- Train Loss: 0.32911  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 5241 -- Train Loss: 0.32924  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 5242 -- Train Loss: 0.32816  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 5243 -- Train Loss: 0.32943  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 5244 -- Train Loss: 0.32879  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 5245 -- Train Loss: 0.32897  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 5246 -- Train Loss: 0.32923  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5247 -- Train Loss: 0.32911  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 5248 -- Train Loss: 0.32837  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 5249 -- Train Loss: 0.33030  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 5250 -- Train Loss: 0.32844  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 5251 -- Train Loss: 0.32914  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 5252 -- Train Loss: 0.32955  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 5253 -- Train Loss: 0.32954  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 5254 -- Train Loss: 0.32922  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 5255 -- Train Loss: 0.32983  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 5256 -- Train Loss: 0.32959  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 5257 -- Train Loss: 0.32942  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 5258 -- Train Loss: 0.32948  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 5259 -- Train Loss: 0.32830  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 5260 -- Train Loss: 0.32904  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 5261 -- Train Loss: 0.32886  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 5262 -- Train Loss: 0.32924  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 5263 -- Train Loss: 0.32849  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 5264 -- Train Loss: 0.32941  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 5265 -- Train Loss: 0.32919  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 5266 -- Train Loss: 0.32942  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 5267 -- Train Loss: 0.32991  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5268 -- Train Loss: 0.33039  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 5269 -- Train Loss: 0.32883  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5270 -- Train Loss: 0.32978  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 5271 -- Train Loss: 0.32827  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 5272 -- Train Loss: 0.32883  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 5273 -- Train Loss: 0.32884  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 5274 -- Train Loss: 0.32947  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 5275 -- Train Loss: 0.32886  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 5276 -- Train Loss: 0.32928  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 5277 -- Train Loss: 0.32927  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5278 -- Train Loss: 0.32933  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 5279 -- Train Loss: 0.32898  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 5280 -- Train Loss: 0.32941  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 5281 -- Train Loss: 0.32909  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 5282 -- Train Loss: 0.32972  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 5283 -- Train Loss: 0.32887  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 5284 -- Train Loss: 0.32883  Validation Loss: 0.43204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5285 -- Train Loss: 0.32926  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 5286 -- Train Loss: 0.32829  Validation Loss: 0.43061\n",
      "t: 10 EPOCH 5287 -- Train Loss: 0.32888  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 5288 -- Train Loss: 0.32949  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 5289 -- Train Loss: 0.32868  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 5290 -- Train Loss: 0.32874  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 5291 -- Train Loss: 0.32955  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 5292 -- Train Loss: 0.32860  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 5293 -- Train Loss: 0.32845  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 5294 -- Train Loss: 0.32845  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 5295 -- Train Loss: 0.32966  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 5296 -- Train Loss: 0.32904  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 5297 -- Train Loss: 0.32927  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 5298 -- Train Loss: 0.32900  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 5299 -- Train Loss: 0.32866  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 5300 -- Train Loss: 0.32928  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 5301 -- Train Loss: 0.32923  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 5302 -- Train Loss: 0.32774  Validation Loss: 0.43063\n",
      "t: 10 EPOCH 5303 -- Train Loss: 0.32959  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 5304 -- Train Loss: 0.32916  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 5305 -- Train Loss: 0.32929  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 5306 -- Train Loss: 0.32961  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 5307 -- Train Loss: 0.32998  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 5308 -- Train Loss: 0.32957  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 5309 -- Train Loss: 0.33010  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5310 -- Train Loss: 0.32977  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 5311 -- Train Loss: 0.32991  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 5312 -- Train Loss: 0.32960  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 5313 -- Train Loss: 0.33009  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5314 -- Train Loss: 0.32921  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 5315 -- Train Loss: 0.33061  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 5316 -- Train Loss: 0.32955  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 5317 -- Train Loss: 0.32936  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 5318 -- Train Loss: 0.32986  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 5319 -- Train Loss: 0.32946  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 5320 -- Train Loss: 0.32938  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5321 -- Train Loss: 0.32907  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 5322 -- Train Loss: 0.32914  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 5323 -- Train Loss: 0.32918  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 5324 -- Train Loss: 0.32990  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 5325 -- Train Loss: 0.32910  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 5326 -- Train Loss: 0.32942  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 5327 -- Train Loss: 0.32935  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 5328 -- Train Loss: 0.32967  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 5329 -- Train Loss: 0.32988  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 5330 -- Train Loss: 0.32933  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 5331 -- Train Loss: 0.32919  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 5332 -- Train Loss: 0.32913  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 5333 -- Train Loss: 0.32925  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 5334 -- Train Loss: 0.32993  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 5335 -- Train Loss: 0.32999  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 5336 -- Train Loss: 0.32923  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 5337 -- Train Loss: 0.32929  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 5338 -- Train Loss: 0.32980  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 5339 -- Train Loss: 0.32929  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 5340 -- Train Loss: 0.32846  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 5341 -- Train Loss: 0.32988  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 5342 -- Train Loss: 0.32987  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 5343 -- Train Loss: 0.32952  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 5344 -- Train Loss: 0.32973  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 5345 -- Train Loss: 0.32963  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 5346 -- Train Loss: 0.32934  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 5347 -- Train Loss: 0.32892  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 5348 -- Train Loss: 0.32905  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 5349 -- Train Loss: 0.32884  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 5350 -- Train Loss: 0.32889  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 5351 -- Train Loss: 0.32983  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 5352 -- Train Loss: 0.32992  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 5353 -- Train Loss: 0.33016  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5354 -- Train Loss: 0.32975  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 5355 -- Train Loss: 0.32999  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 5356 -- Train Loss: 0.32890  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 5357 -- Train Loss: 0.32996  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5358 -- Train Loss: 0.32981  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 5359 -- Train Loss: 0.32932  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5360 -- Train Loss: 0.32975  Validation Loss: 0.43054\n",
      "t: 10 EPOCH 5361 -- Train Loss: 0.32864  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 5362 -- Train Loss: 0.32929  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 5363 -- Train Loss: 0.32832  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 5364 -- Train Loss: 0.32976  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 5365 -- Train Loss: 0.32817  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 5366 -- Train Loss: 0.32974  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 5367 -- Train Loss: 0.32855  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 5368 -- Train Loss: 0.32989  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 5369 -- Train Loss: 0.32912  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 5370 -- Train Loss: 0.32924  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 5371 -- Train Loss: 0.32828  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 5372 -- Train Loss: 0.32915  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 5373 -- Train Loss: 0.32971  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 5374 -- Train Loss: 0.32882  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 5375 -- Train Loss: 0.32919  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 5376 -- Train Loss: 0.32955  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 5377 -- Train Loss: 0.32903  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5378 -- Train Loss: 0.32879  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 5379 -- Train Loss: 0.32919  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 5380 -- Train Loss: 0.32950  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 5381 -- Train Loss: 0.32947  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 5382 -- Train Loss: 0.32974  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 5383 -- Train Loss: 0.32870  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5384 -- Train Loss: 0.32856  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 5385 -- Train Loss: 0.32925  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 5386 -- Train Loss: 0.32833  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 5387 -- Train Loss: 0.32875  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 5388 -- Train Loss: 0.32903  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 5389 -- Train Loss: 0.32926  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 5390 -- Train Loss: 0.32957  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 5391 -- Train Loss: 0.32893  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 5392 -- Train Loss: 0.32930  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 5393 -- Train Loss: 0.32842  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 5394 -- Train Loss: 0.32852  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 5395 -- Train Loss: 0.32931  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 5396 -- Train Loss: 0.32926  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5397 -- Train Loss: 0.32916  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 5398 -- Train Loss: 0.32870  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 5399 -- Train Loss: 0.32939  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 5400 -- Train Loss: 0.32981  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 5401 -- Train Loss: 0.32882  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 5402 -- Train Loss: 0.32789  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 5403 -- Train Loss: 0.32925  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 5404 -- Train Loss: 0.32799  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 5405 -- Train Loss: 0.32911  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 5406 -- Train Loss: 0.32944  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 5407 -- Train Loss: 0.32893  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 5408 -- Train Loss: 0.32889  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 5409 -- Train Loss: 0.32933  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 5410 -- Train Loss: 0.32936  Validation Loss: 0.43356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5411 -- Train Loss: 0.32900  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5412 -- Train Loss: 0.32940  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 5413 -- Train Loss: 0.32996  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 5414 -- Train Loss: 0.32969  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 5415 -- Train Loss: 0.32835  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 5416 -- Train Loss: 0.32940  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 5417 -- Train Loss: 0.32881  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5418 -- Train Loss: 0.32881  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 5419 -- Train Loss: 0.32837  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5420 -- Train Loss: 0.32912  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 5421 -- Train Loss: 0.32824  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 5422 -- Train Loss: 0.32903  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 5423 -- Train Loss: 0.32997  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 5424 -- Train Loss: 0.32803  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 5425 -- Train Loss: 0.33037  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 5426 -- Train Loss: 0.32861  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 5427 -- Train Loss: 0.32876  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 5428 -- Train Loss: 0.32974  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 5429 -- Train Loss: 0.32949  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 5430 -- Train Loss: 0.32848  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 5431 -- Train Loss: 0.32998  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 5432 -- Train Loss: 0.32897  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5433 -- Train Loss: 0.32976  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 5434 -- Train Loss: 0.32874  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 5435 -- Train Loss: 0.32881  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 5436 -- Train Loss: 0.32930  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 5437 -- Train Loss: 0.32962  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 5438 -- Train Loss: 0.32865  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 5439 -- Train Loss: 0.32947  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5440 -- Train Loss: 0.32928  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5441 -- Train Loss: 0.32964  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5442 -- Train Loss: 0.32767  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 5443 -- Train Loss: 0.32870  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 5444 -- Train Loss: 0.32886  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 5445 -- Train Loss: 0.32952  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 5446 -- Train Loss: 0.32952  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 5447 -- Train Loss: 0.32937  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 5448 -- Train Loss: 0.32971  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 5449 -- Train Loss: 0.32890  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 5450 -- Train Loss: 0.32929  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5451 -- Train Loss: 0.32858  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 5452 -- Train Loss: 0.32912  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 5453 -- Train Loss: 0.32865  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 5454 -- Train Loss: 0.32925  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 5455 -- Train Loss: 0.32828  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 5456 -- Train Loss: 0.32862  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 5457 -- Train Loss: 0.32917  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 5458 -- Train Loss: 0.32984  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 5459 -- Train Loss: 0.32955  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 5460 -- Train Loss: 0.32919  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 5461 -- Train Loss: 0.32951  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 5462 -- Train Loss: 0.32853  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 5463 -- Train Loss: 0.32961  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5464 -- Train Loss: 0.32833  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 5465 -- Train Loss: 0.32907  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 5466 -- Train Loss: 0.32966  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 5467 -- Train Loss: 0.32937  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 5468 -- Train Loss: 0.32883  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 5469 -- Train Loss: 0.32970  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 5470 -- Train Loss: 0.32925  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 5471 -- Train Loss: 0.32894  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 5472 -- Train Loss: 0.32828  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 5473 -- Train Loss: 0.32849  Validation Loss: 0.43031\n",
      "t: 10 EPOCH 5474 -- Train Loss: 0.32931  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 5475 -- Train Loss: 0.32871  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5476 -- Train Loss: 0.32861  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5477 -- Train Loss: 0.32893  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 5478 -- Train Loss: 0.32868  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 5479 -- Train Loss: 0.32887  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 5480 -- Train Loss: 0.32937  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 5481 -- Train Loss: 0.32903  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 5482 -- Train Loss: 0.32922  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 5483 -- Train Loss: 0.32873  Validation Loss: 0.43038\n",
      "t: 10 EPOCH 5484 -- Train Loss: 0.32938  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 5485 -- Train Loss: 0.32867  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 5486 -- Train Loss: 0.32855  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 5487 -- Train Loss: 0.32827  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 5488 -- Train Loss: 0.32844  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 5489 -- Train Loss: 0.32971  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 5490 -- Train Loss: 0.32919  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 5491 -- Train Loss: 0.32990  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 5492 -- Train Loss: 0.32966  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 5493 -- Train Loss: 0.32879  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 5494 -- Train Loss: 0.32894  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 5495 -- Train Loss: 0.32921  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 5496 -- Train Loss: 0.32927  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 5497 -- Train Loss: 0.32929  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 5498 -- Train Loss: 0.32939  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 5499 -- Train Loss: 0.32952  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 5500 -- Train Loss: 0.32869  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 5501 -- Train Loss: 0.32939  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 5502 -- Train Loss: 0.32874  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 5503 -- Train Loss: 0.32988  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 5504 -- Train Loss: 0.32855  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5505 -- Train Loss: 0.32883  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 5506 -- Train Loss: 0.32741  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 5507 -- Train Loss: 0.32880  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 5508 -- Train Loss: 0.32851  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 5509 -- Train Loss: 0.32992  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 5510 -- Train Loss: 0.32863  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 5511 -- Train Loss: 0.32759  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 5512 -- Train Loss: 0.32820  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 5513 -- Train Loss: 0.32900  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 5514 -- Train Loss: 0.32937  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5515 -- Train Loss: 0.32929  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 5516 -- Train Loss: 0.32946  Validation Loss: 0.43097\n",
      "t: 10 EPOCH 5517 -- Train Loss: 0.32925  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 5518 -- Train Loss: 0.32753  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 5519 -- Train Loss: 0.32934  Validation Loss: 0.43037\n",
      "t: 10 EPOCH 5520 -- Train Loss: 0.32851  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 5521 -- Train Loss: 0.32870  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 5522 -- Train Loss: 0.32923  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 5523 -- Train Loss: 0.32939  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 5524 -- Train Loss: 0.32849  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 5525 -- Train Loss: 0.32941  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 5526 -- Train Loss: 0.32816  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 5527 -- Train Loss: 0.32929  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 5528 -- Train Loss: 0.32877  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 5529 -- Train Loss: 0.32844  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 5530 -- Train Loss: 0.32941  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 5531 -- Train Loss: 0.32848  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 5532 -- Train Loss: 0.32944  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 5533 -- Train Loss: 0.32964  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 5534 -- Train Loss: 0.32928  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 5535 -- Train Loss: 0.32905  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 5536 -- Train Loss: 0.32898  Validation Loss: 0.43189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5537 -- Train Loss: 0.32979  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 5538 -- Train Loss: 0.32913  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 5539 -- Train Loss: 0.32903  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 5540 -- Train Loss: 0.32997  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 5541 -- Train Loss: 0.32884  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 5542 -- Train Loss: 0.32950  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 5543 -- Train Loss: 0.32896  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 5544 -- Train Loss: 0.32881  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 5545 -- Train Loss: 0.32953  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 5546 -- Train Loss: 0.32864  Validation Loss: 0.43088\n",
      "t: 10 EPOCH 5547 -- Train Loss: 0.32814  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 5548 -- Train Loss: 0.32884  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 5549 -- Train Loss: 0.32833  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 5550 -- Train Loss: 0.32881  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 5551 -- Train Loss: 0.32883  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 5552 -- Train Loss: 0.32787  Validation Loss: 0.43003\n",
      "t: 10 EPOCH 5553 -- Train Loss: 0.32983  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 5554 -- Train Loss: 0.32908  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 5555 -- Train Loss: 0.32913  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 5556 -- Train Loss: 0.32866  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 5557 -- Train Loss: 0.32868  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 5558 -- Train Loss: 0.32877  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 5559 -- Train Loss: 0.32791  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 5560 -- Train Loss: 0.32865  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 5561 -- Train Loss: 0.32847  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 5562 -- Train Loss: 0.32882  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 5563 -- Train Loss: 0.32888  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 5564 -- Train Loss: 0.32789  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 5565 -- Train Loss: 0.32922  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 5566 -- Train Loss: 0.32923  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 5567 -- Train Loss: 0.32875  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 5568 -- Train Loss: 0.32838  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 5569 -- Train Loss: 0.32868  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 5570 -- Train Loss: 0.32748  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 5571 -- Train Loss: 0.32830  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 5572 -- Train Loss: 0.32844  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 5573 -- Train Loss: 0.32858  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 5574 -- Train Loss: 0.32869  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5575 -- Train Loss: 0.32866  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 5576 -- Train Loss: 0.32857  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5577 -- Train Loss: 0.32949  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 5578 -- Train Loss: 0.32872  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 5579 -- Train Loss: 0.32940  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 5580 -- Train Loss: 0.32788  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 5581 -- Train Loss: 0.33004  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 5582 -- Train Loss: 0.32893  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 5583 -- Train Loss: 0.33007  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 5584 -- Train Loss: 0.32780  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5585 -- Train Loss: 0.32935  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 5586 -- Train Loss: 0.32904  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 5587 -- Train Loss: 0.32900  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 5588 -- Train Loss: 0.32879  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 5589 -- Train Loss: 0.32862  Validation Loss: 0.43085\n",
      "t: 10 EPOCH 5590 -- Train Loss: 0.32848  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 5591 -- Train Loss: 0.32909  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 5592 -- Train Loss: 0.32906  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 5593 -- Train Loss: 0.32887  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 5594 -- Train Loss: 0.32851  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 5595 -- Train Loss: 0.32863  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 5596 -- Train Loss: 0.32909  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 5597 -- Train Loss: 0.32832  Validation Loss: 0.43075\n",
      "t: 10 EPOCH 5598 -- Train Loss: 0.32816  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 5599 -- Train Loss: 0.32992  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 5600 -- Train Loss: 0.32818  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 5601 -- Train Loss: 0.32839  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 5602 -- Train Loss: 0.32916  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 5603 -- Train Loss: 0.32993  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 5604 -- Train Loss: 0.32907  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 5605 -- Train Loss: 0.32931  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 5606 -- Train Loss: 0.32890  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 5607 -- Train Loss: 0.32962  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 5608 -- Train Loss: 0.32870  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 5609 -- Train Loss: 0.33018  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5610 -- Train Loss: 0.32867  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 5611 -- Train Loss: 0.32939  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5612 -- Train Loss: 0.32877  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5613 -- Train Loss: 0.32924  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 5614 -- Train Loss: 0.32842  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 5615 -- Train Loss: 0.33000  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 5616 -- Train Loss: 0.32829  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 5617 -- Train Loss: 0.32975  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 5618 -- Train Loss: 0.32957  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 5619 -- Train Loss: 0.32953  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 5620 -- Train Loss: 0.32806  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 5621 -- Train Loss: 0.33006  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 5622 -- Train Loss: 0.32943  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 5623 -- Train Loss: 0.32956  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 5624 -- Train Loss: 0.33011  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 5625 -- Train Loss: 0.32969  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 5626 -- Train Loss: 0.32846  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 5627 -- Train Loss: 0.33028  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 5628 -- Train Loss: 0.32913  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 5629 -- Train Loss: 0.32957  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 5630 -- Train Loss: 0.32941  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 5631 -- Train Loss: 0.32933  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 5632 -- Train Loss: 0.32898  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 5633 -- Train Loss: 0.32962  Validation Loss: 0.42976\n",
      "t: 10 EPOCH 5634 -- Train Loss: 0.33021  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 5635 -- Train Loss: 0.32861  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 5636 -- Train Loss: 0.32926  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 5637 -- Train Loss: 0.32971  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 5638 -- Train Loss: 0.32972  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 5639 -- Train Loss: 0.32997  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5640 -- Train Loss: 0.33041  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 5641 -- Train Loss: 0.33061  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 5642 -- Train Loss: 0.32935  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 5643 -- Train Loss: 0.32908  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 5644 -- Train Loss: 0.33078  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 5645 -- Train Loss: 0.33013  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 5646 -- Train Loss: 0.33043  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 5647 -- Train Loss: 0.32899  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 5648 -- Train Loss: 0.32930  Validation Loss: 0.43070\n",
      "t: 10 EPOCH 5649 -- Train Loss: 0.32873  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 5650 -- Train Loss: 0.33006  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 5651 -- Train Loss: 0.32933  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 5652 -- Train Loss: 0.33046  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 5653 -- Train Loss: 0.32967  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 5654 -- Train Loss: 0.32904  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 5655 -- Train Loss: 0.32891  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 5656 -- Train Loss: 0.32991  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 5657 -- Train Loss: 0.33017  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 5658 -- Train Loss: 0.32859  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 5659 -- Train Loss: 0.33002  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 5660 -- Train Loss: 0.32867  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 5661 -- Train Loss: 0.32914  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 5662 -- Train Loss: 0.32872  Validation Loss: 0.43223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5663 -- Train Loss: 0.32960  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 5664 -- Train Loss: 0.32887  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 5665 -- Train Loss: 0.32924  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 5666 -- Train Loss: 0.32755  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 5667 -- Train Loss: 0.32936  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 5668 -- Train Loss: 0.32945  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 5669 -- Train Loss: 0.32961  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 5670 -- Train Loss: 0.32908  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 5671 -- Train Loss: 0.32942  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 5672 -- Train Loss: 0.32856  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 5673 -- Train Loss: 0.33020  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 5674 -- Train Loss: 0.32927  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 5675 -- Train Loss: 0.32988  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 5676 -- Train Loss: 0.32916  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 5677 -- Train Loss: 0.32934  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 5678 -- Train Loss: 0.32887  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 5679 -- Train Loss: 0.32837  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 5680 -- Train Loss: 0.32880  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 5681 -- Train Loss: 0.32953  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 5682 -- Train Loss: 0.32935  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 5683 -- Train Loss: 0.32945  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 5684 -- Train Loss: 0.32818  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 5685 -- Train Loss: 0.33044  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5686 -- Train Loss: 0.32871  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 5687 -- Train Loss: 0.32901  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 5688 -- Train Loss: 0.32927  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 5689 -- Train Loss: 0.32891  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 5690 -- Train Loss: 0.32893  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 5691 -- Train Loss: 0.32904  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 5692 -- Train Loss: 0.32948  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 5693 -- Train Loss: 0.32829  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 5694 -- Train Loss: 0.32933  Validation Loss: 0.43051\n",
      "t: 10 EPOCH 5695 -- Train Loss: 0.32794  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 5696 -- Train Loss: 0.32914  Validation Loss: 0.43082\n",
      "t: 10 EPOCH 5697 -- Train Loss: 0.32952  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 5698 -- Train Loss: 0.32821  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 5699 -- Train Loss: 0.32836  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 5700 -- Train Loss: 0.32854  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 5701 -- Train Loss: 0.32974  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 5702 -- Train Loss: 0.32908  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 5703 -- Train Loss: 0.32882  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 5704 -- Train Loss: 0.32791  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5705 -- Train Loss: 0.32812  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 5706 -- Train Loss: 0.32835  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 5707 -- Train Loss: 0.32869  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 5708 -- Train Loss: 0.32931  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 5709 -- Train Loss: 0.32903  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 5710 -- Train Loss: 0.32927  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5711 -- Train Loss: 0.32927  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 5712 -- Train Loss: 0.32901  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 5713 -- Train Loss: 0.32889  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 5714 -- Train Loss: 0.32929  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 5715 -- Train Loss: 0.32797  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 5716 -- Train Loss: 0.32919  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 5717 -- Train Loss: 0.32900  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 5718 -- Train Loss: 0.32819  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 5719 -- Train Loss: 0.32795  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 5720 -- Train Loss: 0.32807  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 5721 -- Train Loss: 0.32872  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 5722 -- Train Loss: 0.32861  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 5723 -- Train Loss: 0.32856  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 5724 -- Train Loss: 0.32920  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 5725 -- Train Loss: 0.32774  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5726 -- Train Loss: 0.32924  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 5727 -- Train Loss: 0.32931  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 5728 -- Train Loss: 0.32863  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 5729 -- Train Loss: 0.32813  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 5730 -- Train Loss: 0.32706  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 5731 -- Train Loss: 0.32877  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 5732 -- Train Loss: 0.32874  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 5733 -- Train Loss: 0.32873  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 5734 -- Train Loss: 0.32803  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 5735 -- Train Loss: 0.32955  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 5736 -- Train Loss: 0.32954  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 5737 -- Train Loss: 0.32879  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 5738 -- Train Loss: 0.32838  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 5739 -- Train Loss: 0.32946  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 5740 -- Train Loss: 0.32845  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 5741 -- Train Loss: 0.32847  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 5742 -- Train Loss: 0.32768  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 5743 -- Train Loss: 0.32895  Validation Loss: 0.43043\n",
      "t: 10 EPOCH 5744 -- Train Loss: 0.32889  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 5745 -- Train Loss: 0.32804  Validation Loss: 0.43079\n",
      "t: 10 EPOCH 5746 -- Train Loss: 0.32803  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 5747 -- Train Loss: 0.32787  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 5748 -- Train Loss: 0.32824  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 5749 -- Train Loss: 0.32900  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 5750 -- Train Loss: 0.32807  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 5751 -- Train Loss: 0.32848  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 5752 -- Train Loss: 0.32896  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 5753 -- Train Loss: 0.32800  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 5754 -- Train Loss: 0.32884  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 5755 -- Train Loss: 0.32758  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 5756 -- Train Loss: 0.32930  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 5757 -- Train Loss: 0.32799  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 5758 -- Train Loss: 0.32851  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 5759 -- Train Loss: 0.32931  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 5760 -- Train Loss: 0.32832  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 5761 -- Train Loss: 0.32871  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5762 -- Train Loss: 0.32876  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 5763 -- Train Loss: 0.32810  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 5764 -- Train Loss: 0.32870  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 5765 -- Train Loss: 0.32865  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 5766 -- Train Loss: 0.32829  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 5767 -- Train Loss: 0.32954  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 5768 -- Train Loss: 0.32770  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 5769 -- Train Loss: 0.32848  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 5770 -- Train Loss: 0.32783  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 5771 -- Train Loss: 0.32831  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 5772 -- Train Loss: 0.32834  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 5773 -- Train Loss: 0.32859  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 5774 -- Train Loss: 0.32849  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 5775 -- Train Loss: 0.32835  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 5776 -- Train Loss: 0.32734  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 5777 -- Train Loss: 0.32783  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5778 -- Train Loss: 0.32811  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 5779 -- Train Loss: 0.32851  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 5780 -- Train Loss: 0.32761  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 5781 -- Train Loss: 0.32849  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 5782 -- Train Loss: 0.32840  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 5783 -- Train Loss: 0.32936  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 5784 -- Train Loss: 0.32886  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 5785 -- Train Loss: 0.32825  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 5786 -- Train Loss: 0.32803  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 5787 -- Train Loss: 0.32872  Validation Loss: 0.43234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5788 -- Train Loss: 0.32843  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 5789 -- Train Loss: 0.32865  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 5790 -- Train Loss: 0.32870  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 5791 -- Train Loss: 0.32847  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 5792 -- Train Loss: 0.32824  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 5793 -- Train Loss: 0.32853  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 5794 -- Train Loss: 0.32886  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 5795 -- Train Loss: 0.32889  Validation Loss: 0.43019\n",
      "t: 10 EPOCH 5796 -- Train Loss: 0.32889  Validation Loss: 0.43055\n",
      "t: 10 EPOCH 5797 -- Train Loss: 0.32970  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 5798 -- Train Loss: 0.32802  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 5799 -- Train Loss: 0.32876  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5800 -- Train Loss: 0.32882  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 5801 -- Train Loss: 0.32978  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 5802 -- Train Loss: 0.32868  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 5803 -- Train Loss: 0.32879  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 5804 -- Train Loss: 0.32846  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 5805 -- Train Loss: 0.32916  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 5806 -- Train Loss: 0.32896  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 5807 -- Train Loss: 0.32933  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 5808 -- Train Loss: 0.32922  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 5809 -- Train Loss: 0.32926  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 5810 -- Train Loss: 0.32972  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 5811 -- Train Loss: 0.32903  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5812 -- Train Loss: 0.32917  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 5813 -- Train Loss: 0.32928  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 5814 -- Train Loss: 0.32926  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 5815 -- Train Loss: 0.32930  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 5816 -- Train Loss: 0.32926  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 5817 -- Train Loss: 0.32970  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 5818 -- Train Loss: 0.33024  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 5819 -- Train Loss: 0.33021  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 5820 -- Train Loss: 0.32927  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 5821 -- Train Loss: 0.32961  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 5822 -- Train Loss: 0.32952  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5823 -- Train Loss: 0.32884  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 5824 -- Train Loss: 0.32918  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 5825 -- Train Loss: 0.32895  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 5826 -- Train Loss: 0.32930  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 5827 -- Train Loss: 0.32948  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 5828 -- Train Loss: 0.32945  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 5829 -- Train Loss: 0.32916  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 5830 -- Train Loss: 0.32899  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5831 -- Train Loss: 0.32928  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 5832 -- Train Loss: 0.32854  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 5833 -- Train Loss: 0.32946  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 5834 -- Train Loss: 0.32882  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 5835 -- Train Loss: 0.32963  Validation Loss: 0.43130\n",
      "t: 10 EPOCH 5836 -- Train Loss: 0.32845  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 5837 -- Train Loss: 0.32997  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 5838 -- Train Loss: 0.32848  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5839 -- Train Loss: 0.33001  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 5840 -- Train Loss: 0.32806  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 5841 -- Train Loss: 0.32968  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5842 -- Train Loss: 0.32911  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 5843 -- Train Loss: 0.32930  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 5844 -- Train Loss: 0.32901  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 5845 -- Train Loss: 0.32989  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 5846 -- Train Loss: 0.32861  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 5847 -- Train Loss: 0.32928  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 5848 -- Train Loss: 0.32960  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5849 -- Train Loss: 0.32908  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 5850 -- Train Loss: 0.32888  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 5851 -- Train Loss: 0.32837  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 5852 -- Train Loss: 0.32848  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 5853 -- Train Loss: 0.32995  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 5854 -- Train Loss: 0.32883  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 5855 -- Train Loss: 0.32858  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5856 -- Train Loss: 0.32825  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 5857 -- Train Loss: 0.32936  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 5858 -- Train Loss: 0.32957  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 5859 -- Train Loss: 0.32825  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 5860 -- Train Loss: 0.32925  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 5861 -- Train Loss: 0.32874  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 5862 -- Train Loss: 0.32894  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 5863 -- Train Loss: 0.32928  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 5864 -- Train Loss: 0.32962  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5865 -- Train Loss: 0.32781  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5866 -- Train Loss: 0.32841  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 5867 -- Train Loss: 0.32845  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 5868 -- Train Loss: 0.32920  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 5869 -- Train Loss: 0.32891  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 5870 -- Train Loss: 0.32846  Validation Loss: 0.42991\n",
      "t: 10 EPOCH 5871 -- Train Loss: 0.32830  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 5872 -- Train Loss: 0.32863  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 5873 -- Train Loss: 0.32888  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5874 -- Train Loss: 0.32875  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 5875 -- Train Loss: 0.32853  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 5876 -- Train Loss: 0.32805  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 5877 -- Train Loss: 0.32972  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 5878 -- Train Loss: 0.32849  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 5879 -- Train Loss: 0.32854  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 5880 -- Train Loss: 0.32830  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 5881 -- Train Loss: 0.32755  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 5882 -- Train Loss: 0.32874  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 5883 -- Train Loss: 0.32867  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 5884 -- Train Loss: 0.32802  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 5885 -- Train Loss: 0.32869  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 5886 -- Train Loss: 0.32795  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 5887 -- Train Loss: 0.32841  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 5888 -- Train Loss: 0.32864  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 5889 -- Train Loss: 0.32867  Validation Loss: 0.43047\n",
      "t: 10 EPOCH 5890 -- Train Loss: 0.32853  Validation Loss: 0.42987\n",
      "t: 10 EPOCH 5891 -- Train Loss: 0.32860  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 5892 -- Train Loss: 0.32978  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 5893 -- Train Loss: 0.32757  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 5894 -- Train Loss: 0.32855  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 5895 -- Train Loss: 0.32785  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 5896 -- Train Loss: 0.32803  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 5897 -- Train Loss: 0.32825  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 5898 -- Train Loss: 0.32868  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 5899 -- Train Loss: 0.32910  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 5900 -- Train Loss: 0.32771  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 5901 -- Train Loss: 0.32791  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 5902 -- Train Loss: 0.32907  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 5903 -- Train Loss: 0.32821  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 5904 -- Train Loss: 0.32909  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 5905 -- Train Loss: 0.32883  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 5906 -- Train Loss: 0.32873  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 5907 -- Train Loss: 0.32762  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 5908 -- Train Loss: 0.32794  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 5909 -- Train Loss: 0.32922  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 5910 -- Train Loss: 0.32930  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 5911 -- Train Loss: 0.32829  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 5912 -- Train Loss: 0.32838  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 5913 -- Train Loss: 0.32877  Validation Loss: 0.43143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 5914 -- Train Loss: 0.32948  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 5915 -- Train Loss: 0.32904  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 5916 -- Train Loss: 0.32915  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 5917 -- Train Loss: 0.32842  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 5918 -- Train Loss: 0.32851  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 5919 -- Train Loss: 0.32866  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 5920 -- Train Loss: 0.32895  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 5921 -- Train Loss: 0.32844  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 5922 -- Train Loss: 0.32966  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 5923 -- Train Loss: 0.32956  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 5924 -- Train Loss: 0.32921  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 5925 -- Train Loss: 0.32829  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 5926 -- Train Loss: 0.32878  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 5927 -- Train Loss: 0.32953  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 5928 -- Train Loss: 0.32844  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 5929 -- Train Loss: 0.32884  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 5930 -- Train Loss: 0.32862  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 5931 -- Train Loss: 0.32915  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 5932 -- Train Loss: 0.32952  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 5933 -- Train Loss: 0.32912  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 5934 -- Train Loss: 0.32943  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 5935 -- Train Loss: 0.32888  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 5936 -- Train Loss: 0.32910  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 5937 -- Train Loss: 0.32945  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 5938 -- Train Loss: 0.32895  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 5939 -- Train Loss: 0.32931  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 5940 -- Train Loss: 0.32929  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 5941 -- Train Loss: 0.32937  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 5942 -- Train Loss: 0.32954  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 5943 -- Train Loss: 0.32923  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 5944 -- Train Loss: 0.32868  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 5945 -- Train Loss: 0.32961  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5946 -- Train Loss: 0.32963  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 5947 -- Train Loss: 0.32852  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 5948 -- Train Loss: 0.32854  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 5949 -- Train Loss: 0.32946  Validation Loss: 0.43041\n",
      "t: 10 EPOCH 5950 -- Train Loss: 0.32845  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 5951 -- Train Loss: 0.32939  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 5952 -- Train Loss: 0.32907  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 5953 -- Train Loss: 0.32947  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 5954 -- Train Loss: 0.32829  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 5955 -- Train Loss: 0.32900  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 5956 -- Train Loss: 0.32878  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 5957 -- Train Loss: 0.32851  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 5958 -- Train Loss: 0.32845  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 5959 -- Train Loss: 0.32918  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 5960 -- Train Loss: 0.32983  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 5961 -- Train Loss: 0.32857  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 5962 -- Train Loss: 0.32967  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 5963 -- Train Loss: 0.32886  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 5964 -- Train Loss: 0.32952  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 5965 -- Train Loss: 0.32859  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 5966 -- Train Loss: 0.32980  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 5967 -- Train Loss: 0.32828  Validation Loss: 0.43058\n",
      "t: 10 EPOCH 5968 -- Train Loss: 0.32856  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 5969 -- Train Loss: 0.32881  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 5970 -- Train Loss: 0.32934  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 5971 -- Train Loss: 0.32914  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 5972 -- Train Loss: 0.32968  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 5973 -- Train Loss: 0.32894  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 5974 -- Train Loss: 0.32912  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5975 -- Train Loss: 0.32886  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 5976 -- Train Loss: 0.32838  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 5977 -- Train Loss: 0.32825  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 5978 -- Train Loss: 0.32879  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 5979 -- Train Loss: 0.32846  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 5980 -- Train Loss: 0.32858  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 5981 -- Train Loss: 0.32858  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 5982 -- Train Loss: 0.32805  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 5983 -- Train Loss: 0.32833  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 5984 -- Train Loss: 0.32802  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 5985 -- Train Loss: 0.32935  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 5986 -- Train Loss: 0.32905  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 5987 -- Train Loss: 0.32926  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 5988 -- Train Loss: 0.32829  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 5989 -- Train Loss: 0.32863  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 5990 -- Train Loss: 0.32887  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 5991 -- Train Loss: 0.32927  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 5992 -- Train Loss: 0.32833  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 5993 -- Train Loss: 0.33042  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 5994 -- Train Loss: 0.32849  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 5995 -- Train Loss: 0.32807  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 5996 -- Train Loss: 0.32899  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 5997 -- Train Loss: 0.32851  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 5998 -- Train Loss: 0.32849  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 5999 -- Train Loss: 0.32808  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 6000 -- Train Loss: 0.32842  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 6001 -- Train Loss: 0.32874  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 6002 -- Train Loss: 0.32865  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 6003 -- Train Loss: 0.32811  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 6004 -- Train Loss: 0.32909  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6005 -- Train Loss: 0.32915  Validation Loss: 0.42983\n",
      "t: 10 EPOCH 6006 -- Train Loss: 0.32950  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 6007 -- Train Loss: 0.32840  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6008 -- Train Loss: 0.32870  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6009 -- Train Loss: 0.32813  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 6010 -- Train Loss: 0.32903  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 6011 -- Train Loss: 0.32859  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6012 -- Train Loss: 0.32838  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 6013 -- Train Loss: 0.32859  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 6014 -- Train Loss: 0.32960  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6015 -- Train Loss: 0.32802  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 6016 -- Train Loss: 0.32862  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 6017 -- Train Loss: 0.32851  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 6018 -- Train Loss: 0.32791  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 6019 -- Train Loss: 0.32873  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 6020 -- Train Loss: 0.32895  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 6021 -- Train Loss: 0.32826  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 6022 -- Train Loss: 0.32802  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6023 -- Train Loss: 0.32889  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 6024 -- Train Loss: 0.32890  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 6025 -- Train Loss: 0.32828  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 6026 -- Train Loss: 0.32857  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 6027 -- Train Loss: 0.32818  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 6028 -- Train Loss: 0.32859  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 6029 -- Train Loss: 0.32853  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 6030 -- Train Loss: 0.32844  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 6031 -- Train Loss: 0.32833  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 6032 -- Train Loss: 0.32867  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6033 -- Train Loss: 0.32773  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 6034 -- Train Loss: 0.32848  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 6035 -- Train Loss: 0.32755  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 6036 -- Train Loss: 0.32903  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 6037 -- Train Loss: 0.32856  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 6038 -- Train Loss: 0.32860  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 6039 -- Train Loss: 0.32718  Validation Loss: 0.43240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6040 -- Train Loss: 0.32754  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 6041 -- Train Loss: 0.32954  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6042 -- Train Loss: 0.32894  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6043 -- Train Loss: 0.32925  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 6044 -- Train Loss: 0.32842  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 6045 -- Train Loss: 0.32844  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 6046 -- Train Loss: 0.32876  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6047 -- Train Loss: 0.32864  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 6048 -- Train Loss: 0.32905  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 6049 -- Train Loss: 0.32814  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 6050 -- Train Loss: 0.32925  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 6051 -- Train Loss: 0.32917  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6052 -- Train Loss: 0.32820  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 6053 -- Train Loss: 0.32895  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 6054 -- Train Loss: 0.32800  Validation Loss: 0.43080\n",
      "t: 10 EPOCH 6055 -- Train Loss: 0.32868  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 6056 -- Train Loss: 0.32891  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 6057 -- Train Loss: 0.32768  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6058 -- Train Loss: 0.32928  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6059 -- Train Loss: 0.32774  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 6060 -- Train Loss: 0.32792  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 6061 -- Train Loss: 0.32788  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6062 -- Train Loss: 0.32824  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 6063 -- Train Loss: 0.32870  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 6064 -- Train Loss: 0.32829  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 6065 -- Train Loss: 0.32777  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 6066 -- Train Loss: 0.32881  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6067 -- Train Loss: 0.32797  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 6068 -- Train Loss: 0.32760  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 6069 -- Train Loss: 0.32901  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 6070 -- Train Loss: 0.32754  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 6071 -- Train Loss: 0.32893  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 6072 -- Train Loss: 0.32880  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 6073 -- Train Loss: 0.32899  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 6074 -- Train Loss: 0.32771  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6075 -- Train Loss: 0.32901  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 6076 -- Train Loss: 0.32829  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6077 -- Train Loss: 0.32880  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 6078 -- Train Loss: 0.32851  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6079 -- Train Loss: 0.32895  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 6080 -- Train Loss: 0.32950  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 6081 -- Train Loss: 0.32898  Validation Loss: 0.43010\n",
      "t: 10 EPOCH 6082 -- Train Loss: 0.32794  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 6083 -- Train Loss: 0.32876  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 6084 -- Train Loss: 0.32879  Validation Loss: 0.43024\n",
      "t: 10 EPOCH 6085 -- Train Loss: 0.32858  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 6086 -- Train Loss: 0.32816  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 6087 -- Train Loss: 0.32859  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 6088 -- Train Loss: 0.32828  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 6089 -- Train Loss: 0.32828  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 6090 -- Train Loss: 0.32875  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 6091 -- Train Loss: 0.32734  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 6092 -- Train Loss: 0.32976  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 6093 -- Train Loss: 0.32778  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6094 -- Train Loss: 0.32903  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 6095 -- Train Loss: 0.32901  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6096 -- Train Loss: 0.32863  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 6097 -- Train Loss: 0.32869  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 6098 -- Train Loss: 0.32849  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 6099 -- Train Loss: 0.32900  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 6100 -- Train Loss: 0.32782  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 6101 -- Train Loss: 0.32821  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 6102 -- Train Loss: 0.32830  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 6103 -- Train Loss: 0.32824  Validation Loss: 0.43104\n",
      "t: 10 EPOCH 6104 -- Train Loss: 0.32962  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 6105 -- Train Loss: 0.32860  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6106 -- Train Loss: 0.32889  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6107 -- Train Loss: 0.32834  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 6108 -- Train Loss: 0.32939  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 6109 -- Train Loss: 0.32860  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 6110 -- Train Loss: 0.32732  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 6111 -- Train Loss: 0.32896  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 6112 -- Train Loss: 0.32845  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 6113 -- Train Loss: 0.32957  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 6114 -- Train Loss: 0.32903  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 6115 -- Train Loss: 0.32936  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 6116 -- Train Loss: 0.32813  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 6117 -- Train Loss: 0.32925  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 6118 -- Train Loss: 0.32852  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 6119 -- Train Loss: 0.32869  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 6120 -- Train Loss: 0.32855  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 6121 -- Train Loss: 0.32856  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 6122 -- Train Loss: 0.32923  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 6123 -- Train Loss: 0.32874  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 6124 -- Train Loss: 0.32985  Validation Loss: 0.43135\n",
      "t: 10 EPOCH 6125 -- Train Loss: 0.32904  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 6126 -- Train Loss: 0.32926  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 6127 -- Train Loss: 0.32922  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 6128 -- Train Loss: 0.32841  Validation Loss: 0.43077\n",
      "t: 10 EPOCH 6129 -- Train Loss: 0.32896  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 6130 -- Train Loss: 0.32854  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 6131 -- Train Loss: 0.32866  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 6132 -- Train Loss: 0.32908  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 6133 -- Train Loss: 0.32926  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 6134 -- Train Loss: 0.32942  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 6135 -- Train Loss: 0.32908  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 6136 -- Train Loss: 0.32873  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6137 -- Train Loss: 0.32875  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6138 -- Train Loss: 0.32933  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 6139 -- Train Loss: 0.32858  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 6140 -- Train Loss: 0.32931  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 6141 -- Train Loss: 0.32901  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 6142 -- Train Loss: 0.32870  Validation Loss: 0.43062\n",
      "t: 10 EPOCH 6143 -- Train Loss: 0.32847  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 6144 -- Train Loss: 0.32873  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 6145 -- Train Loss: 0.32931  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6146 -- Train Loss: 0.32879  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 6147 -- Train Loss: 0.32826  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 6148 -- Train Loss: 0.32803  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 6149 -- Train Loss: 0.32956  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 6150 -- Train Loss: 0.32904  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 6151 -- Train Loss: 0.32907  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 6152 -- Train Loss: 0.32832  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 6153 -- Train Loss: 0.32900  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 6154 -- Train Loss: 0.32858  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 6155 -- Train Loss: 0.32940  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6156 -- Train Loss: 0.32808  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 6157 -- Train Loss: 0.32899  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 6158 -- Train Loss: 0.32888  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 6159 -- Train Loss: 0.32840  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 6160 -- Train Loss: 0.32862  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 6161 -- Train Loss: 0.32801  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6162 -- Train Loss: 0.32903  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6163 -- Train Loss: 0.32856  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 6164 -- Train Loss: 0.32945  Validation Loss: 0.43033\n",
      "t: 10 EPOCH 6165 -- Train Loss: 0.32838  Validation Loss: 0.43162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6166 -- Train Loss: 0.32817  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 6167 -- Train Loss: 0.32930  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 6168 -- Train Loss: 0.32864  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 6169 -- Train Loss: 0.32812  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 6170 -- Train Loss: 0.32817  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6171 -- Train Loss: 0.32830  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6172 -- Train Loss: 0.32869  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 6173 -- Train Loss: 0.32841  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 6174 -- Train Loss: 0.32765  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 6175 -- Train Loss: 0.32820  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 6176 -- Train Loss: 0.32807  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6177 -- Train Loss: 0.32848  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 6178 -- Train Loss: 0.32787  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6179 -- Train Loss: 0.32738  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6180 -- Train Loss: 0.32862  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 6181 -- Train Loss: 0.32766  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 6182 -- Train Loss: 0.32886  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 6183 -- Train Loss: 0.32805  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 6184 -- Train Loss: 0.32850  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6185 -- Train Loss: 0.32822  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 6186 -- Train Loss: 0.32820  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 6187 -- Train Loss: 0.32790  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 6188 -- Train Loss: 0.32931  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 6189 -- Train Loss: 0.32829  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 6190 -- Train Loss: 0.32865  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 6191 -- Train Loss: 0.32865  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 6192 -- Train Loss: 0.32814  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6193 -- Train Loss: 0.32913  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 6194 -- Train Loss: 0.32747  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 6195 -- Train Loss: 0.32845  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 6196 -- Train Loss: 0.32722  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 6197 -- Train Loss: 0.32884  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 6198 -- Train Loss: 0.32779  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 6199 -- Train Loss: 0.32815  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 6200 -- Train Loss: 0.32898  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 6201 -- Train Loss: 0.32883  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 6202 -- Train Loss: 0.32909  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 6203 -- Train Loss: 0.32864  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 6204 -- Train Loss: 0.32891  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 6205 -- Train Loss: 0.32818  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 6206 -- Train Loss: 0.32816  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 6207 -- Train Loss: 0.32859  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6208 -- Train Loss: 0.32784  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 6209 -- Train Loss: 0.32813  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6210 -- Train Loss: 0.32696  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 6211 -- Train Loss: 0.32853  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 6212 -- Train Loss: 0.32853  Validation Loss: 0.43089\n",
      "t: 10 EPOCH 6213 -- Train Loss: 0.32898  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 6214 -- Train Loss: 0.32773  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 6215 -- Train Loss: 0.32925  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 6216 -- Train Loss: 0.32858  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 6217 -- Train Loss: 0.32863  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 6218 -- Train Loss: 0.32807  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 6219 -- Train Loss: 0.32906  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 6220 -- Train Loss: 0.32735  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 6221 -- Train Loss: 0.32980  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 6222 -- Train Loss: 0.32801  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 6223 -- Train Loss: 0.32918  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6224 -- Train Loss: 0.32840  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 6225 -- Train Loss: 0.32977  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 6226 -- Train Loss: 0.32869  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 6227 -- Train Loss: 0.32964  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 6228 -- Train Loss: 0.32857  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 6229 -- Train Loss: 0.32900  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 6230 -- Train Loss: 0.32846  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 6231 -- Train Loss: 0.32934  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 6232 -- Train Loss: 0.32885  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 6233 -- Train Loss: 0.32942  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 6234 -- Train Loss: 0.32818  Validation Loss: 0.43111\n",
      "t: 10 EPOCH 6235 -- Train Loss: 0.32833  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 6236 -- Train Loss: 0.32887  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 6237 -- Train Loss: 0.32897  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 6238 -- Train Loss: 0.32918  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6239 -- Train Loss: 0.32912  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 6240 -- Train Loss: 0.32865  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 6241 -- Train Loss: 0.32862  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 6242 -- Train Loss: 0.32908  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6243 -- Train Loss: 0.32879  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 6244 -- Train Loss: 0.32873  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6245 -- Train Loss: 0.32890  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 6246 -- Train Loss: 0.33019  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 6247 -- Train Loss: 0.32894  Validation Loss: 0.43154\n",
      "t: 10 EPOCH 6248 -- Train Loss: 0.32883  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 6249 -- Train Loss: 0.32800  Validation Loss: 0.43122\n",
      "t: 10 EPOCH 6250 -- Train Loss: 0.32823  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 6251 -- Train Loss: 0.32846  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 6252 -- Train Loss: 0.32832  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 6253 -- Train Loss: 0.32850  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 6254 -- Train Loss: 0.32850  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6255 -- Train Loss: 0.32866  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 6256 -- Train Loss: 0.32841  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 6257 -- Train Loss: 0.32899  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 6258 -- Train Loss: 0.32874  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 6259 -- Train Loss: 0.32830  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 6260 -- Train Loss: 0.32903  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6261 -- Train Loss: 0.32962  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 6262 -- Train Loss: 0.32831  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 6263 -- Train Loss: 0.32892  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 6264 -- Train Loss: 0.32804  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 6265 -- Train Loss: 0.32921  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 6266 -- Train Loss: 0.32859  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 6267 -- Train Loss: 0.32852  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 6268 -- Train Loss: 0.32877  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 6269 -- Train Loss: 0.32800  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 6270 -- Train Loss: 0.32804  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 6271 -- Train Loss: 0.32882  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 6272 -- Train Loss: 0.32801  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 6273 -- Train Loss: 0.32905  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 6274 -- Train Loss: 0.32893  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 6275 -- Train Loss: 0.32910  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 6276 -- Train Loss: 0.32772  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 6277 -- Train Loss: 0.32914  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 6278 -- Train Loss: 0.32798  Validation Loss: 0.43029\n",
      "t: 10 EPOCH 6279 -- Train Loss: 0.32841  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 6280 -- Train Loss: 0.32920  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 6281 -- Train Loss: 0.32918  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 6282 -- Train Loss: 0.32784  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 6283 -- Train Loss: 0.32864  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 6284 -- Train Loss: 0.32824  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 6285 -- Train Loss: 0.32881  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 6286 -- Train Loss: 0.32814  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 6287 -- Train Loss: 0.32860  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 6288 -- Train Loss: 0.32864  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6289 -- Train Loss: 0.32902  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 6290 -- Train Loss: 0.32823  Validation Loss: 0.43214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6291 -- Train Loss: 0.32828  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 6292 -- Train Loss: 0.32784  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 6293 -- Train Loss: 0.32931  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6294 -- Train Loss: 0.32869  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 6295 -- Train Loss: 0.32812  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 6296 -- Train Loss: 0.32869  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 6297 -- Train Loss: 0.32926  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6298 -- Train Loss: 0.32855  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 6299 -- Train Loss: 0.32820  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6300 -- Train Loss: 0.32827  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6301 -- Train Loss: 0.32919  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 6302 -- Train Loss: 0.32820  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 6303 -- Train Loss: 0.32864  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 6304 -- Train Loss: 0.32868  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 6305 -- Train Loss: 0.32839  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 6306 -- Train Loss: 0.32757  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 6307 -- Train Loss: 0.32829  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 6308 -- Train Loss: 0.32883  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6309 -- Train Loss: 0.32791  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 6310 -- Train Loss: 0.32830  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 6311 -- Train Loss: 0.32885  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 6312 -- Train Loss: 0.32866  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 6313 -- Train Loss: 0.32791  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 6314 -- Train Loss: 0.32858  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 6315 -- Train Loss: 0.32817  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 6316 -- Train Loss: 0.32828  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 6317 -- Train Loss: 0.32753  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6318 -- Train Loss: 0.32890  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 6319 -- Train Loss: 0.32730  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6320 -- Train Loss: 0.32832  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 6321 -- Train Loss: 0.32819  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 6322 -- Train Loss: 0.32829  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 6323 -- Train Loss: 0.32788  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 6324 -- Train Loss: 0.32838  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 6325 -- Train Loss: 0.32816  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 6326 -- Train Loss: 0.32807  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 6327 -- Train Loss: 0.32868  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 6328 -- Train Loss: 0.32835  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6329 -- Train Loss: 0.32786  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 6330 -- Train Loss: 0.32863  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 6331 -- Train Loss: 0.32802  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 6332 -- Train Loss: 0.32873  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 6333 -- Train Loss: 0.32819  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6334 -- Train Loss: 0.32862  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 6335 -- Train Loss: 0.32769  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6336 -- Train Loss: 0.32828  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 6337 -- Train Loss: 0.32815  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 6338 -- Train Loss: 0.32801  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 6339 -- Train Loss: 0.32783  Validation Loss: 0.43129\n",
      "t: 10 EPOCH 6340 -- Train Loss: 0.32792  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6341 -- Train Loss: 0.32760  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 6342 -- Train Loss: 0.32836  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 6343 -- Train Loss: 0.32785  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 6344 -- Train Loss: 0.32876  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6345 -- Train Loss: 0.32820  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 6346 -- Train Loss: 0.32902  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 6347 -- Train Loss: 0.32774  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 6348 -- Train Loss: 0.32840  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 6349 -- Train Loss: 0.32774  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 6350 -- Train Loss: 0.32793  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 6351 -- Train Loss: 0.32931  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 6352 -- Train Loss: 0.32803  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 6353 -- Train Loss: 0.32788  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 6354 -- Train Loss: 0.32741  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 6355 -- Train Loss: 0.32809  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 6356 -- Train Loss: 0.32772  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 6357 -- Train Loss: 0.32804  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 6358 -- Train Loss: 0.32803  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6359 -- Train Loss: 0.32849  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 6360 -- Train Loss: 0.32958  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 6361 -- Train Loss: 0.32808  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 6362 -- Train Loss: 0.32759  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 6363 -- Train Loss: 0.32835  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 6364 -- Train Loss: 0.32817  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 6365 -- Train Loss: 0.32876  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 6366 -- Train Loss: 0.32858  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 6367 -- Train Loss: 0.32847  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 6368 -- Train Loss: 0.32851  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 6369 -- Train Loss: 0.33001  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 6370 -- Train Loss: 0.32872  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 6371 -- Train Loss: 0.32951  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6372 -- Train Loss: 0.32821  Validation Loss: 0.43012\n",
      "t: 10 EPOCH 6373 -- Train Loss: 0.32913  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 6374 -- Train Loss: 0.32798  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 6375 -- Train Loss: 0.32862  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 6376 -- Train Loss: 0.32894  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 6377 -- Train Loss: 0.32850  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 6378 -- Train Loss: 0.32856  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 6379 -- Train Loss: 0.32832  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6380 -- Train Loss: 0.32951  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 6381 -- Train Loss: 0.32952  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 6382 -- Train Loss: 0.32846  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 6383 -- Train Loss: 0.32849  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 6384 -- Train Loss: 0.32921  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 6385 -- Train Loss: 0.32840  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 6386 -- Train Loss: 0.32854  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 6387 -- Train Loss: 0.32756  Validation Loss: 0.43159\n",
      "t: 10 EPOCH 6388 -- Train Loss: 0.32913  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 6389 -- Train Loss: 0.32810  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 6390 -- Train Loss: 0.32827  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 6391 -- Train Loss: 0.32766  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 6392 -- Train Loss: 0.32868  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 6393 -- Train Loss: 0.32912  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6394 -- Train Loss: 0.32801  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 6395 -- Train Loss: 0.32841  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 6396 -- Train Loss: 0.32799  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 6397 -- Train Loss: 0.32842  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6398 -- Train Loss: 0.32749  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 6399 -- Train Loss: 0.32945  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 6400 -- Train Loss: 0.32833  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 6401 -- Train Loss: 0.32825  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6402 -- Train Loss: 0.32823  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 6403 -- Train Loss: 0.32863  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 6404 -- Train Loss: 0.32773  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 6405 -- Train Loss: 0.32884  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 6406 -- Train Loss: 0.32808  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 6407 -- Train Loss: 0.32923  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 6408 -- Train Loss: 0.32833  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 6409 -- Train Loss: 0.32876  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 6410 -- Train Loss: 0.32809  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 6411 -- Train Loss: 0.32805  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 6412 -- Train Loss: 0.32796  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6413 -- Train Loss: 0.32793  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 6414 -- Train Loss: 0.32813  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 6415 -- Train Loss: 0.32826  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 6416 -- Train Loss: 0.32821  Validation Loss: 0.43247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6417 -- Train Loss: 0.32773  Validation Loss: 0.43071\n",
      "t: 10 EPOCH 6418 -- Train Loss: 0.32855  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 6419 -- Train Loss: 0.32790  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 6420 -- Train Loss: 0.32851  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 6421 -- Train Loss: 0.32754  Validation Loss: 0.43093\n",
      "t: 10 EPOCH 6422 -- Train Loss: 0.32728  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 6423 -- Train Loss: 0.32748  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 6424 -- Train Loss: 0.32883  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 6425 -- Train Loss: 0.32772  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 6426 -- Train Loss: 0.32855  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6427 -- Train Loss: 0.32765  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 6428 -- Train Loss: 0.32771  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 6429 -- Train Loss: 0.32789  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 6430 -- Train Loss: 0.32823  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 6431 -- Train Loss: 0.32853  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 6432 -- Train Loss: 0.32866  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 6433 -- Train Loss: 0.32786  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 6434 -- Train Loss: 0.32783  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 6435 -- Train Loss: 0.32883  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 6436 -- Train Loss: 0.32812  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 6437 -- Train Loss: 0.32784  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 6438 -- Train Loss: 0.32753  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6439 -- Train Loss: 0.32851  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6440 -- Train Loss: 0.32765  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 6441 -- Train Loss: 0.32706  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 6442 -- Train Loss: 0.32818  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 6443 -- Train Loss: 0.32774  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 6444 -- Train Loss: 0.32784  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 6445 -- Train Loss: 0.32879  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 6446 -- Train Loss: 0.32828  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 6447 -- Train Loss: 0.32767  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 6448 -- Train Loss: 0.32933  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6449 -- Train Loss: 0.32819  Validation Loss: 0.43118\n",
      "t: 10 EPOCH 6450 -- Train Loss: 0.32783  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 6451 -- Train Loss: 0.32773  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 6452 -- Train Loss: 0.32858  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 6453 -- Train Loss: 0.32820  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 6454 -- Train Loss: 0.32775  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 6455 -- Train Loss: 0.32750  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 6456 -- Train Loss: 0.32834  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 6457 -- Train Loss: 0.32893  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 6458 -- Train Loss: 0.32835  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 6459 -- Train Loss: 0.32889  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 6460 -- Train Loss: 0.32871  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 6461 -- Train Loss: 0.32860  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6462 -- Train Loss: 0.32823  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6463 -- Train Loss: 0.32946  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6464 -- Train Loss: 0.32801  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6465 -- Train Loss: 0.32876  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6466 -- Train Loss: 0.32795  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 6467 -- Train Loss: 0.32824  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 6468 -- Train Loss: 0.32775  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 6469 -- Train Loss: 0.32919  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 6470 -- Train Loss: 0.32820  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 6471 -- Train Loss: 0.32857  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 6472 -- Train Loss: 0.32819  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6473 -- Train Loss: 0.32833  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 6474 -- Train Loss: 0.32883  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 6475 -- Train Loss: 0.32850  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 6476 -- Train Loss: 0.32787  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 6477 -- Train Loss: 0.32930  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 6478 -- Train Loss: 0.32859  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6479 -- Train Loss: 0.32924  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 6480 -- Train Loss: 0.32884  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6481 -- Train Loss: 0.32885  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 6482 -- Train Loss: 0.32885  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6483 -- Train Loss: 0.32972  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 6484 -- Train Loss: 0.32857  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 6485 -- Train Loss: 0.32956  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 6486 -- Train Loss: 0.32888  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 6487 -- Train Loss: 0.32883  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 6488 -- Train Loss: 0.32950  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 6489 -- Train Loss: 0.32977  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6490 -- Train Loss: 0.32888  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 6491 -- Train Loss: 0.32844  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6492 -- Train Loss: 0.32896  Validation Loss: 0.43040\n",
      "t: 10 EPOCH 6493 -- Train Loss: 0.32882  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 6494 -- Train Loss: 0.32979  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 6495 -- Train Loss: 0.32834  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 6496 -- Train Loss: 0.32939  Validation Loss: 0.43105\n",
      "t: 10 EPOCH 6497 -- Train Loss: 0.32849  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 6498 -- Train Loss: 0.32859  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 6499 -- Train Loss: 0.32814  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 6500 -- Train Loss: 0.32868  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6501 -- Train Loss: 0.32805  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 6502 -- Train Loss: 0.32930  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 6503 -- Train Loss: 0.32761  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 6504 -- Train Loss: 0.32932  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 6505 -- Train Loss: 0.32938  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 6506 -- Train Loss: 0.32820  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6507 -- Train Loss: 0.32887  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 6508 -- Train Loss: 0.32856  Validation Loss: 0.43039\n",
      "t: 10 EPOCH 6509 -- Train Loss: 0.32766  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 6510 -- Train Loss: 0.32824  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 6511 -- Train Loss: 0.32826  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 6512 -- Train Loss: 0.32846  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6513 -- Train Loss: 0.32810  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 6514 -- Train Loss: 0.32752  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 6515 -- Train Loss: 0.32834  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 6516 -- Train Loss: 0.32810  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 6517 -- Train Loss: 0.32860  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 6518 -- Train Loss: 0.32743  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 6519 -- Train Loss: 0.32773  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 6520 -- Train Loss: 0.32856  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 6521 -- Train Loss: 0.32823  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 6522 -- Train Loss: 0.32818  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6523 -- Train Loss: 0.32789  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 6524 -- Train Loss: 0.32791  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 6525 -- Train Loss: 0.32898  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 6526 -- Train Loss: 0.32821  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 6527 -- Train Loss: 0.32815  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 6528 -- Train Loss: 0.32775  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 6529 -- Train Loss: 0.32849  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6530 -- Train Loss: 0.32763  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 6531 -- Train Loss: 0.32878  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 6532 -- Train Loss: 0.32833  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 6533 -- Train Loss: 0.32892  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6534 -- Train Loss: 0.32830  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 6535 -- Train Loss: 0.32822  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 6536 -- Train Loss: 0.32877  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 6537 -- Train Loss: 0.32822  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 6538 -- Train Loss: 0.32768  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 6539 -- Train Loss: 0.32754  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 6540 -- Train Loss: 0.32783  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 6541 -- Train Loss: 0.32763  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 6542 -- Train Loss: 0.32755  Validation Loss: 0.43356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6543 -- Train Loss: 0.32799  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 6544 -- Train Loss: 0.32839  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6545 -- Train Loss: 0.32762  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 6546 -- Train Loss: 0.32714  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 6547 -- Train Loss: 0.32752  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 6548 -- Train Loss: 0.32836  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6549 -- Train Loss: 0.32726  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 6550 -- Train Loss: 0.32713  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 6551 -- Train Loss: 0.32724  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 6552 -- Train Loss: 0.32813  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 6553 -- Train Loss: 0.32734  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6554 -- Train Loss: 0.32775  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 6555 -- Train Loss: 0.32848  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 6556 -- Train Loss: 0.32705  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 6557 -- Train Loss: 0.32797  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 6558 -- Train Loss: 0.32723  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 6559 -- Train Loss: 0.32799  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 6560 -- Train Loss: 0.32853  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 6561 -- Train Loss: 0.32849  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 6562 -- Train Loss: 0.32792  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 6563 -- Train Loss: 0.32779  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 6564 -- Train Loss: 0.32815  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6565 -- Train Loss: 0.32818  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 6566 -- Train Loss: 0.32807  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 6567 -- Train Loss: 0.32744  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 6568 -- Train Loss: 0.32742  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 6569 -- Train Loss: 0.32861  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6570 -- Train Loss: 0.32813  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 6571 -- Train Loss: 0.32815  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 6572 -- Train Loss: 0.32822  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 6573 -- Train Loss: 0.32819  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 6574 -- Train Loss: 0.32872  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 6575 -- Train Loss: 0.32882  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 6576 -- Train Loss: 0.32775  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 6577 -- Train Loss: 0.32864  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6578 -- Train Loss: 0.32869  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 6579 -- Train Loss: 0.32842  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 6580 -- Train Loss: 0.32825  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 6581 -- Train Loss: 0.32783  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6582 -- Train Loss: 0.32842  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 6583 -- Train Loss: 0.32840  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 6584 -- Train Loss: 0.32783  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 6585 -- Train Loss: 0.32702  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 6586 -- Train Loss: 0.32773  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 6587 -- Train Loss: 0.32779  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 6588 -- Train Loss: 0.32887  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 6589 -- Train Loss: 0.32837  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 6590 -- Train Loss: 0.32836  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 6591 -- Train Loss: 0.32798  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 6592 -- Train Loss: 0.32806  Validation Loss: 0.43057\n",
      "t: 10 EPOCH 6593 -- Train Loss: 0.32844  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 6594 -- Train Loss: 0.32824  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 6595 -- Train Loss: 0.32825  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 6596 -- Train Loss: 0.32801  Validation Loss: 0.43101\n",
      "t: 10 EPOCH 6597 -- Train Loss: 0.32922  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 6598 -- Train Loss: 0.32927  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 6599 -- Train Loss: 0.32811  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 6600 -- Train Loss: 0.32810  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 6601 -- Train Loss: 0.32863  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 6602 -- Train Loss: 0.32744  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 6603 -- Train Loss: 0.32884  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 6604 -- Train Loss: 0.32841  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 6605 -- Train Loss: 0.32834  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 6606 -- Train Loss: 0.32760  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6607 -- Train Loss: 0.32842  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 6608 -- Train Loss: 0.32791  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 6609 -- Train Loss: 0.32816  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 6610 -- Train Loss: 0.32802  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 6611 -- Train Loss: 0.32806  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 6612 -- Train Loss: 0.32818  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6613 -- Train Loss: 0.32795  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 6614 -- Train Loss: 0.32794  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 6615 -- Train Loss: 0.32736  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 6616 -- Train Loss: 0.32912  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 6617 -- Train Loss: 0.32728  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 6618 -- Train Loss: 0.32847  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 6619 -- Train Loss: 0.32726  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 6620 -- Train Loss: 0.32825  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 6621 -- Train Loss: 0.32825  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 6622 -- Train Loss: 0.32941  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 6623 -- Train Loss: 0.32742  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 6624 -- Train Loss: 0.32877  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 6625 -- Train Loss: 0.32713  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 6626 -- Train Loss: 0.32853  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6627 -- Train Loss: 0.32770  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 6628 -- Train Loss: 0.32908  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 6629 -- Train Loss: 0.32772  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 6630 -- Train Loss: 0.32828  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 6631 -- Train Loss: 0.32837  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 6632 -- Train Loss: 0.32811  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 6633 -- Train Loss: 0.32814  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 6634 -- Train Loss: 0.32808  Validation Loss: 0.43115\n",
      "t: 10 EPOCH 6635 -- Train Loss: 0.32893  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 6636 -- Train Loss: 0.32753  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 6637 -- Train Loss: 0.32845  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 6638 -- Train Loss: 0.32804  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 6639 -- Train Loss: 0.32775  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 6640 -- Train Loss: 0.32811  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 6641 -- Train Loss: 0.32788  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 6642 -- Train Loss: 0.32817  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6643 -- Train Loss: 0.32888  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 6644 -- Train Loss: 0.32875  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 6645 -- Train Loss: 0.32810  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 6646 -- Train Loss: 0.32876  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 6647 -- Train Loss: 0.32828  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 6648 -- Train Loss: 0.32824  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 6649 -- Train Loss: 0.32728  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 6650 -- Train Loss: 0.32762  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 6651 -- Train Loss: 0.32747  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 6652 -- Train Loss: 0.32846  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 6653 -- Train Loss: 0.32775  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 6654 -- Train Loss: 0.32866  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 6655 -- Train Loss: 0.32865  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 6656 -- Train Loss: 0.32929  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 6657 -- Train Loss: 0.32885  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 6658 -- Train Loss: 0.32826  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 6659 -- Train Loss: 0.32825  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 6660 -- Train Loss: 0.32857  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 6661 -- Train Loss: 0.32798  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 6662 -- Train Loss: 0.32866  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 6663 -- Train Loss: 0.32785  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 6664 -- Train Loss: 0.32867  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 6665 -- Train Loss: 0.32817  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 6666 -- Train Loss: 0.32794  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 6667 -- Train Loss: 0.32774  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 6668 -- Train Loss: 0.32773  Validation Loss: 0.43185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6669 -- Train Loss: 0.32767  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 6670 -- Train Loss: 0.32871  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6671 -- Train Loss: 0.32825  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 6672 -- Train Loss: 0.32811  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 6673 -- Train Loss: 0.32915  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 6674 -- Train Loss: 0.32764  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 6675 -- Train Loss: 0.32881  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 6676 -- Train Loss: 0.32775  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 6677 -- Train Loss: 0.32746  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 6678 -- Train Loss: 0.32873  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6679 -- Train Loss: 0.32797  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 6680 -- Train Loss: 0.32810  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 6681 -- Train Loss: 0.32808  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 6682 -- Train Loss: 0.32883  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 6683 -- Train Loss: 0.32791  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 6684 -- Train Loss: 0.32858  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 6685 -- Train Loss: 0.32840  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 6686 -- Train Loss: 0.32729  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 6687 -- Train Loss: 0.32733  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 6688 -- Train Loss: 0.32882  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6689 -- Train Loss: 0.32834  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 6690 -- Train Loss: 0.32835  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 6691 -- Train Loss: 0.32816  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 6692 -- Train Loss: 0.32783  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 6693 -- Train Loss: 0.32751  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 6694 -- Train Loss: 0.32842  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 6695 -- Train Loss: 0.32882  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 6696 -- Train Loss: 0.32718  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 6697 -- Train Loss: 0.32849  Validation Loss: 0.43090\n",
      "t: 10 EPOCH 6698 -- Train Loss: 0.32828  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 6699 -- Train Loss: 0.32817  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6700 -- Train Loss: 0.32897  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 6701 -- Train Loss: 0.32787  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 6702 -- Train Loss: 0.32840  Validation Loss: 0.43100\n",
      "t: 10 EPOCH 6703 -- Train Loss: 0.32789  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 6704 -- Train Loss: 0.32840  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6705 -- Train Loss: 0.32755  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 6706 -- Train Loss: 0.32717  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 6707 -- Train Loss: 0.32823  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 6708 -- Train Loss: 0.32853  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 6709 -- Train Loss: 0.32876  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6710 -- Train Loss: 0.32754  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 6711 -- Train Loss: 0.32816  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 6712 -- Train Loss: 0.32896  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6713 -- Train Loss: 0.32684  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 6714 -- Train Loss: 0.32803  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 6715 -- Train Loss: 0.32806  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6716 -- Train Loss: 0.32798  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 6717 -- Train Loss: 0.32823  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 6718 -- Train Loss: 0.32882  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 6719 -- Train Loss: 0.32884  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 6720 -- Train Loss: 0.32765  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 6721 -- Train Loss: 0.32861  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 6722 -- Train Loss: 0.32722  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6723 -- Train Loss: 0.32807  Validation Loss: 0.43108\n",
      "t: 10 EPOCH 6724 -- Train Loss: 0.32811  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 6725 -- Train Loss: 0.32879  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 6726 -- Train Loss: 0.32824  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 6727 -- Train Loss: 0.32863  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 6728 -- Train Loss: 0.32849  Validation Loss: 0.43123\n",
      "t: 10 EPOCH 6729 -- Train Loss: 0.32893  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 6730 -- Train Loss: 0.32817  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 6731 -- Train Loss: 0.32767  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 6732 -- Train Loss: 0.32845  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 6733 -- Train Loss: 0.32832  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 6734 -- Train Loss: 0.32825  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 6735 -- Train Loss: 0.32810  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 6736 -- Train Loss: 0.32817  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 6737 -- Train Loss: 0.32864  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 6738 -- Train Loss: 0.32844  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 6739 -- Train Loss: 0.32893  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 6740 -- Train Loss: 0.32839  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 6741 -- Train Loss: 0.32780  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 6742 -- Train Loss: 0.32841  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 6743 -- Train Loss: 0.32871  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 6744 -- Train Loss: 0.32877  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6745 -- Train Loss: 0.32941  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6746 -- Train Loss: 0.32703  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 6747 -- Train Loss: 0.32856  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 6748 -- Train Loss: 0.32820  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 6749 -- Train Loss: 0.32921  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 6750 -- Train Loss: 0.32778  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 6751 -- Train Loss: 0.32926  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 6752 -- Train Loss: 0.32787  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 6753 -- Train Loss: 0.32864  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 6754 -- Train Loss: 0.32792  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 6755 -- Train Loss: 0.32853  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 6756 -- Train Loss: 0.32737  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 6757 -- Train Loss: 0.32800  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 6758 -- Train Loss: 0.32727  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 6759 -- Train Loss: 0.32841  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 6760 -- Train Loss: 0.32888  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 6761 -- Train Loss: 0.32825  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 6762 -- Train Loss: 0.32807  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 6763 -- Train Loss: 0.32679  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 6764 -- Train Loss: 0.32919  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 6765 -- Train Loss: 0.32803  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 6766 -- Train Loss: 0.32775  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 6767 -- Train Loss: 0.32835  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 6768 -- Train Loss: 0.32847  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 6769 -- Train Loss: 0.32798  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 6770 -- Train Loss: 0.32885  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 6771 -- Train Loss: 0.32782  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 6772 -- Train Loss: 0.32892  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 6773 -- Train Loss: 0.32846  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 6774 -- Train Loss: 0.32819  Validation Loss: 0.43052\n",
      "t: 10 EPOCH 6775 -- Train Loss: 0.32788  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6776 -- Train Loss: 0.32857  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 6777 -- Train Loss: 0.32805  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 6778 -- Train Loss: 0.32816  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 6779 -- Train Loss: 0.32719  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 6780 -- Train Loss: 0.32809  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 6781 -- Train Loss: 0.32752  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 6782 -- Train Loss: 0.32845  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 6783 -- Train Loss: 0.32799  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 6784 -- Train Loss: 0.32902  Validation Loss: 0.43016\n",
      "t: 10 EPOCH 6785 -- Train Loss: 0.32805  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 6786 -- Train Loss: 0.32833  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 6787 -- Train Loss: 0.32780  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 6788 -- Train Loss: 0.32861  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 6789 -- Train Loss: 0.32825  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 6790 -- Train Loss: 0.32781  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 6791 -- Train Loss: 0.32883  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 6792 -- Train Loss: 0.32756  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 6793 -- Train Loss: 0.32840  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 6794 -- Train Loss: 0.32757  Validation Loss: 0.43262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6795 -- Train Loss: 0.32858  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 6796 -- Train Loss: 0.32880  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 6797 -- Train Loss: 0.32863  Validation Loss: 0.43076\n",
      "t: 10 EPOCH 6798 -- Train Loss: 0.32794  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 6799 -- Train Loss: 0.32830  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 6800 -- Train Loss: 0.32816  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 6801 -- Train Loss: 0.32800  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 6802 -- Train Loss: 0.32836  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 6803 -- Train Loss: 0.32715  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 6804 -- Train Loss: 0.32815  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6805 -- Train Loss: 0.32773  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 6806 -- Train Loss: 0.32894  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 6807 -- Train Loss: 0.32767  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 6808 -- Train Loss: 0.32764  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 6809 -- Train Loss: 0.32784  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 6810 -- Train Loss: 0.32795  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 6811 -- Train Loss: 0.32802  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 6812 -- Train Loss: 0.32853  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 6813 -- Train Loss: 0.32802  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 6814 -- Train Loss: 0.32748  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 6815 -- Train Loss: 0.32847  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 6816 -- Train Loss: 0.32808  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 6817 -- Train Loss: 0.32769  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 6818 -- Train Loss: 0.32781  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 6819 -- Train Loss: 0.32925  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 6820 -- Train Loss: 0.32847  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 6821 -- Train Loss: 0.32788  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 6822 -- Train Loss: 0.32786  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 6823 -- Train Loss: 0.32873  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 6824 -- Train Loss: 0.32731  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 6825 -- Train Loss: 0.32794  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 6826 -- Train Loss: 0.32820  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 6827 -- Train Loss: 0.32673  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 6828 -- Train Loss: 0.32807  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 6829 -- Train Loss: 0.32852  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 6830 -- Train Loss: 0.32776  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 6831 -- Train Loss: 0.32838  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 6832 -- Train Loss: 0.32780  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 6833 -- Train Loss: 0.32842  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6834 -- Train Loss: 0.32733  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 6835 -- Train Loss: 0.32783  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 6836 -- Train Loss: 0.32864  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 6837 -- Train Loss: 0.32727  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 6838 -- Train Loss: 0.32867  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 6839 -- Train Loss: 0.32784  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 6840 -- Train Loss: 0.32850  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 6841 -- Train Loss: 0.32809  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 6842 -- Train Loss: 0.32737  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 6843 -- Train Loss: 0.32729  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 6844 -- Train Loss: 0.32795  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 6845 -- Train Loss: 0.32828  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 6846 -- Train Loss: 0.32803  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 6847 -- Train Loss: 0.32770  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 6848 -- Train Loss: 0.32703  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 6849 -- Train Loss: 0.32853  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 6850 -- Train Loss: 0.32802  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 6851 -- Train Loss: 0.32772  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 6852 -- Train Loss: 0.32760  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 6853 -- Train Loss: 0.32775  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 6854 -- Train Loss: 0.32804  Validation Loss: 0.43053\n",
      "t: 10 EPOCH 6855 -- Train Loss: 0.32742  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 6856 -- Train Loss: 0.32677  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 6857 -- Train Loss: 0.32738  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 6858 -- Train Loss: 0.32751  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 6859 -- Train Loss: 0.32672  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 6860 -- Train Loss: 0.32863  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 6861 -- Train Loss: 0.32762  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 6862 -- Train Loss: 0.32744  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 6863 -- Train Loss: 0.32879  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 6864 -- Train Loss: 0.32902  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 6865 -- Train Loss: 0.32666  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 6866 -- Train Loss: 0.32821  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 6867 -- Train Loss: 0.32790  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 6868 -- Train Loss: 0.32846  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 6869 -- Train Loss: 0.32809  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6870 -- Train Loss: 0.32860  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 6871 -- Train Loss: 0.32734  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 6872 -- Train Loss: 0.32809  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 6873 -- Train Loss: 0.32667  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 6874 -- Train Loss: 0.32777  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 6875 -- Train Loss: 0.32732  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 6876 -- Train Loss: 0.32759  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6877 -- Train Loss: 0.32811  Validation Loss: 0.43066\n",
      "t: 10 EPOCH 6878 -- Train Loss: 0.32689  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 6879 -- Train Loss: 0.32748  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 6880 -- Train Loss: 0.32834  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 6881 -- Train Loss: 0.32840  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 6882 -- Train Loss: 0.32818  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 6883 -- Train Loss: 0.32810  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 6884 -- Train Loss: 0.32814  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 6885 -- Train Loss: 0.32701  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 6886 -- Train Loss: 0.32788  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 6887 -- Train Loss: 0.32701  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6888 -- Train Loss: 0.32794  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 6889 -- Train Loss: 0.32773  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 6890 -- Train Loss: 0.32845  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 6891 -- Train Loss: 0.32718  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 6892 -- Train Loss: 0.32816  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 6893 -- Train Loss: 0.32824  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 6894 -- Train Loss: 0.32898  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 6895 -- Train Loss: 0.32823  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 6896 -- Train Loss: 0.32700  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 6897 -- Train Loss: 0.32780  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 6898 -- Train Loss: 0.32778  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 6899 -- Train Loss: 0.32750  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 6900 -- Train Loss: 0.32736  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 6901 -- Train Loss: 0.32772  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6902 -- Train Loss: 0.32845  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 6903 -- Train Loss: 0.32794  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 6904 -- Train Loss: 0.32831  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 6905 -- Train Loss: 0.32723  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 6906 -- Train Loss: 0.32812  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 6907 -- Train Loss: 0.32827  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 6908 -- Train Loss: 0.32742  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 6909 -- Train Loss: 0.32831  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 6910 -- Train Loss: 0.32672  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 6911 -- Train Loss: 0.32841  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 6912 -- Train Loss: 0.32731  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 6913 -- Train Loss: 0.32845  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 6914 -- Train Loss: 0.32715  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 6915 -- Train Loss: 0.32846  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 6916 -- Train Loss: 0.32827  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 6917 -- Train Loss: 0.32822  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 6918 -- Train Loss: 0.32872  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 6919 -- Train Loss: 0.32818  Validation Loss: 0.43277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 6920 -- Train Loss: 0.32803  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 6921 -- Train Loss: 0.32977  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 6922 -- Train Loss: 0.32731  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 6923 -- Train Loss: 0.32833  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 6924 -- Train Loss: 0.32685  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 6925 -- Train Loss: 0.32780  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 6926 -- Train Loss: 0.32739  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 6927 -- Train Loss: 0.32849  Validation Loss: 0.43119\n",
      "t: 10 EPOCH 6928 -- Train Loss: 0.32771  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 6929 -- Train Loss: 0.32891  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 6930 -- Train Loss: 0.32797  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 6931 -- Train Loss: 0.32861  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 6932 -- Train Loss: 0.32755  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 6933 -- Train Loss: 0.32946  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 6934 -- Train Loss: 0.32759  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 6935 -- Train Loss: 0.32915  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 6936 -- Train Loss: 0.32832  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 6937 -- Train Loss: 0.32817  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 6938 -- Train Loss: 0.32767  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 6939 -- Train Loss: 0.32820  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 6940 -- Train Loss: 0.32828  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 6941 -- Train Loss: 0.32774  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 6942 -- Train Loss: 0.32871  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 6943 -- Train Loss: 0.32788  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 6944 -- Train Loss: 0.32868  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 6945 -- Train Loss: 0.32834  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 6946 -- Train Loss: 0.32852  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 6947 -- Train Loss: 0.32861  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 6948 -- Train Loss: 0.32828  Validation Loss: 0.43096\n",
      "t: 10 EPOCH 6949 -- Train Loss: 0.32822  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 6950 -- Train Loss: 0.32812  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 6951 -- Train Loss: 0.32815  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 6952 -- Train Loss: 0.32862  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6953 -- Train Loss: 0.32746  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 6954 -- Train Loss: 0.32873  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 6955 -- Train Loss: 0.32732  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 6956 -- Train Loss: 0.32732  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 6957 -- Train Loss: 0.32804  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 6958 -- Train Loss: 0.32699  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 6959 -- Train Loss: 0.32794  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 6960 -- Train Loss: 0.32847  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 6961 -- Train Loss: 0.32780  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 6962 -- Train Loss: 0.32763  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 6963 -- Train Loss: 0.32863  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 6964 -- Train Loss: 0.32767  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 6965 -- Train Loss: 0.32826  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6966 -- Train Loss: 0.32731  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 6967 -- Train Loss: 0.32792  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 6968 -- Train Loss: 0.32759  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 6969 -- Train Loss: 0.32712  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 6970 -- Train Loss: 0.32832  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 6971 -- Train Loss: 0.32850  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 6972 -- Train Loss: 0.32866  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 6973 -- Train Loss: 0.32782  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 6974 -- Train Loss: 0.32697  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 6975 -- Train Loss: 0.32827  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 6976 -- Train Loss: 0.32847  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 6977 -- Train Loss: 0.32739  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 6978 -- Train Loss: 0.32780  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 6979 -- Train Loss: 0.32793  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 6980 -- Train Loss: 0.32786  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 6981 -- Train Loss: 0.32783  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 6982 -- Train Loss: 0.32770  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 6983 -- Train Loss: 0.32841  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 6984 -- Train Loss: 0.32839  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 6985 -- Train Loss: 0.32847  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 6986 -- Train Loss: 0.32784  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 6987 -- Train Loss: 0.32749  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 6988 -- Train Loss: 0.32872  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 6989 -- Train Loss: 0.32788  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 6990 -- Train Loss: 0.32813  Validation Loss: 0.43145\n",
      "t: 10 EPOCH 6991 -- Train Loss: 0.32772  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 6992 -- Train Loss: 0.32889  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 6993 -- Train Loss: 0.32748  Validation Loss: 0.43136\n",
      "t: 10 EPOCH 6994 -- Train Loss: 0.32766  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 6995 -- Train Loss: 0.32799  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 6996 -- Train Loss: 0.32691  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 6997 -- Train Loss: 0.32735  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 6998 -- Train Loss: 0.32851  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 6999 -- Train Loss: 0.32780  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 7000 -- Train Loss: 0.32758  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 7001 -- Train Loss: 0.32791  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7002 -- Train Loss: 0.32841  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 7003 -- Train Loss: 0.32806  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 7004 -- Train Loss: 0.32910  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 7005 -- Train Loss: 0.32754  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 7006 -- Train Loss: 0.32838  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 7007 -- Train Loss: 0.32841  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 7008 -- Train Loss: 0.32827  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 7009 -- Train Loss: 0.32758  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7010 -- Train Loss: 0.32836  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 7011 -- Train Loss: 0.32779  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 7012 -- Train Loss: 0.32834  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 7013 -- Train Loss: 0.32821  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 7014 -- Train Loss: 0.32853  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 7015 -- Train Loss: 0.32723  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 7016 -- Train Loss: 0.32961  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 7017 -- Train Loss: 0.32830  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 7018 -- Train Loss: 0.32849  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 7019 -- Train Loss: 0.32821  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 7020 -- Train Loss: 0.32775  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 7021 -- Train Loss: 0.32785  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 7022 -- Train Loss: 0.32794  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 7023 -- Train Loss: 0.32816  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 7024 -- Train Loss: 0.32789  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7025 -- Train Loss: 0.32789  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 7026 -- Train Loss: 0.32839  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 7027 -- Train Loss: 0.32822  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 7028 -- Train Loss: 0.32816  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 7029 -- Train Loss: 0.32750  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 7030 -- Train Loss: 0.32850  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 7031 -- Train Loss: 0.32770  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 7032 -- Train Loss: 0.32876  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 7033 -- Train Loss: 0.32717  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 7034 -- Train Loss: 0.32788  Validation Loss: 0.43125\n",
      "t: 10 EPOCH 7035 -- Train Loss: 0.32725  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 7036 -- Train Loss: 0.32811  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 7037 -- Train Loss: 0.32786  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 7038 -- Train Loss: 0.32783  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 7039 -- Train Loss: 0.32730  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 7040 -- Train Loss: 0.32844  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 7041 -- Train Loss: 0.32771  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 7042 -- Train Loss: 0.32806  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7043 -- Train Loss: 0.32775  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 7044 -- Train Loss: 0.32802  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 7045 -- Train Loss: 0.32823  Validation Loss: 0.43282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7046 -- Train Loss: 0.32793  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 7047 -- Train Loss: 0.32734  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 7048 -- Train Loss: 0.32827  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 7049 -- Train Loss: 0.32825  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 7050 -- Train Loss: 0.32851  Validation Loss: 0.43120\n",
      "t: 10 EPOCH 7051 -- Train Loss: 0.32719  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 7052 -- Train Loss: 0.32792  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 7053 -- Train Loss: 0.32838  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 7054 -- Train Loss: 0.32850  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 7055 -- Train Loss: 0.32820  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 7056 -- Train Loss: 0.32818  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 7057 -- Train Loss: 0.32756  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 7058 -- Train Loss: 0.32855  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 7059 -- Train Loss: 0.32763  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 7060 -- Train Loss: 0.32929  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 7061 -- Train Loss: 0.32825  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 7062 -- Train Loss: 0.32744  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 7063 -- Train Loss: 0.32840  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 7064 -- Train Loss: 0.32765  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 7065 -- Train Loss: 0.32936  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 7066 -- Train Loss: 0.32791  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 7067 -- Train Loss: 0.32844  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 7068 -- Train Loss: 0.32778  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 7069 -- Train Loss: 0.32909  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 7070 -- Train Loss: 0.32777  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 7071 -- Train Loss: 0.32758  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 7072 -- Train Loss: 0.32762  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 7073 -- Train Loss: 0.32849  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7074 -- Train Loss: 0.32813  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 7075 -- Train Loss: 0.32893  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 7076 -- Train Loss: 0.32801  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 7077 -- Train Loss: 0.32832  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 7078 -- Train Loss: 0.32812  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 7079 -- Train Loss: 0.32825  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 7080 -- Train Loss: 0.32816  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 7081 -- Train Loss: 0.32840  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 7082 -- Train Loss: 0.32788  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 7083 -- Train Loss: 0.32794  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 7084 -- Train Loss: 0.32778  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 7085 -- Train Loss: 0.32888  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 7086 -- Train Loss: 0.32774  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 7087 -- Train Loss: 0.32818  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 7088 -- Train Loss: 0.32781  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 7089 -- Train Loss: 0.32850  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 7090 -- Train Loss: 0.32861  Validation Loss: 0.43078\n",
      "t: 10 EPOCH 7091 -- Train Loss: 0.32764  Validation Loss: 0.43067\n",
      "t: 10 EPOCH 7092 -- Train Loss: 0.32821  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 7093 -- Train Loss: 0.32900  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 7094 -- Train Loss: 0.32791  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 7095 -- Train Loss: 0.32861  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 7096 -- Train Loss: 0.32712  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 7097 -- Train Loss: 0.32609  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 7098 -- Train Loss: 0.32756  Validation Loss: 0.43139\n",
      "t: 10 EPOCH 7099 -- Train Loss: 0.32699  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 7100 -- Train Loss: 0.32795  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7101 -- Train Loss: 0.32724  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 7102 -- Train Loss: 0.32771  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 7103 -- Train Loss: 0.32798  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 7104 -- Train Loss: 0.32784  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 7105 -- Train Loss: 0.32817  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 7106 -- Train Loss: 0.32664  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 7107 -- Train Loss: 0.32700  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 7108 -- Train Loss: 0.32720  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 7109 -- Train Loss: 0.32810  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 7110 -- Train Loss: 0.32790  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 7111 -- Train Loss: 0.32937  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 7112 -- Train Loss: 0.32745  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 7113 -- Train Loss: 0.32820  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 7114 -- Train Loss: 0.32653  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 7115 -- Train Loss: 0.32763  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 7116 -- Train Loss: 0.32746  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 7117 -- Train Loss: 0.32762  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 7118 -- Train Loss: 0.32775  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 7119 -- Train Loss: 0.32834  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 7120 -- Train Loss: 0.32783  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 7121 -- Train Loss: 0.32807  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 7122 -- Train Loss: 0.32803  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 7123 -- Train Loss: 0.32783  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 7124 -- Train Loss: 0.32801  Validation Loss: 0.43152\n",
      "t: 10 EPOCH 7125 -- Train Loss: 0.32811  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 7126 -- Train Loss: 0.32844  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 7127 -- Train Loss: 0.32680  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 7128 -- Train Loss: 0.32718  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 7129 -- Train Loss: 0.32700  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 7130 -- Train Loss: 0.32837  Validation Loss: 0.43042\n",
      "t: 10 EPOCH 7131 -- Train Loss: 0.32799  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 7132 -- Train Loss: 0.32776  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 7133 -- Train Loss: 0.32775  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 7134 -- Train Loss: 0.32815  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7135 -- Train Loss: 0.32731  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 7136 -- Train Loss: 0.32672  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 7137 -- Train Loss: 0.32779  Validation Loss: 0.43106\n",
      "t: 10 EPOCH 7138 -- Train Loss: 0.32652  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 7139 -- Train Loss: 0.32734  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 7140 -- Train Loss: 0.32766  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 7141 -- Train Loss: 0.32662  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 7142 -- Train Loss: 0.32754  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7143 -- Train Loss: 0.32741  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 7144 -- Train Loss: 0.32776  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 7145 -- Train Loss: 0.32769  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 7146 -- Train Loss: 0.32775  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 7147 -- Train Loss: 0.32747  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 7148 -- Train Loss: 0.32730  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 7149 -- Train Loss: 0.32692  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 7150 -- Train Loss: 0.32706  Validation Loss: 0.43131\n",
      "t: 10 EPOCH 7151 -- Train Loss: 0.32766  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 7152 -- Train Loss: 0.32844  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 7153 -- Train Loss: 0.32731  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7154 -- Train Loss: 0.32787  Validation Loss: 0.43103\n",
      "t: 10 EPOCH 7155 -- Train Loss: 0.32737  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 7156 -- Train Loss: 0.32828  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 7157 -- Train Loss: 0.32715  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 7158 -- Train Loss: 0.32728  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 7159 -- Train Loss: 0.32723  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 7160 -- Train Loss: 0.32798  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 7161 -- Train Loss: 0.32777  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 7162 -- Train Loss: 0.32864  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 7163 -- Train Loss: 0.32793  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7164 -- Train Loss: 0.32755  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7165 -- Train Loss: 0.32734  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 7166 -- Train Loss: 0.32744  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 7167 -- Train Loss: 0.32700  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7168 -- Train Loss: 0.32795  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 7169 -- Train Loss: 0.32834  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 7170 -- Train Loss: 0.32744  Validation Loss: 0.43218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7171 -- Train Loss: 0.32799  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7172 -- Train Loss: 0.32727  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7173 -- Train Loss: 0.32758  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 7174 -- Train Loss: 0.32808  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 7175 -- Train Loss: 0.32714  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 7176 -- Train Loss: 0.32753  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 7177 -- Train Loss: 0.32664  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 7178 -- Train Loss: 0.32789  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 7179 -- Train Loss: 0.32762  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 7180 -- Train Loss: 0.32731  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 7181 -- Train Loss: 0.32751  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 7182 -- Train Loss: 0.32752  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 7183 -- Train Loss: 0.32764  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 7184 -- Train Loss: 0.32751  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 7185 -- Train Loss: 0.32841  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 7186 -- Train Loss: 0.32705  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 7187 -- Train Loss: 0.32767  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 7188 -- Train Loss: 0.32820  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 7189 -- Train Loss: 0.32714  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 7190 -- Train Loss: 0.32730  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 7191 -- Train Loss: 0.32652  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 7192 -- Train Loss: 0.32818  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 7193 -- Train Loss: 0.32729  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 7194 -- Train Loss: 0.32809  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 7195 -- Train Loss: 0.32790  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 7196 -- Train Loss: 0.32764  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 7197 -- Train Loss: 0.32794  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 7198 -- Train Loss: 0.32819  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 7199 -- Train Loss: 0.32796  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 7200 -- Train Loss: 0.32800  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 7201 -- Train Loss: 0.32768  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 7202 -- Train Loss: 0.32808  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 7203 -- Train Loss: 0.32899  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 7204 -- Train Loss: 0.32792  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 7205 -- Train Loss: 0.32789  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 7206 -- Train Loss: 0.32863  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 7207 -- Train Loss: 0.32756  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 7208 -- Train Loss: 0.32779  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 7209 -- Train Loss: 0.32851  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 7210 -- Train Loss: 0.32729  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 7211 -- Train Loss: 0.32733  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 7212 -- Train Loss: 0.32798  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7213 -- Train Loss: 0.32746  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 7214 -- Train Loss: 0.32719  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 7215 -- Train Loss: 0.32822  Validation Loss: 0.43134\n",
      "t: 10 EPOCH 7216 -- Train Loss: 0.32834  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 7217 -- Train Loss: 0.32751  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 7218 -- Train Loss: 0.32751  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 7219 -- Train Loss: 0.32757  Validation Loss: 0.43081\n",
      "t: 10 EPOCH 7220 -- Train Loss: 0.32796  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 7221 -- Train Loss: 0.32729  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 7222 -- Train Loss: 0.32742  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 7223 -- Train Loss: 0.32799  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 7224 -- Train Loss: 0.32833  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 7225 -- Train Loss: 0.32780  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 7226 -- Train Loss: 0.32844  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 7227 -- Train Loss: 0.32798  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 7228 -- Train Loss: 0.32857  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 7229 -- Train Loss: 0.32754  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 7230 -- Train Loss: 0.32799  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 7231 -- Train Loss: 0.32809  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 7232 -- Train Loss: 0.32846  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 7233 -- Train Loss: 0.32791  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 7234 -- Train Loss: 0.32834  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 7235 -- Train Loss: 0.32784  Validation Loss: 0.42934\n",
      "t: 10 EPOCH 7236 -- Train Loss: 0.32753  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 7237 -- Train Loss: 0.32747  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 7238 -- Train Loss: 0.32797  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 7239 -- Train Loss: 0.32883  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 7240 -- Train Loss: 0.32800  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 7241 -- Train Loss: 0.32794  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 7242 -- Train Loss: 0.32686  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 7243 -- Train Loss: 0.32822  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 7244 -- Train Loss: 0.32818  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 7245 -- Train Loss: 0.32773  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 7246 -- Train Loss: 0.32804  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 7247 -- Train Loss: 0.32804  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 7248 -- Train Loss: 0.32783  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 7249 -- Train Loss: 0.32768  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 7250 -- Train Loss: 0.32809  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 7251 -- Train Loss: 0.32774  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 7252 -- Train Loss: 0.32817  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 7253 -- Train Loss: 0.32794  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 7254 -- Train Loss: 0.32757  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 7255 -- Train Loss: 0.32875  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 7256 -- Train Loss: 0.32780  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 7257 -- Train Loss: 0.32807  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 7258 -- Train Loss: 0.32821  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 7259 -- Train Loss: 0.32782  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 7260 -- Train Loss: 0.32783  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 7261 -- Train Loss: 0.32837  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 7262 -- Train Loss: 0.32816  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 7263 -- Train Loss: 0.32867  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 7264 -- Train Loss: 0.32784  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 7265 -- Train Loss: 0.32834  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 7266 -- Train Loss: 0.32778  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 7267 -- Train Loss: 0.32853  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 7268 -- Train Loss: 0.32830  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 7269 -- Train Loss: 0.32909  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 7270 -- Train Loss: 0.32799  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 7271 -- Train Loss: 0.32931  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 7272 -- Train Loss: 0.32826  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 7273 -- Train Loss: 0.32861  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 7274 -- Train Loss: 0.32744  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 7275 -- Train Loss: 0.32908  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 7276 -- Train Loss: 0.32786  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7277 -- Train Loss: 0.32904  Validation Loss: 0.43170\n",
      "t: 10 EPOCH 7278 -- Train Loss: 0.32869  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 7279 -- Train Loss: 0.32835  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 7280 -- Train Loss: 0.32771  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 7281 -- Train Loss: 0.32915  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 7282 -- Train Loss: 0.32784  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 7283 -- Train Loss: 0.32839  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 7284 -- Train Loss: 0.32762  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 7285 -- Train Loss: 0.32799  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 7286 -- Train Loss: 0.32748  Validation Loss: 0.43098\n",
      "t: 10 EPOCH 7287 -- Train Loss: 0.32818  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 7288 -- Train Loss: 0.32736  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 7289 -- Train Loss: 0.32822  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 7290 -- Train Loss: 0.32788  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 7291 -- Train Loss: 0.32963  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 7292 -- Train Loss: 0.32765  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 7293 -- Train Loss: 0.32825  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 7294 -- Train Loss: 0.32836  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7295 -- Train Loss: 0.32847  Validation Loss: 0.43222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7296 -- Train Loss: 0.32826  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 7297 -- Train Loss: 0.32715  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 7298 -- Train Loss: 0.32847  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7299 -- Train Loss: 0.32843  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 7300 -- Train Loss: 0.32808  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 7301 -- Train Loss: 0.32789  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 7302 -- Train Loss: 0.32804  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 7303 -- Train Loss: 0.32732  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 7304 -- Train Loss: 0.32901  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 7305 -- Train Loss: 0.32848  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 7306 -- Train Loss: 0.32894  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 7307 -- Train Loss: 0.32808  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 7308 -- Train Loss: 0.32674  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 7309 -- Train Loss: 0.32739  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 7310 -- Train Loss: 0.32724  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 7311 -- Train Loss: 0.32711  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 7312 -- Train Loss: 0.32762  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 7313 -- Train Loss: 0.32791  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 7314 -- Train Loss: 0.32799  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 7315 -- Train Loss: 0.32823  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 7316 -- Train Loss: 0.32789  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 7317 -- Train Loss: 0.32828  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 7318 -- Train Loss: 0.32823  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 7319 -- Train Loss: 0.32777  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 7320 -- Train Loss: 0.32788  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 7321 -- Train Loss: 0.32833  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 7322 -- Train Loss: 0.32645  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 7323 -- Train Loss: 0.32775  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 7324 -- Train Loss: 0.32757  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 7325 -- Train Loss: 0.32752  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 7326 -- Train Loss: 0.32703  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 7327 -- Train Loss: 0.32783  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 7328 -- Train Loss: 0.32763  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 7329 -- Train Loss: 0.32859  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 7330 -- Train Loss: 0.32718  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 7331 -- Train Loss: 0.32776  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 7332 -- Train Loss: 0.32708  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 7333 -- Train Loss: 0.32824  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 7334 -- Train Loss: 0.32638  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 7335 -- Train Loss: 0.32754  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 7336 -- Train Loss: 0.32805  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 7337 -- Train Loss: 0.32825  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 7338 -- Train Loss: 0.32752  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 7339 -- Train Loss: 0.32787  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 7340 -- Train Loss: 0.32701  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 7341 -- Train Loss: 0.32695  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 7342 -- Train Loss: 0.32762  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 7343 -- Train Loss: 0.32734  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 7344 -- Train Loss: 0.32743  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 7345 -- Train Loss: 0.32691  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 7346 -- Train Loss: 0.32834  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 7347 -- Train Loss: 0.32725  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 7348 -- Train Loss: 0.32790  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 7349 -- Train Loss: 0.32733  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 7350 -- Train Loss: 0.32634  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 7351 -- Train Loss: 0.32693  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 7352 -- Train Loss: 0.32758  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 7353 -- Train Loss: 0.32725  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 7354 -- Train Loss: 0.32744  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 7355 -- Train Loss: 0.32685  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 7356 -- Train Loss: 0.32793  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 7357 -- Train Loss: 0.32717  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 7358 -- Train Loss: 0.32769  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 7359 -- Train Loss: 0.32692  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 7360 -- Train Loss: 0.32709  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 7361 -- Train Loss: 0.32704  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 7362 -- Train Loss: 0.32707  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 7363 -- Train Loss: 0.32685  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 7364 -- Train Loss: 0.32774  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 7365 -- Train Loss: 0.32747  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 7366 -- Train Loss: 0.32808  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 7367 -- Train Loss: 0.32785  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 7368 -- Train Loss: 0.32777  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7369 -- Train Loss: 0.32704  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 7370 -- Train Loss: 0.32781  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 7371 -- Train Loss: 0.32747  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 7372 -- Train Loss: 0.32814  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 7373 -- Train Loss: 0.32791  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 7374 -- Train Loss: 0.32730  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 7375 -- Train Loss: 0.32722  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 7376 -- Train Loss: 0.32712  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 7377 -- Train Loss: 0.32851  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 7378 -- Train Loss: 0.32762  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 7379 -- Train Loss: 0.32767  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 7380 -- Train Loss: 0.32872  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 7381 -- Train Loss: 0.32688  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 7382 -- Train Loss: 0.32775  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 7383 -- Train Loss: 0.32794  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 7384 -- Train Loss: 0.32769  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 7385 -- Train Loss: 0.32739  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 7386 -- Train Loss: 0.32811  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 7387 -- Train Loss: 0.32831  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 7388 -- Train Loss: 0.32846  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 7389 -- Train Loss: 0.32735  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7390 -- Train Loss: 0.32752  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 7391 -- Train Loss: 0.32825  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 7392 -- Train Loss: 0.32767  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 7393 -- Train Loss: 0.32753  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 7394 -- Train Loss: 0.32857  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7395 -- Train Loss: 0.32832  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 7396 -- Train Loss: 0.32707  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 7397 -- Train Loss: 0.32686  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 7398 -- Train Loss: 0.32737  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 7399 -- Train Loss: 0.32777  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 7400 -- Train Loss: 0.32780  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 7401 -- Train Loss: 0.32789  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 7402 -- Train Loss: 0.32777  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 7403 -- Train Loss: 0.32773  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 7404 -- Train Loss: 0.32828  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 7405 -- Train Loss: 0.32713  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7406 -- Train Loss: 0.32748  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 7407 -- Train Loss: 0.32749  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 7408 -- Train Loss: 0.32792  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 7409 -- Train Loss: 0.32819  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 7410 -- Train Loss: 0.32873  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 7411 -- Train Loss: 0.32698  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 7412 -- Train Loss: 0.32815  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 7413 -- Train Loss: 0.32700  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7414 -- Train Loss: 0.32845  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 7415 -- Train Loss: 0.32656  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 7416 -- Train Loss: 0.32862  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 7417 -- Train Loss: 0.32749  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 7418 -- Train Loss: 0.32858  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 7419 -- Train Loss: 0.32854  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 7420 -- Train Loss: 0.32759  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 7421 -- Train Loss: 0.32794  Validation Loss: 0.43430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7422 -- Train Loss: 0.32774  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 7423 -- Train Loss: 0.32761  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 7424 -- Train Loss: 0.32760  Validation Loss: 0.43065\n",
      "t: 10 EPOCH 7425 -- Train Loss: 0.32779  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 7426 -- Train Loss: 0.32719  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 7427 -- Train Loss: 0.32779  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 7428 -- Train Loss: 0.32791  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 7429 -- Train Loss: 0.32802  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 7430 -- Train Loss: 0.32734  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7431 -- Train Loss: 0.32907  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 7432 -- Train Loss: 0.32710  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 7433 -- Train Loss: 0.32777  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 7434 -- Train Loss: 0.32755  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 7435 -- Train Loss: 0.32748  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 7436 -- Train Loss: 0.32757  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7437 -- Train Loss: 0.32810  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 7438 -- Train Loss: 0.32764  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 7439 -- Train Loss: 0.32782  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 7440 -- Train Loss: 0.32749  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 7441 -- Train Loss: 0.32751  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 7442 -- Train Loss: 0.32783  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 7443 -- Train Loss: 0.32742  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 7444 -- Train Loss: 0.32629  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 7445 -- Train Loss: 0.32846  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 7446 -- Train Loss: 0.32757  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 7447 -- Train Loss: 0.32775  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 7448 -- Train Loss: 0.32808  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 7449 -- Train Loss: 0.32735  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 7450 -- Train Loss: 0.32804  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 7451 -- Train Loss: 0.32831  Validation Loss: 0.43158\n",
      "t: 10 EPOCH 7452 -- Train Loss: 0.32614  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 7453 -- Train Loss: 0.32770  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7454 -- Train Loss: 0.32683  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 7455 -- Train Loss: 0.32749  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 7456 -- Train Loss: 0.32771  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 7457 -- Train Loss: 0.32763  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 7458 -- Train Loss: 0.32827  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 7459 -- Train Loss: 0.32710  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 7460 -- Train Loss: 0.32761  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 7461 -- Train Loss: 0.32851  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 7462 -- Train Loss: 0.32801  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 7463 -- Train Loss: 0.32759  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 7464 -- Train Loss: 0.32746  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 7465 -- Train Loss: 0.32634  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 7466 -- Train Loss: 0.32712  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 7467 -- Train Loss: 0.32712  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 7468 -- Train Loss: 0.32738  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 7469 -- Train Loss: 0.32767  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 7470 -- Train Loss: 0.32812  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 7471 -- Train Loss: 0.32737  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7472 -- Train Loss: 0.32702  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 7473 -- Train Loss: 0.32685  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 7474 -- Train Loss: 0.32852  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 7475 -- Train Loss: 0.32701  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 7476 -- Train Loss: 0.32710  Validation Loss: 0.43045\n",
      "t: 10 EPOCH 7477 -- Train Loss: 0.32767  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7478 -- Train Loss: 0.32694  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 7479 -- Train Loss: 0.32794  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 7480 -- Train Loss: 0.32777  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 7481 -- Train Loss: 0.32798  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 7482 -- Train Loss: 0.32753  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7483 -- Train Loss: 0.32783  Validation Loss: 0.43132\n",
      "t: 10 EPOCH 7484 -- Train Loss: 0.32781  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 7485 -- Train Loss: 0.32733  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 7486 -- Train Loss: 0.32726  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 7487 -- Train Loss: 0.32822  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 7488 -- Train Loss: 0.32670  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 7489 -- Train Loss: 0.32823  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 7490 -- Train Loss: 0.32810  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 7491 -- Train Loss: 0.32714  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 7492 -- Train Loss: 0.32753  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 7493 -- Train Loss: 0.32780  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 7494 -- Train Loss: 0.32729  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 7495 -- Train Loss: 0.32760  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 7496 -- Train Loss: 0.32603  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 7497 -- Train Loss: 0.32786  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 7498 -- Train Loss: 0.32686  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 7499 -- Train Loss: 0.32719  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 7500 -- Train Loss: 0.32764  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 7501 -- Train Loss: 0.32815  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 7502 -- Train Loss: 0.32728  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 7503 -- Train Loss: 0.32772  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 7504 -- Train Loss: 0.32756  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 7505 -- Train Loss: 0.32734  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 7506 -- Train Loss: 0.32741  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 7507 -- Train Loss: 0.32810  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 7508 -- Train Loss: 0.32735  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 7509 -- Train Loss: 0.32827  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 7510 -- Train Loss: 0.32712  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7511 -- Train Loss: 0.32705  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 7512 -- Train Loss: 0.32755  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 7513 -- Train Loss: 0.32825  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 7514 -- Train Loss: 0.32670  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 7515 -- Train Loss: 0.32630  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 7516 -- Train Loss: 0.32765  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 7517 -- Train Loss: 0.32728  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 7518 -- Train Loss: 0.32778  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 7519 -- Train Loss: 0.32818  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 7520 -- Train Loss: 0.32785  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 7521 -- Train Loss: 0.32756  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 7522 -- Train Loss: 0.32741  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 7523 -- Train Loss: 0.32792  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 7524 -- Train Loss: 0.32709  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 7525 -- Train Loss: 0.32807  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 7526 -- Train Loss: 0.32773  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 7527 -- Train Loss: 0.32746  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 7528 -- Train Loss: 0.32694  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 7529 -- Train Loss: 0.32740  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 7530 -- Train Loss: 0.32673  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7531 -- Train Loss: 0.32682  Validation Loss: 0.43172\n",
      "t: 10 EPOCH 7532 -- Train Loss: 0.32739  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7533 -- Train Loss: 0.32741  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 7534 -- Train Loss: 0.32626  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 7535 -- Train Loss: 0.32737  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 7536 -- Train Loss: 0.32790  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 7537 -- Train Loss: 0.32679  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 7538 -- Train Loss: 0.32672  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7539 -- Train Loss: 0.32726  Validation Loss: 0.43178\n",
      "t: 10 EPOCH 7540 -- Train Loss: 0.32724  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 7541 -- Train Loss: 0.32681  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 7542 -- Train Loss: 0.32734  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 7543 -- Train Loss: 0.32784  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 7544 -- Train Loss: 0.32741  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7545 -- Train Loss: 0.32713  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 7546 -- Train Loss: 0.32773  Validation Loss: 0.43068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7547 -- Train Loss: 0.32729  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 7548 -- Train Loss: 0.32750  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 7549 -- Train Loss: 0.32772  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7550 -- Train Loss: 0.32737  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 7551 -- Train Loss: 0.32774  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 7552 -- Train Loss: 0.32712  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 7553 -- Train Loss: 0.32815  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 7554 -- Train Loss: 0.32756  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 7555 -- Train Loss: 0.32807  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 7556 -- Train Loss: 0.32831  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 7557 -- Train Loss: 0.32785  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 7558 -- Train Loss: 0.32722  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 7559 -- Train Loss: 0.32844  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 7560 -- Train Loss: 0.32814  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 7561 -- Train Loss: 0.32800  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 7562 -- Train Loss: 0.32782  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 7563 -- Train Loss: 0.32794  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 7564 -- Train Loss: 0.32807  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 7565 -- Train Loss: 0.32774  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7566 -- Train Loss: 0.32825  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7567 -- Train Loss: 0.32883  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 7568 -- Train Loss: 0.32805  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 7569 -- Train Loss: 0.32786  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 7570 -- Train Loss: 0.32775  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 7571 -- Train Loss: 0.32837  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 7572 -- Train Loss: 0.32732  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 7573 -- Train Loss: 0.32828  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7574 -- Train Loss: 0.32832  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 7575 -- Train Loss: 0.32825  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 7576 -- Train Loss: 0.32734  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 7577 -- Train Loss: 0.32760  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 7578 -- Train Loss: 0.32834  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 7579 -- Train Loss: 0.32842  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 7580 -- Train Loss: 0.32779  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7581 -- Train Loss: 0.32840  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 7582 -- Train Loss: 0.32770  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 7583 -- Train Loss: 0.32751  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 7584 -- Train Loss: 0.32762  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 7585 -- Train Loss: 0.32794  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 7586 -- Train Loss: 0.32769  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 7587 -- Train Loss: 0.32708  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 7588 -- Train Loss: 0.32851  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 7589 -- Train Loss: 0.32847  Validation Loss: 0.43128\n",
      "t: 10 EPOCH 7590 -- Train Loss: 0.32791  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 7591 -- Train Loss: 0.32817  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 7592 -- Train Loss: 0.32701  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 7593 -- Train Loss: 0.32635  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 7594 -- Train Loss: 0.32746  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 7595 -- Train Loss: 0.32767  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 7596 -- Train Loss: 0.32838  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 7597 -- Train Loss: 0.32804  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 7598 -- Train Loss: 0.32647  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 7599 -- Train Loss: 0.32802  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 7600 -- Train Loss: 0.32760  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7601 -- Train Loss: 0.32773  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 7602 -- Train Loss: 0.32758  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 7603 -- Train Loss: 0.32714  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 7604 -- Train Loss: 0.32801  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 7605 -- Train Loss: 0.32617  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 7606 -- Train Loss: 0.32777  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 7607 -- Train Loss: 0.32702  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 7608 -- Train Loss: 0.32795  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7609 -- Train Loss: 0.32806  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 7610 -- Train Loss: 0.32785  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 7611 -- Train Loss: 0.32779  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 7612 -- Train Loss: 0.32744  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7613 -- Train Loss: 0.32751  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 7614 -- Train Loss: 0.32712  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 7615 -- Train Loss: 0.32644  Validation Loss: 0.43153\n",
      "t: 10 EPOCH 7616 -- Train Loss: 0.32774  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 7617 -- Train Loss: 0.32671  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 7618 -- Train Loss: 0.32740  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 7619 -- Train Loss: 0.32723  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 7620 -- Train Loss: 0.32709  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 7621 -- Train Loss: 0.32865  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 7622 -- Train Loss: 0.32691  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 7623 -- Train Loss: 0.32728  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7624 -- Train Loss: 0.32715  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 7625 -- Train Loss: 0.32736  Validation Loss: 0.43147\n",
      "t: 10 EPOCH 7626 -- Train Loss: 0.32763  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 7627 -- Train Loss: 0.32608  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7628 -- Train Loss: 0.32664  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 7629 -- Train Loss: 0.32667  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 7630 -- Train Loss: 0.32756  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 7631 -- Train Loss: 0.32743  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 7632 -- Train Loss: 0.32752  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 7633 -- Train Loss: 0.32594  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 7634 -- Train Loss: 0.32771  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 7635 -- Train Loss: 0.32694  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 7636 -- Train Loss: 0.32726  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 7637 -- Train Loss: 0.32724  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 7638 -- Train Loss: 0.32673  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 7639 -- Train Loss: 0.32762  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 7640 -- Train Loss: 0.32757  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 7641 -- Train Loss: 0.32740  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7642 -- Train Loss: 0.32685  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 7643 -- Train Loss: 0.32744  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 7644 -- Train Loss: 0.32697  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 7645 -- Train Loss: 0.32730  Validation Loss: 0.43095\n",
      "t: 10 EPOCH 7646 -- Train Loss: 0.32677  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 7647 -- Train Loss: 0.32778  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 7648 -- Train Loss: 0.32658  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 7649 -- Train Loss: 0.32724  Validation Loss: 0.43137\n",
      "t: 10 EPOCH 7650 -- Train Loss: 0.32687  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 7651 -- Train Loss: 0.32806  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 7652 -- Train Loss: 0.32720  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 7653 -- Train Loss: 0.32760  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 7654 -- Train Loss: 0.32657  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 7655 -- Train Loss: 0.32783  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 7656 -- Train Loss: 0.32730  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 7657 -- Train Loss: 0.32833  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 7658 -- Train Loss: 0.32840  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 7659 -- Train Loss: 0.32661  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 7660 -- Train Loss: 0.32779  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 7661 -- Train Loss: 0.32765  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 7662 -- Train Loss: 0.32766  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 7663 -- Train Loss: 0.32720  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 7664 -- Train Loss: 0.32803  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 7665 -- Train Loss: 0.32689  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 7666 -- Train Loss: 0.32746  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 7667 -- Train Loss: 0.32798  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 7668 -- Train Loss: 0.32793  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 7669 -- Train Loss: 0.32745  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 7670 -- Train Loss: 0.32761  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 7671 -- Train Loss: 0.32668  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 7672 -- Train Loss: 0.32799  Validation Loss: 0.43354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7673 -- Train Loss: 0.32732  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 7674 -- Train Loss: 0.32718  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 7675 -- Train Loss: 0.32742  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 7676 -- Train Loss: 0.32659  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 7677 -- Train Loss: 0.32743  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 7678 -- Train Loss: 0.32753  Validation Loss: 0.43141\n",
      "t: 10 EPOCH 7679 -- Train Loss: 0.32799  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 7680 -- Train Loss: 0.32860  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 7681 -- Train Loss: 0.32735  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 7682 -- Train Loss: 0.32744  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 7683 -- Train Loss: 0.32764  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 7684 -- Train Loss: 0.32718  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 7685 -- Train Loss: 0.32795  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 7686 -- Train Loss: 0.32705  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 7687 -- Train Loss: 0.32824  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 7688 -- Train Loss: 0.32779  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 7689 -- Train Loss: 0.32725  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 7690 -- Train Loss: 0.32744  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 7691 -- Train Loss: 0.32661  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7692 -- Train Loss: 0.32737  Validation Loss: 0.43228\n",
      "t: 10 EPOCH 7693 -- Train Loss: 0.32769  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 7694 -- Train Loss: 0.32745  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 7695 -- Train Loss: 0.32698  Validation Loss: 0.43086\n",
      "t: 10 EPOCH 7696 -- Train Loss: 0.32687  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 7697 -- Train Loss: 0.32647  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 7698 -- Train Loss: 0.32746  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 7699 -- Train Loss: 0.32788  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 7700 -- Train Loss: 0.32750  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 7701 -- Train Loss: 0.32809  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 7702 -- Train Loss: 0.32707  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 7703 -- Train Loss: 0.32743  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 7704 -- Train Loss: 0.32737  Validation Loss: 0.43124\n",
      "t: 10 EPOCH 7705 -- Train Loss: 0.32698  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7706 -- Train Loss: 0.32706  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 7707 -- Train Loss: 0.32728  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 7708 -- Train Loss: 0.32655  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 7709 -- Train Loss: 0.32698  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 7710 -- Train Loss: 0.32742  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 7711 -- Train Loss: 0.32665  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7712 -- Train Loss: 0.32706  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 7713 -- Train Loss: 0.32693  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 7714 -- Train Loss: 0.32694  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 7715 -- Train Loss: 0.32659  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 7716 -- Train Loss: 0.32720  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 7717 -- Train Loss: 0.32641  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 7718 -- Train Loss: 0.32690  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 7719 -- Train Loss: 0.32732  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 7720 -- Train Loss: 0.32772  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7721 -- Train Loss: 0.32696  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 7722 -- Train Loss: 0.32728  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 7723 -- Train Loss: 0.32755  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 7724 -- Train Loss: 0.32688  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 7725 -- Train Loss: 0.32691  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 7726 -- Train Loss: 0.32784  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 7727 -- Train Loss: 0.32877  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 7728 -- Train Loss: 0.32794  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 7729 -- Train Loss: 0.32778  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 7730 -- Train Loss: 0.32656  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 7731 -- Train Loss: 0.32716  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 7732 -- Train Loss: 0.32781  Validation Loss: 0.43191\n",
      "t: 10 EPOCH 7733 -- Train Loss: 0.32703  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 7734 -- Train Loss: 0.32743  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 7735 -- Train Loss: 0.32728  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 7736 -- Train Loss: 0.32730  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 7737 -- Train Loss: 0.32764  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 7738 -- Train Loss: 0.32645  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 7739 -- Train Loss: 0.32732  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 7740 -- Train Loss: 0.32679  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 7741 -- Train Loss: 0.32705  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 7742 -- Train Loss: 0.32700  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7743 -- Train Loss: 0.32779  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 7744 -- Train Loss: 0.32723  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 7745 -- Train Loss: 0.32773  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 7746 -- Train Loss: 0.32807  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 7747 -- Train Loss: 0.32732  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 7748 -- Train Loss: 0.32785  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 7749 -- Train Loss: 0.32794  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 7750 -- Train Loss: 0.32767  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 7751 -- Train Loss: 0.32686  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 7752 -- Train Loss: 0.32790  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 7753 -- Train Loss: 0.32668  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 7754 -- Train Loss: 0.32688  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 7755 -- Train Loss: 0.32715  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 7756 -- Train Loss: 0.32765  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 7757 -- Train Loss: 0.32693  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 7758 -- Train Loss: 0.32706  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 7759 -- Train Loss: 0.32725  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7760 -- Train Loss: 0.32619  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 7761 -- Train Loss: 0.32756  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 7762 -- Train Loss: 0.32672  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 7763 -- Train Loss: 0.32743  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 7764 -- Train Loss: 0.32764  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 7765 -- Train Loss: 0.32833  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 7766 -- Train Loss: 0.32793  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 7767 -- Train Loss: 0.32794  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 7768 -- Train Loss: 0.32725  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 7769 -- Train Loss: 0.32833  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 7770 -- Train Loss: 0.32774  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 7771 -- Train Loss: 0.32867  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 7772 -- Train Loss: 0.32646  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 7773 -- Train Loss: 0.32777  Validation Loss: 0.43091\n",
      "t: 10 EPOCH 7774 -- Train Loss: 0.32855  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 7775 -- Train Loss: 0.32684  Validation Loss: 0.43156\n",
      "t: 10 EPOCH 7776 -- Train Loss: 0.32744  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 7777 -- Train Loss: 0.32726  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 7778 -- Train Loss: 0.32849  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 7779 -- Train Loss: 0.32813  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 7780 -- Train Loss: 0.32684  Validation Loss: 0.43126\n",
      "t: 10 EPOCH 7781 -- Train Loss: 0.32791  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 7782 -- Train Loss: 0.32756  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 7783 -- Train Loss: 0.32728  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 7784 -- Train Loss: 0.32734  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 7785 -- Train Loss: 0.32807  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 7786 -- Train Loss: 0.32749  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 7787 -- Train Loss: 0.32735  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 7788 -- Train Loss: 0.32756  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 7789 -- Train Loss: 0.32785  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 7790 -- Train Loss: 0.32800  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 7791 -- Train Loss: 0.32726  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 7792 -- Train Loss: 0.32749  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 7793 -- Train Loss: 0.32797  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 7794 -- Train Loss: 0.32828  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 7795 -- Train Loss: 0.32695  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7796 -- Train Loss: 0.32760  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 7797 -- Train Loss: 0.32794  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 7798 -- Train Loss: 0.32765  Validation Loss: 0.43365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7799 -- Train Loss: 0.32758  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 7800 -- Train Loss: 0.32752  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 7801 -- Train Loss: 0.32715  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 7802 -- Train Loss: 0.32727  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 7803 -- Train Loss: 0.32811  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 7804 -- Train Loss: 0.32674  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 7805 -- Train Loss: 0.32876  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 7806 -- Train Loss: 0.32815  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 7807 -- Train Loss: 0.32746  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 7808 -- Train Loss: 0.32715  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7809 -- Train Loss: 0.32686  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 7810 -- Train Loss: 0.32709  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 7811 -- Train Loss: 0.32762  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 7812 -- Train Loss: 0.32698  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 7813 -- Train Loss: 0.32785  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 7814 -- Train Loss: 0.32790  Validation Loss: 0.43084\n",
      "t: 10 EPOCH 7815 -- Train Loss: 0.32793  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 7816 -- Train Loss: 0.32688  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 7817 -- Train Loss: 0.32701  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 7818 -- Train Loss: 0.32695  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 7819 -- Train Loss: 0.32698  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 7820 -- Train Loss: 0.32729  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 7821 -- Train Loss: 0.32684  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 7822 -- Train Loss: 0.32760  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 7823 -- Train Loss: 0.32762  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 7824 -- Train Loss: 0.32704  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 7825 -- Train Loss: 0.32676  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 7826 -- Train Loss: 0.32782  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 7827 -- Train Loss: 0.32743  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 7828 -- Train Loss: 0.32717  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 7829 -- Train Loss: 0.32842  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 7830 -- Train Loss: 0.32754  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 7831 -- Train Loss: 0.32758  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7832 -- Train Loss: 0.32812  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 7833 -- Train Loss: 0.32775  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 7834 -- Train Loss: 0.32816  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 7835 -- Train Loss: 0.32794  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 7836 -- Train Loss: 0.32737  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 7837 -- Train Loss: 0.32766  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 7838 -- Train Loss: 0.32784  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 7839 -- Train Loss: 0.32730  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 7840 -- Train Loss: 0.32738  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 7841 -- Train Loss: 0.32755  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 7842 -- Train Loss: 0.32730  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 7843 -- Train Loss: 0.32690  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 7844 -- Train Loss: 0.32776  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 7845 -- Train Loss: 0.32806  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 7846 -- Train Loss: 0.32798  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 7847 -- Train Loss: 0.32644  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 7848 -- Train Loss: 0.32652  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 7849 -- Train Loss: 0.32815  Validation Loss: 0.43176\n",
      "t: 10 EPOCH 7850 -- Train Loss: 0.32649  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 7851 -- Train Loss: 0.32761  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 7852 -- Train Loss: 0.32653  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 7853 -- Train Loss: 0.32672  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 7854 -- Train Loss: 0.32733  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 7855 -- Train Loss: 0.32750  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 7856 -- Train Loss: 0.32742  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 7857 -- Train Loss: 0.32750  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7858 -- Train Loss: 0.32732  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 7859 -- Train Loss: 0.32691  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 7860 -- Train Loss: 0.32697  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 7861 -- Train Loss: 0.32787  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 7862 -- Train Loss: 0.32734  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 7863 -- Train Loss: 0.32730  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 7864 -- Train Loss: 0.32698  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 7865 -- Train Loss: 0.32781  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 7866 -- Train Loss: 0.32666  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 7867 -- Train Loss: 0.32694  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 7868 -- Train Loss: 0.32673  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 7869 -- Train Loss: 0.32817  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 7870 -- Train Loss: 0.32688  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 7871 -- Train Loss: 0.32716  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 7872 -- Train Loss: 0.32730  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 7873 -- Train Loss: 0.32836  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 7874 -- Train Loss: 0.32771  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 7875 -- Train Loss: 0.32732  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 7876 -- Train Loss: 0.32750  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 7877 -- Train Loss: 0.32706  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 7878 -- Train Loss: 0.32781  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 7879 -- Train Loss: 0.32665  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 7880 -- Train Loss: 0.32810  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 7881 -- Train Loss: 0.32659  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 7882 -- Train Loss: 0.32766  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 7883 -- Train Loss: 0.32771  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 7884 -- Train Loss: 0.32690  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 7885 -- Train Loss: 0.32792  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 7886 -- Train Loss: 0.32749  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 7887 -- Train Loss: 0.32686  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 7888 -- Train Loss: 0.32754  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 7889 -- Train Loss: 0.32721  Validation Loss: 0.43151\n",
      "t: 10 EPOCH 7890 -- Train Loss: 0.32741  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 7891 -- Train Loss: 0.32670  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 7892 -- Train Loss: 0.32701  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 7893 -- Train Loss: 0.32734  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 7894 -- Train Loss: 0.32629  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 7895 -- Train Loss: 0.32781  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 7896 -- Train Loss: 0.32697  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 7897 -- Train Loss: 0.32700  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 7898 -- Train Loss: 0.32726  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 7899 -- Train Loss: 0.32814  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 7900 -- Train Loss: 0.32624  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 7901 -- Train Loss: 0.32768  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 7902 -- Train Loss: 0.32631  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 7903 -- Train Loss: 0.32674  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 7904 -- Train Loss: 0.32698  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 7905 -- Train Loss: 0.32679  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 7906 -- Train Loss: 0.32665  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 7907 -- Train Loss: 0.32733  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 7908 -- Train Loss: 0.32702  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 7909 -- Train Loss: 0.32579  Validation Loss: 0.43197\n",
      "t: 10 EPOCH 7910 -- Train Loss: 0.32684  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 7911 -- Train Loss: 0.32753  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 7912 -- Train Loss: 0.32700  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 7913 -- Train Loss: 0.32658  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 7914 -- Train Loss: 0.32764  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 7915 -- Train Loss: 0.32805  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 7916 -- Train Loss: 0.32771  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 7917 -- Train Loss: 0.32670  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 7918 -- Train Loss: 0.32772  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 7919 -- Train Loss: 0.32705  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 7920 -- Train Loss: 0.32727  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 7921 -- Train Loss: 0.32564  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 7922 -- Train Loss: 0.32668  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 7923 -- Train Loss: 0.32650  Validation Loss: 0.43277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 7924 -- Train Loss: 0.32716  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 7925 -- Train Loss: 0.32691  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 7926 -- Train Loss: 0.32688  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 7927 -- Train Loss: 0.32741  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 7928 -- Train Loss: 0.32657  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 7929 -- Train Loss: 0.32666  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 7930 -- Train Loss: 0.32633  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 7931 -- Train Loss: 0.32621  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 7932 -- Train Loss: 0.32650  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 7933 -- Train Loss: 0.32714  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 7934 -- Train Loss: 0.32679  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 7935 -- Train Loss: 0.32695  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 7936 -- Train Loss: 0.32688  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 7937 -- Train Loss: 0.32600  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 7938 -- Train Loss: 0.32760  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 7939 -- Train Loss: 0.32561  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 7940 -- Train Loss: 0.32582  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 7941 -- Train Loss: 0.32735  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 7942 -- Train Loss: 0.32669  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 7943 -- Train Loss: 0.32814  Validation Loss: 0.43121\n",
      "t: 10 EPOCH 7944 -- Train Loss: 0.32800  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 7945 -- Train Loss: 0.32666  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 7946 -- Train Loss: 0.32766  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 7947 -- Train Loss: 0.32731  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 7948 -- Train Loss: 0.32667  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 7949 -- Train Loss: 0.32673  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 7950 -- Train Loss: 0.32615  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 7951 -- Train Loss: 0.32729  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 7952 -- Train Loss: 0.32627  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 7953 -- Train Loss: 0.32644  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 7954 -- Train Loss: 0.32653  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 7955 -- Train Loss: 0.32716  Validation Loss: 0.43083\n",
      "t: 10 EPOCH 7956 -- Train Loss: 0.32613  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 7957 -- Train Loss: 0.32739  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 7958 -- Train Loss: 0.32724  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 7959 -- Train Loss: 0.32791  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 7960 -- Train Loss: 0.32676  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 7961 -- Train Loss: 0.32721  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 7962 -- Train Loss: 0.32760  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 7963 -- Train Loss: 0.32804  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 7964 -- Train Loss: 0.32721  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 7965 -- Train Loss: 0.32708  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 7966 -- Train Loss: 0.32814  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 7967 -- Train Loss: 0.32745  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 7968 -- Train Loss: 0.32720  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 7969 -- Train Loss: 0.32783  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 7970 -- Train Loss: 0.32805  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 7971 -- Train Loss: 0.32841  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 7972 -- Train Loss: 0.32799  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 7973 -- Train Loss: 0.32678  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 7974 -- Train Loss: 0.32797  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 7975 -- Train Loss: 0.32870  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 7976 -- Train Loss: 0.32789  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 7977 -- Train Loss: 0.32768  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 7978 -- Train Loss: 0.32759  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 7979 -- Train Loss: 0.32772  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 7980 -- Train Loss: 0.32710  Validation Loss: 0.43028\n",
      "t: 10 EPOCH 7981 -- Train Loss: 0.32748  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 7982 -- Train Loss: 0.32769  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 7983 -- Train Loss: 0.32833  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 7984 -- Train Loss: 0.32749  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 7985 -- Train Loss: 0.32651  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 7986 -- Train Loss: 0.32760  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 7987 -- Train Loss: 0.32753  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 7988 -- Train Loss: 0.32791  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 7989 -- Train Loss: 0.32842  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 7990 -- Train Loss: 0.32692  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 7991 -- Train Loss: 0.32774  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 7992 -- Train Loss: 0.32727  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 7993 -- Train Loss: 0.32784  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 7994 -- Train Loss: 0.32710  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 7995 -- Train Loss: 0.32766  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 7996 -- Train Loss: 0.32783  Validation Loss: 0.43212\n",
      "t: 10 EPOCH 7997 -- Train Loss: 0.32768  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 7998 -- Train Loss: 0.32808  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 7999 -- Train Loss: 0.32732  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 8000 -- Train Loss: 0.32853  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 8001 -- Train Loss: 0.32700  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 8002 -- Train Loss: 0.32816  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 8003 -- Train Loss: 0.32751  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8004 -- Train Loss: 0.32732  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 8005 -- Train Loss: 0.32770  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8006 -- Train Loss: 0.32702  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 8007 -- Train Loss: 0.32712  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 8008 -- Train Loss: 0.32800  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 8009 -- Train Loss: 0.32728  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 8010 -- Train Loss: 0.32678  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 8011 -- Train Loss: 0.32763  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 8012 -- Train Loss: 0.32695  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 8013 -- Train Loss: 0.32699  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 8014 -- Train Loss: 0.32763  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 8015 -- Train Loss: 0.32709  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 8016 -- Train Loss: 0.32754  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 8017 -- Train Loss: 0.32737  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 8018 -- Train Loss: 0.32681  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 8019 -- Train Loss: 0.32790  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 8020 -- Train Loss: 0.32773  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 8021 -- Train Loss: 0.32791  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 8022 -- Train Loss: 0.32709  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8023 -- Train Loss: 0.32676  Validation Loss: 0.43142\n",
      "t: 10 EPOCH 8024 -- Train Loss: 0.32792  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 8025 -- Train Loss: 0.32705  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 8026 -- Train Loss: 0.32799  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8027 -- Train Loss: 0.32797  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 8028 -- Train Loss: 0.32702  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 8029 -- Train Loss: 0.32726  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 8030 -- Train Loss: 0.32832  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 8031 -- Train Loss: 0.32771  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 8032 -- Train Loss: 0.32693  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 8033 -- Train Loss: 0.32721  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 8034 -- Train Loss: 0.32721  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 8035 -- Train Loss: 0.32678  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8036 -- Train Loss: 0.32734  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 8037 -- Train Loss: 0.32771  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 8038 -- Train Loss: 0.32770  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 8039 -- Train Loss: 0.32669  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 8040 -- Train Loss: 0.32701  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 8041 -- Train Loss: 0.32759  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 8042 -- Train Loss: 0.32720  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 8043 -- Train Loss: 0.32637  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 8044 -- Train Loss: 0.32754  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 8045 -- Train Loss: 0.32659  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 8046 -- Train Loss: 0.32701  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8047 -- Train Loss: 0.32762  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 8048 -- Train Loss: 0.32694  Validation Loss: 0.43301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8049 -- Train Loss: 0.32788  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 8050 -- Train Loss: 0.32782  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 8051 -- Train Loss: 0.32641  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 8052 -- Train Loss: 0.32612  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 8053 -- Train Loss: 0.32708  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 8054 -- Train Loss: 0.32700  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 8055 -- Train Loss: 0.32805  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8056 -- Train Loss: 0.32647  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 8057 -- Train Loss: 0.32778  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8058 -- Train Loss: 0.32683  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8059 -- Train Loss: 0.32744  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 8060 -- Train Loss: 0.32676  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 8061 -- Train Loss: 0.32741  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 8062 -- Train Loss: 0.32676  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 8063 -- Train Loss: 0.32603  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 8064 -- Train Loss: 0.32707  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 8065 -- Train Loss: 0.32798  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 8066 -- Train Loss: 0.32711  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8067 -- Train Loss: 0.32818  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8068 -- Train Loss: 0.32699  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 8069 -- Train Loss: 0.32804  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 8070 -- Train Loss: 0.32633  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 8071 -- Train Loss: 0.32714  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 8072 -- Train Loss: 0.32603  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8073 -- Train Loss: 0.32763  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 8074 -- Train Loss: 0.32717  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 8075 -- Train Loss: 0.32788  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 8076 -- Train Loss: 0.32728  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 8077 -- Train Loss: 0.32673  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 8078 -- Train Loss: 0.32730  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 8079 -- Train Loss: 0.32741  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 8080 -- Train Loss: 0.32681  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 8081 -- Train Loss: 0.32628  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 8082 -- Train Loss: 0.32778  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 8083 -- Train Loss: 0.32732  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 8084 -- Train Loss: 0.32731  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 8085 -- Train Loss: 0.32743  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8086 -- Train Loss: 0.32815  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 8087 -- Train Loss: 0.32689  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 8088 -- Train Loss: 0.32646  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 8089 -- Train Loss: 0.32728  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 8090 -- Train Loss: 0.32691  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 8091 -- Train Loss: 0.32633  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8092 -- Train Loss: 0.32768  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 8093 -- Train Loss: 0.32627  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8094 -- Train Loss: 0.32721  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8095 -- Train Loss: 0.32757  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8096 -- Train Loss: 0.32699  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 8097 -- Train Loss: 0.32743  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 8098 -- Train Loss: 0.32700  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 8099 -- Train Loss: 0.32702  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 8100 -- Train Loss: 0.32711  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 8101 -- Train Loss: 0.32700  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 8102 -- Train Loss: 0.32637  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 8103 -- Train Loss: 0.32714  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 8104 -- Train Loss: 0.32692  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 8105 -- Train Loss: 0.32702  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 8106 -- Train Loss: 0.32659  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 8107 -- Train Loss: 0.32698  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 8108 -- Train Loss: 0.32660  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 8109 -- Train Loss: 0.32706  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 8110 -- Train Loss: 0.32578  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8111 -- Train Loss: 0.32726  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 8112 -- Train Loss: 0.32749  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 8113 -- Train Loss: 0.32684  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 8114 -- Train Loss: 0.32676  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 8115 -- Train Loss: 0.32783  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 8116 -- Train Loss: 0.32718  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8117 -- Train Loss: 0.32732  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 8118 -- Train Loss: 0.32677  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 8119 -- Train Loss: 0.32780  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 8120 -- Train Loss: 0.32737  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8121 -- Train Loss: 0.32733  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 8122 -- Train Loss: 0.32647  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 8123 -- Train Loss: 0.32688  Validation Loss: 0.43146\n",
      "t: 10 EPOCH 8124 -- Train Loss: 0.32790  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8125 -- Train Loss: 0.32718  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 8126 -- Train Loss: 0.32724  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 8127 -- Train Loss: 0.32689  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 8128 -- Train Loss: 0.32721  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 8129 -- Train Loss: 0.32726  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 8130 -- Train Loss: 0.32753  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 8131 -- Train Loss: 0.32761  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 8132 -- Train Loss: 0.32780  Validation Loss: 0.43138\n",
      "t: 10 EPOCH 8133 -- Train Loss: 0.32756  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 8134 -- Train Loss: 0.32732  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 8135 -- Train Loss: 0.32672  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 8136 -- Train Loss: 0.32703  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 8137 -- Train Loss: 0.32698  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 8138 -- Train Loss: 0.32630  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 8139 -- Train Loss: 0.32779  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 8140 -- Train Loss: 0.32703  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 8141 -- Train Loss: 0.32609  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 8142 -- Train Loss: 0.32647  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 8143 -- Train Loss: 0.32761  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 8144 -- Train Loss: 0.32625  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 8145 -- Train Loss: 0.32653  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 8146 -- Train Loss: 0.32692  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8147 -- Train Loss: 0.32707  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 8148 -- Train Loss: 0.32653  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 8149 -- Train Loss: 0.32716  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 8150 -- Train Loss: 0.32668  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 8151 -- Train Loss: 0.32798  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 8152 -- Train Loss: 0.32672  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 8153 -- Train Loss: 0.32773  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 8154 -- Train Loss: 0.32642  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 8155 -- Train Loss: 0.32592  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 8156 -- Train Loss: 0.32722  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 8157 -- Train Loss: 0.32667  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 8158 -- Train Loss: 0.32660  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 8159 -- Train Loss: 0.32671  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 8160 -- Train Loss: 0.32613  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 8161 -- Train Loss: 0.32674  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 8162 -- Train Loss: 0.32716  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8163 -- Train Loss: 0.32707  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 8164 -- Train Loss: 0.32672  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 8165 -- Train Loss: 0.32765  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8166 -- Train Loss: 0.32656  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 8167 -- Train Loss: 0.32752  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 8168 -- Train Loss: 0.32640  Validation Loss: 0.43611\n",
      "t: 10 EPOCH 8169 -- Train Loss: 0.32628  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8170 -- Train Loss: 0.32756  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 8171 -- Train Loss: 0.32706  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 8172 -- Train Loss: 0.32692  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 8173 -- Train Loss: 0.32700  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8174 -- Train Loss: 0.32742  Validation Loss: 0.43291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8175 -- Train Loss: 0.32654  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 8176 -- Train Loss: 0.32571  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 8177 -- Train Loss: 0.32731  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 8178 -- Train Loss: 0.32709  Validation Loss: 0.43140\n",
      "t: 10 EPOCH 8179 -- Train Loss: 0.32629  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 8180 -- Train Loss: 0.32667  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 8181 -- Train Loss: 0.32730  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 8182 -- Train Loss: 0.32743  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 8183 -- Train Loss: 0.32644  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 8184 -- Train Loss: 0.32634  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 8185 -- Train Loss: 0.32738  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8186 -- Train Loss: 0.32595  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 8187 -- Train Loss: 0.32653  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8188 -- Train Loss: 0.32659  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 8189 -- Train Loss: 0.32743  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 8190 -- Train Loss: 0.32684  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 8191 -- Train Loss: 0.32668  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 8192 -- Train Loss: 0.32531  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8193 -- Train Loss: 0.32674  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 8194 -- Train Loss: 0.32745  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 8195 -- Train Loss: 0.32688  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8196 -- Train Loss: 0.32791  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 8197 -- Train Loss: 0.32743  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 8198 -- Train Loss: 0.32741  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8199 -- Train Loss: 0.32726  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 8200 -- Train Loss: 0.32717  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 8201 -- Train Loss: 0.32739  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 8202 -- Train Loss: 0.32720  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 8203 -- Train Loss: 0.32638  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 8204 -- Train Loss: 0.32615  Validation Loss: 0.43114\n",
      "t: 10 EPOCH 8205 -- Train Loss: 0.32694  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 8206 -- Train Loss: 0.32603  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8207 -- Train Loss: 0.32662  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 8208 -- Train Loss: 0.32608  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8209 -- Train Loss: 0.32652  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 8210 -- Train Loss: 0.32623  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 8211 -- Train Loss: 0.32691  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 8212 -- Train Loss: 0.32715  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 8213 -- Train Loss: 0.32655  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 8214 -- Train Loss: 0.32692  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 8215 -- Train Loss: 0.32731  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 8216 -- Train Loss: 0.32672  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 8217 -- Train Loss: 0.32634  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 8218 -- Train Loss: 0.32683  Validation Loss: 0.43117\n",
      "t: 10 EPOCH 8219 -- Train Loss: 0.32700  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 8220 -- Train Loss: 0.32696  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 8221 -- Train Loss: 0.32764  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8222 -- Train Loss: 0.32734  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8223 -- Train Loss: 0.32689  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 8224 -- Train Loss: 0.32677  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8225 -- Train Loss: 0.32644  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 8226 -- Train Loss: 0.32608  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 8227 -- Train Loss: 0.32703  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 8228 -- Train Loss: 0.32758  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 8229 -- Train Loss: 0.32649  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8230 -- Train Loss: 0.32755  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 8231 -- Train Loss: 0.32755  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 8232 -- Train Loss: 0.32775  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 8233 -- Train Loss: 0.32754  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 8234 -- Train Loss: 0.32695  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 8235 -- Train Loss: 0.32712  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 8236 -- Train Loss: 0.32694  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8237 -- Train Loss: 0.32690  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 8238 -- Train Loss: 0.32717  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 8239 -- Train Loss: 0.32743  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8240 -- Train Loss: 0.32684  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 8241 -- Train Loss: 0.32682  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 8242 -- Train Loss: 0.32717  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 8243 -- Train Loss: 0.32642  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 8244 -- Train Loss: 0.32634  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 8245 -- Train Loss: 0.32701  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 8246 -- Train Loss: 0.32661  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 8247 -- Train Loss: 0.32675  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8248 -- Train Loss: 0.32695  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 8249 -- Train Loss: 0.32708  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 8250 -- Train Loss: 0.32813  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 8251 -- Train Loss: 0.32757  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 8252 -- Train Loss: 0.32749  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 8253 -- Train Loss: 0.32734  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 8254 -- Train Loss: 0.32783  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 8255 -- Train Loss: 0.32638  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 8256 -- Train Loss: 0.32803  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 8257 -- Train Loss: 0.32697  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 8258 -- Train Loss: 0.32652  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 8259 -- Train Loss: 0.32758  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8260 -- Train Loss: 0.32772  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 8261 -- Train Loss: 0.32702  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8262 -- Train Loss: 0.32711  Validation Loss: 0.43116\n",
      "t: 10 EPOCH 8263 -- Train Loss: 0.32701  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 8264 -- Train Loss: 0.32744  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 8265 -- Train Loss: 0.32724  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 8266 -- Train Loss: 0.32691  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 8267 -- Train Loss: 0.32734  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 8268 -- Train Loss: 0.32824  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 8269 -- Train Loss: 0.32765  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 8270 -- Train Loss: 0.32810  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 8271 -- Train Loss: 0.32657  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 8272 -- Train Loss: 0.32723  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 8273 -- Train Loss: 0.32700  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 8274 -- Train Loss: 0.32835  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 8275 -- Train Loss: 0.32636  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 8276 -- Train Loss: 0.32768  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 8277 -- Train Loss: 0.32698  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8278 -- Train Loss: 0.32780  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8279 -- Train Loss: 0.32730  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 8280 -- Train Loss: 0.32805  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 8281 -- Train Loss: 0.32692  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 8282 -- Train Loss: 0.32776  Validation Loss: 0.43148\n",
      "t: 10 EPOCH 8283 -- Train Loss: 0.32727  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 8284 -- Train Loss: 0.32800  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 8285 -- Train Loss: 0.32785  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8286 -- Train Loss: 0.32831  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 8287 -- Train Loss: 0.32654  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 8288 -- Train Loss: 0.32889  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8289 -- Train Loss: 0.32671  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8290 -- Train Loss: 0.32779  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 8291 -- Train Loss: 0.32685  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 8292 -- Train Loss: 0.32802  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 8293 -- Train Loss: 0.32703  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 8294 -- Train Loss: 0.32740  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 8295 -- Train Loss: 0.32804  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 8296 -- Train Loss: 0.32863  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 8297 -- Train Loss: 0.32749  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 8298 -- Train Loss: 0.32856  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 8299 -- Train Loss: 0.32803  Validation Loss: 0.43226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8300 -- Train Loss: 0.32711  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8301 -- Train Loss: 0.32795  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 8302 -- Train Loss: 0.32788  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 8303 -- Train Loss: 0.32648  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 8304 -- Train Loss: 0.32837  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 8305 -- Train Loss: 0.32687  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 8306 -- Train Loss: 0.32872  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 8307 -- Train Loss: 0.32763  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 8308 -- Train Loss: 0.32689  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 8309 -- Train Loss: 0.32754  Validation Loss: 0.43143\n",
      "t: 10 EPOCH 8310 -- Train Loss: 0.32771  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 8311 -- Train Loss: 0.32706  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 8312 -- Train Loss: 0.32701  Validation Loss: 0.43107\n",
      "t: 10 EPOCH 8313 -- Train Loss: 0.32845  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8314 -- Train Loss: 0.32726  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8315 -- Train Loss: 0.32780  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 8316 -- Train Loss: 0.32711  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 8317 -- Train Loss: 0.32794  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 8318 -- Train Loss: 0.32746  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 8319 -- Train Loss: 0.32749  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 8320 -- Train Loss: 0.32704  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 8321 -- Train Loss: 0.32845  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 8322 -- Train Loss: 0.32757  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 8323 -- Train Loss: 0.32803  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 8324 -- Train Loss: 0.32717  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 8325 -- Train Loss: 0.32637  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 8326 -- Train Loss: 0.32776  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 8327 -- Train Loss: 0.32685  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 8328 -- Train Loss: 0.32795  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 8329 -- Train Loss: 0.32596  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 8330 -- Train Loss: 0.32746  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 8331 -- Train Loss: 0.32623  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8332 -- Train Loss: 0.32771  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8333 -- Train Loss: 0.32592  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 8334 -- Train Loss: 0.32657  Validation Loss: 0.43199\n",
      "t: 10 EPOCH 8335 -- Train Loss: 0.32640  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 8336 -- Train Loss: 0.32685  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8337 -- Train Loss: 0.32716  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 8338 -- Train Loss: 0.32699  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 8339 -- Train Loss: 0.32643  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 8340 -- Train Loss: 0.32689  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 8341 -- Train Loss: 0.32760  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 8342 -- Train Loss: 0.32638  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 8343 -- Train Loss: 0.32581  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8344 -- Train Loss: 0.32693  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8345 -- Train Loss: 0.32738  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 8346 -- Train Loss: 0.32665  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8347 -- Train Loss: 0.32680  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 8348 -- Train Loss: 0.32726  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 8349 -- Train Loss: 0.32710  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8350 -- Train Loss: 0.32756  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 8351 -- Train Loss: 0.32609  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 8352 -- Train Loss: 0.32661  Validation Loss: 0.43165\n",
      "t: 10 EPOCH 8353 -- Train Loss: 0.32695  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 8354 -- Train Loss: 0.32665  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 8355 -- Train Loss: 0.32704  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 8356 -- Train Loss: 0.32751  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8357 -- Train Loss: 0.32643  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 8358 -- Train Loss: 0.32640  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 8359 -- Train Loss: 0.32719  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 8360 -- Train Loss: 0.32685  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 8361 -- Train Loss: 0.32714  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8362 -- Train Loss: 0.32673  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 8363 -- Train Loss: 0.32642  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8364 -- Train Loss: 0.32689  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 8365 -- Train Loss: 0.32686  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 8366 -- Train Loss: 0.32650  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 8367 -- Train Loss: 0.32677  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 8368 -- Train Loss: 0.32786  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8369 -- Train Loss: 0.32641  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 8370 -- Train Loss: 0.32782  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 8371 -- Train Loss: 0.32728  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 8372 -- Train Loss: 0.32699  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8373 -- Train Loss: 0.32622  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 8374 -- Train Loss: 0.32748  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 8375 -- Train Loss: 0.32549  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 8376 -- Train Loss: 0.32709  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 8377 -- Train Loss: 0.32702  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 8378 -- Train Loss: 0.32607  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 8379 -- Train Loss: 0.32674  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 8380 -- Train Loss: 0.32670  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 8381 -- Train Loss: 0.32720  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 8382 -- Train Loss: 0.32703  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 8383 -- Train Loss: 0.32670  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 8384 -- Train Loss: 0.32677  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8385 -- Train Loss: 0.32712  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 8386 -- Train Loss: 0.32640  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 8387 -- Train Loss: 0.32632  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 8388 -- Train Loss: 0.32636  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 8389 -- Train Loss: 0.32693  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 8390 -- Train Loss: 0.32586  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 8391 -- Train Loss: 0.32700  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 8392 -- Train Loss: 0.32626  Validation Loss: 0.43201\n",
      "t: 10 EPOCH 8393 -- Train Loss: 0.32724  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 8394 -- Train Loss: 0.32719  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8395 -- Train Loss: 0.32677  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 8396 -- Train Loss: 0.32639  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8397 -- Train Loss: 0.32663  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8398 -- Train Loss: 0.32740  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8399 -- Train Loss: 0.32668  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 8400 -- Train Loss: 0.32674  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 8401 -- Train Loss: 0.32688  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 8402 -- Train Loss: 0.32650  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 8403 -- Train Loss: 0.32698  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 8404 -- Train Loss: 0.32640  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 8405 -- Train Loss: 0.32733  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 8406 -- Train Loss: 0.32685  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8407 -- Train Loss: 0.32634  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 8408 -- Train Loss: 0.32793  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 8409 -- Train Loss: 0.32705  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 8410 -- Train Loss: 0.32741  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 8411 -- Train Loss: 0.32633  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 8412 -- Train Loss: 0.32617  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 8413 -- Train Loss: 0.32716  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8414 -- Train Loss: 0.32598  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 8415 -- Train Loss: 0.32675  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 8416 -- Train Loss: 0.32626  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 8417 -- Train Loss: 0.32608  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 8418 -- Train Loss: 0.32680  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 8419 -- Train Loss: 0.32606  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 8420 -- Train Loss: 0.32633  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 8421 -- Train Loss: 0.32638  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 8422 -- Train Loss: 0.32642  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 8423 -- Train Loss: 0.32635  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 8424 -- Train Loss: 0.32652  Validation Loss: 0.43305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8425 -- Train Loss: 0.32692  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 8426 -- Train Loss: 0.32699  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 8427 -- Train Loss: 0.32720  Validation Loss: 0.43168\n",
      "t: 10 EPOCH 8428 -- Train Loss: 0.32683  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 8429 -- Train Loss: 0.32772  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 8430 -- Train Loss: 0.32691  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 8431 -- Train Loss: 0.32737  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 8432 -- Train Loss: 0.32598  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 8433 -- Train Loss: 0.32729  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 8434 -- Train Loss: 0.32672  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 8435 -- Train Loss: 0.32669  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 8436 -- Train Loss: 0.32743  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 8437 -- Train Loss: 0.32606  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 8438 -- Train Loss: 0.32716  Validation Loss: 0.43092\n",
      "t: 10 EPOCH 8439 -- Train Loss: 0.32637  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 8440 -- Train Loss: 0.32784  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 8441 -- Train Loss: 0.32583  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 8442 -- Train Loss: 0.32803  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 8443 -- Train Loss: 0.32609  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8444 -- Train Loss: 0.32769  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 8445 -- Train Loss: 0.32689  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 8446 -- Train Loss: 0.32746  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 8447 -- Train Loss: 0.32566  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 8448 -- Train Loss: 0.32682  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8449 -- Train Loss: 0.32614  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8450 -- Train Loss: 0.32615  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 8451 -- Train Loss: 0.32645  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 8452 -- Train Loss: 0.32669  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 8453 -- Train Loss: 0.32636  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 8454 -- Train Loss: 0.32653  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 8455 -- Train Loss: 0.32702  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 8456 -- Train Loss: 0.32666  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8457 -- Train Loss: 0.32678  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8458 -- Train Loss: 0.32701  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 8459 -- Train Loss: 0.32736  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 8460 -- Train Loss: 0.32611  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 8461 -- Train Loss: 0.32675  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 8462 -- Train Loss: 0.32743  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 8463 -- Train Loss: 0.32692  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8464 -- Train Loss: 0.32653  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 8465 -- Train Loss: 0.32617  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 8466 -- Train Loss: 0.32767  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 8467 -- Train Loss: 0.32633  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 8468 -- Train Loss: 0.32585  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 8469 -- Train Loss: 0.32618  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 8470 -- Train Loss: 0.32674  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 8471 -- Train Loss: 0.32626  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 8472 -- Train Loss: 0.32625  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 8473 -- Train Loss: 0.32671  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 8474 -- Train Loss: 0.32702  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 8475 -- Train Loss: 0.32735  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 8476 -- Train Loss: 0.32650  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8477 -- Train Loss: 0.32697  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 8478 -- Train Loss: 0.32651  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 8479 -- Train Loss: 0.32595  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 8480 -- Train Loss: 0.32690  Validation Loss: 0.43167\n",
      "t: 10 EPOCH 8481 -- Train Loss: 0.32649  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 8482 -- Train Loss: 0.32638  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8483 -- Train Loss: 0.32718  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 8484 -- Train Loss: 0.32666  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 8485 -- Train Loss: 0.32693  Validation Loss: 0.43194\n",
      "t: 10 EPOCH 8486 -- Train Loss: 0.32652  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 8487 -- Train Loss: 0.32695  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 8488 -- Train Loss: 0.32695  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8489 -- Train Loss: 0.32738  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 8490 -- Train Loss: 0.32570  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 8491 -- Train Loss: 0.32709  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 8492 -- Train Loss: 0.32617  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 8493 -- Train Loss: 0.32794  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 8494 -- Train Loss: 0.32688  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 8495 -- Train Loss: 0.32767  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 8496 -- Train Loss: 0.32759  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 8497 -- Train Loss: 0.32818  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 8498 -- Train Loss: 0.32756  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8499 -- Train Loss: 0.32774  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 8500 -- Train Loss: 0.32652  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 8501 -- Train Loss: 0.32769  Validation Loss: 0.43224\n",
      "t: 10 EPOCH 8502 -- Train Loss: 0.32702  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 8503 -- Train Loss: 0.32792  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 8504 -- Train Loss: 0.32717  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8505 -- Train Loss: 0.32694  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 8506 -- Train Loss: 0.32692  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8507 -- Train Loss: 0.32694  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 8508 -- Train Loss: 0.32705  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 8509 -- Train Loss: 0.32741  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 8510 -- Train Loss: 0.32739  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8511 -- Train Loss: 0.32769  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8512 -- Train Loss: 0.32725  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 8513 -- Train Loss: 0.32681  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 8514 -- Train Loss: 0.32768  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 8515 -- Train Loss: 0.32652  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 8516 -- Train Loss: 0.32695  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 8517 -- Train Loss: 0.32751  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 8518 -- Train Loss: 0.32751  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 8519 -- Train Loss: 0.32731  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 8520 -- Train Loss: 0.32639  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 8521 -- Train Loss: 0.32706  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8522 -- Train Loss: 0.32594  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 8523 -- Train Loss: 0.32799  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 8524 -- Train Loss: 0.32681  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8525 -- Train Loss: 0.32671  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 8526 -- Train Loss: 0.32675  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 8527 -- Train Loss: 0.32722  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 8528 -- Train Loss: 0.32661  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 8529 -- Train Loss: 0.32681  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 8530 -- Train Loss: 0.32660  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 8531 -- Train Loss: 0.32649  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 8532 -- Train Loss: 0.32779  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8533 -- Train Loss: 0.32670  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 8534 -- Train Loss: 0.32786  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 8535 -- Train Loss: 0.32717  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 8536 -- Train Loss: 0.32678  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 8537 -- Train Loss: 0.32646  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 8538 -- Train Loss: 0.32681  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 8539 -- Train Loss: 0.32706  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 8540 -- Train Loss: 0.32733  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 8541 -- Train Loss: 0.32688  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 8542 -- Train Loss: 0.32808  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 8543 -- Train Loss: 0.32744  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 8544 -- Train Loss: 0.32683  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 8545 -- Train Loss: 0.32688  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 8546 -- Train Loss: 0.32693  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8547 -- Train Loss: 0.32754  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 8548 -- Train Loss: 0.32601  Validation Loss: 0.43109\n",
      "t: 10 EPOCH 8549 -- Train Loss: 0.32757  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8550 -- Train Loss: 0.32777  Validation Loss: 0.43308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8551 -- Train Loss: 0.32659  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8552 -- Train Loss: 0.32673  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 8553 -- Train Loss: 0.32720  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 8554 -- Train Loss: 0.32748  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 8555 -- Train Loss: 0.32747  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 8556 -- Train Loss: 0.32657  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 8557 -- Train Loss: 0.32676  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 8558 -- Train Loss: 0.32540  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 8559 -- Train Loss: 0.32665  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8560 -- Train Loss: 0.32694  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8561 -- Train Loss: 0.32811  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 8562 -- Train Loss: 0.32683  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 8563 -- Train Loss: 0.32626  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 8564 -- Train Loss: 0.32584  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 8565 -- Train Loss: 0.32650  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 8566 -- Train Loss: 0.32655  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 8567 -- Train Loss: 0.32664  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 8568 -- Train Loss: 0.32659  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 8569 -- Train Loss: 0.32657  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8570 -- Train Loss: 0.32621  Validation Loss: 0.43102\n",
      "t: 10 EPOCH 8571 -- Train Loss: 0.32772  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 8572 -- Train Loss: 0.32621  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 8573 -- Train Loss: 0.32644  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 8574 -- Train Loss: 0.32637  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 8575 -- Train Loss: 0.32702  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 8576 -- Train Loss: 0.32748  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 8577 -- Train Loss: 0.32701  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 8578 -- Train Loss: 0.32670  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 8579 -- Train Loss: 0.32703  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 8580 -- Train Loss: 0.32643  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8581 -- Train Loss: 0.32622  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 8582 -- Train Loss: 0.32621  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8583 -- Train Loss: 0.32620  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 8584 -- Train Loss: 0.32611  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 8585 -- Train Loss: 0.32556  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 8586 -- Train Loss: 0.32671  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 8587 -- Train Loss: 0.32602  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 8588 -- Train Loss: 0.32623  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 8589 -- Train Loss: 0.32624  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 8590 -- Train Loss: 0.32628  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 8591 -- Train Loss: 0.32600  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 8592 -- Train Loss: 0.32711  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8593 -- Train Loss: 0.32649  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 8594 -- Train Loss: 0.32660  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8595 -- Train Loss: 0.32617  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 8596 -- Train Loss: 0.32650  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 8597 -- Train Loss: 0.32632  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8598 -- Train Loss: 0.32683  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 8599 -- Train Loss: 0.32601  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8600 -- Train Loss: 0.32629  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 8601 -- Train Loss: 0.32680  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 8602 -- Train Loss: 0.32613  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 8603 -- Train Loss: 0.32659  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8604 -- Train Loss: 0.32661  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 8605 -- Train Loss: 0.32741  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 8606 -- Train Loss: 0.32704  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 8607 -- Train Loss: 0.32711  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8608 -- Train Loss: 0.32700  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 8609 -- Train Loss: 0.32715  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 8610 -- Train Loss: 0.32657  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 8611 -- Train Loss: 0.32703  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8612 -- Train Loss: 0.32648  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8613 -- Train Loss: 0.32724  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 8614 -- Train Loss: 0.32719  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 8615 -- Train Loss: 0.32718  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8616 -- Train Loss: 0.32688  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 8617 -- Train Loss: 0.32617  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 8618 -- Train Loss: 0.32707  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 8619 -- Train Loss: 0.32701  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 8620 -- Train Loss: 0.32745  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 8621 -- Train Loss: 0.32669  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 8622 -- Train Loss: 0.32730  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8623 -- Train Loss: 0.32611  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 8624 -- Train Loss: 0.32702  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 8625 -- Train Loss: 0.32705  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 8626 -- Train Loss: 0.32669  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 8627 -- Train Loss: 0.32675  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 8628 -- Train Loss: 0.32715  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 8629 -- Train Loss: 0.32691  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8630 -- Train Loss: 0.32721  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 8631 -- Train Loss: 0.32681  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 8632 -- Train Loss: 0.32692  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 8633 -- Train Loss: 0.32616  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 8634 -- Train Loss: 0.32709  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 8635 -- Train Loss: 0.32551  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 8636 -- Train Loss: 0.32780  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 8637 -- Train Loss: 0.32705  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 8638 -- Train Loss: 0.32779  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 8639 -- Train Loss: 0.32656  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 8640 -- Train Loss: 0.32672  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 8641 -- Train Loss: 0.32605  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8642 -- Train Loss: 0.32683  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 8643 -- Train Loss: 0.32724  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 8644 -- Train Loss: 0.32775  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 8645 -- Train Loss: 0.32598  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 8646 -- Train Loss: 0.32741  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8647 -- Train Loss: 0.32629  Validation Loss: 0.43226\n",
      "t: 10 EPOCH 8648 -- Train Loss: 0.32754  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 8649 -- Train Loss: 0.32701  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 8650 -- Train Loss: 0.32762  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 8651 -- Train Loss: 0.32737  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 8652 -- Train Loss: 0.32715  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 8653 -- Train Loss: 0.32738  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8654 -- Train Loss: 0.32696  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 8655 -- Train Loss: 0.32667  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8656 -- Train Loss: 0.32741  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 8657 -- Train Loss: 0.32679  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 8658 -- Train Loss: 0.32689  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 8659 -- Train Loss: 0.32674  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 8660 -- Train Loss: 0.32800  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8661 -- Train Loss: 0.32690  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 8662 -- Train Loss: 0.32689  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8663 -- Train Loss: 0.32756  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 8664 -- Train Loss: 0.32751  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 8665 -- Train Loss: 0.32649  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 8666 -- Train Loss: 0.32735  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8667 -- Train Loss: 0.32756  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8668 -- Train Loss: 0.32736  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 8669 -- Train Loss: 0.32622  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 8670 -- Train Loss: 0.32690  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8671 -- Train Loss: 0.32659  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 8672 -- Train Loss: 0.32665  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8673 -- Train Loss: 0.32630  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 8674 -- Train Loss: 0.32752  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 8675 -- Train Loss: 0.32724  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 8676 -- Train Loss: 0.32708  Validation Loss: 0.43210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8677 -- Train Loss: 0.32711  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 8678 -- Train Loss: 0.32641  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 8679 -- Train Loss: 0.32641  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 8680 -- Train Loss: 0.32686  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 8681 -- Train Loss: 0.32746  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 8682 -- Train Loss: 0.32654  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 8683 -- Train Loss: 0.32695  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 8684 -- Train Loss: 0.32644  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 8685 -- Train Loss: 0.32706  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 8686 -- Train Loss: 0.32664  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 8687 -- Train Loss: 0.32656  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 8688 -- Train Loss: 0.32738  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 8689 -- Train Loss: 0.32622  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 8690 -- Train Loss: 0.32696  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 8691 -- Train Loss: 0.32661  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 8692 -- Train Loss: 0.32648  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 8693 -- Train Loss: 0.32692  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 8694 -- Train Loss: 0.32626  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 8695 -- Train Loss: 0.32814  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 8696 -- Train Loss: 0.32579  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 8697 -- Train Loss: 0.32794  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 8698 -- Train Loss: 0.32706  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 8699 -- Train Loss: 0.32677  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 8700 -- Train Loss: 0.32689  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 8701 -- Train Loss: 0.32713  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 8702 -- Train Loss: 0.32685  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 8703 -- Train Loss: 0.32628  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 8704 -- Train Loss: 0.32541  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 8705 -- Train Loss: 0.32736  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 8706 -- Train Loss: 0.32683  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 8707 -- Train Loss: 0.32685  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8708 -- Train Loss: 0.32681  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 8709 -- Train Loss: 0.32658  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 8710 -- Train Loss: 0.32666  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 8711 -- Train Loss: 0.32707  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 8712 -- Train Loss: 0.32586  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 8713 -- Train Loss: 0.32623  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8714 -- Train Loss: 0.32751  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 8715 -- Train Loss: 0.32635  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8716 -- Train Loss: 0.32680  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 8717 -- Train Loss: 0.32690  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8718 -- Train Loss: 0.32634  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 8719 -- Train Loss: 0.32691  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 8720 -- Train Loss: 0.32684  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 8721 -- Train Loss: 0.32698  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 8722 -- Train Loss: 0.32573  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8723 -- Train Loss: 0.32692  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 8724 -- Train Loss: 0.32645  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 8725 -- Train Loss: 0.32706  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 8726 -- Train Loss: 0.32689  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 8727 -- Train Loss: 0.32681  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 8728 -- Train Loss: 0.32695  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 8729 -- Train Loss: 0.32569  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 8730 -- Train Loss: 0.32683  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 8731 -- Train Loss: 0.32652  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8732 -- Train Loss: 0.32636  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 8733 -- Train Loss: 0.32703  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 8734 -- Train Loss: 0.32677  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 8735 -- Train Loss: 0.32601  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 8736 -- Train Loss: 0.32651  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 8737 -- Train Loss: 0.32632  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8738 -- Train Loss: 0.32614  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8739 -- Train Loss: 0.32731  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 8740 -- Train Loss: 0.32713  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 8741 -- Train Loss: 0.32649  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 8742 -- Train Loss: 0.32761  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 8743 -- Train Loss: 0.32658  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 8744 -- Train Loss: 0.32690  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 8745 -- Train Loss: 0.32628  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 8746 -- Train Loss: 0.32721  Validation Loss: 0.43155\n",
      "t: 10 EPOCH 8747 -- Train Loss: 0.32681  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 8748 -- Train Loss: 0.32615  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 8749 -- Train Loss: 0.32603  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 8750 -- Train Loss: 0.32699  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 8751 -- Train Loss: 0.32593  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 8752 -- Train Loss: 0.32715  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8753 -- Train Loss: 0.32752  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8754 -- Train Loss: 0.32816  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 8755 -- Train Loss: 0.32675  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 8756 -- Train Loss: 0.32706  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 8757 -- Train Loss: 0.32634  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 8758 -- Train Loss: 0.32661  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 8759 -- Train Loss: 0.32613  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 8760 -- Train Loss: 0.32691  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 8761 -- Train Loss: 0.32597  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 8762 -- Train Loss: 0.32797  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8763 -- Train Loss: 0.32608  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 8764 -- Train Loss: 0.32687  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 8765 -- Train Loss: 0.32684  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 8766 -- Train Loss: 0.32679  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8767 -- Train Loss: 0.32693  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 8768 -- Train Loss: 0.32606  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 8769 -- Train Loss: 0.32706  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 8770 -- Train Loss: 0.32682  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8771 -- Train Loss: 0.32727  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 8772 -- Train Loss: 0.32646  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 8773 -- Train Loss: 0.32634  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 8774 -- Train Loss: 0.32681  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8775 -- Train Loss: 0.32696  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 8776 -- Train Loss: 0.32705  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 8777 -- Train Loss: 0.32687  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 8778 -- Train Loss: 0.32656  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8779 -- Train Loss: 0.32654  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 8780 -- Train Loss: 0.32620  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 8781 -- Train Loss: 0.32737  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 8782 -- Train Loss: 0.32709  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 8783 -- Train Loss: 0.32657  Validation Loss: 0.43133\n",
      "t: 10 EPOCH 8784 -- Train Loss: 0.32669  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8785 -- Train Loss: 0.32703  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 8786 -- Train Loss: 0.32629  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 8787 -- Train Loss: 0.32630  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8788 -- Train Loss: 0.32570  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 8789 -- Train Loss: 0.32589  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 8790 -- Train Loss: 0.32664  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 8791 -- Train Loss: 0.32615  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 8792 -- Train Loss: 0.32656  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8793 -- Train Loss: 0.32690  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 8794 -- Train Loss: 0.32554  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 8795 -- Train Loss: 0.32620  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 8796 -- Train Loss: 0.32681  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 8797 -- Train Loss: 0.32699  Validation Loss: 0.43196\n",
      "t: 10 EPOCH 8798 -- Train Loss: 0.32656  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 8799 -- Train Loss: 0.32667  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 8800 -- Train Loss: 0.32637  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 8801 -- Train Loss: 0.32639  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8802 -- Train Loss: 0.32596  Validation Loss: 0.43360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8803 -- Train Loss: 0.32541  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 8804 -- Train Loss: 0.32644  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 8805 -- Train Loss: 0.32630  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8806 -- Train Loss: 0.32664  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 8807 -- Train Loss: 0.32626  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 8808 -- Train Loss: 0.32634  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 8809 -- Train Loss: 0.32575  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 8810 -- Train Loss: 0.32677  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8811 -- Train Loss: 0.32653  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 8812 -- Train Loss: 0.32677  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8813 -- Train Loss: 0.32590  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 8814 -- Train Loss: 0.32687  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 8815 -- Train Loss: 0.32678  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 8816 -- Train Loss: 0.32675  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8817 -- Train Loss: 0.32633  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 8818 -- Train Loss: 0.32672  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 8819 -- Train Loss: 0.32621  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 8820 -- Train Loss: 0.32620  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 8821 -- Train Loss: 0.32680  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 8822 -- Train Loss: 0.32607  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 8823 -- Train Loss: 0.32613  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 8824 -- Train Loss: 0.32521  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 8825 -- Train Loss: 0.32604  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 8826 -- Train Loss: 0.32709  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 8827 -- Train Loss: 0.32707  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8828 -- Train Loss: 0.32492  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 8829 -- Train Loss: 0.32669  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 8830 -- Train Loss: 0.32591  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 8831 -- Train Loss: 0.32596  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 8832 -- Train Loss: 0.32633  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 8833 -- Train Loss: 0.32673  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 8834 -- Train Loss: 0.32663  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 8835 -- Train Loss: 0.32496  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8836 -- Train Loss: 0.32674  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 8837 -- Train Loss: 0.32623  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 8838 -- Train Loss: 0.32688  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 8839 -- Train Loss: 0.32637  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 8840 -- Train Loss: 0.32698  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 8841 -- Train Loss: 0.32648  Validation Loss: 0.43230\n",
      "t: 10 EPOCH 8842 -- Train Loss: 0.32631  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 8843 -- Train Loss: 0.32689  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 8844 -- Train Loss: 0.32733  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 8845 -- Train Loss: 0.32620  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 8846 -- Train Loss: 0.32644  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 8847 -- Train Loss: 0.32673  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 8848 -- Train Loss: 0.32667  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 8849 -- Train Loss: 0.32588  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 8850 -- Train Loss: 0.32635  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 8851 -- Train Loss: 0.32694  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8852 -- Train Loss: 0.32680  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 8853 -- Train Loss: 0.32685  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 8854 -- Train Loss: 0.32643  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 8855 -- Train Loss: 0.32703  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 8856 -- Train Loss: 0.32619  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 8857 -- Train Loss: 0.32658  Validation Loss: 0.43198\n",
      "t: 10 EPOCH 8858 -- Train Loss: 0.32591  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 8859 -- Train Loss: 0.32701  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 8860 -- Train Loss: 0.32616  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 8861 -- Train Loss: 0.32664  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8862 -- Train Loss: 0.32596  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8863 -- Train Loss: 0.32694  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 8864 -- Train Loss: 0.32568  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 8865 -- Train Loss: 0.32726  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 8866 -- Train Loss: 0.32688  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 8867 -- Train Loss: 0.32723  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8868 -- Train Loss: 0.32633  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 8869 -- Train Loss: 0.32679  Validation Loss: 0.43233\n",
      "t: 10 EPOCH 8870 -- Train Loss: 0.32631  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 8871 -- Train Loss: 0.32729  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 8872 -- Train Loss: 0.32709  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 8873 -- Train Loss: 0.32709  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 8874 -- Train Loss: 0.32634  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 8875 -- Train Loss: 0.32803  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 8876 -- Train Loss: 0.32722  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 8877 -- Train Loss: 0.32686  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8878 -- Train Loss: 0.32629  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 8879 -- Train Loss: 0.32804  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 8880 -- Train Loss: 0.32702  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 8881 -- Train Loss: 0.32752  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 8882 -- Train Loss: 0.32734  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 8883 -- Train Loss: 0.32756  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 8884 -- Train Loss: 0.32674  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 8885 -- Train Loss: 0.32658  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 8886 -- Train Loss: 0.32743  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 8887 -- Train Loss: 0.32737  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 8888 -- Train Loss: 0.32659  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 8889 -- Train Loss: 0.32775  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 8890 -- Train Loss: 0.32678  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 8891 -- Train Loss: 0.32683  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 8892 -- Train Loss: 0.32652  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 8893 -- Train Loss: 0.32697  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 8894 -- Train Loss: 0.32738  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 8895 -- Train Loss: 0.32716  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 8896 -- Train Loss: 0.32722  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 8897 -- Train Loss: 0.32705  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 8898 -- Train Loss: 0.32737  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 8899 -- Train Loss: 0.32641  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 8900 -- Train Loss: 0.32651  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 8901 -- Train Loss: 0.32595  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8902 -- Train Loss: 0.32686  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 8903 -- Train Loss: 0.32571  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 8904 -- Train Loss: 0.32758  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8905 -- Train Loss: 0.32700  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8906 -- Train Loss: 0.32633  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 8907 -- Train Loss: 0.32645  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 8908 -- Train Loss: 0.32715  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 8909 -- Train Loss: 0.32599  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 8910 -- Train Loss: 0.32676  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 8911 -- Train Loss: 0.32690  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 8912 -- Train Loss: 0.32659  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 8913 -- Train Loss: 0.32595  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 8914 -- Train Loss: 0.32637  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 8915 -- Train Loss: 0.32703  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 8916 -- Train Loss: 0.32627  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8917 -- Train Loss: 0.32719  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 8918 -- Train Loss: 0.32677  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8919 -- Train Loss: 0.32596  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 8920 -- Train Loss: 0.32637  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 8921 -- Train Loss: 0.32645  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 8922 -- Train Loss: 0.32650  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 8923 -- Train Loss: 0.32702  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 8924 -- Train Loss: 0.32613  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 8925 -- Train Loss: 0.32689  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8926 -- Train Loss: 0.32620  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 8927 -- Train Loss: 0.32677  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 8928 -- Train Loss: 0.32685  Validation Loss: 0.43223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 8929 -- Train Loss: 0.32573  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 8930 -- Train Loss: 0.32693  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 8931 -- Train Loss: 0.32644  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 8932 -- Train Loss: 0.32671  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 8933 -- Train Loss: 0.32624  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8934 -- Train Loss: 0.32708  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 8935 -- Train Loss: 0.32617  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 8936 -- Train Loss: 0.32651  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 8937 -- Train Loss: 0.32573  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 8938 -- Train Loss: 0.32628  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8939 -- Train Loss: 0.32618  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 8940 -- Train Loss: 0.32691  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 8941 -- Train Loss: 0.32609  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 8942 -- Train Loss: 0.32716  Validation Loss: 0.43179\n",
      "t: 10 EPOCH 8943 -- Train Loss: 0.32554  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 8944 -- Train Loss: 0.32711  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8945 -- Train Loss: 0.32630  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 8946 -- Train Loss: 0.32675  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 8947 -- Train Loss: 0.32672  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 8948 -- Train Loss: 0.32651  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 8949 -- Train Loss: 0.32630  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 8950 -- Train Loss: 0.32560  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 8951 -- Train Loss: 0.32670  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 8952 -- Train Loss: 0.32670  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 8953 -- Train Loss: 0.32680  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 8954 -- Train Loss: 0.32621  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 8955 -- Train Loss: 0.32683  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 8956 -- Train Loss: 0.32656  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 8957 -- Train Loss: 0.32537  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 8958 -- Train Loss: 0.32669  Validation Loss: 0.43094\n",
      "t: 10 EPOCH 8959 -- Train Loss: 0.32624  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 8960 -- Train Loss: 0.32628  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 8961 -- Train Loss: 0.32524  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 8962 -- Train Loss: 0.32724  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 8963 -- Train Loss: 0.32536  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 8964 -- Train Loss: 0.32653  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 8965 -- Train Loss: 0.32657  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8966 -- Train Loss: 0.32733  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 8967 -- Train Loss: 0.32599  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 8968 -- Train Loss: 0.32687  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 8969 -- Train Loss: 0.32645  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 8970 -- Train Loss: 0.32648  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 8971 -- Train Loss: 0.32604  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8972 -- Train Loss: 0.32545  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 8973 -- Train Loss: 0.32553  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 8974 -- Train Loss: 0.32623  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 8975 -- Train Loss: 0.32496  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 8976 -- Train Loss: 0.32641  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 8977 -- Train Loss: 0.32687  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 8978 -- Train Loss: 0.32600  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 8979 -- Train Loss: 0.32568  Validation Loss: 0.43186\n",
      "t: 10 EPOCH 8980 -- Train Loss: 0.32633  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 8981 -- Train Loss: 0.32682  Validation Loss: 0.43162\n",
      "t: 10 EPOCH 8982 -- Train Loss: 0.32624  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 8983 -- Train Loss: 0.32700  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 8984 -- Train Loss: 0.32636  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 8985 -- Train Loss: 0.32617  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 8986 -- Train Loss: 0.32610  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 8987 -- Train Loss: 0.32667  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 8988 -- Train Loss: 0.32704  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 8989 -- Train Loss: 0.32661  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 8990 -- Train Loss: 0.32659  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 8991 -- Train Loss: 0.32538  Validation Loss: 0.43157\n",
      "t: 10 EPOCH 8992 -- Train Loss: 0.32591  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 8993 -- Train Loss: 0.32601  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 8994 -- Train Loss: 0.32542  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 8995 -- Train Loss: 0.32662  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 8996 -- Train Loss: 0.32592  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 8997 -- Train Loss: 0.32651  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 8998 -- Train Loss: 0.32730  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 8999 -- Train Loss: 0.32715  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 9000 -- Train Loss: 0.32661  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 9001 -- Train Loss: 0.32601  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9002 -- Train Loss: 0.32599  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 9003 -- Train Loss: 0.32758  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 9004 -- Train Loss: 0.32692  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 9005 -- Train Loss: 0.32666  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 9006 -- Train Loss: 0.32638  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9007 -- Train Loss: 0.32647  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 9008 -- Train Loss: 0.32650  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 9009 -- Train Loss: 0.32620  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9010 -- Train Loss: 0.32712  Validation Loss: 0.43166\n",
      "t: 10 EPOCH 9011 -- Train Loss: 0.32661  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 9012 -- Train Loss: 0.32651  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 9013 -- Train Loss: 0.32613  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 9014 -- Train Loss: 0.32679  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 9015 -- Train Loss: 0.32608  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 9016 -- Train Loss: 0.32731  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 9017 -- Train Loss: 0.32523  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 9018 -- Train Loss: 0.32705  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 9019 -- Train Loss: 0.32565  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 9020 -- Train Loss: 0.32713  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 9021 -- Train Loss: 0.32642  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9022 -- Train Loss: 0.32639  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 9023 -- Train Loss: 0.32655  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 9024 -- Train Loss: 0.32745  Validation Loss: 0.43169\n",
      "t: 10 EPOCH 9025 -- Train Loss: 0.32699  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 9026 -- Train Loss: 0.32518  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 9027 -- Train Loss: 0.32735  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 9028 -- Train Loss: 0.32721  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 9029 -- Train Loss: 0.32646  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9030 -- Train Loss: 0.32689  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9031 -- Train Loss: 0.32560  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 9032 -- Train Loss: 0.32647  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 9033 -- Train Loss: 0.32601  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 9034 -- Train Loss: 0.32642  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9035 -- Train Loss: 0.32732  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 9036 -- Train Loss: 0.32690  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9037 -- Train Loss: 0.32675  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 9038 -- Train Loss: 0.32624  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 9039 -- Train Loss: 0.32577  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 9040 -- Train Loss: 0.32625  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 9041 -- Train Loss: 0.32668  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 9042 -- Train Loss: 0.32680  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 9043 -- Train Loss: 0.32583  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 9044 -- Train Loss: 0.32649  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 9045 -- Train Loss: 0.32666  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 9046 -- Train Loss: 0.32532  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 9047 -- Train Loss: 0.32629  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 9048 -- Train Loss: 0.32631  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 9049 -- Train Loss: 0.32606  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 9050 -- Train Loss: 0.32678  Validation Loss: 0.43160\n",
      "t: 10 EPOCH 9051 -- Train Loss: 0.32581  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 9052 -- Train Loss: 0.32686  Validation Loss: 0.43177\n",
      "t: 10 EPOCH 9053 -- Train Loss: 0.32585  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9054 -- Train Loss: 0.32655  Validation Loss: 0.43299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9055 -- Train Loss: 0.32637  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 9056 -- Train Loss: 0.32664  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 9057 -- Train Loss: 0.32601  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 9058 -- Train Loss: 0.32687  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 9059 -- Train Loss: 0.32630  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 9060 -- Train Loss: 0.32604  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 9061 -- Train Loss: 0.32541  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 9062 -- Train Loss: 0.32632  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 9063 -- Train Loss: 0.32584  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 9064 -- Train Loss: 0.32625  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 9065 -- Train Loss: 0.32571  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 9066 -- Train Loss: 0.32668  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 9067 -- Train Loss: 0.32636  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 9068 -- Train Loss: 0.32729  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 9069 -- Train Loss: 0.32609  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 9070 -- Train Loss: 0.32624  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 9071 -- Train Loss: 0.32567  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 9072 -- Train Loss: 0.32706  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 9073 -- Train Loss: 0.32545  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9074 -- Train Loss: 0.32670  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 9075 -- Train Loss: 0.32567  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 9076 -- Train Loss: 0.32666  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 9077 -- Train Loss: 0.32621  Validation Loss: 0.43206\n",
      "t: 10 EPOCH 9078 -- Train Loss: 0.32608  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 9079 -- Train Loss: 0.32685  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 9080 -- Train Loss: 0.32635  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 9081 -- Train Loss: 0.32649  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 9082 -- Train Loss: 0.32608  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 9083 -- Train Loss: 0.32639  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 9084 -- Train Loss: 0.32695  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 9085 -- Train Loss: 0.32556  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 9086 -- Train Loss: 0.32586  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9087 -- Train Loss: 0.32608  Validation Loss: 0.43180\n",
      "t: 10 EPOCH 9088 -- Train Loss: 0.32625  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9089 -- Train Loss: 0.32639  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 9090 -- Train Loss: 0.32620  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 9091 -- Train Loss: 0.32668  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 9092 -- Train Loss: 0.32639  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 9093 -- Train Loss: 0.32614  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 9094 -- Train Loss: 0.32595  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 9095 -- Train Loss: 0.32710  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 9096 -- Train Loss: 0.32679  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 9097 -- Train Loss: 0.32642  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 9098 -- Train Loss: 0.32650  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 9099 -- Train Loss: 0.32697  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 9100 -- Train Loss: 0.32635  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9101 -- Train Loss: 0.32676  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 9102 -- Train Loss: 0.32681  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9103 -- Train Loss: 0.32687  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 9104 -- Train Loss: 0.32697  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 9105 -- Train Loss: 0.32705  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 9106 -- Train Loss: 0.32726  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 9107 -- Train Loss: 0.32651  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 9108 -- Train Loss: 0.32709  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 9109 -- Train Loss: 0.32678  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 9110 -- Train Loss: 0.32737  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 9111 -- Train Loss: 0.32734  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9112 -- Train Loss: 0.32725  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 9113 -- Train Loss: 0.32660  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 9114 -- Train Loss: 0.32719  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 9115 -- Train Loss: 0.32694  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 9116 -- Train Loss: 0.32666  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 9117 -- Train Loss: 0.32706  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 9118 -- Train Loss: 0.32746  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9119 -- Train Loss: 0.32646  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 9120 -- Train Loss: 0.32764  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 9121 -- Train Loss: 0.32736  Validation Loss: 0.43164\n",
      "t: 10 EPOCH 9122 -- Train Loss: 0.32661  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 9123 -- Train Loss: 0.32727  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 9124 -- Train Loss: 0.32703  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9125 -- Train Loss: 0.32767  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 9126 -- Train Loss: 0.32580  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 9127 -- Train Loss: 0.32720  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 9128 -- Train Loss: 0.32690  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 9129 -- Train Loss: 0.32747  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9130 -- Train Loss: 0.32642  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 9131 -- Train Loss: 0.32718  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 9132 -- Train Loss: 0.32513  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 9133 -- Train Loss: 0.32718  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 9134 -- Train Loss: 0.32636  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 9135 -- Train Loss: 0.32812  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 9136 -- Train Loss: 0.32602  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 9137 -- Train Loss: 0.32680  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 9138 -- Train Loss: 0.32711  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 9139 -- Train Loss: 0.32695  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 9140 -- Train Loss: 0.32685  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 9141 -- Train Loss: 0.32612  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 9142 -- Train Loss: 0.32790  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 9143 -- Train Loss: 0.32586  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 9144 -- Train Loss: 0.32718  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 9145 -- Train Loss: 0.32563  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9146 -- Train Loss: 0.32651  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 9147 -- Train Loss: 0.32670  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 9148 -- Train Loss: 0.32662  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9149 -- Train Loss: 0.32566  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9150 -- Train Loss: 0.32681  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 9151 -- Train Loss: 0.32635  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9152 -- Train Loss: 0.32678  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 9153 -- Train Loss: 0.32660  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 9154 -- Train Loss: 0.32726  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 9155 -- Train Loss: 0.32593  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 9156 -- Train Loss: 0.32619  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 9157 -- Train Loss: 0.32666  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 9158 -- Train Loss: 0.32607  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 9159 -- Train Loss: 0.32675  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 9160 -- Train Loss: 0.32731  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 9161 -- Train Loss: 0.32615  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 9162 -- Train Loss: 0.32709  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 9163 -- Train Loss: 0.32594  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 9164 -- Train Loss: 0.32691  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 9165 -- Train Loss: 0.32593  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 9166 -- Train Loss: 0.32665  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 9167 -- Train Loss: 0.32643  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 9168 -- Train Loss: 0.32614  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9169 -- Train Loss: 0.32657  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 9170 -- Train Loss: 0.32545  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 9171 -- Train Loss: 0.32513  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 9172 -- Train Loss: 0.32633  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 9173 -- Train Loss: 0.32599  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9174 -- Train Loss: 0.32608  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 9175 -- Train Loss: 0.32675  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 9176 -- Train Loss: 0.32656  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 9177 -- Train Loss: 0.32572  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 9178 -- Train Loss: 0.32519  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 9179 -- Train Loss: 0.32576  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 9180 -- Train Loss: 0.32543  Validation Loss: 0.43399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9181 -- Train Loss: 0.32645  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 9182 -- Train Loss: 0.32667  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 9183 -- Train Loss: 0.32546  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 9184 -- Train Loss: 0.32631  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 9185 -- Train Loss: 0.32557  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 9186 -- Train Loss: 0.32680  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9187 -- Train Loss: 0.32500  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 9188 -- Train Loss: 0.32664  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 9189 -- Train Loss: 0.32602  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 9190 -- Train Loss: 0.32585  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9191 -- Train Loss: 0.32628  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 9192 -- Train Loss: 0.32636  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 9193 -- Train Loss: 0.32715  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 9194 -- Train Loss: 0.32654  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 9195 -- Train Loss: 0.32582  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9196 -- Train Loss: 0.32583  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 9197 -- Train Loss: 0.32660  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 9198 -- Train Loss: 0.32607  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9199 -- Train Loss: 0.32661  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 9200 -- Train Loss: 0.32554  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 9201 -- Train Loss: 0.32563  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 9202 -- Train Loss: 0.32651  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 9203 -- Train Loss: 0.32572  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 9204 -- Train Loss: 0.32629  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 9205 -- Train Loss: 0.32588  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 9206 -- Train Loss: 0.32711  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 9207 -- Train Loss: 0.32597  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9208 -- Train Loss: 0.32604  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 9209 -- Train Loss: 0.32563  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 9210 -- Train Loss: 0.32697  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9211 -- Train Loss: 0.32564  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 9212 -- Train Loss: 0.32664  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 9213 -- Train Loss: 0.32651  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 9214 -- Train Loss: 0.32543  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9215 -- Train Loss: 0.32632  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 9216 -- Train Loss: 0.32645  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 9217 -- Train Loss: 0.32673  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 9218 -- Train Loss: 0.32651  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 9219 -- Train Loss: 0.32553  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 9220 -- Train Loss: 0.32490  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 9221 -- Train Loss: 0.32576  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 9222 -- Train Loss: 0.32613  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 9223 -- Train Loss: 0.32639  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9224 -- Train Loss: 0.32650  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9225 -- Train Loss: 0.32599  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 9226 -- Train Loss: 0.32673  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 9227 -- Train Loss: 0.32622  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 9228 -- Train Loss: 0.32513  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 9229 -- Train Loss: 0.32590  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 9230 -- Train Loss: 0.32637  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 9231 -- Train Loss: 0.32570  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 9232 -- Train Loss: 0.32568  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 9233 -- Train Loss: 0.32608  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9234 -- Train Loss: 0.32667  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9235 -- Train Loss: 0.32630  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9236 -- Train Loss: 0.32646  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 9237 -- Train Loss: 0.32581  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 9238 -- Train Loss: 0.32651  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 9239 -- Train Loss: 0.32560  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 9240 -- Train Loss: 0.32601  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 9241 -- Train Loss: 0.32600  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 9242 -- Train Loss: 0.32607  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 9243 -- Train Loss: 0.32640  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 9244 -- Train Loss: 0.32578  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 9245 -- Train Loss: 0.32607  Validation Loss: 0.43215\n",
      "t: 10 EPOCH 9246 -- Train Loss: 0.32682  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 9247 -- Train Loss: 0.32580  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 9248 -- Train Loss: 0.32667  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 9249 -- Train Loss: 0.32630  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 9250 -- Train Loss: 0.32668  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9251 -- Train Loss: 0.32648  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 9252 -- Train Loss: 0.32553  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 9253 -- Train Loss: 0.32574  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 9254 -- Train Loss: 0.32604  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 9255 -- Train Loss: 0.32605  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 9256 -- Train Loss: 0.32615  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 9257 -- Train Loss: 0.32616  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 9258 -- Train Loss: 0.32694  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 9259 -- Train Loss: 0.32583  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 9260 -- Train Loss: 0.32628  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 9261 -- Train Loss: 0.32568  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 9262 -- Train Loss: 0.32610  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9263 -- Train Loss: 0.32673  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 9264 -- Train Loss: 0.32600  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 9265 -- Train Loss: 0.32632  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 9266 -- Train Loss: 0.32632  Validation Loss: 0.43243\n",
      "t: 10 EPOCH 9267 -- Train Loss: 0.32687  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 9268 -- Train Loss: 0.32661  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 9269 -- Train Loss: 0.32665  Validation Loss: 0.43203\n",
      "t: 10 EPOCH 9270 -- Train Loss: 0.32635  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 9271 -- Train Loss: 0.32669  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 9272 -- Train Loss: 0.32603  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 9273 -- Train Loss: 0.32615  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 9274 -- Train Loss: 0.32643  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9275 -- Train Loss: 0.32613  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 9276 -- Train Loss: 0.32592  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 9277 -- Train Loss: 0.32615  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 9278 -- Train Loss: 0.32626  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 9279 -- Train Loss: 0.32636  Validation Loss: 0.43195\n",
      "t: 10 EPOCH 9280 -- Train Loss: 0.32670  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 9281 -- Train Loss: 0.32645  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 9282 -- Train Loss: 0.32638  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9283 -- Train Loss: 0.32690  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 9284 -- Train Loss: 0.32620  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9285 -- Train Loss: 0.32635  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9286 -- Train Loss: 0.32716  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9287 -- Train Loss: 0.32625  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 9288 -- Train Loss: 0.32555  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 9289 -- Train Loss: 0.32596  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 9290 -- Train Loss: 0.32602  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 9291 -- Train Loss: 0.32680  Validation Loss: 0.43214\n",
      "t: 10 EPOCH 9292 -- Train Loss: 0.32706  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 9293 -- Train Loss: 0.32647  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9294 -- Train Loss: 0.32614  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 9295 -- Train Loss: 0.32632  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 9296 -- Train Loss: 0.32637  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 9297 -- Train Loss: 0.32730  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 9298 -- Train Loss: 0.32548  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 9299 -- Train Loss: 0.32616  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 9300 -- Train Loss: 0.32527  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 9301 -- Train Loss: 0.32631  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 9302 -- Train Loss: 0.32621  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 9303 -- Train Loss: 0.32705  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 9304 -- Train Loss: 0.32666  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 9305 -- Train Loss: 0.32721  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 9306 -- Train Loss: 0.32609  Validation Loss: 0.43427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9307 -- Train Loss: 0.32650  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 9308 -- Train Loss: 0.32649  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 9309 -- Train Loss: 0.32613  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9310 -- Train Loss: 0.32660  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 9311 -- Train Loss: 0.32592  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 9312 -- Train Loss: 0.32674  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 9313 -- Train Loss: 0.32587  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 9314 -- Train Loss: 0.32659  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 9315 -- Train Loss: 0.32596  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 9316 -- Train Loss: 0.32657  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 9317 -- Train Loss: 0.32612  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 9318 -- Train Loss: 0.32778  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 9319 -- Train Loss: 0.32523  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 9320 -- Train Loss: 0.32673  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 9321 -- Train Loss: 0.32653  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 9322 -- Train Loss: 0.32650  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 9323 -- Train Loss: 0.32655  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 9324 -- Train Loss: 0.32576  Validation Loss: 0.43193\n",
      "t: 10 EPOCH 9325 -- Train Loss: 0.32636  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 9326 -- Train Loss: 0.32680  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 9327 -- Train Loss: 0.32675  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 9328 -- Train Loss: 0.32591  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 9329 -- Train Loss: 0.32584  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 9330 -- Train Loss: 0.32694  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 9331 -- Train Loss: 0.32723  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 9332 -- Train Loss: 0.32669  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 9333 -- Train Loss: 0.32677  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 9334 -- Train Loss: 0.32748  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 9335 -- Train Loss: 0.32622  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 9336 -- Train Loss: 0.32589  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 9337 -- Train Loss: 0.32654  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 9338 -- Train Loss: 0.32609  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9339 -- Train Loss: 0.32668  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 9340 -- Train Loss: 0.32603  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 9341 -- Train Loss: 0.32618  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 9342 -- Train Loss: 0.32638  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 9343 -- Train Loss: 0.32675  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9344 -- Train Loss: 0.32684  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 9345 -- Train Loss: 0.32697  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 9346 -- Train Loss: 0.32624  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 9347 -- Train Loss: 0.32719  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 9348 -- Train Loss: 0.32603  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 9349 -- Train Loss: 0.32661  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 9350 -- Train Loss: 0.32566  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 9351 -- Train Loss: 0.32729  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 9352 -- Train Loss: 0.32588  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 9353 -- Train Loss: 0.32647  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 9354 -- Train Loss: 0.32618  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 9355 -- Train Loss: 0.32641  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 9356 -- Train Loss: 0.32628  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 9357 -- Train Loss: 0.32705  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9358 -- Train Loss: 0.32679  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 9359 -- Train Loss: 0.32684  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 9360 -- Train Loss: 0.32665  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 9361 -- Train Loss: 0.32652  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 9362 -- Train Loss: 0.32656  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 9363 -- Train Loss: 0.32642  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 9364 -- Train Loss: 0.32693  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 9365 -- Train Loss: 0.32639  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 9366 -- Train Loss: 0.32674  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9367 -- Train Loss: 0.32622  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 9368 -- Train Loss: 0.32700  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9369 -- Train Loss: 0.32610  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 9370 -- Train Loss: 0.32676  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 9371 -- Train Loss: 0.32528  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 9372 -- Train Loss: 0.32712  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 9373 -- Train Loss: 0.32542  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 9374 -- Train Loss: 0.32695  Validation Loss: 0.43188\n",
      "t: 10 EPOCH 9375 -- Train Loss: 0.32584  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 9376 -- Train Loss: 0.32618  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 9377 -- Train Loss: 0.32730  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9378 -- Train Loss: 0.32587  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 9379 -- Train Loss: 0.32696  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 9380 -- Train Loss: 0.32537  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 9381 -- Train Loss: 0.32622  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 9382 -- Train Loss: 0.32643  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 9383 -- Train Loss: 0.32648  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 9384 -- Train Loss: 0.32558  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 9385 -- Train Loss: 0.32624  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 9386 -- Train Loss: 0.32569  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 9387 -- Train Loss: 0.32688  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 9388 -- Train Loss: 0.32600  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 9389 -- Train Loss: 0.32558  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 9390 -- Train Loss: 0.32554  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 9391 -- Train Loss: 0.32687  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9392 -- Train Loss: 0.32567  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 9393 -- Train Loss: 0.32646  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 9394 -- Train Loss: 0.32545  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 9395 -- Train Loss: 0.32620  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 9396 -- Train Loss: 0.32712  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 9397 -- Train Loss: 0.32671  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 9398 -- Train Loss: 0.32691  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 9399 -- Train Loss: 0.32571  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 9400 -- Train Loss: 0.32564  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 9401 -- Train Loss: 0.32489  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 9402 -- Train Loss: 0.32678  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 9403 -- Train Loss: 0.32614  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9404 -- Train Loss: 0.32673  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 9405 -- Train Loss: 0.32550  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 9406 -- Train Loss: 0.32733  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 9407 -- Train Loss: 0.32539  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 9408 -- Train Loss: 0.32739  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 9409 -- Train Loss: 0.32610  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 9410 -- Train Loss: 0.32700  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 9411 -- Train Loss: 0.32605  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 9412 -- Train Loss: 0.32574  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 9413 -- Train Loss: 0.32722  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 9414 -- Train Loss: 0.32601  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 9415 -- Train Loss: 0.32623  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 9416 -- Train Loss: 0.32587  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 9417 -- Train Loss: 0.32612  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 9418 -- Train Loss: 0.32575  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 9419 -- Train Loss: 0.32679  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 9420 -- Train Loss: 0.32576  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9421 -- Train Loss: 0.32599  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 9422 -- Train Loss: 0.32615  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 9423 -- Train Loss: 0.32667  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 9424 -- Train Loss: 0.32634  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 9425 -- Train Loss: 0.32602  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9426 -- Train Loss: 0.32609  Validation Loss: 0.43113\n",
      "t: 10 EPOCH 9427 -- Train Loss: 0.32527  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9428 -- Train Loss: 0.32628  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9429 -- Train Loss: 0.32543  Validation Loss: 0.43181\n",
      "t: 10 EPOCH 9430 -- Train Loss: 0.32651  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9431 -- Train Loss: 0.32555  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9432 -- Train Loss: 0.32645  Validation Loss: 0.43303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9433 -- Train Loss: 0.32575  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 9434 -- Train Loss: 0.32613  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9435 -- Train Loss: 0.32556  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 9436 -- Train Loss: 0.32472  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9437 -- Train Loss: 0.32550  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 9438 -- Train Loss: 0.32524  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 9439 -- Train Loss: 0.32619  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 9440 -- Train Loss: 0.32624  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 9441 -- Train Loss: 0.32543  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9442 -- Train Loss: 0.32573  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 9443 -- Train Loss: 0.32595  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 9444 -- Train Loss: 0.32626  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 9445 -- Train Loss: 0.32630  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 9446 -- Train Loss: 0.32552  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 9447 -- Train Loss: 0.32690  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 9448 -- Train Loss: 0.32578  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 9449 -- Train Loss: 0.32605  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 9450 -- Train Loss: 0.32540  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 9451 -- Train Loss: 0.32614  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 9452 -- Train Loss: 0.32529  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 9453 -- Train Loss: 0.32643  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 9454 -- Train Loss: 0.32665  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 9455 -- Train Loss: 0.32528  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9456 -- Train Loss: 0.32609  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 9457 -- Train Loss: 0.32582  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 9458 -- Train Loss: 0.32556  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 9459 -- Train Loss: 0.32578  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9460 -- Train Loss: 0.32582  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 9461 -- Train Loss: 0.32545  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 9462 -- Train Loss: 0.32694  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 9463 -- Train Loss: 0.32541  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 9464 -- Train Loss: 0.32670  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 9465 -- Train Loss: 0.32510  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 9466 -- Train Loss: 0.32584  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 9467 -- Train Loss: 0.32610  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 9468 -- Train Loss: 0.32563  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 9469 -- Train Loss: 0.32594  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 9470 -- Train Loss: 0.32603  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 9471 -- Train Loss: 0.32660  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 9472 -- Train Loss: 0.32659  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 9473 -- Train Loss: 0.32621  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 9474 -- Train Loss: 0.32623  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 9475 -- Train Loss: 0.32686  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 9476 -- Train Loss: 0.32676  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 9477 -- Train Loss: 0.32658  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 9478 -- Train Loss: 0.32508  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 9479 -- Train Loss: 0.32597  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9480 -- Train Loss: 0.32623  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 9481 -- Train Loss: 0.32678  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 9482 -- Train Loss: 0.32572  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 9483 -- Train Loss: 0.32618  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 9484 -- Train Loss: 0.32633  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 9485 -- Train Loss: 0.32542  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 9486 -- Train Loss: 0.32639  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 9487 -- Train Loss: 0.32610  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 9488 -- Train Loss: 0.32542  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 9489 -- Train Loss: 0.32679  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9490 -- Train Loss: 0.32611  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9491 -- Train Loss: 0.32658  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9492 -- Train Loss: 0.32539  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 9493 -- Train Loss: 0.32550  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 9494 -- Train Loss: 0.32598  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 9495 -- Train Loss: 0.32677  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 9496 -- Train Loss: 0.32562  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 9497 -- Train Loss: 0.32639  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 9498 -- Train Loss: 0.32605  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 9499 -- Train Loss: 0.32604  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 9500 -- Train Loss: 0.32704  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 9501 -- Train Loss: 0.32670  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 9502 -- Train Loss: 0.32619  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 9503 -- Train Loss: 0.32662  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 9504 -- Train Loss: 0.32630  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 9505 -- Train Loss: 0.32640  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 9506 -- Train Loss: 0.32743  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9507 -- Train Loss: 0.32568  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 9508 -- Train Loss: 0.32538  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 9509 -- Train Loss: 0.32679  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 9510 -- Train Loss: 0.32593  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 9511 -- Train Loss: 0.32647  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 9512 -- Train Loss: 0.32531  Validation Loss: 0.43189\n",
      "t: 10 EPOCH 9513 -- Train Loss: 0.32598  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9514 -- Train Loss: 0.32634  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 9515 -- Train Loss: 0.32459  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 9516 -- Train Loss: 0.32613  Validation Loss: 0.43175\n",
      "t: 10 EPOCH 9517 -- Train Loss: 0.32663  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 9518 -- Train Loss: 0.32709  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 9519 -- Train Loss: 0.32598  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 9520 -- Train Loss: 0.32691  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9521 -- Train Loss: 0.32674  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 9522 -- Train Loss: 0.32656  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 9523 -- Train Loss: 0.32597  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 9524 -- Train Loss: 0.32660  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 9525 -- Train Loss: 0.32682  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 9526 -- Train Loss: 0.32646  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 9527 -- Train Loss: 0.32623  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 9528 -- Train Loss: 0.32642  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 9529 -- Train Loss: 0.32635  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9530 -- Train Loss: 0.32634  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 9531 -- Train Loss: 0.32599  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 9532 -- Train Loss: 0.32655  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 9533 -- Train Loss: 0.32573  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 9534 -- Train Loss: 0.32704  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 9535 -- Train Loss: 0.32678  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 9536 -- Train Loss: 0.32657  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9537 -- Train Loss: 0.32520  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 9538 -- Train Loss: 0.32613  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 9539 -- Train Loss: 0.32652  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9540 -- Train Loss: 0.32664  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 9541 -- Train Loss: 0.32555  Validation Loss: 0.43187\n",
      "t: 10 EPOCH 9542 -- Train Loss: 0.32718  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 9543 -- Train Loss: 0.32555  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 9544 -- Train Loss: 0.32657  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 9545 -- Train Loss: 0.32605  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 9546 -- Train Loss: 0.32669  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 9547 -- Train Loss: 0.32527  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9548 -- Train Loss: 0.32579  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 9549 -- Train Loss: 0.32569  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 9550 -- Train Loss: 0.32585  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 9551 -- Train Loss: 0.32674  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 9552 -- Train Loss: 0.32552  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 9553 -- Train Loss: 0.32590  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 9554 -- Train Loss: 0.32581  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 9555 -- Train Loss: 0.32545  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 9556 -- Train Loss: 0.32631  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 9557 -- Train Loss: 0.32730  Validation Loss: 0.43326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9558 -- Train Loss: 0.32616  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 9559 -- Train Loss: 0.32633  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 9560 -- Train Loss: 0.32539  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 9561 -- Train Loss: 0.32588  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 9562 -- Train Loss: 0.32579  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 9563 -- Train Loss: 0.32520  Validation Loss: 0.43171\n",
      "t: 10 EPOCH 9564 -- Train Loss: 0.32562  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 9565 -- Train Loss: 0.32646  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 9566 -- Train Loss: 0.32598  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 9567 -- Train Loss: 0.32550  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 9568 -- Train Loss: 0.32637  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 9569 -- Train Loss: 0.32600  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 9570 -- Train Loss: 0.32651  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 9571 -- Train Loss: 0.32562  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 9572 -- Train Loss: 0.32577  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9573 -- Train Loss: 0.32548  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 9574 -- Train Loss: 0.32688  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 9575 -- Train Loss: 0.32543  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 9576 -- Train Loss: 0.32651  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 9577 -- Train Loss: 0.32585  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 9578 -- Train Loss: 0.32703  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 9579 -- Train Loss: 0.32551  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 9580 -- Train Loss: 0.32516  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 9581 -- Train Loss: 0.32537  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 9582 -- Train Loss: 0.32592  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 9583 -- Train Loss: 0.32587  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9584 -- Train Loss: 0.32641  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 9585 -- Train Loss: 0.32699  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 9586 -- Train Loss: 0.32680  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 9587 -- Train Loss: 0.32635  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 9588 -- Train Loss: 0.32687  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 9589 -- Train Loss: 0.32597  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 9590 -- Train Loss: 0.32670  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 9591 -- Train Loss: 0.32576  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 9592 -- Train Loss: 0.32691  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9593 -- Train Loss: 0.32585  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 9594 -- Train Loss: 0.32692  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 9595 -- Train Loss: 0.32618  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 9596 -- Train Loss: 0.32709  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 9597 -- Train Loss: 0.32641  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9598 -- Train Loss: 0.32680  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 9599 -- Train Loss: 0.32581  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 9600 -- Train Loss: 0.32782  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 9601 -- Train Loss: 0.32702  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9602 -- Train Loss: 0.32632  Validation Loss: 0.43161\n",
      "t: 10 EPOCH 9603 -- Train Loss: 0.32657  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 9604 -- Train Loss: 0.32685  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 9605 -- Train Loss: 0.32702  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 9606 -- Train Loss: 0.32603  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9607 -- Train Loss: 0.32649  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 9608 -- Train Loss: 0.32607  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 9609 -- Train Loss: 0.32664  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 9610 -- Train Loss: 0.32528  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 9611 -- Train Loss: 0.32703  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9612 -- Train Loss: 0.32629  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9613 -- Train Loss: 0.32608  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9614 -- Train Loss: 0.32581  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 9615 -- Train Loss: 0.32693  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 9616 -- Train Loss: 0.32627  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 9617 -- Train Loss: 0.32607  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9618 -- Train Loss: 0.32729  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 9619 -- Train Loss: 0.32650  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9620 -- Train Loss: 0.32709  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9621 -- Train Loss: 0.32514  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 9622 -- Train Loss: 0.32670  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 9623 -- Train Loss: 0.32604  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 9624 -- Train Loss: 0.32614  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 9625 -- Train Loss: 0.32614  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9626 -- Train Loss: 0.32692  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 9627 -- Train Loss: 0.32576  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 9628 -- Train Loss: 0.32677  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 9629 -- Train Loss: 0.32550  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 9630 -- Train Loss: 0.32664  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 9631 -- Train Loss: 0.32638  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 9632 -- Train Loss: 0.32554  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9633 -- Train Loss: 0.32595  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9634 -- Train Loss: 0.32609  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 9635 -- Train Loss: 0.32586  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 9636 -- Train Loss: 0.32620  Validation Loss: 0.43149\n",
      "t: 10 EPOCH 9637 -- Train Loss: 0.32566  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 9638 -- Train Loss: 0.32636  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 9639 -- Train Loss: 0.32606  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 9640 -- Train Loss: 0.32604  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 9641 -- Train Loss: 0.32619  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9642 -- Train Loss: 0.32758  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9643 -- Train Loss: 0.32632  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 9644 -- Train Loss: 0.32617  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 9645 -- Train Loss: 0.32639  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 9646 -- Train Loss: 0.32618  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 9647 -- Train Loss: 0.32609  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 9648 -- Train Loss: 0.32574  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 9649 -- Train Loss: 0.32606  Validation Loss: 0.43192\n",
      "t: 10 EPOCH 9650 -- Train Loss: 0.32624  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 9651 -- Train Loss: 0.32536  Validation Loss: 0.43213\n",
      "t: 10 EPOCH 9652 -- Train Loss: 0.32625  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 9653 -- Train Loss: 0.32605  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 9654 -- Train Loss: 0.32634  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 9655 -- Train Loss: 0.32549  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 9656 -- Train Loss: 0.32563  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 9657 -- Train Loss: 0.32603  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 9658 -- Train Loss: 0.32583  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 9659 -- Train Loss: 0.32627  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9660 -- Train Loss: 0.32516  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 9661 -- Train Loss: 0.32586  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 9662 -- Train Loss: 0.32640  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 9663 -- Train Loss: 0.32656  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 9664 -- Train Loss: 0.32536  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 9665 -- Train Loss: 0.32556  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 9666 -- Train Loss: 0.32593  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 9667 -- Train Loss: 0.32594  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 9668 -- Train Loss: 0.32593  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 9669 -- Train Loss: 0.32522  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 9670 -- Train Loss: 0.32593  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 9671 -- Train Loss: 0.32549  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 9672 -- Train Loss: 0.32537  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 9673 -- Train Loss: 0.32561  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 9674 -- Train Loss: 0.32624  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 9675 -- Train Loss: 0.32618  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 9676 -- Train Loss: 0.32526  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9677 -- Train Loss: 0.32630  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 9678 -- Train Loss: 0.32619  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 9679 -- Train Loss: 0.32530  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 9680 -- Train Loss: 0.32607  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 9681 -- Train Loss: 0.32463  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 9682 -- Train Loss: 0.32601  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 9683 -- Train Loss: 0.32585  Validation Loss: 0.43320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9684 -- Train Loss: 0.32573  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 9685 -- Train Loss: 0.32529  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 9686 -- Train Loss: 0.32556  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 9687 -- Train Loss: 0.32568  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 9688 -- Train Loss: 0.32514  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 9689 -- Train Loss: 0.32546  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 9690 -- Train Loss: 0.32514  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 9691 -- Train Loss: 0.32604  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 9692 -- Train Loss: 0.32618  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 9693 -- Train Loss: 0.32591  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 9694 -- Train Loss: 0.32554  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 9695 -- Train Loss: 0.32575  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 9696 -- Train Loss: 0.32636  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9697 -- Train Loss: 0.32585  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9698 -- Train Loss: 0.32560  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 9699 -- Train Loss: 0.32559  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 9700 -- Train Loss: 0.32650  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 9701 -- Train Loss: 0.32516  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 9702 -- Train Loss: 0.32570  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 9703 -- Train Loss: 0.32500  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 9704 -- Train Loss: 0.32650  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 9705 -- Train Loss: 0.32601  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 9706 -- Train Loss: 0.32639  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 9707 -- Train Loss: 0.32620  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 9708 -- Train Loss: 0.32513  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 9709 -- Train Loss: 0.32610  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 9710 -- Train Loss: 0.32529  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 9711 -- Train Loss: 0.32584  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 9712 -- Train Loss: 0.32583  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 9713 -- Train Loss: 0.32603  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 9714 -- Train Loss: 0.32633  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 9715 -- Train Loss: 0.32664  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 9716 -- Train Loss: 0.32542  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 9717 -- Train Loss: 0.32550  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 9718 -- Train Loss: 0.32527  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9719 -- Train Loss: 0.32546  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 9720 -- Train Loss: 0.32643  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 9721 -- Train Loss: 0.32630  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 9722 -- Train Loss: 0.32591  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 9723 -- Train Loss: 0.32534  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 9724 -- Train Loss: 0.32639  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 9725 -- Train Loss: 0.32587  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 9726 -- Train Loss: 0.32567  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 9727 -- Train Loss: 0.32425  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9728 -- Train Loss: 0.32611  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 9729 -- Train Loss: 0.32565  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 9730 -- Train Loss: 0.32611  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 9731 -- Train Loss: 0.32623  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9732 -- Train Loss: 0.32613  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 9733 -- Train Loss: 0.32549  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 9734 -- Train Loss: 0.32651  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9735 -- Train Loss: 0.32547  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 9736 -- Train Loss: 0.32593  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 9737 -- Train Loss: 0.32556  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 9738 -- Train Loss: 0.32620  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 9739 -- Train Loss: 0.32524  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 9740 -- Train Loss: 0.32560  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 9741 -- Train Loss: 0.32526  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 9742 -- Train Loss: 0.32542  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9743 -- Train Loss: 0.32624  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 9744 -- Train Loss: 0.32632  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 9745 -- Train Loss: 0.32617  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 9746 -- Train Loss: 0.32574  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 9747 -- Train Loss: 0.32642  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 9748 -- Train Loss: 0.32694  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 9749 -- Train Loss: 0.32576  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 9750 -- Train Loss: 0.32581  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 9751 -- Train Loss: 0.32560  Validation Loss: 0.43217\n",
      "t: 10 EPOCH 9752 -- Train Loss: 0.32672  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 9753 -- Train Loss: 0.32510  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 9754 -- Train Loss: 0.32605  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 9755 -- Train Loss: 0.32623  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 9756 -- Train Loss: 0.32730  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 9757 -- Train Loss: 0.32570  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9758 -- Train Loss: 0.32571  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 9759 -- Train Loss: 0.32449  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 9760 -- Train Loss: 0.32617  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 9761 -- Train Loss: 0.32561  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9762 -- Train Loss: 0.32524  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 9763 -- Train Loss: 0.32689  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 9764 -- Train Loss: 0.32617  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 9765 -- Train Loss: 0.32540  Validation Loss: 0.43174\n",
      "t: 10 EPOCH 9766 -- Train Loss: 0.32592  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 9767 -- Train Loss: 0.32607  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 9768 -- Train Loss: 0.32595  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 9769 -- Train Loss: 0.32478  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 9770 -- Train Loss: 0.32601  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9771 -- Train Loss: 0.32566  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 9772 -- Train Loss: 0.32573  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 9773 -- Train Loss: 0.32631  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 9774 -- Train Loss: 0.32674  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 9775 -- Train Loss: 0.32604  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 9776 -- Train Loss: 0.32716  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9777 -- Train Loss: 0.32579  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 9778 -- Train Loss: 0.32598  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 9779 -- Train Loss: 0.32603  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 9780 -- Train Loss: 0.32578  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 9781 -- Train Loss: 0.32548  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 9782 -- Train Loss: 0.32572  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9783 -- Train Loss: 0.32569  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 9784 -- Train Loss: 0.32681  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 9785 -- Train Loss: 0.32575  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 9786 -- Train Loss: 0.32611  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 9787 -- Train Loss: 0.32642  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 9788 -- Train Loss: 0.32684  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 9789 -- Train Loss: 0.32543  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9790 -- Train Loss: 0.32728  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 9791 -- Train Loss: 0.32534  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 9792 -- Train Loss: 0.32631  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 9793 -- Train Loss: 0.32496  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 9794 -- Train Loss: 0.32634  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9795 -- Train Loss: 0.32502  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 9796 -- Train Loss: 0.32568  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 9797 -- Train Loss: 0.32670  Validation Loss: 0.43190\n",
      "t: 10 EPOCH 9798 -- Train Loss: 0.32600  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 9799 -- Train Loss: 0.32560  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 9800 -- Train Loss: 0.32655  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 9801 -- Train Loss: 0.32601  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 9802 -- Train Loss: 0.32592  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 9803 -- Train Loss: 0.32612  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 9804 -- Train Loss: 0.32611  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 9805 -- Train Loss: 0.32550  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 9806 -- Train Loss: 0.32570  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 9807 -- Train Loss: 0.32545  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 9808 -- Train Loss: 0.32585  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9809 -- Train Loss: 0.32640  Validation Loss: 0.43418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9810 -- Train Loss: 0.32702  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 9811 -- Train Loss: 0.32584  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 9812 -- Train Loss: 0.32627  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 9813 -- Train Loss: 0.32547  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 9814 -- Train Loss: 0.32657  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 9815 -- Train Loss: 0.32594  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 9816 -- Train Loss: 0.32552  Validation Loss: 0.43127\n",
      "t: 10 EPOCH 9817 -- Train Loss: 0.32703  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 9818 -- Train Loss: 0.32707  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9819 -- Train Loss: 0.32658  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 9820 -- Train Loss: 0.32591  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 9821 -- Train Loss: 0.32637  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9822 -- Train Loss: 0.32593  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9823 -- Train Loss: 0.32696  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 9824 -- Train Loss: 0.32564  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 9825 -- Train Loss: 0.32677  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 9826 -- Train Loss: 0.32627  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 9827 -- Train Loss: 0.32656  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 9828 -- Train Loss: 0.32593  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 9829 -- Train Loss: 0.32627  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9830 -- Train Loss: 0.32659  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 9831 -- Train Loss: 0.32712  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 9832 -- Train Loss: 0.32652  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 9833 -- Train Loss: 0.32695  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 9834 -- Train Loss: 0.32626  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 9835 -- Train Loss: 0.32621  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 9836 -- Train Loss: 0.32617  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 9837 -- Train Loss: 0.32589  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 9838 -- Train Loss: 0.32714  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 9839 -- Train Loss: 0.32613  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 9840 -- Train Loss: 0.32665  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 9841 -- Train Loss: 0.32612  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 9842 -- Train Loss: 0.32583  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 9843 -- Train Loss: 0.32581  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 9844 -- Train Loss: 0.32598  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9845 -- Train Loss: 0.32634  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 9846 -- Train Loss: 0.32614  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 9847 -- Train Loss: 0.32535  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 9848 -- Train Loss: 0.32543  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 9849 -- Train Loss: 0.32637  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 9850 -- Train Loss: 0.32618  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 9851 -- Train Loss: 0.32603  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 9852 -- Train Loss: 0.32658  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 9853 -- Train Loss: 0.32605  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 9854 -- Train Loss: 0.32653  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 9855 -- Train Loss: 0.32586  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9856 -- Train Loss: 0.32629  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 9857 -- Train Loss: 0.32629  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 9858 -- Train Loss: 0.32703  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 9859 -- Train Loss: 0.32610  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 9860 -- Train Loss: 0.32626  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 9861 -- Train Loss: 0.32557  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 9862 -- Train Loss: 0.32585  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9863 -- Train Loss: 0.32587  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 9864 -- Train Loss: 0.32615  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9865 -- Train Loss: 0.32522  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 9866 -- Train Loss: 0.32702  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 9867 -- Train Loss: 0.32516  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9868 -- Train Loss: 0.32552  Validation Loss: 0.43208\n",
      "t: 10 EPOCH 9869 -- Train Loss: 0.32582  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 9870 -- Train Loss: 0.32689  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 9871 -- Train Loss: 0.32547  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 9872 -- Train Loss: 0.32587  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 9873 -- Train Loss: 0.32632  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 9874 -- Train Loss: 0.32647  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 9875 -- Train Loss: 0.32508  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 9876 -- Train Loss: 0.32677  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9877 -- Train Loss: 0.32596  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 9878 -- Train Loss: 0.32565  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 9879 -- Train Loss: 0.32655  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 9880 -- Train Loss: 0.32627  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 9881 -- Train Loss: 0.32608  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 9882 -- Train Loss: 0.32612  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 9883 -- Train Loss: 0.32681  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 9884 -- Train Loss: 0.32574  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 9885 -- Train Loss: 0.32655  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 9886 -- Train Loss: 0.32516  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 9887 -- Train Loss: 0.32654  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 9888 -- Train Loss: 0.32559  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 9889 -- Train Loss: 0.32584  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 9890 -- Train Loss: 0.32551  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 9891 -- Train Loss: 0.32566  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 9892 -- Train Loss: 0.32614  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 9893 -- Train Loss: 0.32591  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 9894 -- Train Loss: 0.32497  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 9895 -- Train Loss: 0.32572  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 9896 -- Train Loss: 0.32549  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 9897 -- Train Loss: 0.32556  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 9898 -- Train Loss: 0.32657  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 9899 -- Train Loss: 0.32515  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 9900 -- Train Loss: 0.32569  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 9901 -- Train Loss: 0.32576  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 9902 -- Train Loss: 0.32540  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9903 -- Train Loss: 0.32502  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 9904 -- Train Loss: 0.32562  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 9905 -- Train Loss: 0.32616  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 9906 -- Train Loss: 0.32567  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9907 -- Train Loss: 0.32611  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 9908 -- Train Loss: 0.32551  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 9909 -- Train Loss: 0.32498  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 9910 -- Train Loss: 0.32550  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 9911 -- Train Loss: 0.32550  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 9912 -- Train Loss: 0.32583  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 9913 -- Train Loss: 0.32554  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 9914 -- Train Loss: 0.32509  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 9915 -- Train Loss: 0.32565  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 9916 -- Train Loss: 0.32487  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 9917 -- Train Loss: 0.32617  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 9918 -- Train Loss: 0.32577  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 9919 -- Train Loss: 0.32597  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 9920 -- Train Loss: 0.32675  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 9921 -- Train Loss: 0.32518  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9922 -- Train Loss: 0.32656  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 9923 -- Train Loss: 0.32620  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 9924 -- Train Loss: 0.32560  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 9925 -- Train Loss: 0.32546  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 9926 -- Train Loss: 0.32538  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 9927 -- Train Loss: 0.32588  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 9928 -- Train Loss: 0.32527  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 9929 -- Train Loss: 0.32507  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 9930 -- Train Loss: 0.32562  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 9931 -- Train Loss: 0.32422  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 9932 -- Train Loss: 0.32572  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 9933 -- Train Loss: 0.32571  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 9934 -- Train Loss: 0.32619  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 9935 -- Train Loss: 0.32610  Validation Loss: 0.43332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 9936 -- Train Loss: 0.32597  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 9937 -- Train Loss: 0.32524  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 9938 -- Train Loss: 0.32513  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 9939 -- Train Loss: 0.32553  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 9940 -- Train Loss: 0.32535  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 9941 -- Train Loss: 0.32610  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 9942 -- Train Loss: 0.32559  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 9943 -- Train Loss: 0.32601  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 9944 -- Train Loss: 0.32436  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 9945 -- Train Loss: 0.32595  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 9946 -- Train Loss: 0.32539  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 9947 -- Train Loss: 0.32642  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 9948 -- Train Loss: 0.32515  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 9949 -- Train Loss: 0.32632  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 9950 -- Train Loss: 0.32479  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 9951 -- Train Loss: 0.32563  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 9952 -- Train Loss: 0.32544  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 9953 -- Train Loss: 0.32512  Validation Loss: 0.43218\n",
      "t: 10 EPOCH 9954 -- Train Loss: 0.32585  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 9955 -- Train Loss: 0.32576  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 9956 -- Train Loss: 0.32647  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 9957 -- Train Loss: 0.32529  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 9958 -- Train Loss: 0.32485  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 9959 -- Train Loss: 0.32568  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 9960 -- Train Loss: 0.32572  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 9961 -- Train Loss: 0.32509  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 9962 -- Train Loss: 0.32610  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 9963 -- Train Loss: 0.32548  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 9964 -- Train Loss: 0.32554  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 9965 -- Train Loss: 0.32580  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 9966 -- Train Loss: 0.32530  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 9967 -- Train Loss: 0.32619  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 9968 -- Train Loss: 0.32652  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 9969 -- Train Loss: 0.32638  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 9970 -- Train Loss: 0.32625  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 9971 -- Train Loss: 0.32643  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 9972 -- Train Loss: 0.32555  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 9973 -- Train Loss: 0.32637  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 9974 -- Train Loss: 0.32525  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 9975 -- Train Loss: 0.32639  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 9976 -- Train Loss: 0.32536  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 9977 -- Train Loss: 0.32634  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 9978 -- Train Loss: 0.32620  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 9979 -- Train Loss: 0.32568  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 9980 -- Train Loss: 0.32592  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 9981 -- Train Loss: 0.32630  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 9982 -- Train Loss: 0.32554  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 9983 -- Train Loss: 0.32604  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 9984 -- Train Loss: 0.32638  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 9985 -- Train Loss: 0.32653  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 9986 -- Train Loss: 0.32539  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 9987 -- Train Loss: 0.32578  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 9988 -- Train Loss: 0.32563  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 9989 -- Train Loss: 0.32570  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 9990 -- Train Loss: 0.32528  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 9991 -- Train Loss: 0.32683  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 9992 -- Train Loss: 0.32614  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 9993 -- Train Loss: 0.32588  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 9994 -- Train Loss: 0.32640  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 9995 -- Train Loss: 0.32567  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 9996 -- Train Loss: 0.32558  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 9997 -- Train Loss: 0.32577  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 9998 -- Train Loss: 0.32508  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 9999 -- Train Loss: 0.32613  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 10000 -- Train Loss: 0.32613  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 10001 -- Train Loss: 0.32568  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 10002 -- Train Loss: 0.32643  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 10003 -- Train Loss: 0.32509  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 10004 -- Train Loss: 0.32727  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 10005 -- Train Loss: 0.32510  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 10006 -- Train Loss: 0.32697  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 10007 -- Train Loss: 0.32534  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 10008 -- Train Loss: 0.32633  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 10009 -- Train Loss: 0.32609  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 10010 -- Train Loss: 0.32656  Validation Loss: 0.43232\n",
      "t: 10 EPOCH 10011 -- Train Loss: 0.32543  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 10012 -- Train Loss: 0.32628  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 10013 -- Train Loss: 0.32553  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 10014 -- Train Loss: 0.32502  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 10015 -- Train Loss: 0.32625  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 10016 -- Train Loss: 0.32492  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 10017 -- Train Loss: 0.32623  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10018 -- Train Loss: 0.32622  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 10019 -- Train Loss: 0.32635  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 10020 -- Train Loss: 0.32573  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 10021 -- Train Loss: 0.32640  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10022 -- Train Loss: 0.32626  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 10023 -- Train Loss: 0.32575  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 10024 -- Train Loss: 0.32616  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 10025 -- Train Loss: 0.32602  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 10026 -- Train Loss: 0.32621  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10027 -- Train Loss: 0.32609  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 10028 -- Train Loss: 0.32576  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 10029 -- Train Loss: 0.32565  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 10030 -- Train Loss: 0.32648  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 10031 -- Train Loss: 0.32545  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 10032 -- Train Loss: 0.32576  Validation Loss: 0.43110\n",
      "t: 10 EPOCH 10033 -- Train Loss: 0.32658  Validation Loss: 0.43163\n",
      "t: 10 EPOCH 10034 -- Train Loss: 0.32555  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10035 -- Train Loss: 0.32550  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 10036 -- Train Loss: 0.32522  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 10037 -- Train Loss: 0.32651  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 10038 -- Train Loss: 0.32591  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 10039 -- Train Loss: 0.32691  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 10040 -- Train Loss: 0.32494  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 10041 -- Train Loss: 0.32605  Validation Loss: 0.43241\n",
      "t: 10 EPOCH 10042 -- Train Loss: 0.32517  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 10043 -- Train Loss: 0.32592  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 10044 -- Train Loss: 0.32642  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 10045 -- Train Loss: 0.32567  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 10046 -- Train Loss: 0.32590  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 10047 -- Train Loss: 0.32573  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 10048 -- Train Loss: 0.32569  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 10049 -- Train Loss: 0.32549  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 10050 -- Train Loss: 0.32591  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 10051 -- Train Loss: 0.32586  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10052 -- Train Loss: 0.32558  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 10053 -- Train Loss: 0.32634  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 10054 -- Train Loss: 0.32462  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 10055 -- Train Loss: 0.32621  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 10056 -- Train Loss: 0.32649  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 10057 -- Train Loss: 0.32578  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 10058 -- Train Loss: 0.32486  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 10059 -- Train Loss: 0.32616  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 10060 -- Train Loss: 0.32507  Validation Loss: 0.43355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10061 -- Train Loss: 0.32591  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 10062 -- Train Loss: 0.32513  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 10063 -- Train Loss: 0.32610  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 10064 -- Train Loss: 0.32546  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 10065 -- Train Loss: 0.32572  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 10066 -- Train Loss: 0.32637  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 10067 -- Train Loss: 0.32591  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10068 -- Train Loss: 0.32591  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10069 -- Train Loss: 0.32542  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10070 -- Train Loss: 0.32570  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 10071 -- Train Loss: 0.32533  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 10072 -- Train Loss: 0.32615  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10073 -- Train Loss: 0.32542  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 10074 -- Train Loss: 0.32482  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 10075 -- Train Loss: 0.32524  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 10076 -- Train Loss: 0.32621  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 10077 -- Train Loss: 0.32555  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 10078 -- Train Loss: 0.32669  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 10079 -- Train Loss: 0.32566  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 10080 -- Train Loss: 0.32539  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 10081 -- Train Loss: 0.32580  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 10082 -- Train Loss: 0.32584  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 10083 -- Train Loss: 0.32570  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 10084 -- Train Loss: 0.32529  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 10085 -- Train Loss: 0.32609  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 10086 -- Train Loss: 0.32584  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 10087 -- Train Loss: 0.32512  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10088 -- Train Loss: 0.32568  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 10089 -- Train Loss: 0.32579  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 10090 -- Train Loss: 0.32452  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 10091 -- Train Loss: 0.32598  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10092 -- Train Loss: 0.32599  Validation Loss: 0.43150\n",
      "t: 10 EPOCH 10093 -- Train Loss: 0.32678  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10094 -- Train Loss: 0.32601  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 10095 -- Train Loss: 0.32592  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 10096 -- Train Loss: 0.32530  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 10097 -- Train Loss: 0.32586  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 10098 -- Train Loss: 0.32513  Validation Loss: 0.43183\n",
      "t: 10 EPOCH 10099 -- Train Loss: 0.32577  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 10100 -- Train Loss: 0.32511  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 10101 -- Train Loss: 0.32538  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 10102 -- Train Loss: 0.32530  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 10103 -- Train Loss: 0.32579  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 10104 -- Train Loss: 0.32687  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 10105 -- Train Loss: 0.32525  Validation Loss: 0.43204\n",
      "t: 10 EPOCH 10106 -- Train Loss: 0.32627  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10107 -- Train Loss: 0.32519  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 10108 -- Train Loss: 0.32584  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 10109 -- Train Loss: 0.32505  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10110 -- Train Loss: 0.32581  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 10111 -- Train Loss: 0.32541  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 10112 -- Train Loss: 0.32532  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 10113 -- Train Loss: 0.32543  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 10114 -- Train Loss: 0.32549  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 10115 -- Train Loss: 0.32634  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 10116 -- Train Loss: 0.32611  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 10117 -- Train Loss: 0.32504  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10118 -- Train Loss: 0.32659  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 10119 -- Train Loss: 0.32553  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 10120 -- Train Loss: 0.32700  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 10121 -- Train Loss: 0.32535  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 10122 -- Train Loss: 0.32585  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 10123 -- Train Loss: 0.32549  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 10124 -- Train Loss: 0.32543  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 10125 -- Train Loss: 0.32514  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 10126 -- Train Loss: 0.32524  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 10127 -- Train Loss: 0.32516  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 10128 -- Train Loss: 0.32586  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 10129 -- Train Loss: 0.32560  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 10130 -- Train Loss: 0.32447  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 10131 -- Train Loss: 0.32514  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 10132 -- Train Loss: 0.32511  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 10133 -- Train Loss: 0.32543  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 10134 -- Train Loss: 0.32530  Validation Loss: 0.43256\n",
      "t: 10 EPOCH 10135 -- Train Loss: 0.32636  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 10136 -- Train Loss: 0.32430  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10137 -- Train Loss: 0.32583  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 10138 -- Train Loss: 0.32515  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 10139 -- Train Loss: 0.32647  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 10140 -- Train Loss: 0.32527  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 10141 -- Train Loss: 0.32624  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 10142 -- Train Loss: 0.32516  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 10143 -- Train Loss: 0.32491  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 10144 -- Train Loss: 0.32560  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 10145 -- Train Loss: 0.32597  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10146 -- Train Loss: 0.32556  Validation Loss: 0.43248\n",
      "t: 10 EPOCH 10147 -- Train Loss: 0.32489  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10148 -- Train Loss: 0.32508  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 10149 -- Train Loss: 0.32548  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 10150 -- Train Loss: 0.32609  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 10151 -- Train Loss: 0.32578  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 10152 -- Train Loss: 0.32480  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 10153 -- Train Loss: 0.32538  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 10154 -- Train Loss: 0.32584  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 10155 -- Train Loss: 0.32517  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 10156 -- Train Loss: 0.32558  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 10157 -- Train Loss: 0.32511  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 10158 -- Train Loss: 0.32500  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 10159 -- Train Loss: 0.32522  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 10160 -- Train Loss: 0.32595  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10161 -- Train Loss: 0.32510  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 10162 -- Train Loss: 0.32586  Validation Loss: 0.43185\n",
      "t: 10 EPOCH 10163 -- Train Loss: 0.32439  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 10164 -- Train Loss: 0.32418  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 10165 -- Train Loss: 0.32564  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 10166 -- Train Loss: 0.32472  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 10167 -- Train Loss: 0.32554  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 10168 -- Train Loss: 0.32558  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10169 -- Train Loss: 0.32657  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 10170 -- Train Loss: 0.32433  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10171 -- Train Loss: 0.32576  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 10172 -- Train Loss: 0.32468  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 10173 -- Train Loss: 0.32546  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 10174 -- Train Loss: 0.32556  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 10175 -- Train Loss: 0.32541  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10176 -- Train Loss: 0.32565  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 10177 -- Train Loss: 0.32559  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 10178 -- Train Loss: 0.32594  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10179 -- Train Loss: 0.32625  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 10180 -- Train Loss: 0.32525  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 10181 -- Train Loss: 0.32563  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 10182 -- Train Loss: 0.32662  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 10183 -- Train Loss: 0.32501  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 10184 -- Train Loss: 0.32655  Validation Loss: 0.43365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10185 -- Train Loss: 0.32591  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 10186 -- Train Loss: 0.32593  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 10187 -- Train Loss: 0.32643  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 10188 -- Train Loss: 0.32653  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 10189 -- Train Loss: 0.32616  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 10190 -- Train Loss: 0.32672  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 10191 -- Train Loss: 0.32622  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 10192 -- Train Loss: 0.32641  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 10193 -- Train Loss: 0.32632  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 10194 -- Train Loss: 0.32626  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 10195 -- Train Loss: 0.32664  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 10196 -- Train Loss: 0.32599  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10197 -- Train Loss: 0.32578  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 10198 -- Train Loss: 0.32566  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 10199 -- Train Loss: 0.32639  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 10200 -- Train Loss: 0.32552  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10201 -- Train Loss: 0.32590  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 10202 -- Train Loss: 0.32577  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 10203 -- Train Loss: 0.32703  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 10204 -- Train Loss: 0.32611  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 10205 -- Train Loss: 0.32678  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10206 -- Train Loss: 0.32592  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 10207 -- Train Loss: 0.32597  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 10208 -- Train Loss: 0.32611  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 10209 -- Train Loss: 0.32639  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10210 -- Train Loss: 0.32600  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 10211 -- Train Loss: 0.32612  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 10212 -- Train Loss: 0.32619  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 10213 -- Train Loss: 0.32608  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 10214 -- Train Loss: 0.32490  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 10215 -- Train Loss: 0.32681  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 10216 -- Train Loss: 0.32665  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 10217 -- Train Loss: 0.32573  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 10218 -- Train Loss: 0.32617  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 10219 -- Train Loss: 0.32657  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 10220 -- Train Loss: 0.32722  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10221 -- Train Loss: 0.32584  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 10222 -- Train Loss: 0.32636  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10223 -- Train Loss: 0.32592  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 10224 -- Train Loss: 0.32727  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 10225 -- Train Loss: 0.32542  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 10226 -- Train Loss: 0.32585  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 10227 -- Train Loss: 0.32577  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 10228 -- Train Loss: 0.32623  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 10229 -- Train Loss: 0.32579  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 10230 -- Train Loss: 0.32609  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 10231 -- Train Loss: 0.32605  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 10232 -- Train Loss: 0.32572  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 10233 -- Train Loss: 0.32548  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 10234 -- Train Loss: 0.32571  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 10235 -- Train Loss: 0.32587  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10236 -- Train Loss: 0.32571  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 10237 -- Train Loss: 0.32539  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 10238 -- Train Loss: 0.32541  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 10239 -- Train Loss: 0.32533  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 10240 -- Train Loss: 0.32517  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 10241 -- Train Loss: 0.32557  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 10242 -- Train Loss: 0.32453  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 10243 -- Train Loss: 0.32606  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10244 -- Train Loss: 0.32476  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 10245 -- Train Loss: 0.32602  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 10246 -- Train Loss: 0.32523  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10247 -- Train Loss: 0.32597  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10248 -- Train Loss: 0.32535  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 10249 -- Train Loss: 0.32581  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10250 -- Train Loss: 0.32502  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 10251 -- Train Loss: 0.32535  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 10252 -- Train Loss: 0.32464  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 10253 -- Train Loss: 0.32598  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 10254 -- Train Loss: 0.32512  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 10255 -- Train Loss: 0.32598  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 10256 -- Train Loss: 0.32580  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 10257 -- Train Loss: 0.32523  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 10258 -- Train Loss: 0.32494  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 10259 -- Train Loss: 0.32514  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 10260 -- Train Loss: 0.32570  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 10261 -- Train Loss: 0.32496  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 10262 -- Train Loss: 0.32545  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 10263 -- Train Loss: 0.32450  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 10264 -- Train Loss: 0.32481  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 10265 -- Train Loss: 0.32482  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 10266 -- Train Loss: 0.32513  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 10267 -- Train Loss: 0.32462  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 10268 -- Train Loss: 0.32588  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 10269 -- Train Loss: 0.32501  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 10270 -- Train Loss: 0.32474  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 10271 -- Train Loss: 0.32490  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 10272 -- Train Loss: 0.32552  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10273 -- Train Loss: 0.32655  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 10274 -- Train Loss: 0.32535  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 10275 -- Train Loss: 0.32482  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 10276 -- Train Loss: 0.32537  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 10277 -- Train Loss: 0.32490  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 10278 -- Train Loss: 0.32558  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 10279 -- Train Loss: 0.32539  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 10280 -- Train Loss: 0.32539  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 10281 -- Train Loss: 0.32648  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 10282 -- Train Loss: 0.32478  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 10283 -- Train Loss: 0.32490  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10284 -- Train Loss: 0.32490  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10285 -- Train Loss: 0.32439  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 10286 -- Train Loss: 0.32541  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 10287 -- Train Loss: 0.32468  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 10288 -- Train Loss: 0.32523  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10289 -- Train Loss: 0.32451  Validation Loss: 0.43184\n",
      "t: 10 EPOCH 10290 -- Train Loss: 0.32529  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 10291 -- Train Loss: 0.32604  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 10292 -- Train Loss: 0.32499  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 10293 -- Train Loss: 0.32585  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 10294 -- Train Loss: 0.32627  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 10295 -- Train Loss: 0.32538  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 10296 -- Train Loss: 0.32604  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 10297 -- Train Loss: 0.32533  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 10298 -- Train Loss: 0.32531  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 10299 -- Train Loss: 0.32628  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 10300 -- Train Loss: 0.32532  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 10301 -- Train Loss: 0.32486  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 10302 -- Train Loss: 0.32597  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10303 -- Train Loss: 0.32530  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 10304 -- Train Loss: 0.32564  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 10305 -- Train Loss: 0.32545  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 10306 -- Train Loss: 0.32559  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10307 -- Train Loss: 0.32606  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 10308 -- Train Loss: 0.32453  Validation Loss: 0.43348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10309 -- Train Loss: 0.32446  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 10310 -- Train Loss: 0.32574  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 10311 -- Train Loss: 0.32621  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 10312 -- Train Loss: 0.32572  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 10313 -- Train Loss: 0.32611  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 10314 -- Train Loss: 0.32611  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 10315 -- Train Loss: 0.32601  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 10316 -- Train Loss: 0.32516  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10317 -- Train Loss: 0.32527  Validation Loss: 0.43246\n",
      "t: 10 EPOCH 10318 -- Train Loss: 0.32559  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 10319 -- Train Loss: 0.32525  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 10320 -- Train Loss: 0.32567  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 10321 -- Train Loss: 0.32622  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 10322 -- Train Loss: 0.32586  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 10323 -- Train Loss: 0.32660  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 10324 -- Train Loss: 0.32526  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 10325 -- Train Loss: 0.32546  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 10326 -- Train Loss: 0.32547  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10327 -- Train Loss: 0.32545  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 10328 -- Train Loss: 0.32613  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 10329 -- Train Loss: 0.32501  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 10330 -- Train Loss: 0.32585  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 10331 -- Train Loss: 0.32465  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 10332 -- Train Loss: 0.32517  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 10333 -- Train Loss: 0.32420  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 10334 -- Train Loss: 0.32663  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 10335 -- Train Loss: 0.32494  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 10336 -- Train Loss: 0.32597  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 10337 -- Train Loss: 0.32567  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10338 -- Train Loss: 0.32570  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 10339 -- Train Loss: 0.32546  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 10340 -- Train Loss: 0.32568  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 10341 -- Train Loss: 0.32514  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 10342 -- Train Loss: 0.32562  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 10343 -- Train Loss: 0.32488  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 10344 -- Train Loss: 0.32526  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 10345 -- Train Loss: 0.32479  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 10346 -- Train Loss: 0.32503  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 10347 -- Train Loss: 0.32492  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 10348 -- Train Loss: 0.32497  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 10349 -- Train Loss: 0.32543  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 10350 -- Train Loss: 0.32599  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 10351 -- Train Loss: 0.32590  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 10352 -- Train Loss: 0.32490  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10353 -- Train Loss: 0.32605  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10354 -- Train Loss: 0.32589  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 10355 -- Train Loss: 0.32536  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 10356 -- Train Loss: 0.32531  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 10357 -- Train Loss: 0.32484  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 10358 -- Train Loss: 0.32496  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 10359 -- Train Loss: 0.32453  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 10360 -- Train Loss: 0.32476  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 10361 -- Train Loss: 0.32537  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10362 -- Train Loss: 0.32633  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 10363 -- Train Loss: 0.32526  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 10364 -- Train Loss: 0.32580  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 10365 -- Train Loss: 0.32512  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10366 -- Train Loss: 0.32515  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 10367 -- Train Loss: 0.32536  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 10368 -- Train Loss: 0.32539  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10369 -- Train Loss: 0.32541  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 10370 -- Train Loss: 0.32570  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 10371 -- Train Loss: 0.32597  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 10372 -- Train Loss: 0.32572  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 10373 -- Train Loss: 0.32658  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 10374 -- Train Loss: 0.32639  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10375 -- Train Loss: 0.32575  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 10376 -- Train Loss: 0.32617  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 10377 -- Train Loss: 0.32601  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 10378 -- Train Loss: 0.32591  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 10379 -- Train Loss: 0.32525  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 10380 -- Train Loss: 0.32583  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 10381 -- Train Loss: 0.32544  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 10382 -- Train Loss: 0.32583  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 10383 -- Train Loss: 0.32617  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 10384 -- Train Loss: 0.32589  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 10385 -- Train Loss: 0.32424  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 10386 -- Train Loss: 0.32586  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 10387 -- Train Loss: 0.32534  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 10388 -- Train Loss: 0.32591  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 10389 -- Train Loss: 0.32551  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 10390 -- Train Loss: 0.32665  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 10391 -- Train Loss: 0.32564  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10392 -- Train Loss: 0.32615  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 10393 -- Train Loss: 0.32583  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 10394 -- Train Loss: 0.32587  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 10395 -- Train Loss: 0.32565  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 10396 -- Train Loss: 0.32710  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 10397 -- Train Loss: 0.32578  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 10398 -- Train Loss: 0.32619  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 10399 -- Train Loss: 0.32607  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 10400 -- Train Loss: 0.32672  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 10401 -- Train Loss: 0.32549  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 10402 -- Train Loss: 0.32589  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 10403 -- Train Loss: 0.32612  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 10404 -- Train Loss: 0.32571  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 10405 -- Train Loss: 0.32615  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 10406 -- Train Loss: 0.32554  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 10407 -- Train Loss: 0.32561  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 10408 -- Train Loss: 0.32555  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 10409 -- Train Loss: 0.32568  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 10410 -- Train Loss: 0.32547  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 10411 -- Train Loss: 0.32551  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 10412 -- Train Loss: 0.32520  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10413 -- Train Loss: 0.32587  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 10414 -- Train Loss: 0.32605  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 10415 -- Train Loss: 0.32627  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 10416 -- Train Loss: 0.32556  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 10417 -- Train Loss: 0.32511  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 10418 -- Train Loss: 0.32647  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 10419 -- Train Loss: 0.32604  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 10420 -- Train Loss: 0.32569  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 10421 -- Train Loss: 0.32600  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 10422 -- Train Loss: 0.32546  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 10423 -- Train Loss: 0.32598  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10424 -- Train Loss: 0.32485  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 10425 -- Train Loss: 0.32485  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 10426 -- Train Loss: 0.32542  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 10427 -- Train Loss: 0.32586  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10428 -- Train Loss: 0.32485  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 10429 -- Train Loss: 0.32527  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 10430 -- Train Loss: 0.32606  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10431 -- Train Loss: 0.32486  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10432 -- Train Loss: 0.32480  Validation Loss: 0.43490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10433 -- Train Loss: 0.32548  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10434 -- Train Loss: 0.32573  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 10435 -- Train Loss: 0.32519  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 10436 -- Train Loss: 0.32478  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 10437 -- Train Loss: 0.32548  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10438 -- Train Loss: 0.32544  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 10439 -- Train Loss: 0.32596  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 10440 -- Train Loss: 0.32564  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 10441 -- Train Loss: 0.32527  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 10442 -- Train Loss: 0.32488  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 10443 -- Train Loss: 0.32572  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 10444 -- Train Loss: 0.32552  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 10445 -- Train Loss: 0.32536  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 10446 -- Train Loss: 0.32519  Validation Loss: 0.43182\n",
      "t: 10 EPOCH 10447 -- Train Loss: 0.32504  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 10448 -- Train Loss: 0.32609  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 10449 -- Train Loss: 0.32476  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 10450 -- Train Loss: 0.32515  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 10451 -- Train Loss: 0.32504  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 10452 -- Train Loss: 0.32460  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 10453 -- Train Loss: 0.32554  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 10454 -- Train Loss: 0.32491  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 10455 -- Train Loss: 0.32418  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 10456 -- Train Loss: 0.32505  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 10457 -- Train Loss: 0.32560  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10458 -- Train Loss: 0.32521  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 10459 -- Train Loss: 0.32459  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 10460 -- Train Loss: 0.32485  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 10461 -- Train Loss: 0.32479  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 10462 -- Train Loss: 0.32566  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 10463 -- Train Loss: 0.32462  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 10464 -- Train Loss: 0.32598  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 10465 -- Train Loss: 0.32413  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 10466 -- Train Loss: 0.32561  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 10467 -- Train Loss: 0.32490  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 10468 -- Train Loss: 0.32612  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 10469 -- Train Loss: 0.32596  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 10470 -- Train Loss: 0.32600  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 10471 -- Train Loss: 0.32614  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10472 -- Train Loss: 0.32582  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 10473 -- Train Loss: 0.32542  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 10474 -- Train Loss: 0.32577  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 10475 -- Train Loss: 0.32530  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 10476 -- Train Loss: 0.32658  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 10477 -- Train Loss: 0.32613  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 10478 -- Train Loss: 0.32574  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 10479 -- Train Loss: 0.32577  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 10480 -- Train Loss: 0.32559  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10481 -- Train Loss: 0.32540  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 10482 -- Train Loss: 0.32547  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10483 -- Train Loss: 0.32497  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 10484 -- Train Loss: 0.32589  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 10485 -- Train Loss: 0.32541  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 10486 -- Train Loss: 0.32520  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 10487 -- Train Loss: 0.32579  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 10488 -- Train Loss: 0.32527  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 10489 -- Train Loss: 0.32530  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 10490 -- Train Loss: 0.32538  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10491 -- Train Loss: 0.32573  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 10492 -- Train Loss: 0.32611  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 10493 -- Train Loss: 0.32505  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 10494 -- Train Loss: 0.32615  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 10495 -- Train Loss: 0.32595  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10496 -- Train Loss: 0.32584  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 10497 -- Train Loss: 0.32558  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 10498 -- Train Loss: 0.32569  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 10499 -- Train Loss: 0.32607  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 10500 -- Train Loss: 0.32616  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 10501 -- Train Loss: 0.32595  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 10502 -- Train Loss: 0.32584  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 10503 -- Train Loss: 0.32625  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 10504 -- Train Loss: 0.32632  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 10505 -- Train Loss: 0.32505  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 10506 -- Train Loss: 0.32538  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 10507 -- Train Loss: 0.32522  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10508 -- Train Loss: 0.32598  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 10509 -- Train Loss: 0.32630  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 10510 -- Train Loss: 0.32466  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 10511 -- Train Loss: 0.32683  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 10512 -- Train Loss: 0.32452  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 10513 -- Train Loss: 0.32573  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 10514 -- Train Loss: 0.32534  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10515 -- Train Loss: 0.32564  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 10516 -- Train Loss: 0.32509  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10517 -- Train Loss: 0.32590  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 10518 -- Train Loss: 0.32469  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 10519 -- Train Loss: 0.32506  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 10520 -- Train Loss: 0.32468  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 10521 -- Train Loss: 0.32548  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 10522 -- Train Loss: 0.32446  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 10523 -- Train Loss: 0.32494  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 10524 -- Train Loss: 0.32477  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 10525 -- Train Loss: 0.32453  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 10526 -- Train Loss: 0.32522  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 10527 -- Train Loss: 0.32554  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 10528 -- Train Loss: 0.32610  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 10529 -- Train Loss: 0.32532  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 10530 -- Train Loss: 0.32606  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 10531 -- Train Loss: 0.32493  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10532 -- Train Loss: 0.32590  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 10533 -- Train Loss: 0.32596  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 10534 -- Train Loss: 0.32453  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 10535 -- Train Loss: 0.32588  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 10536 -- Train Loss: 0.32489  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 10537 -- Train Loss: 0.32608  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 10538 -- Train Loss: 0.32488  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 10539 -- Train Loss: 0.32608  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 10540 -- Train Loss: 0.32519  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 10541 -- Train Loss: 0.32655  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 10542 -- Train Loss: 0.32565  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10543 -- Train Loss: 0.32548  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 10544 -- Train Loss: 0.32591  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 10545 -- Train Loss: 0.32572  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10546 -- Train Loss: 0.32610  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 10547 -- Train Loss: 0.32450  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 10548 -- Train Loss: 0.32586  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 10549 -- Train Loss: 0.32523  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 10550 -- Train Loss: 0.32557  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 10551 -- Train Loss: 0.32558  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 10552 -- Train Loss: 0.32560  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 10553 -- Train Loss: 0.32503  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10554 -- Train Loss: 0.32575  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 10555 -- Train Loss: 0.32537  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 10556 -- Train Loss: 0.32588  Validation Loss: 0.43369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10557 -- Train Loss: 0.32491  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 10558 -- Train Loss: 0.32682  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 10559 -- Train Loss: 0.32516  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 10560 -- Train Loss: 0.32608  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 10561 -- Train Loss: 0.32565  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 10562 -- Train Loss: 0.32572  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 10563 -- Train Loss: 0.32534  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 10564 -- Train Loss: 0.32529  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10565 -- Train Loss: 0.32553  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10566 -- Train Loss: 0.32544  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 10567 -- Train Loss: 0.32702  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10568 -- Train Loss: 0.32459  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 10569 -- Train Loss: 0.32621  Validation Loss: 0.43231\n",
      "t: 10 EPOCH 10570 -- Train Loss: 0.32510  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 10571 -- Train Loss: 0.32596  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 10572 -- Train Loss: 0.32513  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 10573 -- Train Loss: 0.32546  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 10574 -- Train Loss: 0.32540  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 10575 -- Train Loss: 0.32504  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 10576 -- Train Loss: 0.32567  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 10577 -- Train Loss: 0.32575  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 10578 -- Train Loss: 0.32565  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 10579 -- Train Loss: 0.32510  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 10580 -- Train Loss: 0.32548  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 10581 -- Train Loss: 0.32602  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 10582 -- Train Loss: 0.32629  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 10583 -- Train Loss: 0.32550  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 10584 -- Train Loss: 0.32505  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 10585 -- Train Loss: 0.32670  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 10586 -- Train Loss: 0.32508  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 10587 -- Train Loss: 0.32505  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 10588 -- Train Loss: 0.32535  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 10589 -- Train Loss: 0.32542  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 10590 -- Train Loss: 0.32554  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 10591 -- Train Loss: 0.32544  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10592 -- Train Loss: 0.32573  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 10593 -- Train Loss: 0.32450  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 10594 -- Train Loss: 0.32449  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 10595 -- Train Loss: 0.32522  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 10596 -- Train Loss: 0.32507  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 10597 -- Train Loss: 0.32542  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 10598 -- Train Loss: 0.32553  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 10599 -- Train Loss: 0.32512  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10600 -- Train Loss: 0.32561  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10601 -- Train Loss: 0.32468  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 10602 -- Train Loss: 0.32510  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 10603 -- Train Loss: 0.32520  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 10604 -- Train Loss: 0.32566  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 10605 -- Train Loss: 0.32551  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10606 -- Train Loss: 0.32528  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 10607 -- Train Loss: 0.32605  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 10608 -- Train Loss: 0.32405  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 10609 -- Train Loss: 0.32535  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 10610 -- Train Loss: 0.32480  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 10611 -- Train Loss: 0.32519  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10612 -- Train Loss: 0.32454  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 10613 -- Train Loss: 0.32572  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 10614 -- Train Loss: 0.32535  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10615 -- Train Loss: 0.32505  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 10616 -- Train Loss: 0.32415  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 10617 -- Train Loss: 0.32505  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 10618 -- Train Loss: 0.32428  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 10619 -- Train Loss: 0.32548  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 10620 -- Train Loss: 0.32528  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 10621 -- Train Loss: 0.32556  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 10622 -- Train Loss: 0.32553  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 10623 -- Train Loss: 0.32501  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 10624 -- Train Loss: 0.32507  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10625 -- Train Loss: 0.32467  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 10626 -- Train Loss: 0.32490  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 10627 -- Train Loss: 0.32492  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 10628 -- Train Loss: 0.32590  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 10629 -- Train Loss: 0.32480  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 10630 -- Train Loss: 0.32521  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 10631 -- Train Loss: 0.32519  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 10632 -- Train Loss: 0.32584  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 10633 -- Train Loss: 0.32531  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 10634 -- Train Loss: 0.32623  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 10635 -- Train Loss: 0.32417  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 10636 -- Train Loss: 0.32446  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 10637 -- Train Loss: 0.32485  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 10638 -- Train Loss: 0.32566  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 10639 -- Train Loss: 0.32554  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 10640 -- Train Loss: 0.32592  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 10641 -- Train Loss: 0.32542  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 10642 -- Train Loss: 0.32584  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10643 -- Train Loss: 0.32574  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 10644 -- Train Loss: 0.32558  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 10645 -- Train Loss: 0.32484  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 10646 -- Train Loss: 0.32572  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10647 -- Train Loss: 0.32580  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 10648 -- Train Loss: 0.32477  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 10649 -- Train Loss: 0.32550  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 10650 -- Train Loss: 0.32572  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10651 -- Train Loss: 0.32594  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 10652 -- Train Loss: 0.32609  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 10653 -- Train Loss: 0.32512  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 10654 -- Train Loss: 0.32517  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 10655 -- Train Loss: 0.32582  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 10656 -- Train Loss: 0.32472  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 10657 -- Train Loss: 0.32508  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 10658 -- Train Loss: 0.32568  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 10659 -- Train Loss: 0.32669  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 10660 -- Train Loss: 0.32550  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 10661 -- Train Loss: 0.32606  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 10662 -- Train Loss: 0.32608  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 10663 -- Train Loss: 0.32545  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 10664 -- Train Loss: 0.32493  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 10665 -- Train Loss: 0.32563  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 10666 -- Train Loss: 0.32497  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 10667 -- Train Loss: 0.32560  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 10668 -- Train Loss: 0.32498  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 10669 -- Train Loss: 0.32618  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 10670 -- Train Loss: 0.32527  Validation Loss: 0.43296\n",
      "t: 10 EPOCH 10671 -- Train Loss: 0.32522  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 10672 -- Train Loss: 0.32520  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 10673 -- Train Loss: 0.32552  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10674 -- Train Loss: 0.32522  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10675 -- Train Loss: 0.32606  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 10676 -- Train Loss: 0.32550  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 10677 -- Train Loss: 0.32504  Validation Loss: 0.43112\n",
      "t: 10 EPOCH 10678 -- Train Loss: 0.32554  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 10679 -- Train Loss: 0.32521  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 10680 -- Train Loss: 0.32440  Validation Loss: 0.43365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10681 -- Train Loss: 0.32512  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10682 -- Train Loss: 0.32466  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 10683 -- Train Loss: 0.32564  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10684 -- Train Loss: 0.32535  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 10685 -- Train Loss: 0.32533  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10686 -- Train Loss: 0.32604  Validation Loss: 0.43249\n",
      "t: 10 EPOCH 10687 -- Train Loss: 0.32568  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 10688 -- Train Loss: 0.32659  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10689 -- Train Loss: 0.32467  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 10690 -- Train Loss: 0.32577  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 10691 -- Train Loss: 0.32581  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10692 -- Train Loss: 0.32600  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 10693 -- Train Loss: 0.32500  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 10694 -- Train Loss: 0.32496  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10695 -- Train Loss: 0.32670  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 10696 -- Train Loss: 0.32558  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 10697 -- Train Loss: 0.32537  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 10698 -- Train Loss: 0.32518  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 10699 -- Train Loss: 0.32586  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 10700 -- Train Loss: 0.32479  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 10701 -- Train Loss: 0.32536  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 10702 -- Train Loss: 0.32491  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 10703 -- Train Loss: 0.32549  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 10704 -- Train Loss: 0.32509  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 10705 -- Train Loss: 0.32567  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 10706 -- Train Loss: 0.32572  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 10707 -- Train Loss: 0.32540  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 10708 -- Train Loss: 0.32545  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10709 -- Train Loss: 0.32509  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 10710 -- Train Loss: 0.32506  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 10711 -- Train Loss: 0.32506  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 10712 -- Train Loss: 0.32539  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 10713 -- Train Loss: 0.32558  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 10714 -- Train Loss: 0.32510  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 10715 -- Train Loss: 0.32539  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 10716 -- Train Loss: 0.32555  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 10717 -- Train Loss: 0.32599  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 10718 -- Train Loss: 0.32586  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 10719 -- Train Loss: 0.32476  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 10720 -- Train Loss: 0.32566  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 10721 -- Train Loss: 0.32530  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 10722 -- Train Loss: 0.32467  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 10723 -- Train Loss: 0.32574  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 10724 -- Train Loss: 0.32475  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 10725 -- Train Loss: 0.32492  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 10726 -- Train Loss: 0.32474  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 10727 -- Train Loss: 0.32479  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 10728 -- Train Loss: 0.32521  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 10729 -- Train Loss: 0.32594  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 10730 -- Train Loss: 0.32487  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 10731 -- Train Loss: 0.32588  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10732 -- Train Loss: 0.32559  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 10733 -- Train Loss: 0.32505  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 10734 -- Train Loss: 0.32518  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 10735 -- Train Loss: 0.32531  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 10736 -- Train Loss: 0.32495  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 10737 -- Train Loss: 0.32641  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10738 -- Train Loss: 0.32462  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 10739 -- Train Loss: 0.32458  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 10740 -- Train Loss: 0.32567  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 10741 -- Train Loss: 0.32499  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 10742 -- Train Loss: 0.32515  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 10743 -- Train Loss: 0.32567  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 10744 -- Train Loss: 0.32519  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 10745 -- Train Loss: 0.32523  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 10746 -- Train Loss: 0.32518  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 10747 -- Train Loss: 0.32426  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 10748 -- Train Loss: 0.32500  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 10749 -- Train Loss: 0.32535  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 10750 -- Train Loss: 0.32482  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 10751 -- Train Loss: 0.32562  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 10752 -- Train Loss: 0.32558  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10753 -- Train Loss: 0.32433  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 10754 -- Train Loss: 0.32513  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 10755 -- Train Loss: 0.32550  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 10756 -- Train Loss: 0.32514  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 10757 -- Train Loss: 0.32448  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 10758 -- Train Loss: 0.32494  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 10759 -- Train Loss: 0.32512  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 10760 -- Train Loss: 0.32565  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 10761 -- Train Loss: 0.32511  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 10762 -- Train Loss: 0.32523  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 10763 -- Train Loss: 0.32559  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 10764 -- Train Loss: 0.32536  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 10765 -- Train Loss: 0.32472  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10766 -- Train Loss: 0.32540  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 10767 -- Train Loss: 0.32536  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 10768 -- Train Loss: 0.32533  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 10769 -- Train Loss: 0.32496  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 10770 -- Train Loss: 0.32527  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 10771 -- Train Loss: 0.32447  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 10772 -- Train Loss: 0.32606  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 10773 -- Train Loss: 0.32510  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 10774 -- Train Loss: 0.32420  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 10775 -- Train Loss: 0.32566  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 10776 -- Train Loss: 0.32566  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 10777 -- Train Loss: 0.32538  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 10778 -- Train Loss: 0.32658  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 10779 -- Train Loss: 0.32491  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 10780 -- Train Loss: 0.32625  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 10781 -- Train Loss: 0.32455  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 10782 -- Train Loss: 0.32546  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 10783 -- Train Loss: 0.32512  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10784 -- Train Loss: 0.32548  Validation Loss: 0.43205\n",
      "t: 10 EPOCH 10785 -- Train Loss: 0.32500  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 10786 -- Train Loss: 0.32652  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 10787 -- Train Loss: 0.32492  Validation Loss: 0.43282\n",
      "t: 10 EPOCH 10788 -- Train Loss: 0.32525  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 10789 -- Train Loss: 0.32546  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 10790 -- Train Loss: 0.32569  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 10791 -- Train Loss: 0.32566  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 10792 -- Train Loss: 0.32606  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 10793 -- Train Loss: 0.32631  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 10794 -- Train Loss: 0.32635  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 10795 -- Train Loss: 0.32603  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 10796 -- Train Loss: 0.32615  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 10797 -- Train Loss: 0.32489  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 10798 -- Train Loss: 0.32597  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 10799 -- Train Loss: 0.32492  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 10800 -- Train Loss: 0.32602  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 10801 -- Train Loss: 0.32486  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 10802 -- Train Loss: 0.32585  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 10803 -- Train Loss: 0.32440  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 10804 -- Train Loss: 0.32589  Validation Loss: 0.43355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10805 -- Train Loss: 0.32497  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 10806 -- Train Loss: 0.32539  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 10807 -- Train Loss: 0.32593  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 10808 -- Train Loss: 0.32466  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10809 -- Train Loss: 0.32561  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 10810 -- Train Loss: 0.32420  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 10811 -- Train Loss: 0.32483  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 10812 -- Train Loss: 0.32584  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10813 -- Train Loss: 0.32525  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 10814 -- Train Loss: 0.32489  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 10815 -- Train Loss: 0.32545  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 10816 -- Train Loss: 0.32493  Validation Loss: 0.43271\n",
      "t: 10 EPOCH 10817 -- Train Loss: 0.32598  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 10818 -- Train Loss: 0.32504  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 10819 -- Train Loss: 0.32498  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 10820 -- Train Loss: 0.32486  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 10821 -- Train Loss: 0.32560  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 10822 -- Train Loss: 0.32505  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 10823 -- Train Loss: 0.32529  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 10824 -- Train Loss: 0.32568  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 10825 -- Train Loss: 0.32482  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10826 -- Train Loss: 0.32504  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 10827 -- Train Loss: 0.32555  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 10828 -- Train Loss: 0.32484  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 10829 -- Train Loss: 0.32475  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 10830 -- Train Loss: 0.32539  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 10831 -- Train Loss: 0.32478  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 10832 -- Train Loss: 0.32563  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 10833 -- Train Loss: 0.32551  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 10834 -- Train Loss: 0.32511  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 10835 -- Train Loss: 0.32554  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 10836 -- Train Loss: 0.32575  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 10837 -- Train Loss: 0.32568  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 10838 -- Train Loss: 0.32584  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 10839 -- Train Loss: 0.32460  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 10840 -- Train Loss: 0.32534  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 10841 -- Train Loss: 0.32440  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 10842 -- Train Loss: 0.32507  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 10843 -- Train Loss: 0.32483  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 10844 -- Train Loss: 0.32457  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 10845 -- Train Loss: 0.32351  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 10846 -- Train Loss: 0.32537  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 10847 -- Train Loss: 0.32550  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 10848 -- Train Loss: 0.32501  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 10849 -- Train Loss: 0.32517  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 10850 -- Train Loss: 0.32528  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 10851 -- Train Loss: 0.32557  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 10852 -- Train Loss: 0.32510  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 10853 -- Train Loss: 0.32503  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 10854 -- Train Loss: 0.32466  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 10855 -- Train Loss: 0.32564  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 10856 -- Train Loss: 0.32512  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 10857 -- Train Loss: 0.32575  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 10858 -- Train Loss: 0.32521  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 10859 -- Train Loss: 0.32461  Validation Loss: 0.43649\n",
      "t: 10 EPOCH 10860 -- Train Loss: 0.32442  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 10861 -- Train Loss: 0.32642  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 10862 -- Train Loss: 0.32581  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 10863 -- Train Loss: 0.32481  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 10864 -- Train Loss: 0.32565  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 10865 -- Train Loss: 0.32440  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 10866 -- Train Loss: 0.32490  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 10867 -- Train Loss: 0.32476  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10868 -- Train Loss: 0.32536  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 10869 -- Train Loss: 0.32436  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 10870 -- Train Loss: 0.32489  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10871 -- Train Loss: 0.32437  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 10872 -- Train Loss: 0.32495  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 10873 -- Train Loss: 0.32528  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 10874 -- Train Loss: 0.32587  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 10875 -- Train Loss: 0.32491  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10876 -- Train Loss: 0.32524  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 10877 -- Train Loss: 0.32484  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 10878 -- Train Loss: 0.32526  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 10879 -- Train Loss: 0.32470  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 10880 -- Train Loss: 0.32502  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 10881 -- Train Loss: 0.32545  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 10882 -- Train Loss: 0.32453  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 10883 -- Train Loss: 0.32557  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 10884 -- Train Loss: 0.32585  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 10885 -- Train Loss: 0.32525  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10886 -- Train Loss: 0.32519  Validation Loss: 0.43281\n",
      "t: 10 EPOCH 10887 -- Train Loss: 0.32529  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 10888 -- Train Loss: 0.32571  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 10889 -- Train Loss: 0.32521  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 10890 -- Train Loss: 0.32536  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 10891 -- Train Loss: 0.32503  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 10892 -- Train Loss: 0.32605  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 10893 -- Train Loss: 0.32558  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 10894 -- Train Loss: 0.32504  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 10895 -- Train Loss: 0.32608  Validation Loss: 0.43223\n",
      "t: 10 EPOCH 10896 -- Train Loss: 0.32474  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 10897 -- Train Loss: 0.32529  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 10898 -- Train Loss: 0.32569  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 10899 -- Train Loss: 0.32508  Validation Loss: 0.43258\n",
      "t: 10 EPOCH 10900 -- Train Loss: 0.32525  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 10901 -- Train Loss: 0.32507  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 10902 -- Train Loss: 0.32499  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 10903 -- Train Loss: 0.32563  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 10904 -- Train Loss: 0.32575  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 10905 -- Train Loss: 0.32569  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 10906 -- Train Loss: 0.32558  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 10907 -- Train Loss: 0.32596  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 10908 -- Train Loss: 0.32586  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 10909 -- Train Loss: 0.32600  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 10910 -- Train Loss: 0.32532  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 10911 -- Train Loss: 0.32531  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 10912 -- Train Loss: 0.32521  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 10913 -- Train Loss: 0.32493  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 10914 -- Train Loss: 0.32507  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 10915 -- Train Loss: 0.32576  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 10916 -- Train Loss: 0.32549  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 10917 -- Train Loss: 0.32584  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 10918 -- Train Loss: 0.32548  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 10919 -- Train Loss: 0.32478  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 10920 -- Train Loss: 0.32516  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 10921 -- Train Loss: 0.32570  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 10922 -- Train Loss: 0.32532  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 10923 -- Train Loss: 0.32530  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 10924 -- Train Loss: 0.32537  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10925 -- Train Loss: 0.32486  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 10926 -- Train Loss: 0.32539  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 10927 -- Train Loss: 0.32460  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 10928 -- Train Loss: 0.32480  Validation Loss: 0.43325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 10929 -- Train Loss: 0.32456  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 10930 -- Train Loss: 0.32595  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 10931 -- Train Loss: 0.32443  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 10932 -- Train Loss: 0.32586  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 10933 -- Train Loss: 0.32532  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 10934 -- Train Loss: 0.32585  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 10935 -- Train Loss: 0.32501  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 10936 -- Train Loss: 0.32535  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 10937 -- Train Loss: 0.32602  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 10938 -- Train Loss: 0.32573  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 10939 -- Train Loss: 0.32524  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 10940 -- Train Loss: 0.32520  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 10941 -- Train Loss: 0.32602  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 10942 -- Train Loss: 0.32552  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 10943 -- Train Loss: 0.32601  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 10944 -- Train Loss: 0.32541  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 10945 -- Train Loss: 0.32636  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 10946 -- Train Loss: 0.32485  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 10947 -- Train Loss: 0.32605  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 10948 -- Train Loss: 0.32583  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 10949 -- Train Loss: 0.32526  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 10950 -- Train Loss: 0.32507  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 10951 -- Train Loss: 0.32627  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 10952 -- Train Loss: 0.32564  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 10953 -- Train Loss: 0.32531  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 10954 -- Train Loss: 0.32529  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 10955 -- Train Loss: 0.32623  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 10956 -- Train Loss: 0.32531  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 10957 -- Train Loss: 0.32549  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 10958 -- Train Loss: 0.32490  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 10959 -- Train Loss: 0.32524  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 10960 -- Train Loss: 0.32470  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 10961 -- Train Loss: 0.32552  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 10962 -- Train Loss: 0.32518  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 10963 -- Train Loss: 0.32574  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 10964 -- Train Loss: 0.32387  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 10965 -- Train Loss: 0.32590  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 10966 -- Train Loss: 0.32537  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 10967 -- Train Loss: 0.32590  Validation Loss: 0.43219\n",
      "t: 10 EPOCH 10968 -- Train Loss: 0.32517  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 10969 -- Train Loss: 0.32588  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 10970 -- Train Loss: 0.32561  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 10971 -- Train Loss: 0.32604  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 10972 -- Train Loss: 0.32492  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 10973 -- Train Loss: 0.32568  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 10974 -- Train Loss: 0.32517  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 10975 -- Train Loss: 0.32554  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 10976 -- Train Loss: 0.32558  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 10977 -- Train Loss: 0.32507  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 10978 -- Train Loss: 0.32537  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 10979 -- Train Loss: 0.32477  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 10980 -- Train Loss: 0.32502  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 10981 -- Train Loss: 0.32525  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 10982 -- Train Loss: 0.32585  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 10983 -- Train Loss: 0.32476  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 10984 -- Train Loss: 0.32523  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 10985 -- Train Loss: 0.32439  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 10986 -- Train Loss: 0.32555  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 10987 -- Train Loss: 0.32432  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 10988 -- Train Loss: 0.32501  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 10989 -- Train Loss: 0.32458  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 10990 -- Train Loss: 0.32573  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 10991 -- Train Loss: 0.32498  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 10992 -- Train Loss: 0.32569  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 10993 -- Train Loss: 0.32469  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 10994 -- Train Loss: 0.32497  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 10995 -- Train Loss: 0.32450  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 10996 -- Train Loss: 0.32625  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 10997 -- Train Loss: 0.32476  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 10998 -- Train Loss: 0.32466  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 10999 -- Train Loss: 0.32466  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 11000 -- Train Loss: 0.32532  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 11001 -- Train Loss: 0.32484  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 11002 -- Train Loss: 0.32481  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 11003 -- Train Loss: 0.32478  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 11004 -- Train Loss: 0.32412  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 11005 -- Train Loss: 0.32502  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 11006 -- Train Loss: 0.32518  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 11007 -- Train Loss: 0.32532  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 11008 -- Train Loss: 0.32422  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 11009 -- Train Loss: 0.32502  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 11010 -- Train Loss: 0.32384  Validation Loss: 0.43251\n",
      "t: 10 EPOCH 11011 -- Train Loss: 0.32419  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 11012 -- Train Loss: 0.32530  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 11013 -- Train Loss: 0.32534  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 11014 -- Train Loss: 0.32491  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 11015 -- Train Loss: 0.32508  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 11016 -- Train Loss: 0.32528  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 11017 -- Train Loss: 0.32562  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 11018 -- Train Loss: 0.32375  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 11019 -- Train Loss: 0.32434  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11020 -- Train Loss: 0.32456  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 11021 -- Train Loss: 0.32606  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 11022 -- Train Loss: 0.32364  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 11023 -- Train Loss: 0.32540  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 11024 -- Train Loss: 0.32566  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 11025 -- Train Loss: 0.32466  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 11026 -- Train Loss: 0.32425  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 11027 -- Train Loss: 0.32606  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11028 -- Train Loss: 0.32466  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 11029 -- Train Loss: 0.32476  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 11030 -- Train Loss: 0.32438  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 11031 -- Train Loss: 0.32446  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 11032 -- Train Loss: 0.32499  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 11033 -- Train Loss: 0.32484  Validation Loss: 0.43222\n",
      "t: 10 EPOCH 11034 -- Train Loss: 0.32542  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 11035 -- Train Loss: 0.32407  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 11036 -- Train Loss: 0.32527  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 11037 -- Train Loss: 0.32462  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 11038 -- Train Loss: 0.32483  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 11039 -- Train Loss: 0.32506  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 11040 -- Train Loss: 0.32535  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 11041 -- Train Loss: 0.32531  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 11042 -- Train Loss: 0.32413  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 11043 -- Train Loss: 0.32384  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 11044 -- Train Loss: 0.32564  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 11045 -- Train Loss: 0.32520  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 11046 -- Train Loss: 0.32501  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 11047 -- Train Loss: 0.32514  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 11048 -- Train Loss: 0.32359  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 11049 -- Train Loss: 0.32440  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 11050 -- Train Loss: 0.32591  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 11051 -- Train Loss: 0.32564  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 11052 -- Train Loss: 0.32522  Validation Loss: 0.43497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11053 -- Train Loss: 0.32532  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 11054 -- Train Loss: 0.32458  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 11055 -- Train Loss: 0.32457  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 11056 -- Train Loss: 0.32471  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 11057 -- Train Loss: 0.32492  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 11058 -- Train Loss: 0.32436  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 11059 -- Train Loss: 0.32537  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 11060 -- Train Loss: 0.32501  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 11061 -- Train Loss: 0.32452  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 11062 -- Train Loss: 0.32433  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 11063 -- Train Loss: 0.32489  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 11064 -- Train Loss: 0.32427  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11065 -- Train Loss: 0.32544  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 11066 -- Train Loss: 0.32453  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 11067 -- Train Loss: 0.32531  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 11068 -- Train Loss: 0.32450  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 11069 -- Train Loss: 0.32498  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 11070 -- Train Loss: 0.32593  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 11071 -- Train Loss: 0.32498  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 11072 -- Train Loss: 0.32466  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 11073 -- Train Loss: 0.32537  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 11074 -- Train Loss: 0.32494  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 11075 -- Train Loss: 0.32449  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11076 -- Train Loss: 0.32550  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 11077 -- Train Loss: 0.32494  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 11078 -- Train Loss: 0.32590  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11079 -- Train Loss: 0.32563  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 11080 -- Train Loss: 0.32433  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 11081 -- Train Loss: 0.32565  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 11082 -- Train Loss: 0.32510  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 11083 -- Train Loss: 0.32496  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 11084 -- Train Loss: 0.32467  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 11085 -- Train Loss: 0.32459  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 11086 -- Train Loss: 0.32574  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 11087 -- Train Loss: 0.32556  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 11088 -- Train Loss: 0.32518  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 11089 -- Train Loss: 0.32482  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 11090 -- Train Loss: 0.32493  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 11091 -- Train Loss: 0.32528  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 11092 -- Train Loss: 0.32433  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 11093 -- Train Loss: 0.32549  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 11094 -- Train Loss: 0.32547  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 11095 -- Train Loss: 0.32538  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 11096 -- Train Loss: 0.32528  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 11097 -- Train Loss: 0.32560  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11098 -- Train Loss: 0.32439  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 11099 -- Train Loss: 0.32500  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 11100 -- Train Loss: 0.32506  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 11101 -- Train Loss: 0.32448  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 11102 -- Train Loss: 0.32429  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 11103 -- Train Loss: 0.32554  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 11104 -- Train Loss: 0.32460  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 11105 -- Train Loss: 0.32515  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 11106 -- Train Loss: 0.32554  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 11107 -- Train Loss: 0.32545  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 11108 -- Train Loss: 0.32470  Validation Loss: 0.43275\n",
      "t: 10 EPOCH 11109 -- Train Loss: 0.32484  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 11110 -- Train Loss: 0.32545  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 11111 -- Train Loss: 0.32490  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 11112 -- Train Loss: 0.32490  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 11113 -- Train Loss: 0.32519  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 11114 -- Train Loss: 0.32603  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 11115 -- Train Loss: 0.32516  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 11116 -- Train Loss: 0.32567  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11117 -- Train Loss: 0.32572  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 11118 -- Train Loss: 0.32417  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 11119 -- Train Loss: 0.32510  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 11120 -- Train Loss: 0.32550  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 11121 -- Train Loss: 0.32515  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 11122 -- Train Loss: 0.32484  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 11123 -- Train Loss: 0.32489  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 11124 -- Train Loss: 0.32543  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 11125 -- Train Loss: 0.32518  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 11126 -- Train Loss: 0.32521  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 11127 -- Train Loss: 0.32466  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 11128 -- Train Loss: 0.32455  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 11129 -- Train Loss: 0.32551  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 11130 -- Train Loss: 0.32454  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 11131 -- Train Loss: 0.32526  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 11132 -- Train Loss: 0.32455  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 11133 -- Train Loss: 0.32498  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 11134 -- Train Loss: 0.32466  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 11135 -- Train Loss: 0.32415  Validation Loss: 0.43270\n",
      "t: 10 EPOCH 11136 -- Train Loss: 0.32467  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 11137 -- Train Loss: 0.32382  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 11138 -- Train Loss: 0.32390  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11139 -- Train Loss: 0.32518  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 11140 -- Train Loss: 0.32438  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 11141 -- Train Loss: 0.32506  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 11142 -- Train Loss: 0.32540  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 11143 -- Train Loss: 0.32351  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 11144 -- Train Loss: 0.32483  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 11145 -- Train Loss: 0.32416  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 11146 -- Train Loss: 0.32542  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 11147 -- Train Loss: 0.32469  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 11148 -- Train Loss: 0.32517  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 11149 -- Train Loss: 0.32563  Validation Loss: 0.43234\n",
      "t: 10 EPOCH 11150 -- Train Loss: 0.32424  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 11151 -- Train Loss: 0.32475  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 11152 -- Train Loss: 0.32557  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 11153 -- Train Loss: 0.32457  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 11154 -- Train Loss: 0.32507  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 11155 -- Train Loss: 0.32485  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 11156 -- Train Loss: 0.32447  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 11157 -- Train Loss: 0.32530  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 11158 -- Train Loss: 0.32448  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 11159 -- Train Loss: 0.32511  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 11160 -- Train Loss: 0.32435  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 11161 -- Train Loss: 0.32535  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 11162 -- Train Loss: 0.32523  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 11163 -- Train Loss: 0.32485  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 11164 -- Train Loss: 0.32490  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 11165 -- Train Loss: 0.32484  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 11166 -- Train Loss: 0.32562  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 11167 -- Train Loss: 0.32457  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 11168 -- Train Loss: 0.32543  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 11169 -- Train Loss: 0.32539  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 11170 -- Train Loss: 0.32506  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 11171 -- Train Loss: 0.32523  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 11172 -- Train Loss: 0.32499  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 11173 -- Train Loss: 0.32523  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 11174 -- Train Loss: 0.32445  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 11175 -- Train Loss: 0.32505  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 11176 -- Train Loss: 0.32573  Validation Loss: 0.43395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11177 -- Train Loss: 0.32411  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 11178 -- Train Loss: 0.32563  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 11179 -- Train Loss: 0.32503  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 11180 -- Train Loss: 0.32565  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 11181 -- Train Loss: 0.32457  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 11182 -- Train Loss: 0.32549  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11183 -- Train Loss: 0.32495  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 11184 -- Train Loss: 0.32499  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 11185 -- Train Loss: 0.32500  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 11186 -- Train Loss: 0.32501  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 11187 -- Train Loss: 0.32506  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 11188 -- Train Loss: 0.32426  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 11189 -- Train Loss: 0.32444  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11190 -- Train Loss: 0.32455  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 11191 -- Train Loss: 0.32518  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 11192 -- Train Loss: 0.32552  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 11193 -- Train Loss: 0.32527  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 11194 -- Train Loss: 0.32557  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 11195 -- Train Loss: 0.32549  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 11196 -- Train Loss: 0.32492  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 11197 -- Train Loss: 0.32454  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 11198 -- Train Loss: 0.32453  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 11199 -- Train Loss: 0.32471  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 11200 -- Train Loss: 0.32461  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 11201 -- Train Loss: 0.32504  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 11202 -- Train Loss: 0.32619  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 11203 -- Train Loss: 0.32541  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 11204 -- Train Loss: 0.32539  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 11205 -- Train Loss: 0.32565  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 11206 -- Train Loss: 0.32639  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 11207 -- Train Loss: 0.32533  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 11208 -- Train Loss: 0.32664  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 11209 -- Train Loss: 0.32506  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 11210 -- Train Loss: 0.32668  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 11211 -- Train Loss: 0.32428  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 11212 -- Train Loss: 0.32614  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 11213 -- Train Loss: 0.32509  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 11214 -- Train Loss: 0.32605  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11215 -- Train Loss: 0.32477  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 11216 -- Train Loss: 0.32601  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 11217 -- Train Loss: 0.32580  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 11218 -- Train Loss: 0.32525  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 11219 -- Train Loss: 0.32487  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 11220 -- Train Loss: 0.32469  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 11221 -- Train Loss: 0.32637  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 11222 -- Train Loss: 0.32454  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 11223 -- Train Loss: 0.32620  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 11224 -- Train Loss: 0.32475  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 11225 -- Train Loss: 0.32554  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 11226 -- Train Loss: 0.32486  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 11227 -- Train Loss: 0.32611  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 11228 -- Train Loss: 0.32474  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11229 -- Train Loss: 0.32511  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 11230 -- Train Loss: 0.32516  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 11231 -- Train Loss: 0.32487  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 11232 -- Train Loss: 0.32503  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 11233 -- Train Loss: 0.32503  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11234 -- Train Loss: 0.32576  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 11235 -- Train Loss: 0.32483  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 11236 -- Train Loss: 0.32543  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 11237 -- Train Loss: 0.32556  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 11238 -- Train Loss: 0.32593  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 11239 -- Train Loss: 0.32475  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 11240 -- Train Loss: 0.32537  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 11241 -- Train Loss: 0.32458  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 11242 -- Train Loss: 0.32617  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 11243 -- Train Loss: 0.32380  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 11244 -- Train Loss: 0.32608  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 11245 -- Train Loss: 0.32481  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 11246 -- Train Loss: 0.32519  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 11247 -- Train Loss: 0.32554  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 11248 -- Train Loss: 0.32463  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11249 -- Train Loss: 0.32504  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 11250 -- Train Loss: 0.32598  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 11251 -- Train Loss: 0.32579  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 11252 -- Train Loss: 0.32525  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 11253 -- Train Loss: 0.32558  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 11254 -- Train Loss: 0.32528  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 11255 -- Train Loss: 0.32610  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 11256 -- Train Loss: 0.32535  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 11257 -- Train Loss: 0.32488  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 11258 -- Train Loss: 0.32444  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11259 -- Train Loss: 0.32471  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 11260 -- Train Loss: 0.32499  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 11261 -- Train Loss: 0.32456  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 11262 -- Train Loss: 0.32520  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 11263 -- Train Loss: 0.32505  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 11264 -- Train Loss: 0.32465  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 11265 -- Train Loss: 0.32448  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 11266 -- Train Loss: 0.32482  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 11267 -- Train Loss: 0.32489  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 11268 -- Train Loss: 0.32574  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 11269 -- Train Loss: 0.32529  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 11270 -- Train Loss: 0.32447  Validation Loss: 0.43225\n",
      "t: 10 EPOCH 11271 -- Train Loss: 0.32503  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11272 -- Train Loss: 0.32554  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 11273 -- Train Loss: 0.32488  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 11274 -- Train Loss: 0.32521  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 11275 -- Train Loss: 0.32491  Validation Loss: 0.43253\n",
      "t: 10 EPOCH 11276 -- Train Loss: 0.32553  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 11277 -- Train Loss: 0.32444  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 11278 -- Train Loss: 0.32481  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 11279 -- Train Loss: 0.32510  Validation Loss: 0.43255\n",
      "t: 10 EPOCH 11280 -- Train Loss: 0.32549  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 11281 -- Train Loss: 0.32492  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 11282 -- Train Loss: 0.32493  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 11283 -- Train Loss: 0.32471  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 11284 -- Train Loss: 0.32513  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 11285 -- Train Loss: 0.32461  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 11286 -- Train Loss: 0.32504  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 11287 -- Train Loss: 0.32533  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11288 -- Train Loss: 0.32498  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 11289 -- Train Loss: 0.32491  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 11290 -- Train Loss: 0.32461  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 11291 -- Train Loss: 0.32513  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 11292 -- Train Loss: 0.32485  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 11293 -- Train Loss: 0.32451  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 11294 -- Train Loss: 0.32374  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 11295 -- Train Loss: 0.32531  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 11296 -- Train Loss: 0.32458  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 11297 -- Train Loss: 0.32607  Validation Loss: 0.43202\n",
      "t: 10 EPOCH 11298 -- Train Loss: 0.32441  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11299 -- Train Loss: 0.32462  Validation Loss: 0.43361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11300 -- Train Loss: 0.32319  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 11301 -- Train Loss: 0.32468  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 11302 -- Train Loss: 0.32511  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 11303 -- Train Loss: 0.32499  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 11304 -- Train Loss: 0.32527  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 11305 -- Train Loss: 0.32417  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 11306 -- Train Loss: 0.32407  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 11307 -- Train Loss: 0.32474  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 11308 -- Train Loss: 0.32387  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 11309 -- Train Loss: 0.32475  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 11310 -- Train Loss: 0.32458  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11311 -- Train Loss: 0.32531  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 11312 -- Train Loss: 0.32417  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 11313 -- Train Loss: 0.32499  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 11314 -- Train Loss: 0.32457  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 11315 -- Train Loss: 0.32475  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 11316 -- Train Loss: 0.32446  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 11317 -- Train Loss: 0.32562  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 11318 -- Train Loss: 0.32525  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 11319 -- Train Loss: 0.32538  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 11320 -- Train Loss: 0.32408  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 11321 -- Train Loss: 0.32509  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 11322 -- Train Loss: 0.32404  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11323 -- Train Loss: 0.32538  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 11324 -- Train Loss: 0.32469  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 11325 -- Train Loss: 0.32516  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 11326 -- Train Loss: 0.32442  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 11327 -- Train Loss: 0.32553  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 11328 -- Train Loss: 0.32461  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 11329 -- Train Loss: 0.32441  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 11330 -- Train Loss: 0.32547  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 11331 -- Train Loss: 0.32506  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 11332 -- Train Loss: 0.32507  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11333 -- Train Loss: 0.32487  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 11334 -- Train Loss: 0.32502  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 11335 -- Train Loss: 0.32499  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11336 -- Train Loss: 0.32465  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 11337 -- Train Loss: 0.32471  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 11338 -- Train Loss: 0.32425  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 11339 -- Train Loss: 0.32448  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 11340 -- Train Loss: 0.32453  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 11341 -- Train Loss: 0.32539  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 11342 -- Train Loss: 0.32488  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 11343 -- Train Loss: 0.32543  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11344 -- Train Loss: 0.32434  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 11345 -- Train Loss: 0.32444  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 11346 -- Train Loss: 0.32494  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11347 -- Train Loss: 0.32529  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 11348 -- Train Loss: 0.32472  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 11349 -- Train Loss: 0.32499  Validation Loss: 0.43260\n",
      "t: 10 EPOCH 11350 -- Train Loss: 0.32529  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 11351 -- Train Loss: 0.32518  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 11352 -- Train Loss: 0.32544  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 11353 -- Train Loss: 0.32422  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 11354 -- Train Loss: 0.32545  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 11355 -- Train Loss: 0.32428  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 11356 -- Train Loss: 0.32570  Validation Loss: 0.43240\n",
      "t: 10 EPOCH 11357 -- Train Loss: 0.32439  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 11358 -- Train Loss: 0.32569  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 11359 -- Train Loss: 0.32506  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 11360 -- Train Loss: 0.32557  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 11361 -- Train Loss: 0.32505  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 11362 -- Train Loss: 0.32504  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 11363 -- Train Loss: 0.32440  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 11364 -- Train Loss: 0.32451  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 11365 -- Train Loss: 0.32502  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 11366 -- Train Loss: 0.32526  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 11367 -- Train Loss: 0.32528  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 11368 -- Train Loss: 0.32507  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 11369 -- Train Loss: 0.32417  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 11370 -- Train Loss: 0.32413  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 11371 -- Train Loss: 0.32506  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 11372 -- Train Loss: 0.32411  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 11373 -- Train Loss: 0.32533  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11374 -- Train Loss: 0.32424  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 11375 -- Train Loss: 0.32548  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 11376 -- Train Loss: 0.32476  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 11377 -- Train Loss: 0.32464  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 11378 -- Train Loss: 0.32400  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11379 -- Train Loss: 0.32535  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 11380 -- Train Loss: 0.32504  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 11381 -- Train Loss: 0.32460  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 11382 -- Train Loss: 0.32382  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 11383 -- Train Loss: 0.32498  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 11384 -- Train Loss: 0.32441  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 11385 -- Train Loss: 0.32539  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 11386 -- Train Loss: 0.32438  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 11387 -- Train Loss: 0.32497  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 11388 -- Train Loss: 0.32475  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 11389 -- Train Loss: 0.32468  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 11390 -- Train Loss: 0.32331  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 11391 -- Train Loss: 0.32378  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 11392 -- Train Loss: 0.32535  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 11393 -- Train Loss: 0.32530  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11394 -- Train Loss: 0.32476  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 11395 -- Train Loss: 0.32522  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 11396 -- Train Loss: 0.32542  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11397 -- Train Loss: 0.32549  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 11398 -- Train Loss: 0.32489  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 11399 -- Train Loss: 0.32451  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 11400 -- Train Loss: 0.32487  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 11401 -- Train Loss: 0.32490  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11402 -- Train Loss: 0.32477  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 11403 -- Train Loss: 0.32460  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 11404 -- Train Loss: 0.32431  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 11405 -- Train Loss: 0.32461  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 11406 -- Train Loss: 0.32500  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 11407 -- Train Loss: 0.32411  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 11408 -- Train Loss: 0.32558  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 11409 -- Train Loss: 0.32468  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 11410 -- Train Loss: 0.32460  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 11411 -- Train Loss: 0.32474  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 11412 -- Train Loss: 0.32468  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 11413 -- Train Loss: 0.32554  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 11414 -- Train Loss: 0.32619  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 11415 -- Train Loss: 0.32439  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 11416 -- Train Loss: 0.32525  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 11417 -- Train Loss: 0.32444  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 11418 -- Train Loss: 0.32421  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 11419 -- Train Loss: 0.32471  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 11420 -- Train Loss: 0.32500  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 11421 -- Train Loss: 0.32494  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 11422 -- Train Loss: 0.32441  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 11423 -- Train Loss: 0.32528  Validation Loss: 0.43287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11424 -- Train Loss: 0.32434  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 11425 -- Train Loss: 0.32523  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 11426 -- Train Loss: 0.32475  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 11427 -- Train Loss: 0.32451  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 11428 -- Train Loss: 0.32436  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 11429 -- Train Loss: 0.32417  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 11430 -- Train Loss: 0.32424  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 11431 -- Train Loss: 0.32449  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 11432 -- Train Loss: 0.32419  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 11433 -- Train Loss: 0.32472  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11434 -- Train Loss: 0.32410  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 11435 -- Train Loss: 0.32433  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 11436 -- Train Loss: 0.32446  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 11437 -- Train Loss: 0.32472  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 11438 -- Train Loss: 0.32515  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 11439 -- Train Loss: 0.32493  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 11440 -- Train Loss: 0.32512  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 11441 -- Train Loss: 0.32500  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 11442 -- Train Loss: 0.32441  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 11443 -- Train Loss: 0.32392  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 11444 -- Train Loss: 0.32495  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 11445 -- Train Loss: 0.32508  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 11446 -- Train Loss: 0.32548  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 11447 -- Train Loss: 0.32393  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 11448 -- Train Loss: 0.32549  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 11449 -- Train Loss: 0.32488  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 11450 -- Train Loss: 0.32484  Validation Loss: 0.43200\n",
      "t: 10 EPOCH 11451 -- Train Loss: 0.32480  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 11452 -- Train Loss: 0.32421  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 11453 -- Train Loss: 0.32480  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 11454 -- Train Loss: 0.32486  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 11455 -- Train Loss: 0.32438  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 11456 -- Train Loss: 0.32547  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 11457 -- Train Loss: 0.32488  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 11458 -- Train Loss: 0.32503  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 11459 -- Train Loss: 0.32511  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 11460 -- Train Loss: 0.32549  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 11461 -- Train Loss: 0.32477  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 11462 -- Train Loss: 0.32537  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 11463 -- Train Loss: 0.32561  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 11464 -- Train Loss: 0.32514  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 11465 -- Train Loss: 0.32451  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 11466 -- Train Loss: 0.32558  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 11467 -- Train Loss: 0.32499  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 11468 -- Train Loss: 0.32494  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 11469 -- Train Loss: 0.32533  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 11470 -- Train Loss: 0.32528  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 11471 -- Train Loss: 0.32560  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 11472 -- Train Loss: 0.32487  Validation Loss: 0.43238\n",
      "t: 10 EPOCH 11473 -- Train Loss: 0.32573  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 11474 -- Train Loss: 0.32451  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 11475 -- Train Loss: 0.32506  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 11476 -- Train Loss: 0.32491  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 11477 -- Train Loss: 0.32445  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 11478 -- Train Loss: 0.32447  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 11479 -- Train Loss: 0.32503  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 11480 -- Train Loss: 0.32525  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11481 -- Train Loss: 0.32527  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 11482 -- Train Loss: 0.32474  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 11483 -- Train Loss: 0.32509  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 11484 -- Train Loss: 0.32558  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 11485 -- Train Loss: 0.32497  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 11486 -- Train Loss: 0.32472  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 11487 -- Train Loss: 0.32497  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 11488 -- Train Loss: 0.32541  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 11489 -- Train Loss: 0.32427  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 11490 -- Train Loss: 0.32585  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 11491 -- Train Loss: 0.32411  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 11492 -- Train Loss: 0.32506  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11493 -- Train Loss: 0.32492  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 11494 -- Train Loss: 0.32541  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 11495 -- Train Loss: 0.32397  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 11496 -- Train Loss: 0.32584  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 11497 -- Train Loss: 0.32519  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 11498 -- Train Loss: 0.32495  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 11499 -- Train Loss: 0.32430  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 11500 -- Train Loss: 0.32496  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 11501 -- Train Loss: 0.32462  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11502 -- Train Loss: 0.32506  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 11503 -- Train Loss: 0.32493  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11504 -- Train Loss: 0.32452  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 11505 -- Train Loss: 0.32473  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11506 -- Train Loss: 0.32438  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 11507 -- Train Loss: 0.32512  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 11508 -- Train Loss: 0.32379  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 11509 -- Train Loss: 0.32524  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 11510 -- Train Loss: 0.32514  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 11511 -- Train Loss: 0.32392  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 11512 -- Train Loss: 0.32407  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11513 -- Train Loss: 0.32462  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 11514 -- Train Loss: 0.32473  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 11515 -- Train Loss: 0.32507  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 11516 -- Train Loss: 0.32432  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 11517 -- Train Loss: 0.32463  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 11518 -- Train Loss: 0.32422  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11519 -- Train Loss: 0.32525  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 11520 -- Train Loss: 0.32591  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 11521 -- Train Loss: 0.32467  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 11522 -- Train Loss: 0.32545  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 11523 -- Train Loss: 0.32429  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 11524 -- Train Loss: 0.32509  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11525 -- Train Loss: 0.32448  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 11526 -- Train Loss: 0.32487  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 11527 -- Train Loss: 0.32432  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 11528 -- Train Loss: 0.32452  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 11529 -- Train Loss: 0.32417  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 11530 -- Train Loss: 0.32487  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 11531 -- Train Loss: 0.32514  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 11532 -- Train Loss: 0.32393  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11533 -- Train Loss: 0.32433  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 11534 -- Train Loss: 0.32486  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 11535 -- Train Loss: 0.32414  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 11536 -- Train Loss: 0.32511  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 11537 -- Train Loss: 0.32383  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 11538 -- Train Loss: 0.32448  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 11539 -- Train Loss: 0.32455  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 11540 -- Train Loss: 0.32425  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11541 -- Train Loss: 0.32524  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 11542 -- Train Loss: 0.32481  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 11543 -- Train Loss: 0.32389  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 11544 -- Train Loss: 0.32583  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 11545 -- Train Loss: 0.32440  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 11546 -- Train Loss: 0.32427  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11547 -- Train Loss: 0.32445  Validation Loss: 0.43316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11548 -- Train Loss: 0.32464  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 11549 -- Train Loss: 0.32436  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 11550 -- Train Loss: 0.32421  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 11551 -- Train Loss: 0.32433  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 11552 -- Train Loss: 0.32449  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 11553 -- Train Loss: 0.32447  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 11554 -- Train Loss: 0.32388  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 11555 -- Train Loss: 0.32431  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 11556 -- Train Loss: 0.32498  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 11557 -- Train Loss: 0.32425  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11558 -- Train Loss: 0.32486  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 11559 -- Train Loss: 0.32506  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 11560 -- Train Loss: 0.32401  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 11561 -- Train Loss: 0.32495  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 11562 -- Train Loss: 0.32479  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 11563 -- Train Loss: 0.32421  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 11564 -- Train Loss: 0.32412  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 11565 -- Train Loss: 0.32427  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 11566 -- Train Loss: 0.32499  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 11567 -- Train Loss: 0.32510  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 11568 -- Train Loss: 0.32454  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 11569 -- Train Loss: 0.32523  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11570 -- Train Loss: 0.32369  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 11571 -- Train Loss: 0.32439  Validation Loss: 0.43273\n",
      "t: 10 EPOCH 11572 -- Train Loss: 0.32412  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11573 -- Train Loss: 0.32461  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 11574 -- Train Loss: 0.32428  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 11575 -- Train Loss: 0.32365  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 11576 -- Train Loss: 0.32468  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11577 -- Train Loss: 0.32491  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 11578 -- Train Loss: 0.32494  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 11579 -- Train Loss: 0.32484  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 11580 -- Train Loss: 0.32489  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 11581 -- Train Loss: 0.32495  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 11582 -- Train Loss: 0.32471  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 11583 -- Train Loss: 0.32405  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 11584 -- Train Loss: 0.32382  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11585 -- Train Loss: 0.32503  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 11586 -- Train Loss: 0.32479  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 11587 -- Train Loss: 0.32528  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 11588 -- Train Loss: 0.32424  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 11589 -- Train Loss: 0.32510  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 11590 -- Train Loss: 0.32515  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 11591 -- Train Loss: 0.32567  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 11592 -- Train Loss: 0.32488  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 11593 -- Train Loss: 0.32492  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 11594 -- Train Loss: 0.32402  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 11595 -- Train Loss: 0.32511  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 11596 -- Train Loss: 0.32351  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 11597 -- Train Loss: 0.32509  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 11598 -- Train Loss: 0.32467  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 11599 -- Train Loss: 0.32497  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 11600 -- Train Loss: 0.32409  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 11601 -- Train Loss: 0.32559  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 11602 -- Train Loss: 0.32480  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 11603 -- Train Loss: 0.32464  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 11604 -- Train Loss: 0.32573  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 11605 -- Train Loss: 0.32593  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 11606 -- Train Loss: 0.32431  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 11607 -- Train Loss: 0.32509  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 11608 -- Train Loss: 0.32446  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 11609 -- Train Loss: 0.32640  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 11610 -- Train Loss: 0.32530  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 11611 -- Train Loss: 0.32509  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 11612 -- Train Loss: 0.32408  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11613 -- Train Loss: 0.32663  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 11614 -- Train Loss: 0.32398  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 11615 -- Train Loss: 0.32615  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 11616 -- Train Loss: 0.32502  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 11617 -- Train Loss: 0.32561  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 11618 -- Train Loss: 0.32512  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 11619 -- Train Loss: 0.32562  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 11620 -- Train Loss: 0.32361  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 11621 -- Train Loss: 0.32396  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11622 -- Train Loss: 0.32439  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 11623 -- Train Loss: 0.32517  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 11624 -- Train Loss: 0.32491  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 11625 -- Train Loss: 0.32490  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 11626 -- Train Loss: 0.32412  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 11627 -- Train Loss: 0.32506  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 11628 -- Train Loss: 0.32462  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 11629 -- Train Loss: 0.32591  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 11630 -- Train Loss: 0.32462  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 11631 -- Train Loss: 0.32572  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 11632 -- Train Loss: 0.32465  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 11633 -- Train Loss: 0.32507  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 11634 -- Train Loss: 0.32588  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 11635 -- Train Loss: 0.32476  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 11636 -- Train Loss: 0.32556  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 11637 -- Train Loss: 0.32427  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 11638 -- Train Loss: 0.32592  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 11639 -- Train Loss: 0.32481  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 11640 -- Train Loss: 0.32606  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 11641 -- Train Loss: 0.32472  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 11642 -- Train Loss: 0.32491  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 11643 -- Train Loss: 0.32467  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 11644 -- Train Loss: 0.32447  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 11645 -- Train Loss: 0.32329  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 11646 -- Train Loss: 0.32522  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 11647 -- Train Loss: 0.32439  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 11648 -- Train Loss: 0.32564  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 11649 -- Train Loss: 0.32482  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 11650 -- Train Loss: 0.32456  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 11651 -- Train Loss: 0.32463  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 11652 -- Train Loss: 0.32438  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 11653 -- Train Loss: 0.32511  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11654 -- Train Loss: 0.32600  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 11655 -- Train Loss: 0.32441  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 11656 -- Train Loss: 0.32510  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 11657 -- Train Loss: 0.32432  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 11658 -- Train Loss: 0.32460  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 11659 -- Train Loss: 0.32471  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 11660 -- Train Loss: 0.32499  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 11661 -- Train Loss: 0.32431  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 11662 -- Train Loss: 0.32521  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 11663 -- Train Loss: 0.32425  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 11664 -- Train Loss: 0.32490  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 11665 -- Train Loss: 0.32495  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 11666 -- Train Loss: 0.32415  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 11667 -- Train Loss: 0.32473  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 11668 -- Train Loss: 0.32564  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 11669 -- Train Loss: 0.32432  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 11670 -- Train Loss: 0.32360  Validation Loss: 0.43264\n",
      "t: 10 EPOCH 11671 -- Train Loss: 0.32537  Validation Loss: 0.43385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11672 -- Train Loss: 0.32368  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 11673 -- Train Loss: 0.32538  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 11674 -- Train Loss: 0.32425  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 11675 -- Train Loss: 0.32418  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 11676 -- Train Loss: 0.32394  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 11677 -- Train Loss: 0.32506  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 11678 -- Train Loss: 0.32524  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11679 -- Train Loss: 0.32542  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 11680 -- Train Loss: 0.32473  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 11681 -- Train Loss: 0.32493  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 11682 -- Train Loss: 0.32379  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 11683 -- Train Loss: 0.32330  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 11684 -- Train Loss: 0.32510  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 11685 -- Train Loss: 0.32339  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 11686 -- Train Loss: 0.32518  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 11687 -- Train Loss: 0.32398  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 11688 -- Train Loss: 0.32414  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 11689 -- Train Loss: 0.32487  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 11690 -- Train Loss: 0.32393  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 11691 -- Train Loss: 0.32495  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 11692 -- Train Loss: 0.32411  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 11693 -- Train Loss: 0.32317  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 11694 -- Train Loss: 0.32332  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 11695 -- Train Loss: 0.32414  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 11696 -- Train Loss: 0.32390  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 11697 -- Train Loss: 0.32406  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 11698 -- Train Loss: 0.32406  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 11699 -- Train Loss: 0.32468  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 11700 -- Train Loss: 0.32447  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 11701 -- Train Loss: 0.32447  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 11702 -- Train Loss: 0.32431  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11703 -- Train Loss: 0.32412  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 11704 -- Train Loss: 0.32449  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 11705 -- Train Loss: 0.32483  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 11706 -- Train Loss: 0.32394  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 11707 -- Train Loss: 0.32299  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 11708 -- Train Loss: 0.32444  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 11709 -- Train Loss: 0.32370  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 11710 -- Train Loss: 0.32411  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 11711 -- Train Loss: 0.32435  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 11712 -- Train Loss: 0.32471  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 11713 -- Train Loss: 0.32482  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 11714 -- Train Loss: 0.32524  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 11715 -- Train Loss: 0.32453  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 11716 -- Train Loss: 0.32477  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 11717 -- Train Loss: 0.32455  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 11718 -- Train Loss: 0.32516  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 11719 -- Train Loss: 0.32480  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 11720 -- Train Loss: 0.32441  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 11721 -- Train Loss: 0.32441  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11722 -- Train Loss: 0.32504  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 11723 -- Train Loss: 0.32388  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 11724 -- Train Loss: 0.32482  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 11725 -- Train Loss: 0.32451  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 11726 -- Train Loss: 0.32443  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 11727 -- Train Loss: 0.32476  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 11728 -- Train Loss: 0.32422  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 11729 -- Train Loss: 0.32511  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 11730 -- Train Loss: 0.32471  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 11731 -- Train Loss: 0.32491  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 11732 -- Train Loss: 0.32419  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 11733 -- Train Loss: 0.32446  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 11734 -- Train Loss: 0.32366  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 11735 -- Train Loss: 0.32421  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 11736 -- Train Loss: 0.32396  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 11737 -- Train Loss: 0.32504  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 11738 -- Train Loss: 0.32444  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 11739 -- Train Loss: 0.32395  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 11740 -- Train Loss: 0.32443  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 11741 -- Train Loss: 0.32385  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 11742 -- Train Loss: 0.32500  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 11743 -- Train Loss: 0.32402  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11744 -- Train Loss: 0.32521  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 11745 -- Train Loss: 0.32438  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 11746 -- Train Loss: 0.32390  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 11747 -- Train Loss: 0.32435  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 11748 -- Train Loss: 0.32433  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 11749 -- Train Loss: 0.32431  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 11750 -- Train Loss: 0.32514  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 11751 -- Train Loss: 0.32473  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 11752 -- Train Loss: 0.32485  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 11753 -- Train Loss: 0.32404  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 11754 -- Train Loss: 0.32456  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 11755 -- Train Loss: 0.32400  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 11756 -- Train Loss: 0.32527  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 11757 -- Train Loss: 0.32544  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 11758 -- Train Loss: 0.32450  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 11759 -- Train Loss: 0.32457  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 11760 -- Train Loss: 0.32365  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 11761 -- Train Loss: 0.32453  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 11762 -- Train Loss: 0.32500  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 11763 -- Train Loss: 0.32463  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 11764 -- Train Loss: 0.32403  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 11765 -- Train Loss: 0.32549  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 11766 -- Train Loss: 0.32378  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 11767 -- Train Loss: 0.32490  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 11768 -- Train Loss: 0.32406  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 11769 -- Train Loss: 0.32450  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 11770 -- Train Loss: 0.32403  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 11771 -- Train Loss: 0.32480  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 11772 -- Train Loss: 0.32472  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 11773 -- Train Loss: 0.32464  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 11774 -- Train Loss: 0.32477  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 11775 -- Train Loss: 0.32444  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 11776 -- Train Loss: 0.32488  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 11777 -- Train Loss: 0.32549  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 11778 -- Train Loss: 0.32465  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 11779 -- Train Loss: 0.32538  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 11780 -- Train Loss: 0.32468  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 11781 -- Train Loss: 0.32513  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 11782 -- Train Loss: 0.32445  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 11783 -- Train Loss: 0.32442  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 11784 -- Train Loss: 0.32475  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 11785 -- Train Loss: 0.32537  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 11786 -- Train Loss: 0.32449  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 11787 -- Train Loss: 0.32486  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 11788 -- Train Loss: 0.32536  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 11789 -- Train Loss: 0.32561  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 11790 -- Train Loss: 0.32442  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 11791 -- Train Loss: 0.32582  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 11792 -- Train Loss: 0.32514  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 11793 -- Train Loss: 0.32484  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 11794 -- Train Loss: 0.32432  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 11795 -- Train Loss: 0.32471  Validation Loss: 0.43268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11796 -- Train Loss: 0.32494  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 11797 -- Train Loss: 0.32524  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 11798 -- Train Loss: 0.32472  Validation Loss: 0.43284\n",
      "t: 10 EPOCH 11799 -- Train Loss: 0.32426  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11800 -- Train Loss: 0.32419  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 11801 -- Train Loss: 0.32443  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 11802 -- Train Loss: 0.32444  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 11803 -- Train Loss: 0.32461  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 11804 -- Train Loss: 0.32580  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 11805 -- Train Loss: 0.32440  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 11806 -- Train Loss: 0.32524  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 11807 -- Train Loss: 0.32509  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 11808 -- Train Loss: 0.32568  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 11809 -- Train Loss: 0.32482  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 11810 -- Train Loss: 0.32554  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 11811 -- Train Loss: 0.32443  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11812 -- Train Loss: 0.32529  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 11813 -- Train Loss: 0.32436  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11814 -- Train Loss: 0.32480  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 11815 -- Train Loss: 0.32498  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 11816 -- Train Loss: 0.32452  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 11817 -- Train Loss: 0.32550  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 11818 -- Train Loss: 0.32470  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 11819 -- Train Loss: 0.32553  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 11820 -- Train Loss: 0.32368  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 11821 -- Train Loss: 0.32502  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 11822 -- Train Loss: 0.32418  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 11823 -- Train Loss: 0.32427  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 11824 -- Train Loss: 0.32455  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 11825 -- Train Loss: 0.32474  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 11826 -- Train Loss: 0.32502  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 11827 -- Train Loss: 0.32473  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 11828 -- Train Loss: 0.32483  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 11829 -- Train Loss: 0.32475  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 11830 -- Train Loss: 0.32442  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 11831 -- Train Loss: 0.32397  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 11832 -- Train Loss: 0.32481  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 11833 -- Train Loss: 0.32461  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 11834 -- Train Loss: 0.32429  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 11835 -- Train Loss: 0.32416  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 11836 -- Train Loss: 0.32479  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11837 -- Train Loss: 0.32501  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 11838 -- Train Loss: 0.32471  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 11839 -- Train Loss: 0.32462  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 11840 -- Train Loss: 0.32307  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 11841 -- Train Loss: 0.32422  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 11842 -- Train Loss: 0.32357  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 11843 -- Train Loss: 0.32433  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 11844 -- Train Loss: 0.32361  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 11845 -- Train Loss: 0.32473  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 11846 -- Train Loss: 0.32454  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 11847 -- Train Loss: 0.32379  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 11848 -- Train Loss: 0.32480  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 11849 -- Train Loss: 0.32402  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 11850 -- Train Loss: 0.32502  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 11851 -- Train Loss: 0.32478  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 11852 -- Train Loss: 0.32464  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 11853 -- Train Loss: 0.32502  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 11854 -- Train Loss: 0.32370  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 11855 -- Train Loss: 0.32437  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11856 -- Train Loss: 0.32451  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 11857 -- Train Loss: 0.32371  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 11858 -- Train Loss: 0.32533  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 11859 -- Train Loss: 0.32423  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 11860 -- Train Loss: 0.32408  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 11861 -- Train Loss: 0.32531  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 11862 -- Train Loss: 0.32418  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 11863 -- Train Loss: 0.32375  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 11864 -- Train Loss: 0.32449  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11865 -- Train Loss: 0.32464  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 11866 -- Train Loss: 0.32359  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 11867 -- Train Loss: 0.32506  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 11868 -- Train Loss: 0.32339  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 11869 -- Train Loss: 0.32464  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 11870 -- Train Loss: 0.32411  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11871 -- Train Loss: 0.32512  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 11872 -- Train Loss: 0.32439  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 11873 -- Train Loss: 0.32505  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 11874 -- Train Loss: 0.32410  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 11875 -- Train Loss: 0.32483  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 11876 -- Train Loss: 0.32495  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 11877 -- Train Loss: 0.32371  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 11878 -- Train Loss: 0.32365  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 11879 -- Train Loss: 0.32362  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 11880 -- Train Loss: 0.32412  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11881 -- Train Loss: 0.32437  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 11882 -- Train Loss: 0.32400  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 11883 -- Train Loss: 0.32369  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11884 -- Train Loss: 0.32500  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 11885 -- Train Loss: 0.32452  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 11886 -- Train Loss: 0.32422  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 11887 -- Train Loss: 0.32394  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 11888 -- Train Loss: 0.32466  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 11889 -- Train Loss: 0.32411  Validation Loss: 0.43287\n",
      "t: 10 EPOCH 11890 -- Train Loss: 0.32389  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 11891 -- Train Loss: 0.32412  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 11892 -- Train Loss: 0.32502  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 11893 -- Train Loss: 0.32473  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11894 -- Train Loss: 0.32397  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 11895 -- Train Loss: 0.32551  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 11896 -- Train Loss: 0.32405  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 11897 -- Train Loss: 0.32506  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 11898 -- Train Loss: 0.32423  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 11899 -- Train Loss: 0.32479  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 11900 -- Train Loss: 0.32390  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 11901 -- Train Loss: 0.32476  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 11902 -- Train Loss: 0.32493  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 11903 -- Train Loss: 0.32475  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 11904 -- Train Loss: 0.32428  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 11905 -- Train Loss: 0.32498  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 11906 -- Train Loss: 0.32445  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 11907 -- Train Loss: 0.32396  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 11908 -- Train Loss: 0.32370  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 11909 -- Train Loss: 0.32492  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 11910 -- Train Loss: 0.32441  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 11911 -- Train Loss: 0.32388  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 11912 -- Train Loss: 0.32379  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 11913 -- Train Loss: 0.32432  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 11914 -- Train Loss: 0.32334  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 11915 -- Train Loss: 0.32576  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 11916 -- Train Loss: 0.32514  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 11917 -- Train Loss: 0.32430  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 11918 -- Train Loss: 0.32305  Validation Loss: 0.43254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 11919 -- Train Loss: 0.32503  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 11920 -- Train Loss: 0.32531  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11921 -- Train Loss: 0.32520  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 11922 -- Train Loss: 0.32418  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 11923 -- Train Loss: 0.32519  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 11924 -- Train Loss: 0.32428  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 11925 -- Train Loss: 0.32420  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 11926 -- Train Loss: 0.32408  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 11927 -- Train Loss: 0.32523  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 11928 -- Train Loss: 0.32482  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 11929 -- Train Loss: 0.32538  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 11930 -- Train Loss: 0.32533  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 11931 -- Train Loss: 0.32451  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 11932 -- Train Loss: 0.32450  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 11933 -- Train Loss: 0.32424  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 11934 -- Train Loss: 0.32470  Validation Loss: 0.43173\n",
      "t: 10 EPOCH 11935 -- Train Loss: 0.32475  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 11936 -- Train Loss: 0.32485  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 11937 -- Train Loss: 0.32406  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 11938 -- Train Loss: 0.32477  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 11939 -- Train Loss: 0.32471  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 11940 -- Train Loss: 0.32485  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 11941 -- Train Loss: 0.32459  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 11942 -- Train Loss: 0.32457  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 11943 -- Train Loss: 0.32432  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 11944 -- Train Loss: 0.32396  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 11945 -- Train Loss: 0.32381  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 11946 -- Train Loss: 0.32430  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 11947 -- Train Loss: 0.32384  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11948 -- Train Loss: 0.32480  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 11949 -- Train Loss: 0.32479  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 11950 -- Train Loss: 0.32489  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 11951 -- Train Loss: 0.32453  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 11952 -- Train Loss: 0.32514  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 11953 -- Train Loss: 0.32404  Validation Loss: 0.43216\n",
      "t: 10 EPOCH 11954 -- Train Loss: 0.32471  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 11955 -- Train Loss: 0.32504  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 11956 -- Train Loss: 0.32489  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 11957 -- Train Loss: 0.32420  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 11958 -- Train Loss: 0.32475  Validation Loss: 0.43245\n",
      "t: 10 EPOCH 11959 -- Train Loss: 0.32444  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 11960 -- Train Loss: 0.32402  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 11961 -- Train Loss: 0.32446  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 11962 -- Train Loss: 0.32509  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 11963 -- Train Loss: 0.32436  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 11964 -- Train Loss: 0.32452  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 11965 -- Train Loss: 0.32443  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 11966 -- Train Loss: 0.32529  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 11967 -- Train Loss: 0.32527  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 11968 -- Train Loss: 0.32346  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 11969 -- Train Loss: 0.32572  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 11970 -- Train Loss: 0.32337  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 11971 -- Train Loss: 0.32408  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 11972 -- Train Loss: 0.32349  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 11973 -- Train Loss: 0.32550  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 11974 -- Train Loss: 0.32422  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 11975 -- Train Loss: 0.32529  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 11976 -- Train Loss: 0.32397  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 11977 -- Train Loss: 0.32560  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 11978 -- Train Loss: 0.32540  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 11979 -- Train Loss: 0.32544  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 11980 -- Train Loss: 0.32526  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 11981 -- Train Loss: 0.32382  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 11982 -- Train Loss: 0.32448  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 11983 -- Train Loss: 0.32498  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 11984 -- Train Loss: 0.32439  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 11985 -- Train Loss: 0.32484  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 11986 -- Train Loss: 0.32504  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 11987 -- Train Loss: 0.32477  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 11988 -- Train Loss: 0.32507  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 11989 -- Train Loss: 0.32405  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 11990 -- Train Loss: 0.32524  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 11991 -- Train Loss: 0.32426  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 11992 -- Train Loss: 0.32493  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 11993 -- Train Loss: 0.32490  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 11994 -- Train Loss: 0.32501  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 11995 -- Train Loss: 0.32489  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 11996 -- Train Loss: 0.32479  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 11997 -- Train Loss: 0.32475  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 11998 -- Train Loss: 0.32543  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 11999 -- Train Loss: 0.32444  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 12000 -- Train Loss: 0.32403  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 12001 -- Train Loss: 0.32483  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 12002 -- Train Loss: 0.32538  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 12003 -- Train Loss: 0.32402  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 12004 -- Train Loss: 0.32494  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 12005 -- Train Loss: 0.32434  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 12006 -- Train Loss: 0.32522  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 12007 -- Train Loss: 0.32463  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 12008 -- Train Loss: 0.32438  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 12009 -- Train Loss: 0.32391  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 12010 -- Train Loss: 0.32510  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 12011 -- Train Loss: 0.32467  Validation Loss: 0.43247\n",
      "t: 10 EPOCH 12012 -- Train Loss: 0.32443  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12013 -- Train Loss: 0.32404  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 12014 -- Train Loss: 0.32461  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 12015 -- Train Loss: 0.32344  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 12016 -- Train Loss: 0.32455  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 12017 -- Train Loss: 0.32417  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 12018 -- Train Loss: 0.32412  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 12019 -- Train Loss: 0.32404  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 12020 -- Train Loss: 0.32389  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 12021 -- Train Loss: 0.32430  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 12022 -- Train Loss: 0.32379  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 12023 -- Train Loss: 0.32417  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 12024 -- Train Loss: 0.32467  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 12025 -- Train Loss: 0.32439  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 12026 -- Train Loss: 0.32465  Validation Loss: 0.43324\n",
      "t: 10 EPOCH 12027 -- Train Loss: 0.32371  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 12028 -- Train Loss: 0.32341  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 12029 -- Train Loss: 0.32390  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 12030 -- Train Loss: 0.32473  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 12031 -- Train Loss: 0.32385  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12032 -- Train Loss: 0.32285  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12033 -- Train Loss: 0.32359  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 12034 -- Train Loss: 0.32382  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12035 -- Train Loss: 0.32433  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 12036 -- Train Loss: 0.32360  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12037 -- Train Loss: 0.32450  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 12038 -- Train Loss: 0.32368  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 12039 -- Train Loss: 0.32384  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 12040 -- Train Loss: 0.32460  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12041 -- Train Loss: 0.32444  Validation Loss: 0.43557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12042 -- Train Loss: 0.32431  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 12043 -- Train Loss: 0.32354  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 12044 -- Train Loss: 0.32294  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 12045 -- Train Loss: 0.32522  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12046 -- Train Loss: 0.32366  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12047 -- Train Loss: 0.32381  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 12048 -- Train Loss: 0.32391  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 12049 -- Train Loss: 0.32464  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 12050 -- Train Loss: 0.32386  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 12051 -- Train Loss: 0.32395  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 12052 -- Train Loss: 0.32393  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 12053 -- Train Loss: 0.32342  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 12054 -- Train Loss: 0.32403  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 12055 -- Train Loss: 0.32377  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 12056 -- Train Loss: 0.32334  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12057 -- Train Loss: 0.32403  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 12058 -- Train Loss: 0.32423  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 12059 -- Train Loss: 0.32443  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12060 -- Train Loss: 0.32414  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 12061 -- Train Loss: 0.32409  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 12062 -- Train Loss: 0.32451  Validation Loss: 0.43210\n",
      "t: 10 EPOCH 12063 -- Train Loss: 0.32450  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 12064 -- Train Loss: 0.32430  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 12065 -- Train Loss: 0.32352  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 12066 -- Train Loss: 0.32388  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 12067 -- Train Loss: 0.32388  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12068 -- Train Loss: 0.32340  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 12069 -- Train Loss: 0.32412  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 12070 -- Train Loss: 0.32449  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 12071 -- Train Loss: 0.32468  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 12072 -- Train Loss: 0.32482  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12073 -- Train Loss: 0.32438  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 12074 -- Train Loss: 0.32407  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 12075 -- Train Loss: 0.32440  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 12076 -- Train Loss: 0.32403  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 12077 -- Train Loss: 0.32380  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 12078 -- Train Loss: 0.32411  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 12079 -- Train Loss: 0.32414  Validation Loss: 0.43207\n",
      "t: 10 EPOCH 12080 -- Train Loss: 0.32398  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 12081 -- Train Loss: 0.32377  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 12082 -- Train Loss: 0.32406  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12083 -- Train Loss: 0.32428  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 12084 -- Train Loss: 0.32366  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 12085 -- Train Loss: 0.32330  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 12086 -- Train Loss: 0.32403  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 12087 -- Train Loss: 0.32447  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 12088 -- Train Loss: 0.32447  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 12089 -- Train Loss: 0.32357  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 12090 -- Train Loss: 0.32435  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 12091 -- Train Loss: 0.32446  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 12092 -- Train Loss: 0.32396  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12093 -- Train Loss: 0.32285  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 12094 -- Train Loss: 0.32459  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 12095 -- Train Loss: 0.32409  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 12096 -- Train Loss: 0.32442  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 12097 -- Train Loss: 0.32389  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 12098 -- Train Loss: 0.32407  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 12099 -- Train Loss: 0.32280  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 12100 -- Train Loss: 0.32516  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 12101 -- Train Loss: 0.32392  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 12102 -- Train Loss: 0.32444  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12103 -- Train Loss: 0.32404  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 12104 -- Train Loss: 0.32539  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 12105 -- Train Loss: 0.32516  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 12106 -- Train Loss: 0.32502  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 12107 -- Train Loss: 0.32382  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 12108 -- Train Loss: 0.32471  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 12109 -- Train Loss: 0.32377  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 12110 -- Train Loss: 0.32394  Validation Loss: 0.43221\n",
      "t: 10 EPOCH 12111 -- Train Loss: 0.32367  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 12112 -- Train Loss: 0.32536  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12113 -- Train Loss: 0.32440  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12114 -- Train Loss: 0.32509  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 12115 -- Train Loss: 0.32469  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 12116 -- Train Loss: 0.32559  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 12117 -- Train Loss: 0.32422  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 12118 -- Train Loss: 0.32520  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12119 -- Train Loss: 0.32371  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 12120 -- Train Loss: 0.32576  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 12121 -- Train Loss: 0.32335  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 12122 -- Train Loss: 0.32607  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 12123 -- Train Loss: 0.32302  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 12124 -- Train Loss: 0.32624  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12125 -- Train Loss: 0.32430  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 12126 -- Train Loss: 0.32473  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 12127 -- Train Loss: 0.32358  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 12128 -- Train Loss: 0.32507  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 12129 -- Train Loss: 0.32460  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 12130 -- Train Loss: 0.32507  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 12131 -- Train Loss: 0.32491  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 12132 -- Train Loss: 0.32613  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 12133 -- Train Loss: 0.32426  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 12134 -- Train Loss: 0.32559  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12135 -- Train Loss: 0.32518  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 12136 -- Train Loss: 0.32525  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 12137 -- Train Loss: 0.32562  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12138 -- Train Loss: 0.32582  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 12139 -- Train Loss: 0.32441  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 12140 -- Train Loss: 0.32525  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 12141 -- Train Loss: 0.32465  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 12142 -- Train Loss: 0.32501  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 12143 -- Train Loss: 0.32493  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12144 -- Train Loss: 0.32528  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 12145 -- Train Loss: 0.32430  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 12146 -- Train Loss: 0.32498  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 12147 -- Train Loss: 0.32471  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 12148 -- Train Loss: 0.32495  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 12149 -- Train Loss: 0.32471  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12150 -- Train Loss: 0.32437  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 12151 -- Train Loss: 0.32420  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 12152 -- Train Loss: 0.32388  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 12153 -- Train Loss: 0.32491  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 12154 -- Train Loss: 0.32490  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 12155 -- Train Loss: 0.32548  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12156 -- Train Loss: 0.32447  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 12157 -- Train Loss: 0.32532  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 12158 -- Train Loss: 0.32527  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 12159 -- Train Loss: 0.32502  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 12160 -- Train Loss: 0.32511  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 12161 -- Train Loss: 0.32519  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 12162 -- Train Loss: 0.32532  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 12163 -- Train Loss: 0.32391  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 12164 -- Train Loss: 0.32541  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 12165 -- Train Loss: 0.32466  Validation Loss: 0.43373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12166 -- Train Loss: 0.32530  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 12167 -- Train Loss: 0.32426  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 12168 -- Train Loss: 0.32451  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 12169 -- Train Loss: 0.32497  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 12170 -- Train Loss: 0.32421  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 12171 -- Train Loss: 0.32466  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 12172 -- Train Loss: 0.32500  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 12173 -- Train Loss: 0.32508  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 12174 -- Train Loss: 0.32406  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 12175 -- Train Loss: 0.32424  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 12176 -- Train Loss: 0.32363  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 12177 -- Train Loss: 0.32426  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 12178 -- Train Loss: 0.32459  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 12179 -- Train Loss: 0.32434  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 12180 -- Train Loss: 0.32384  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 12181 -- Train Loss: 0.32393  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 12182 -- Train Loss: 0.32388  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 12183 -- Train Loss: 0.32445  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 12184 -- Train Loss: 0.32466  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 12185 -- Train Loss: 0.32282  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 12186 -- Train Loss: 0.32382  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12187 -- Train Loss: 0.32357  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 12188 -- Train Loss: 0.32463  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 12189 -- Train Loss: 0.32365  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12190 -- Train Loss: 0.32536  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 12191 -- Train Loss: 0.32418  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 12192 -- Train Loss: 0.32440  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 12193 -- Train Loss: 0.32493  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 12194 -- Train Loss: 0.32451  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 12195 -- Train Loss: 0.32462  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 12196 -- Train Loss: 0.32383  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 12197 -- Train Loss: 0.32402  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 12198 -- Train Loss: 0.32400  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 12199 -- Train Loss: 0.32455  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 12200 -- Train Loss: 0.32414  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 12201 -- Train Loss: 0.32410  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 12202 -- Train Loss: 0.32395  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12203 -- Train Loss: 0.32331  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 12204 -- Train Loss: 0.32505  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 12205 -- Train Loss: 0.32517  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 12206 -- Train Loss: 0.32467  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12207 -- Train Loss: 0.32455  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 12208 -- Train Loss: 0.32405  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 12209 -- Train Loss: 0.32419  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 12210 -- Train Loss: 0.32483  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12211 -- Train Loss: 0.32455  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 12212 -- Train Loss: 0.32437  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12213 -- Train Loss: 0.32451  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 12214 -- Train Loss: 0.32470  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 12215 -- Train Loss: 0.32347  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 12216 -- Train Loss: 0.32411  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 12217 -- Train Loss: 0.32436  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 12218 -- Train Loss: 0.32412  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12219 -- Train Loss: 0.32492  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 12220 -- Train Loss: 0.32367  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 12221 -- Train Loss: 0.32428  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12222 -- Train Loss: 0.32460  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 12223 -- Train Loss: 0.32377  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 12224 -- Train Loss: 0.32350  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 12225 -- Train Loss: 0.32424  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 12226 -- Train Loss: 0.32350  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 12227 -- Train Loss: 0.32469  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 12228 -- Train Loss: 0.32336  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 12229 -- Train Loss: 0.32426  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 12230 -- Train Loss: 0.32335  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 12231 -- Train Loss: 0.32312  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 12232 -- Train Loss: 0.32431  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 12233 -- Train Loss: 0.32491  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 12234 -- Train Loss: 0.32399  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 12235 -- Train Loss: 0.32414  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 12236 -- Train Loss: 0.32350  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 12237 -- Train Loss: 0.32366  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 12238 -- Train Loss: 0.32375  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 12239 -- Train Loss: 0.32413  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12240 -- Train Loss: 0.32387  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 12241 -- Train Loss: 0.32461  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 12242 -- Train Loss: 0.32415  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12243 -- Train Loss: 0.32443  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 12244 -- Train Loss: 0.32362  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 12245 -- Train Loss: 0.32434  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 12246 -- Train Loss: 0.32466  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 12247 -- Train Loss: 0.32488  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12248 -- Train Loss: 0.32430  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 12249 -- Train Loss: 0.32395  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 12250 -- Train Loss: 0.32533  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 12251 -- Train Loss: 0.32324  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 12252 -- Train Loss: 0.32405  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 12253 -- Train Loss: 0.32361  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12254 -- Train Loss: 0.32439  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 12255 -- Train Loss: 0.32414  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 12256 -- Train Loss: 0.32553  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 12257 -- Train Loss: 0.32398  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 12258 -- Train Loss: 0.32339  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 12259 -- Train Loss: 0.32458  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 12260 -- Train Loss: 0.32477  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 12261 -- Train Loss: 0.32416  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 12262 -- Train Loss: 0.32468  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 12263 -- Train Loss: 0.32438  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 12264 -- Train Loss: 0.32411  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 12265 -- Train Loss: 0.32408  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 12266 -- Train Loss: 0.32446  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 12267 -- Train Loss: 0.32505  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 12268 -- Train Loss: 0.32454  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 12269 -- Train Loss: 0.32332  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 12270 -- Train Loss: 0.32476  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 12271 -- Train Loss: 0.32449  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 12272 -- Train Loss: 0.32478  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 12273 -- Train Loss: 0.32408  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 12274 -- Train Loss: 0.32438  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 12275 -- Train Loss: 0.32421  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 12276 -- Train Loss: 0.32498  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 12277 -- Train Loss: 0.32311  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 12278 -- Train Loss: 0.32453  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 12279 -- Train Loss: 0.32362  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12280 -- Train Loss: 0.32452  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 12281 -- Train Loss: 0.32423  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 12282 -- Train Loss: 0.32403  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 12283 -- Train Loss: 0.32329  Validation Loss: 0.43268\n",
      "t: 10 EPOCH 12284 -- Train Loss: 0.32427  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 12285 -- Train Loss: 0.32414  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 12286 -- Train Loss: 0.32356  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 12287 -- Train Loss: 0.32412  Validation Loss: 0.43279\n",
      "t: 10 EPOCH 12288 -- Train Loss: 0.32433  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 12289 -- Train Loss: 0.32447  Validation Loss: 0.43447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12290 -- Train Loss: 0.32422  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 12291 -- Train Loss: 0.32386  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 12292 -- Train Loss: 0.32408  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12293 -- Train Loss: 0.32385  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 12294 -- Train Loss: 0.32283  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 12295 -- Train Loss: 0.32375  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 12296 -- Train Loss: 0.32456  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 12297 -- Train Loss: 0.32416  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 12298 -- Train Loss: 0.32430  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 12299 -- Train Loss: 0.32350  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 12300 -- Train Loss: 0.32274  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 12301 -- Train Loss: 0.32374  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 12302 -- Train Loss: 0.32525  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 12303 -- Train Loss: 0.32348  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 12304 -- Train Loss: 0.32361  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 12305 -- Train Loss: 0.32393  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 12306 -- Train Loss: 0.32494  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 12307 -- Train Loss: 0.32417  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 12308 -- Train Loss: 0.32443  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 12309 -- Train Loss: 0.32441  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 12310 -- Train Loss: 0.32361  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 12311 -- Train Loss: 0.32378  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 12312 -- Train Loss: 0.32273  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 12313 -- Train Loss: 0.32403  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 12314 -- Train Loss: 0.32326  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 12315 -- Train Loss: 0.32405  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 12316 -- Train Loss: 0.32356  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 12317 -- Train Loss: 0.32430  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 12318 -- Train Loss: 0.32350  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 12319 -- Train Loss: 0.32339  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 12320 -- Train Loss: 0.32379  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12321 -- Train Loss: 0.32379  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 12322 -- Train Loss: 0.32385  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 12323 -- Train Loss: 0.32484  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 12324 -- Train Loss: 0.32373  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 12325 -- Train Loss: 0.32462  Validation Loss: 0.43265\n",
      "t: 10 EPOCH 12326 -- Train Loss: 0.32352  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 12327 -- Train Loss: 0.32435  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 12328 -- Train Loss: 0.32431  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 12329 -- Train Loss: 0.32385  Validation Loss: 0.43277\n",
      "t: 10 EPOCH 12330 -- Train Loss: 0.32455  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 12331 -- Train Loss: 0.32330  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 12332 -- Train Loss: 0.32416  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 12333 -- Train Loss: 0.32381  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12334 -- Train Loss: 0.32423  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 12335 -- Train Loss: 0.32407  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 12336 -- Train Loss: 0.32433  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12337 -- Train Loss: 0.32359  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 12338 -- Train Loss: 0.32420  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 12339 -- Train Loss: 0.32378  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 12340 -- Train Loss: 0.32430  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 12341 -- Train Loss: 0.32511  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 12342 -- Train Loss: 0.32446  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 12343 -- Train Loss: 0.32479  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 12344 -- Train Loss: 0.32334  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 12345 -- Train Loss: 0.32337  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 12346 -- Train Loss: 0.32315  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 12347 -- Train Loss: 0.32344  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12348 -- Train Loss: 0.32376  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 12349 -- Train Loss: 0.32363  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 12350 -- Train Loss: 0.32318  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 12351 -- Train Loss: 0.32446  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 12352 -- Train Loss: 0.32364  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 12353 -- Train Loss: 0.32294  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 12354 -- Train Loss: 0.32418  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 12355 -- Train Loss: 0.32377  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 12356 -- Train Loss: 0.32415  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12357 -- Train Loss: 0.32416  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 12358 -- Train Loss: 0.32479  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 12359 -- Train Loss: 0.32482  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 12360 -- Train Loss: 0.32427  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 12361 -- Train Loss: 0.32453  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 12362 -- Train Loss: 0.32378  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 12363 -- Train Loss: 0.32502  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 12364 -- Train Loss: 0.32403  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 12365 -- Train Loss: 0.32519  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 12366 -- Train Loss: 0.32454  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 12367 -- Train Loss: 0.32444  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 12368 -- Train Loss: 0.32353  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 12369 -- Train Loss: 0.32419  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 12370 -- Train Loss: 0.32372  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 12371 -- Train Loss: 0.32483  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 12372 -- Train Loss: 0.32373  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 12373 -- Train Loss: 0.32422  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 12374 -- Train Loss: 0.32319  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 12375 -- Train Loss: 0.32486  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 12376 -- Train Loss: 0.32419  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 12377 -- Train Loss: 0.32512  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 12378 -- Train Loss: 0.32507  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 12379 -- Train Loss: 0.32428  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 12380 -- Train Loss: 0.32392  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 12381 -- Train Loss: 0.32455  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 12382 -- Train Loss: 0.32442  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 12383 -- Train Loss: 0.32449  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 12384 -- Train Loss: 0.32397  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 12385 -- Train Loss: 0.32463  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 12386 -- Train Loss: 0.32430  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 12387 -- Train Loss: 0.32447  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 12388 -- Train Loss: 0.32495  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 12389 -- Train Loss: 0.32481  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12390 -- Train Loss: 0.32359  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 12391 -- Train Loss: 0.32494  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 12392 -- Train Loss: 0.32481  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 12393 -- Train Loss: 0.32430  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 12394 -- Train Loss: 0.32449  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 12395 -- Train Loss: 0.32488  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 12396 -- Train Loss: 0.32479  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12397 -- Train Loss: 0.32533  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12398 -- Train Loss: 0.32433  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 12399 -- Train Loss: 0.32504  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12400 -- Train Loss: 0.32426  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 12401 -- Train Loss: 0.32484  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 12402 -- Train Loss: 0.32502  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 12403 -- Train Loss: 0.32579  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 12404 -- Train Loss: 0.32420  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 12405 -- Train Loss: 0.32530  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12406 -- Train Loss: 0.32411  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12407 -- Train Loss: 0.32463  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12408 -- Train Loss: 0.32394  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 12409 -- Train Loss: 0.32500  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 12410 -- Train Loss: 0.32335  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 12411 -- Train Loss: 0.32414  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 12412 -- Train Loss: 0.32481  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 12413 -- Train Loss: 0.32531  Validation Loss: 0.43459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12414 -- Train Loss: 0.32440  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 12415 -- Train Loss: 0.32496  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 12416 -- Train Loss: 0.32527  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 12417 -- Train Loss: 0.32370  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 12418 -- Train Loss: 0.32509  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 12419 -- Train Loss: 0.32414  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 12420 -- Train Loss: 0.32437  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 12421 -- Train Loss: 0.32363  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 12422 -- Train Loss: 0.32496  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 12423 -- Train Loss: 0.32403  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12424 -- Train Loss: 0.32456  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 12425 -- Train Loss: 0.32485  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 12426 -- Train Loss: 0.32449  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 12427 -- Train Loss: 0.32379  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 12428 -- Train Loss: 0.32421  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 12429 -- Train Loss: 0.32433  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 12430 -- Train Loss: 0.32489  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 12431 -- Train Loss: 0.32343  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12432 -- Train Loss: 0.32491  Validation Loss: 0.43235\n",
      "t: 10 EPOCH 12433 -- Train Loss: 0.32406  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 12434 -- Train Loss: 0.32487  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 12435 -- Train Loss: 0.32434  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 12436 -- Train Loss: 0.32429  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 12437 -- Train Loss: 0.32442  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 12438 -- Train Loss: 0.32456  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 12439 -- Train Loss: 0.32363  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 12440 -- Train Loss: 0.32570  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 12441 -- Train Loss: 0.32534  Validation Loss: 0.43289\n",
      "t: 10 EPOCH 12442 -- Train Loss: 0.32410  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 12443 -- Train Loss: 0.32462  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 12444 -- Train Loss: 0.32486  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 12445 -- Train Loss: 0.32486  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 12446 -- Train Loss: 0.32406  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 12447 -- Train Loss: 0.32327  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 12448 -- Train Loss: 0.32474  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 12449 -- Train Loss: 0.32492  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12450 -- Train Loss: 0.32416  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 12451 -- Train Loss: 0.32422  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 12452 -- Train Loss: 0.32434  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 12453 -- Train Loss: 0.32347  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 12454 -- Train Loss: 0.32489  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 12455 -- Train Loss: 0.32436  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 12456 -- Train Loss: 0.32436  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 12457 -- Train Loss: 0.32450  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 12458 -- Train Loss: 0.32385  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 12459 -- Train Loss: 0.32455  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 12460 -- Train Loss: 0.32432  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 12461 -- Train Loss: 0.32424  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 12462 -- Train Loss: 0.32427  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 12463 -- Train Loss: 0.32427  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 12464 -- Train Loss: 0.32394  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 12465 -- Train Loss: 0.32384  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 12466 -- Train Loss: 0.32362  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 12467 -- Train Loss: 0.32370  Validation Loss: 0.43244\n",
      "t: 10 EPOCH 12468 -- Train Loss: 0.32449  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 12469 -- Train Loss: 0.32409  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 12470 -- Train Loss: 0.32392  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 12471 -- Train Loss: 0.32310  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12472 -- Train Loss: 0.32420  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 12473 -- Train Loss: 0.32413  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12474 -- Train Loss: 0.32497  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 12475 -- Train Loss: 0.32287  Validation Loss: 0.43237\n",
      "t: 10 EPOCH 12476 -- Train Loss: 0.32430  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 12477 -- Train Loss: 0.32349  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 12478 -- Train Loss: 0.32474  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 12479 -- Train Loss: 0.32426  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 12480 -- Train Loss: 0.32484  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 12481 -- Train Loss: 0.32411  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 12482 -- Train Loss: 0.32444  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 12483 -- Train Loss: 0.32425  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 12484 -- Train Loss: 0.32484  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 12485 -- Train Loss: 0.32412  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12486 -- Train Loss: 0.32404  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 12487 -- Train Loss: 0.32441  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 12488 -- Train Loss: 0.32471  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 12489 -- Train Loss: 0.32395  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 12490 -- Train Loss: 0.32428  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 12491 -- Train Loss: 0.32340  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 12492 -- Train Loss: 0.32358  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12493 -- Train Loss: 0.32322  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 12494 -- Train Loss: 0.32378  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 12495 -- Train Loss: 0.32349  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12496 -- Train Loss: 0.32429  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 12497 -- Train Loss: 0.32414  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 12498 -- Train Loss: 0.32399  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 12499 -- Train Loss: 0.32461  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 12500 -- Train Loss: 0.32329  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 12501 -- Train Loss: 0.32347  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 12502 -- Train Loss: 0.32394  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 12503 -- Train Loss: 0.32398  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 12504 -- Train Loss: 0.32392  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 12505 -- Train Loss: 0.32438  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 12506 -- Train Loss: 0.32343  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12507 -- Train Loss: 0.32383  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 12508 -- Train Loss: 0.32333  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 12509 -- Train Loss: 0.32476  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12510 -- Train Loss: 0.32359  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12511 -- Train Loss: 0.32484  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 12512 -- Train Loss: 0.32393  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 12513 -- Train Loss: 0.32480  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 12514 -- Train Loss: 0.32398  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 12515 -- Train Loss: 0.32334  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12516 -- Train Loss: 0.32482  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 12517 -- Train Loss: 0.32391  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 12518 -- Train Loss: 0.32404  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 12519 -- Train Loss: 0.32373  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 12520 -- Train Loss: 0.32413  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 12521 -- Train Loss: 0.32404  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 12522 -- Train Loss: 0.32463  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 12523 -- Train Loss: 0.32381  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 12524 -- Train Loss: 0.32399  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12525 -- Train Loss: 0.32433  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 12526 -- Train Loss: 0.32367  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12527 -- Train Loss: 0.32379  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12528 -- Train Loss: 0.32456  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 12529 -- Train Loss: 0.32374  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 12530 -- Train Loss: 0.32443  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 12531 -- Train Loss: 0.32420  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 12532 -- Train Loss: 0.32340  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 12533 -- Train Loss: 0.32335  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 12534 -- Train Loss: 0.32445  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 12535 -- Train Loss: 0.32385  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 12536 -- Train Loss: 0.32427  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12537 -- Train Loss: 0.32416  Validation Loss: 0.43440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12538 -- Train Loss: 0.32386  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 12539 -- Train Loss: 0.32418  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 12540 -- Train Loss: 0.32396  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 12541 -- Train Loss: 0.32364  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 12542 -- Train Loss: 0.32345  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 12543 -- Train Loss: 0.32343  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 12544 -- Train Loss: 0.32386  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 12545 -- Train Loss: 0.32321  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 12546 -- Train Loss: 0.32354  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12547 -- Train Loss: 0.32406  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 12548 -- Train Loss: 0.32438  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 12549 -- Train Loss: 0.32418  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 12550 -- Train Loss: 0.32428  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 12551 -- Train Loss: 0.32300  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 12552 -- Train Loss: 0.32463  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 12553 -- Train Loss: 0.32402  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 12554 -- Train Loss: 0.32357  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 12555 -- Train Loss: 0.32338  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12556 -- Train Loss: 0.32394  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 12557 -- Train Loss: 0.32395  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 12558 -- Train Loss: 0.32330  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 12559 -- Train Loss: 0.32329  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 12560 -- Train Loss: 0.32382  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 12561 -- Train Loss: 0.32323  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 12562 -- Train Loss: 0.32370  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12563 -- Train Loss: 0.32376  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12564 -- Train Loss: 0.32404  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 12565 -- Train Loss: 0.32427  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 12566 -- Train Loss: 0.32335  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12567 -- Train Loss: 0.32372  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12568 -- Train Loss: 0.32402  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 12569 -- Train Loss: 0.32423  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12570 -- Train Loss: 0.32336  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 12571 -- Train Loss: 0.32377  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12572 -- Train Loss: 0.32272  Validation Loss: 0.43315\n",
      "t: 10 EPOCH 12573 -- Train Loss: 0.32314  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 12574 -- Train Loss: 0.32416  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12575 -- Train Loss: 0.32469  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 12576 -- Train Loss: 0.32316  Validation Loss: 0.43242\n",
      "t: 10 EPOCH 12577 -- Train Loss: 0.32378  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 12578 -- Train Loss: 0.32298  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 12579 -- Train Loss: 0.32372  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 12580 -- Train Loss: 0.32388  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 12581 -- Train Loss: 0.32415  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12582 -- Train Loss: 0.32387  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 12583 -- Train Loss: 0.32328  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 12584 -- Train Loss: 0.32406  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 12585 -- Train Loss: 0.32298  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 12586 -- Train Loss: 0.32360  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 12587 -- Train Loss: 0.32401  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 12588 -- Train Loss: 0.32471  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 12589 -- Train Loss: 0.32326  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 12590 -- Train Loss: 0.32322  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12591 -- Train Loss: 0.32375  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 12592 -- Train Loss: 0.32419  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 12593 -- Train Loss: 0.32505  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 12594 -- Train Loss: 0.32373  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 12595 -- Train Loss: 0.32329  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 12596 -- Train Loss: 0.32434  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12597 -- Train Loss: 0.32347  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 12598 -- Train Loss: 0.32390  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 12599 -- Train Loss: 0.32553  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 12600 -- Train Loss: 0.32408  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 12601 -- Train Loss: 0.32392  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12602 -- Train Loss: 0.32420  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 12603 -- Train Loss: 0.32370  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 12604 -- Train Loss: 0.32485  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12605 -- Train Loss: 0.32314  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 12606 -- Train Loss: 0.32447  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 12607 -- Train Loss: 0.32346  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 12608 -- Train Loss: 0.32414  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 12609 -- Train Loss: 0.32405  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 12610 -- Train Loss: 0.32452  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 12611 -- Train Loss: 0.32416  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12612 -- Train Loss: 0.32487  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12613 -- Train Loss: 0.32417  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 12614 -- Train Loss: 0.32390  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 12615 -- Train Loss: 0.32314  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12616 -- Train Loss: 0.32454  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 12617 -- Train Loss: 0.32432  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12618 -- Train Loss: 0.32432  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 12619 -- Train Loss: 0.32338  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 12620 -- Train Loss: 0.32324  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 12621 -- Train Loss: 0.32456  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 12622 -- Train Loss: 0.32366  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 12623 -- Train Loss: 0.32364  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 12624 -- Train Loss: 0.32472  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 12625 -- Train Loss: 0.32501  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 12626 -- Train Loss: 0.32410  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12627 -- Train Loss: 0.32419  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 12628 -- Train Loss: 0.32394  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 12629 -- Train Loss: 0.32489  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 12630 -- Train Loss: 0.32412  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 12631 -- Train Loss: 0.32460  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12632 -- Train Loss: 0.32390  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 12633 -- Train Loss: 0.32405  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 12634 -- Train Loss: 0.32434  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 12635 -- Train Loss: 0.32348  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 12636 -- Train Loss: 0.32446  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 12637 -- Train Loss: 0.32372  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 12638 -- Train Loss: 0.32438  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12639 -- Train Loss: 0.32388  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 12640 -- Train Loss: 0.32501  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12641 -- Train Loss: 0.32441  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 12642 -- Train Loss: 0.32411  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 12643 -- Train Loss: 0.32352  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 12644 -- Train Loss: 0.32445  Validation Loss: 0.43227\n",
      "t: 10 EPOCH 12645 -- Train Loss: 0.32390  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 12646 -- Train Loss: 0.32356  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 12647 -- Train Loss: 0.32442  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 12648 -- Train Loss: 0.32457  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 12649 -- Train Loss: 0.32425  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 12650 -- Train Loss: 0.32397  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 12651 -- Train Loss: 0.32465  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 12652 -- Train Loss: 0.32477  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 12653 -- Train Loss: 0.32488  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 12654 -- Train Loss: 0.32481  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 12655 -- Train Loss: 0.32461  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 12656 -- Train Loss: 0.32453  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 12657 -- Train Loss: 0.32428  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 12658 -- Train Loss: 0.32364  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 12659 -- Train Loss: 0.32341  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 12660 -- Train Loss: 0.32421  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 12661 -- Train Loss: 0.32395  Validation Loss: 0.43493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12662 -- Train Loss: 0.32461  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 12663 -- Train Loss: 0.32469  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12664 -- Train Loss: 0.32427  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 12665 -- Train Loss: 0.32470  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 12666 -- Train Loss: 0.32609  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 12667 -- Train Loss: 0.32451  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 12668 -- Train Loss: 0.32433  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 12669 -- Train Loss: 0.32455  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 12670 -- Train Loss: 0.32381  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 12671 -- Train Loss: 0.32421  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 12672 -- Train Loss: 0.32420  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 12673 -- Train Loss: 0.32415  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 12674 -- Train Loss: 0.32440  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 12675 -- Train Loss: 0.32380  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 12676 -- Train Loss: 0.32422  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 12677 -- Train Loss: 0.32355  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 12678 -- Train Loss: 0.32461  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 12679 -- Train Loss: 0.32349  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 12680 -- Train Loss: 0.32478  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 12681 -- Train Loss: 0.32417  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 12682 -- Train Loss: 0.32563  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12683 -- Train Loss: 0.32414  Validation Loss: 0.43288\n",
      "t: 10 EPOCH 12684 -- Train Loss: 0.32491  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 12685 -- Train Loss: 0.32441  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 12686 -- Train Loss: 0.32433  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12687 -- Train Loss: 0.32386  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12688 -- Train Loss: 0.32539  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 12689 -- Train Loss: 0.32453  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 12690 -- Train Loss: 0.32409  Validation Loss: 0.43261\n",
      "t: 10 EPOCH 12691 -- Train Loss: 0.32467  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 12692 -- Train Loss: 0.32440  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 12693 -- Train Loss: 0.32362  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12694 -- Train Loss: 0.32501  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 12695 -- Train Loss: 0.32298  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12696 -- Train Loss: 0.32474  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 12697 -- Train Loss: 0.32412  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 12698 -- Train Loss: 0.32423  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 12699 -- Train Loss: 0.32358  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 12700 -- Train Loss: 0.32557  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 12701 -- Train Loss: 0.32364  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12702 -- Train Loss: 0.32354  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12703 -- Train Loss: 0.32393  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 12704 -- Train Loss: 0.32435  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 12705 -- Train Loss: 0.32405  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 12706 -- Train Loss: 0.32449  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 12707 -- Train Loss: 0.32426  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 12708 -- Train Loss: 0.32274  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 12709 -- Train Loss: 0.32446  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 12710 -- Train Loss: 0.32413  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 12711 -- Train Loss: 0.32424  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 12712 -- Train Loss: 0.32354  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 12713 -- Train Loss: 0.32350  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 12714 -- Train Loss: 0.32272  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 12715 -- Train Loss: 0.32442  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 12716 -- Train Loss: 0.32343  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 12717 -- Train Loss: 0.32402  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12718 -- Train Loss: 0.32460  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 12719 -- Train Loss: 0.32407  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 12720 -- Train Loss: 0.32314  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 12721 -- Train Loss: 0.32453  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 12722 -- Train Loss: 0.32336  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 12723 -- Train Loss: 0.32441  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 12724 -- Train Loss: 0.32403  Validation Loss: 0.43290\n",
      "t: 10 EPOCH 12725 -- Train Loss: 0.32317  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 12726 -- Train Loss: 0.32424  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 12727 -- Train Loss: 0.32486  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 12728 -- Train Loss: 0.32387  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 12729 -- Train Loss: 0.32442  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 12730 -- Train Loss: 0.32330  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 12731 -- Train Loss: 0.32407  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 12732 -- Train Loss: 0.32352  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 12733 -- Train Loss: 0.32365  Validation Loss: 0.43298\n",
      "t: 10 EPOCH 12734 -- Train Loss: 0.32345  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 12735 -- Train Loss: 0.32391  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 12736 -- Train Loss: 0.32418  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 12737 -- Train Loss: 0.32401  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 12738 -- Train Loss: 0.32457  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12739 -- Train Loss: 0.32289  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 12740 -- Train Loss: 0.32410  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12741 -- Train Loss: 0.32444  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 12742 -- Train Loss: 0.32458  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 12743 -- Train Loss: 0.32437  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 12744 -- Train Loss: 0.32374  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12745 -- Train Loss: 0.32322  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 12746 -- Train Loss: 0.32342  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 12747 -- Train Loss: 0.32420  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 12748 -- Train Loss: 0.32435  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 12749 -- Train Loss: 0.32454  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 12750 -- Train Loss: 0.32315  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 12751 -- Train Loss: 0.32402  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 12752 -- Train Loss: 0.32321  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 12753 -- Train Loss: 0.32361  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 12754 -- Train Loss: 0.32325  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12755 -- Train Loss: 0.32399  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 12756 -- Train Loss: 0.32370  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 12757 -- Train Loss: 0.32443  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 12758 -- Train Loss: 0.32337  Validation Loss: 0.43337\n",
      "t: 10 EPOCH 12759 -- Train Loss: 0.32409  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12760 -- Train Loss: 0.32380  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 12761 -- Train Loss: 0.32391  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 12762 -- Train Loss: 0.32346  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12763 -- Train Loss: 0.32372  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 12764 -- Train Loss: 0.32371  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 12765 -- Train Loss: 0.32352  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12766 -- Train Loss: 0.32357  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 12767 -- Train Loss: 0.32362  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 12768 -- Train Loss: 0.32384  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12769 -- Train Loss: 0.32388  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 12770 -- Train Loss: 0.32474  Validation Loss: 0.43257\n",
      "t: 10 EPOCH 12771 -- Train Loss: 0.32369  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 12772 -- Train Loss: 0.32424  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 12773 -- Train Loss: 0.32335  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 12774 -- Train Loss: 0.32380  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12775 -- Train Loss: 0.32381  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 12776 -- Train Loss: 0.32377  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 12777 -- Train Loss: 0.32388  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12778 -- Train Loss: 0.32341  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12779 -- Train Loss: 0.32369  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 12780 -- Train Loss: 0.32367  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 12781 -- Train Loss: 0.32353  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12782 -- Train Loss: 0.32362  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 12783 -- Train Loss: 0.32343  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 12784 -- Train Loss: 0.32451  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 12785 -- Train Loss: 0.32317  Validation Loss: 0.43481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12786 -- Train Loss: 0.32367  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 12787 -- Train Loss: 0.32441  Validation Loss: 0.43211\n",
      "t: 10 EPOCH 12788 -- Train Loss: 0.32373  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 12789 -- Train Loss: 0.32388  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 12790 -- Train Loss: 0.32366  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 12791 -- Train Loss: 0.32365  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12792 -- Train Loss: 0.32256  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 12793 -- Train Loss: 0.32461  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 12794 -- Train Loss: 0.32363  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 12795 -- Train Loss: 0.32374  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12796 -- Train Loss: 0.32436  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 12797 -- Train Loss: 0.32439  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 12798 -- Train Loss: 0.32386  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12799 -- Train Loss: 0.32402  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 12800 -- Train Loss: 0.32409  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 12801 -- Train Loss: 0.32366  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 12802 -- Train Loss: 0.32394  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 12803 -- Train Loss: 0.32376  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 12804 -- Train Loss: 0.32402  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 12805 -- Train Loss: 0.32396  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 12806 -- Train Loss: 0.32375  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 12807 -- Train Loss: 0.32397  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 12808 -- Train Loss: 0.32392  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 12809 -- Train Loss: 0.32346  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 12810 -- Train Loss: 0.32388  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 12811 -- Train Loss: 0.32284  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 12812 -- Train Loss: 0.32342  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 12813 -- Train Loss: 0.32422  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 12814 -- Train Loss: 0.32404  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 12815 -- Train Loss: 0.32344  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 12816 -- Train Loss: 0.32387  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 12817 -- Train Loss: 0.32415  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 12818 -- Train Loss: 0.32416  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12819 -- Train Loss: 0.32362  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 12820 -- Train Loss: 0.32319  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12821 -- Train Loss: 0.32346  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 12822 -- Train Loss: 0.32412  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 12823 -- Train Loss: 0.32295  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12824 -- Train Loss: 0.32410  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 12825 -- Train Loss: 0.32229  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 12826 -- Train Loss: 0.32400  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 12827 -- Train Loss: 0.32427  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 12828 -- Train Loss: 0.32434  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 12829 -- Train Loss: 0.32406  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 12830 -- Train Loss: 0.32251  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 12831 -- Train Loss: 0.32381  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 12832 -- Train Loss: 0.32384  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 12833 -- Train Loss: 0.32428  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 12834 -- Train Loss: 0.32397  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 12835 -- Train Loss: 0.32347  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 12836 -- Train Loss: 0.32369  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 12837 -- Train Loss: 0.32343  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 12838 -- Train Loss: 0.32414  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 12839 -- Train Loss: 0.32361  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12840 -- Train Loss: 0.32414  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 12841 -- Train Loss: 0.32297  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 12842 -- Train Loss: 0.32307  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 12843 -- Train Loss: 0.32375  Validation Loss: 0.43302\n",
      "t: 10 EPOCH 12844 -- Train Loss: 0.32400  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 12845 -- Train Loss: 0.32297  Validation Loss: 0.43266\n",
      "t: 10 EPOCH 12846 -- Train Loss: 0.32462  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12847 -- Train Loss: 0.32349  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12848 -- Train Loss: 0.32409  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12849 -- Train Loss: 0.32338  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 12850 -- Train Loss: 0.32433  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 12851 -- Train Loss: 0.32383  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 12852 -- Train Loss: 0.32381  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 12853 -- Train Loss: 0.32287  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 12854 -- Train Loss: 0.32344  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 12855 -- Train Loss: 0.32475  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 12856 -- Train Loss: 0.32374  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12857 -- Train Loss: 0.32408  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 12858 -- Train Loss: 0.32460  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 12859 -- Train Loss: 0.32369  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 12860 -- Train Loss: 0.32399  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 12861 -- Train Loss: 0.32371  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 12862 -- Train Loss: 0.32484  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 12863 -- Train Loss: 0.32504  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 12864 -- Train Loss: 0.32489  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 12865 -- Train Loss: 0.32372  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 12866 -- Train Loss: 0.32452  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 12867 -- Train Loss: 0.32486  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 12868 -- Train Loss: 0.32420  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 12869 -- Train Loss: 0.32369  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 12870 -- Train Loss: 0.32544  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 12871 -- Train Loss: 0.32413  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 12872 -- Train Loss: 0.32456  Validation Loss: 0.43291\n",
      "t: 10 EPOCH 12873 -- Train Loss: 0.32314  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 12874 -- Train Loss: 0.32404  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 12875 -- Train Loss: 0.32433  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 12876 -- Train Loss: 0.32439  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12877 -- Train Loss: 0.32396  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 12878 -- Train Loss: 0.32399  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 12879 -- Train Loss: 0.32370  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 12880 -- Train Loss: 0.32508  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 12881 -- Train Loss: 0.32387  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 12882 -- Train Loss: 0.32513  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12883 -- Train Loss: 0.32445  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 12884 -- Train Loss: 0.32509  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 12885 -- Train Loss: 0.32381  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 12886 -- Train Loss: 0.32393  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 12887 -- Train Loss: 0.32419  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 12888 -- Train Loss: 0.32408  Validation Loss: 0.43670\n",
      "t: 10 EPOCH 12889 -- Train Loss: 0.32405  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 12890 -- Train Loss: 0.32385  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12891 -- Train Loss: 0.32436  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 12892 -- Train Loss: 0.32511  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 12893 -- Train Loss: 0.32394  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 12894 -- Train Loss: 0.32436  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12895 -- Train Loss: 0.32393  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 12896 -- Train Loss: 0.32408  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 12897 -- Train Loss: 0.32491  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12898 -- Train Loss: 0.32450  Validation Loss: 0.43321\n",
      "t: 10 EPOCH 12899 -- Train Loss: 0.32484  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 12900 -- Train Loss: 0.32389  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 12901 -- Train Loss: 0.32387  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 12902 -- Train Loss: 0.32387  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 12903 -- Train Loss: 0.32368  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 12904 -- Train Loss: 0.32325  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 12905 -- Train Loss: 0.32457  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 12906 -- Train Loss: 0.32438  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 12907 -- Train Loss: 0.32412  Validation Loss: 0.43276\n",
      "t: 10 EPOCH 12908 -- Train Loss: 0.32388  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 12909 -- Train Loss: 0.32445  Validation Loss: 0.43436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 12910 -- Train Loss: 0.32387  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 12911 -- Train Loss: 0.32312  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 12912 -- Train Loss: 0.32299  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 12913 -- Train Loss: 0.32395  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12914 -- Train Loss: 0.32347  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 12915 -- Train Loss: 0.32438  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 12916 -- Train Loss: 0.32348  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 12917 -- Train Loss: 0.32407  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 12918 -- Train Loss: 0.32407  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 12919 -- Train Loss: 0.32387  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 12920 -- Train Loss: 0.32378  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 12921 -- Train Loss: 0.32350  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 12922 -- Train Loss: 0.32330  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 12923 -- Train Loss: 0.32364  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 12924 -- Train Loss: 0.32416  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 12925 -- Train Loss: 0.32380  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 12926 -- Train Loss: 0.32430  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 12927 -- Train Loss: 0.32400  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 12928 -- Train Loss: 0.32456  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 12929 -- Train Loss: 0.32329  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 12930 -- Train Loss: 0.32356  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 12931 -- Train Loss: 0.32415  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 12932 -- Train Loss: 0.32333  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 12933 -- Train Loss: 0.32373  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 12934 -- Train Loss: 0.32436  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 12935 -- Train Loss: 0.32348  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 12936 -- Train Loss: 0.32411  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 12937 -- Train Loss: 0.32431  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 12938 -- Train Loss: 0.32362  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12939 -- Train Loss: 0.32437  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 12940 -- Train Loss: 0.32293  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 12941 -- Train Loss: 0.32301  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 12942 -- Train Loss: 0.32332  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 12943 -- Train Loss: 0.32380  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 12944 -- Train Loss: 0.32377  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 12945 -- Train Loss: 0.32410  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 12946 -- Train Loss: 0.32379  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 12947 -- Train Loss: 0.32317  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 12948 -- Train Loss: 0.32259  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 12949 -- Train Loss: 0.32417  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 12950 -- Train Loss: 0.32432  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 12951 -- Train Loss: 0.32333  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 12952 -- Train Loss: 0.32330  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 12953 -- Train Loss: 0.32393  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12954 -- Train Loss: 0.32412  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12955 -- Train Loss: 0.32317  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 12956 -- Train Loss: 0.32385  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 12957 -- Train Loss: 0.32447  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 12958 -- Train Loss: 0.32367  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 12959 -- Train Loss: 0.32367  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 12960 -- Train Loss: 0.32393  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 12961 -- Train Loss: 0.32418  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 12962 -- Train Loss: 0.32381  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 12963 -- Train Loss: 0.32355  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 12964 -- Train Loss: 0.32331  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 12965 -- Train Loss: 0.32278  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 12966 -- Train Loss: 0.32335  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 12967 -- Train Loss: 0.32348  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 12968 -- Train Loss: 0.32399  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 12969 -- Train Loss: 0.32382  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 12970 -- Train Loss: 0.32359  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 12971 -- Train Loss: 0.32355  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 12972 -- Train Loss: 0.32357  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 12973 -- Train Loss: 0.32325  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 12974 -- Train Loss: 0.32367  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 12975 -- Train Loss: 0.32347  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 12976 -- Train Loss: 0.32452  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 12977 -- Train Loss: 0.32400  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 12978 -- Train Loss: 0.32443  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 12979 -- Train Loss: 0.32357  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 12980 -- Train Loss: 0.32450  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 12981 -- Train Loss: 0.32420  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 12982 -- Train Loss: 0.32441  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 12983 -- Train Loss: 0.32394  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 12984 -- Train Loss: 0.32321  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 12985 -- Train Loss: 0.32343  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 12986 -- Train Loss: 0.32393  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 12987 -- Train Loss: 0.32456  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 12988 -- Train Loss: 0.32371  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 12989 -- Train Loss: 0.32437  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 12990 -- Train Loss: 0.32416  Validation Loss: 0.43327\n",
      "t: 10 EPOCH 12991 -- Train Loss: 0.32388  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 12992 -- Train Loss: 0.32468  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 12993 -- Train Loss: 0.32405  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 12994 -- Train Loss: 0.32458  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 12995 -- Train Loss: 0.32416  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 12996 -- Train Loss: 0.32445  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 12997 -- Train Loss: 0.32395  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 12998 -- Train Loss: 0.32389  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 12999 -- Train Loss: 0.32367  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 13000 -- Train Loss: 0.32467  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 13001 -- Train Loss: 0.32322  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 13002 -- Train Loss: 0.32452  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 13003 -- Train Loss: 0.32421  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 13004 -- Train Loss: 0.32466  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13005 -- Train Loss: 0.32380  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 13006 -- Train Loss: 0.32450  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 13007 -- Train Loss: 0.32368  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 13008 -- Train Loss: 0.32467  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 13009 -- Train Loss: 0.32374  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 13010 -- Train Loss: 0.32480  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 13011 -- Train Loss: 0.32307  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 13012 -- Train Loss: 0.32408  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 13013 -- Train Loss: 0.32328  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 13014 -- Train Loss: 0.32543  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 13015 -- Train Loss: 0.32426  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 13016 -- Train Loss: 0.32372  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 13017 -- Train Loss: 0.32453  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 13018 -- Train Loss: 0.32388  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 13019 -- Train Loss: 0.32458  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 13020 -- Train Loss: 0.32400  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13021 -- Train Loss: 0.32356  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 13022 -- Train Loss: 0.32349  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 13023 -- Train Loss: 0.32364  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 13024 -- Train Loss: 0.32470  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13025 -- Train Loss: 0.32345  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 13026 -- Train Loss: 0.32365  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 13027 -- Train Loss: 0.32366  Validation Loss: 0.43259\n",
      "t: 10 EPOCH 13028 -- Train Loss: 0.32364  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 13029 -- Train Loss: 0.32406  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 13030 -- Train Loss: 0.32416  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 13031 -- Train Loss: 0.32299  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13032 -- Train Loss: 0.32437  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 13033 -- Train Loss: 0.32466  Validation Loss: 0.43342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13034 -- Train Loss: 0.32372  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 13035 -- Train Loss: 0.32488  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 13036 -- Train Loss: 0.32432  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 13037 -- Train Loss: 0.32455  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 13038 -- Train Loss: 0.32312  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 13039 -- Train Loss: 0.32399  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 13040 -- Train Loss: 0.32349  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 13041 -- Train Loss: 0.32445  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13042 -- Train Loss: 0.32299  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 13043 -- Train Loss: 0.32366  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13044 -- Train Loss: 0.32415  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 13045 -- Train Loss: 0.32381  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 13046 -- Train Loss: 0.32408  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 13047 -- Train Loss: 0.32321  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 13048 -- Train Loss: 0.32360  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 13049 -- Train Loss: 0.32373  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 13050 -- Train Loss: 0.32398  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 13051 -- Train Loss: 0.32342  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 13052 -- Train Loss: 0.32434  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 13053 -- Train Loss: 0.32392  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 13054 -- Train Loss: 0.32422  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 13055 -- Train Loss: 0.32410  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13056 -- Train Loss: 0.32337  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 13057 -- Train Loss: 0.32349  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 13058 -- Train Loss: 0.32453  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 13059 -- Train Loss: 0.32405  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 13060 -- Train Loss: 0.32331  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 13061 -- Train Loss: 0.32398  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 13062 -- Train Loss: 0.32297  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 13063 -- Train Loss: 0.32469  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 13064 -- Train Loss: 0.32400  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 13065 -- Train Loss: 0.32448  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 13066 -- Train Loss: 0.32400  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 13067 -- Train Loss: 0.32442  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 13068 -- Train Loss: 0.32360  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 13069 -- Train Loss: 0.32332  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 13070 -- Train Loss: 0.32299  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13071 -- Train Loss: 0.32404  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 13072 -- Train Loss: 0.32405  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 13073 -- Train Loss: 0.32304  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 13074 -- Train Loss: 0.32370  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 13075 -- Train Loss: 0.32306  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 13076 -- Train Loss: 0.32359  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 13077 -- Train Loss: 0.32330  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 13078 -- Train Loss: 0.32421  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 13079 -- Train Loss: 0.32315  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13080 -- Train Loss: 0.32317  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 13081 -- Train Loss: 0.32359  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13082 -- Train Loss: 0.32397  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 13083 -- Train Loss: 0.32283  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 13084 -- Train Loss: 0.32345  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 13085 -- Train Loss: 0.32332  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 13086 -- Train Loss: 0.32280  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 13087 -- Train Loss: 0.32362  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 13088 -- Train Loss: 0.32268  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 13089 -- Train Loss: 0.32284  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 13090 -- Train Loss: 0.32333  Validation Loss: 0.43305\n",
      "t: 10 EPOCH 13091 -- Train Loss: 0.32225  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 13092 -- Train Loss: 0.32330  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13093 -- Train Loss: 0.32331  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 13094 -- Train Loss: 0.32351  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 13095 -- Train Loss: 0.32343  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 13096 -- Train Loss: 0.32354  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 13097 -- Train Loss: 0.32320  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 13098 -- Train Loss: 0.32344  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 13099 -- Train Loss: 0.32350  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13100 -- Train Loss: 0.32290  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 13101 -- Train Loss: 0.32319  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 13102 -- Train Loss: 0.32329  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 13103 -- Train Loss: 0.32374  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 13104 -- Train Loss: 0.32314  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 13105 -- Train Loss: 0.32398  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 13106 -- Train Loss: 0.32325  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 13107 -- Train Loss: 0.32358  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 13108 -- Train Loss: 0.32387  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 13109 -- Train Loss: 0.32345  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13110 -- Train Loss: 0.32292  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 13111 -- Train Loss: 0.32308  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 13112 -- Train Loss: 0.32293  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 13113 -- Train Loss: 0.32396  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 13114 -- Train Loss: 0.32463  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 13115 -- Train Loss: 0.32299  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 13116 -- Train Loss: 0.32388  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 13117 -- Train Loss: 0.32353  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 13118 -- Train Loss: 0.32402  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 13119 -- Train Loss: 0.32390  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 13120 -- Train Loss: 0.32387  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 13121 -- Train Loss: 0.32379  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 13122 -- Train Loss: 0.32329  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 13123 -- Train Loss: 0.32416  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 13124 -- Train Loss: 0.32347  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 13125 -- Train Loss: 0.32409  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 13126 -- Train Loss: 0.32306  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 13127 -- Train Loss: 0.32412  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 13128 -- Train Loss: 0.32288  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 13129 -- Train Loss: 0.32327  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 13130 -- Train Loss: 0.32385  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13131 -- Train Loss: 0.32391  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 13132 -- Train Loss: 0.32408  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 13133 -- Train Loss: 0.32455  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 13134 -- Train Loss: 0.32304  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 13135 -- Train Loss: 0.32331  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 13136 -- Train Loss: 0.32399  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 13137 -- Train Loss: 0.32389  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 13138 -- Train Loss: 0.32356  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 13139 -- Train Loss: 0.32387  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 13140 -- Train Loss: 0.32460  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 13141 -- Train Loss: 0.32449  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 13142 -- Train Loss: 0.32335  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 13143 -- Train Loss: 0.32382  Validation Loss: 0.43274\n",
      "t: 10 EPOCH 13144 -- Train Loss: 0.32351  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 13145 -- Train Loss: 0.32319  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 13146 -- Train Loss: 0.32400  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 13147 -- Train Loss: 0.32410  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 13148 -- Train Loss: 0.32269  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 13149 -- Train Loss: 0.32321  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 13150 -- Train Loss: 0.32234  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 13151 -- Train Loss: 0.32423  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 13152 -- Train Loss: 0.32438  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13153 -- Train Loss: 0.32373  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 13154 -- Train Loss: 0.32330  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 13155 -- Train Loss: 0.32347  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 13156 -- Train Loss: 0.32381  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 13157 -- Train Loss: 0.32285  Validation Loss: 0.43466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13158 -- Train Loss: 0.32414  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 13159 -- Train Loss: 0.32384  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 13160 -- Train Loss: 0.32406  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 13161 -- Train Loss: 0.32359  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 13162 -- Train Loss: 0.32412  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 13163 -- Train Loss: 0.32349  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 13164 -- Train Loss: 0.32338  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 13165 -- Train Loss: 0.32440  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 13166 -- Train Loss: 0.32427  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 13167 -- Train Loss: 0.32337  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 13168 -- Train Loss: 0.32403  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 13169 -- Train Loss: 0.32398  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 13170 -- Train Loss: 0.32515  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 13171 -- Train Loss: 0.32361  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 13172 -- Train Loss: 0.32374  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13173 -- Train Loss: 0.32334  Validation Loss: 0.43310\n",
      "t: 10 EPOCH 13174 -- Train Loss: 0.32324  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 13175 -- Train Loss: 0.32364  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 13176 -- Train Loss: 0.32363  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 13177 -- Train Loss: 0.32449  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 13178 -- Train Loss: 0.32430  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 13179 -- Train Loss: 0.32310  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 13180 -- Train Loss: 0.32300  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 13181 -- Train Loss: 0.32371  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 13182 -- Train Loss: 0.32396  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 13183 -- Train Loss: 0.32354  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 13184 -- Train Loss: 0.32330  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 13185 -- Train Loss: 0.32353  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 13186 -- Train Loss: 0.32396  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 13187 -- Train Loss: 0.32330  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 13188 -- Train Loss: 0.32429  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 13189 -- Train Loss: 0.32366  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13190 -- Train Loss: 0.32382  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 13191 -- Train Loss: 0.32426  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 13192 -- Train Loss: 0.32445  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 13193 -- Train Loss: 0.32300  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 13194 -- Train Loss: 0.32360  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 13195 -- Train Loss: 0.32351  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 13196 -- Train Loss: 0.32400  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 13197 -- Train Loss: 0.32372  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 13198 -- Train Loss: 0.32372  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 13199 -- Train Loss: 0.32402  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 13200 -- Train Loss: 0.32370  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 13201 -- Train Loss: 0.32333  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 13202 -- Train Loss: 0.32330  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 13203 -- Train Loss: 0.32434  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 13204 -- Train Loss: 0.32313  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 13205 -- Train Loss: 0.32372  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 13206 -- Train Loss: 0.32371  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 13207 -- Train Loss: 0.32414  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13208 -- Train Loss: 0.32285  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13209 -- Train Loss: 0.32525  Validation Loss: 0.43690\n",
      "t: 10 EPOCH 13210 -- Train Loss: 0.32344  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 13211 -- Train Loss: 0.32475  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 13212 -- Train Loss: 0.32350  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 13213 -- Train Loss: 0.32398  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 13214 -- Train Loss: 0.32419  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 13215 -- Train Loss: 0.32447  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 13216 -- Train Loss: 0.32317  Validation Loss: 0.43301\n",
      "t: 10 EPOCH 13217 -- Train Loss: 0.32367  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 13218 -- Train Loss: 0.32379  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 13219 -- Train Loss: 0.32325  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 13220 -- Train Loss: 0.32441  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 13221 -- Train Loss: 0.32316  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 13222 -- Train Loss: 0.32331  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 13223 -- Train Loss: 0.32446  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 13224 -- Train Loss: 0.32350  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 13225 -- Train Loss: 0.32402  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 13226 -- Train Loss: 0.32352  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 13227 -- Train Loss: 0.32464  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13228 -- Train Loss: 0.32335  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13229 -- Train Loss: 0.32450  Validation Loss: 0.43209\n",
      "t: 10 EPOCH 13230 -- Train Loss: 0.32334  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 13231 -- Train Loss: 0.32369  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 13232 -- Train Loss: 0.32361  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 13233 -- Train Loss: 0.32427  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 13234 -- Train Loss: 0.32369  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 13235 -- Train Loss: 0.32397  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 13236 -- Train Loss: 0.32372  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 13237 -- Train Loss: 0.32283  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 13238 -- Train Loss: 0.32333  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 13239 -- Train Loss: 0.32348  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 13240 -- Train Loss: 0.32334  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 13241 -- Train Loss: 0.32397  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 13242 -- Train Loss: 0.32405  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 13243 -- Train Loss: 0.32318  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 13244 -- Train Loss: 0.32344  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 13245 -- Train Loss: 0.32360  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 13246 -- Train Loss: 0.32411  Validation Loss: 0.43319\n",
      "t: 10 EPOCH 13247 -- Train Loss: 0.32302  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 13248 -- Train Loss: 0.32313  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13249 -- Train Loss: 0.32320  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13250 -- Train Loss: 0.32342  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 13251 -- Train Loss: 0.32365  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 13252 -- Train Loss: 0.32240  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 13253 -- Train Loss: 0.32412  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 13254 -- Train Loss: 0.32358  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13255 -- Train Loss: 0.32335  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 13256 -- Train Loss: 0.32280  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13257 -- Train Loss: 0.32326  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 13258 -- Train Loss: 0.32237  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 13259 -- Train Loss: 0.32334  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 13260 -- Train Loss: 0.32385  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 13261 -- Train Loss: 0.32308  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 13262 -- Train Loss: 0.32334  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 13263 -- Train Loss: 0.32242  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 13264 -- Train Loss: 0.32433  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 13265 -- Train Loss: 0.32436  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 13266 -- Train Loss: 0.32303  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 13267 -- Train Loss: 0.32383  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 13268 -- Train Loss: 0.32413  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13269 -- Train Loss: 0.32418  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 13270 -- Train Loss: 0.32362  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 13271 -- Train Loss: 0.32373  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 13272 -- Train Loss: 0.32329  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 13273 -- Train Loss: 0.32380  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 13274 -- Train Loss: 0.32286  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 13275 -- Train Loss: 0.32273  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 13276 -- Train Loss: 0.32298  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 13277 -- Train Loss: 0.32310  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 13278 -- Train Loss: 0.32291  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 13279 -- Train Loss: 0.32387  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 13280 -- Train Loss: 0.32306  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 13281 -- Train Loss: 0.32380  Validation Loss: 0.43460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13282 -- Train Loss: 0.32396  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 13283 -- Train Loss: 0.32297  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 13284 -- Train Loss: 0.32367  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 13285 -- Train Loss: 0.32331  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 13286 -- Train Loss: 0.32342  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 13287 -- Train Loss: 0.32328  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 13288 -- Train Loss: 0.32363  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 13289 -- Train Loss: 0.32449  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13290 -- Train Loss: 0.32281  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 13291 -- Train Loss: 0.32343  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 13292 -- Train Loss: 0.32355  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13293 -- Train Loss: 0.32428  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 13294 -- Train Loss: 0.32412  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 13295 -- Train Loss: 0.32423  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 13296 -- Train Loss: 0.32383  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13297 -- Train Loss: 0.32356  Validation Loss: 0.43360\n",
      "t: 10 EPOCH 13298 -- Train Loss: 0.32353  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 13299 -- Train Loss: 0.32380  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 13300 -- Train Loss: 0.32317  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 13301 -- Train Loss: 0.32338  Validation Loss: 0.43311\n",
      "t: 10 EPOCH 13302 -- Train Loss: 0.32344  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 13303 -- Train Loss: 0.32311  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 13304 -- Train Loss: 0.32373  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13305 -- Train Loss: 0.32361  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13306 -- Train Loss: 0.32347  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 13307 -- Train Loss: 0.32431  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 13308 -- Train Loss: 0.32342  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 13309 -- Train Loss: 0.32329  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13310 -- Train Loss: 0.32444  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 13311 -- Train Loss: 0.32397  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 13312 -- Train Loss: 0.32444  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 13313 -- Train Loss: 0.32395  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 13314 -- Train Loss: 0.32363  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 13315 -- Train Loss: 0.32317  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 13316 -- Train Loss: 0.32379  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 13317 -- Train Loss: 0.32414  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 13318 -- Train Loss: 0.32338  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13319 -- Train Loss: 0.32343  Validation Loss: 0.43322\n",
      "t: 10 EPOCH 13320 -- Train Loss: 0.32265  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 13321 -- Train Loss: 0.32409  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 13322 -- Train Loss: 0.32320  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13323 -- Train Loss: 0.32255  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13324 -- Train Loss: 0.32322  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13325 -- Train Loss: 0.32260  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 13326 -- Train Loss: 0.32302  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 13327 -- Train Loss: 0.32470  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 13328 -- Train Loss: 0.32435  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 13329 -- Train Loss: 0.32413  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 13330 -- Train Loss: 0.32377  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 13331 -- Train Loss: 0.32413  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 13332 -- Train Loss: 0.32400  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13333 -- Train Loss: 0.32326  Validation Loss: 0.43295\n",
      "t: 10 EPOCH 13334 -- Train Loss: 0.32316  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 13335 -- Train Loss: 0.32274  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 13336 -- Train Loss: 0.32253  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 13337 -- Train Loss: 0.32307  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 13338 -- Train Loss: 0.32409  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 13339 -- Train Loss: 0.32355  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 13340 -- Train Loss: 0.32318  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 13341 -- Train Loss: 0.32286  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 13342 -- Train Loss: 0.32510  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 13343 -- Train Loss: 0.32305  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13344 -- Train Loss: 0.32484  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 13345 -- Train Loss: 0.32315  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 13346 -- Train Loss: 0.32426  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 13347 -- Train Loss: 0.32303  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 13348 -- Train Loss: 0.32323  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 13349 -- Train Loss: 0.32366  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 13350 -- Train Loss: 0.32428  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 13351 -- Train Loss: 0.32355  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 13352 -- Train Loss: 0.32365  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 13353 -- Train Loss: 0.32433  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 13354 -- Train Loss: 0.32386  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 13355 -- Train Loss: 0.32394  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 13356 -- Train Loss: 0.32307  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 13357 -- Train Loss: 0.32453  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 13358 -- Train Loss: 0.32368  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 13359 -- Train Loss: 0.32276  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 13360 -- Train Loss: 0.32347  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 13361 -- Train Loss: 0.32336  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 13362 -- Train Loss: 0.32314  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 13363 -- Train Loss: 0.32339  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 13364 -- Train Loss: 0.32340  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 13365 -- Train Loss: 0.32306  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 13366 -- Train Loss: 0.32288  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 13367 -- Train Loss: 0.32366  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 13368 -- Train Loss: 0.32320  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 13369 -- Train Loss: 0.32346  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 13370 -- Train Loss: 0.32335  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 13371 -- Train Loss: 0.32332  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 13372 -- Train Loss: 0.32405  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 13373 -- Train Loss: 0.32329  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 13374 -- Train Loss: 0.32317  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 13375 -- Train Loss: 0.32367  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 13376 -- Train Loss: 0.32384  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 13377 -- Train Loss: 0.32342  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 13378 -- Train Loss: 0.32315  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 13379 -- Train Loss: 0.32304  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 13380 -- Train Loss: 0.32280  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13381 -- Train Loss: 0.32289  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 13382 -- Train Loss: 0.32304  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 13383 -- Train Loss: 0.32438  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 13384 -- Train Loss: 0.32304  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 13385 -- Train Loss: 0.32264  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13386 -- Train Loss: 0.32327  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 13387 -- Train Loss: 0.32468  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 13388 -- Train Loss: 0.32333  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 13389 -- Train Loss: 0.32341  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 13390 -- Train Loss: 0.32413  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 13391 -- Train Loss: 0.32409  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 13392 -- Train Loss: 0.32339  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 13393 -- Train Loss: 0.32440  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 13394 -- Train Loss: 0.32318  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 13395 -- Train Loss: 0.32357  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 13396 -- Train Loss: 0.32390  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 13397 -- Train Loss: 0.32259  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 13398 -- Train Loss: 0.32377  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 13399 -- Train Loss: 0.32386  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 13400 -- Train Loss: 0.32361  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13401 -- Train Loss: 0.32371  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 13402 -- Train Loss: 0.32310  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 13403 -- Train Loss: 0.32420  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13404 -- Train Loss: 0.32369  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13405 -- Train Loss: 0.32272  Validation Loss: 0.43468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13406 -- Train Loss: 0.32323  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 13407 -- Train Loss: 0.32274  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 13408 -- Train Loss: 0.32358  Validation Loss: 0.43286\n",
      "t: 10 EPOCH 13409 -- Train Loss: 0.32384  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 13410 -- Train Loss: 0.32323  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 13411 -- Train Loss: 0.32315  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 13412 -- Train Loss: 0.32368  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 13413 -- Train Loss: 0.32318  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 13414 -- Train Loss: 0.32328  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13415 -- Train Loss: 0.32286  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13416 -- Train Loss: 0.32354  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 13417 -- Train Loss: 0.32343  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13418 -- Train Loss: 0.32420  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13419 -- Train Loss: 0.32298  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 13420 -- Train Loss: 0.32330  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 13421 -- Train Loss: 0.32287  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 13422 -- Train Loss: 0.32323  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13423 -- Train Loss: 0.32292  Validation Loss: 0.43326\n",
      "t: 10 EPOCH 13424 -- Train Loss: 0.32297  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 13425 -- Train Loss: 0.32351  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 13426 -- Train Loss: 0.32326  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 13427 -- Train Loss: 0.32351  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 13428 -- Train Loss: 0.32355  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 13429 -- Train Loss: 0.32310  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 13430 -- Train Loss: 0.32437  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 13431 -- Train Loss: 0.32313  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 13432 -- Train Loss: 0.32366  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 13433 -- Train Loss: 0.32414  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 13434 -- Train Loss: 0.32430  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 13435 -- Train Loss: 0.32349  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 13436 -- Train Loss: 0.32270  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 13437 -- Train Loss: 0.32378  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 13438 -- Train Loss: 0.32434  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 13439 -- Train Loss: 0.32358  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 13440 -- Train Loss: 0.32326  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 13441 -- Train Loss: 0.32401  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 13442 -- Train Loss: 0.32348  Validation Loss: 0.43229\n",
      "t: 10 EPOCH 13443 -- Train Loss: 0.32315  Validation Loss: 0.43355\n",
      "t: 10 EPOCH 13444 -- Train Loss: 0.32303  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 13445 -- Train Loss: 0.32400  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 13446 -- Train Loss: 0.32355  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 13447 -- Train Loss: 0.32319  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 13448 -- Train Loss: 0.32321  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 13449 -- Train Loss: 0.32375  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 13450 -- Train Loss: 0.32349  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 13451 -- Train Loss: 0.32353  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 13452 -- Train Loss: 0.32498  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 13453 -- Train Loss: 0.32204  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 13454 -- Train Loss: 0.32402  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 13455 -- Train Loss: 0.32303  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 13456 -- Train Loss: 0.32371  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 13457 -- Train Loss: 0.32386  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 13458 -- Train Loss: 0.32373  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 13459 -- Train Loss: 0.32274  Validation Loss: 0.43611\n",
      "t: 10 EPOCH 13460 -- Train Loss: 0.32416  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13461 -- Train Loss: 0.32399  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 13462 -- Train Loss: 0.32400  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 13463 -- Train Loss: 0.32341  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 13464 -- Train Loss: 0.32371  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 13465 -- Train Loss: 0.32417  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 13466 -- Train Loss: 0.32352  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 13467 -- Train Loss: 0.32459  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 13468 -- Train Loss: 0.32374  Validation Loss: 0.43649\n",
      "t: 10 EPOCH 13469 -- Train Loss: 0.32350  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 13470 -- Train Loss: 0.32362  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 13471 -- Train Loss: 0.32416  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 13472 -- Train Loss: 0.32312  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 13473 -- Train Loss: 0.32363  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 13474 -- Train Loss: 0.32366  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 13475 -- Train Loss: 0.32377  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 13476 -- Train Loss: 0.32238  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 13477 -- Train Loss: 0.32372  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 13478 -- Train Loss: 0.32444  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 13479 -- Train Loss: 0.32376  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 13480 -- Train Loss: 0.32411  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 13481 -- Train Loss: 0.32352  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 13482 -- Train Loss: 0.32324  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 13483 -- Train Loss: 0.32337  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 13484 -- Train Loss: 0.32352  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 13485 -- Train Loss: 0.32393  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 13486 -- Train Loss: 0.32385  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 13487 -- Train Loss: 0.32352  Validation Loss: 0.43144\n",
      "t: 10 EPOCH 13488 -- Train Loss: 0.32439  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 13489 -- Train Loss: 0.32354  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 13490 -- Train Loss: 0.32350  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 13491 -- Train Loss: 0.32410  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13492 -- Train Loss: 0.32395  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13493 -- Train Loss: 0.32409  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 13494 -- Train Loss: 0.32307  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 13495 -- Train Loss: 0.32423  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13496 -- Train Loss: 0.32341  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 13497 -- Train Loss: 0.32250  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 13498 -- Train Loss: 0.32290  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 13499 -- Train Loss: 0.32404  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 13500 -- Train Loss: 0.32423  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 13501 -- Train Loss: 0.32228  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 13502 -- Train Loss: 0.32243  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 13503 -- Train Loss: 0.32464  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 13504 -- Train Loss: 0.32376  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 13505 -- Train Loss: 0.32355  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 13506 -- Train Loss: 0.32304  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 13507 -- Train Loss: 0.32366  Validation Loss: 0.43254\n",
      "t: 10 EPOCH 13508 -- Train Loss: 0.32407  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 13509 -- Train Loss: 0.32351  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 13510 -- Train Loss: 0.32403  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 13511 -- Train Loss: 0.32362  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13512 -- Train Loss: 0.32337  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13513 -- Train Loss: 0.32382  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 13514 -- Train Loss: 0.32418  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 13515 -- Train Loss: 0.32352  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 13516 -- Train Loss: 0.32357  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 13517 -- Train Loss: 0.32339  Validation Loss: 0.43307\n",
      "t: 10 EPOCH 13518 -- Train Loss: 0.32332  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 13519 -- Train Loss: 0.32449  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 13520 -- Train Loss: 0.32282  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 13521 -- Train Loss: 0.32448  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13522 -- Train Loss: 0.32228  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 13523 -- Train Loss: 0.32449  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 13524 -- Train Loss: 0.32346  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 13525 -- Train Loss: 0.32453  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 13526 -- Train Loss: 0.32221  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 13527 -- Train Loss: 0.32386  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 13528 -- Train Loss: 0.32285  Validation Loss: 0.43405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13529 -- Train Loss: 0.32294  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 13530 -- Train Loss: 0.32239  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 13531 -- Train Loss: 0.32349  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 13532 -- Train Loss: 0.32333  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 13533 -- Train Loss: 0.32360  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13534 -- Train Loss: 0.32315  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 13535 -- Train Loss: 0.32327  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 13536 -- Train Loss: 0.32330  Validation Loss: 0.43250\n",
      "t: 10 EPOCH 13537 -- Train Loss: 0.32380  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 13538 -- Train Loss: 0.32326  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 13539 -- Train Loss: 0.32398  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 13540 -- Train Loss: 0.32320  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 13541 -- Train Loss: 0.32230  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 13542 -- Train Loss: 0.32366  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 13543 -- Train Loss: 0.32387  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 13544 -- Train Loss: 0.32331  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13545 -- Train Loss: 0.32190  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 13546 -- Train Loss: 0.32346  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 13547 -- Train Loss: 0.32319  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 13548 -- Train Loss: 0.32354  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 13549 -- Train Loss: 0.32313  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 13550 -- Train Loss: 0.32314  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 13551 -- Train Loss: 0.32323  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 13552 -- Train Loss: 0.32331  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 13553 -- Train Loss: 0.32227  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 13554 -- Train Loss: 0.32355  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13555 -- Train Loss: 0.32298  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 13556 -- Train Loss: 0.32334  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 13557 -- Train Loss: 0.32267  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 13558 -- Train Loss: 0.32298  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 13559 -- Train Loss: 0.32330  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13560 -- Train Loss: 0.32419  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 13561 -- Train Loss: 0.32283  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13562 -- Train Loss: 0.32162  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 13563 -- Train Loss: 0.32328  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 13564 -- Train Loss: 0.32343  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 13565 -- Train Loss: 0.32384  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 13566 -- Train Loss: 0.32364  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 13567 -- Train Loss: 0.32406  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 13568 -- Train Loss: 0.32360  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 13569 -- Train Loss: 0.32330  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 13570 -- Train Loss: 0.32348  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 13571 -- Train Loss: 0.32337  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 13572 -- Train Loss: 0.32247  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 13573 -- Train Loss: 0.32237  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 13574 -- Train Loss: 0.32318  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 13575 -- Train Loss: 0.32280  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 13576 -- Train Loss: 0.32301  Validation Loss: 0.43304\n",
      "t: 10 EPOCH 13577 -- Train Loss: 0.32287  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13578 -- Train Loss: 0.32300  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 13579 -- Train Loss: 0.32322  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 13580 -- Train Loss: 0.32402  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 13581 -- Train Loss: 0.32365  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 13582 -- Train Loss: 0.32348  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 13583 -- Train Loss: 0.32210  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 13584 -- Train Loss: 0.32343  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 13585 -- Train Loss: 0.32347  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 13586 -- Train Loss: 0.32429  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 13587 -- Train Loss: 0.32332  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 13588 -- Train Loss: 0.32361  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 13589 -- Train Loss: 0.32330  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13590 -- Train Loss: 0.32409  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 13591 -- Train Loss: 0.32272  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 13592 -- Train Loss: 0.32376  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 13593 -- Train Loss: 0.32283  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 13594 -- Train Loss: 0.32341  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 13595 -- Train Loss: 0.32296  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 13596 -- Train Loss: 0.32451  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 13597 -- Train Loss: 0.32250  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 13598 -- Train Loss: 0.32373  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 13599 -- Train Loss: 0.32355  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 13600 -- Train Loss: 0.32383  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 13601 -- Train Loss: 0.32189  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 13602 -- Train Loss: 0.32445  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 13603 -- Train Loss: 0.32353  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 13604 -- Train Loss: 0.32407  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 13605 -- Train Loss: 0.32290  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 13606 -- Train Loss: 0.32427  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 13607 -- Train Loss: 0.32212  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 13608 -- Train Loss: 0.32357  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 13609 -- Train Loss: 0.32391  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13610 -- Train Loss: 0.32458  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 13611 -- Train Loss: 0.32249  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 13612 -- Train Loss: 0.32379  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 13613 -- Train Loss: 0.32367  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 13614 -- Train Loss: 0.32417  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 13615 -- Train Loss: 0.32259  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 13616 -- Train Loss: 0.32414  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 13617 -- Train Loss: 0.32366  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 13618 -- Train Loss: 0.32378  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 13619 -- Train Loss: 0.32331  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 13620 -- Train Loss: 0.32454  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 13621 -- Train Loss: 0.32375  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 13622 -- Train Loss: 0.32336  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 13623 -- Train Loss: 0.32391  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 13624 -- Train Loss: 0.32367  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13625 -- Train Loss: 0.32333  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 13626 -- Train Loss: 0.32378  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13627 -- Train Loss: 0.32373  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 13628 -- Train Loss: 0.32376  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 13629 -- Train Loss: 0.32365  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 13630 -- Train Loss: 0.32313  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 13631 -- Train Loss: 0.32424  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 13632 -- Train Loss: 0.32236  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 13633 -- Train Loss: 0.32452  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 13634 -- Train Loss: 0.32156  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 13635 -- Train Loss: 0.32485  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 13636 -- Train Loss: 0.32346  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 13637 -- Train Loss: 0.32309  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 13638 -- Train Loss: 0.32186  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13639 -- Train Loss: 0.32312  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 13640 -- Train Loss: 0.32357  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 13641 -- Train Loss: 0.32328  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 13642 -- Train Loss: 0.32312  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13643 -- Train Loss: 0.32273  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 13644 -- Train Loss: 0.32398  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 13645 -- Train Loss: 0.32288  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 13646 -- Train Loss: 0.32352  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13647 -- Train Loss: 0.32233  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 13648 -- Train Loss: 0.32419  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 13649 -- Train Loss: 0.32399  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 13650 -- Train Loss: 0.32357  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 13651 -- Train Loss: 0.32319  Validation Loss: 0.43330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13652 -- Train Loss: 0.32489  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 13653 -- Train Loss: 0.32284  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 13654 -- Train Loss: 0.32381  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 13655 -- Train Loss: 0.32351  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 13656 -- Train Loss: 0.32391  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13657 -- Train Loss: 0.32334  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 13658 -- Train Loss: 0.32371  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 13659 -- Train Loss: 0.32326  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13660 -- Train Loss: 0.32385  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 13661 -- Train Loss: 0.32382  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 13662 -- Train Loss: 0.32401  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 13663 -- Train Loss: 0.32223  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 13664 -- Train Loss: 0.32399  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 13665 -- Train Loss: 0.32348  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 13666 -- Train Loss: 0.32332  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 13667 -- Train Loss: 0.32350  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 13668 -- Train Loss: 0.32356  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 13669 -- Train Loss: 0.32412  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 13670 -- Train Loss: 0.32393  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 13671 -- Train Loss: 0.32297  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 13672 -- Train Loss: 0.32291  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 13673 -- Train Loss: 0.32379  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 13674 -- Train Loss: 0.32317  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 13675 -- Train Loss: 0.32288  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 13676 -- Train Loss: 0.32362  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 13677 -- Train Loss: 0.32399  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 13678 -- Train Loss: 0.32289  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 13679 -- Train Loss: 0.32383  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 13680 -- Train Loss: 0.32316  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 13681 -- Train Loss: 0.32353  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 13682 -- Train Loss: 0.32307  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 13683 -- Train Loss: 0.32321  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 13684 -- Train Loss: 0.32326  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 13685 -- Train Loss: 0.32313  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 13686 -- Train Loss: 0.32215  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 13687 -- Train Loss: 0.32393  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 13688 -- Train Loss: 0.32289  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 13689 -- Train Loss: 0.32391  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 13690 -- Train Loss: 0.32321  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 13691 -- Train Loss: 0.32416  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 13692 -- Train Loss: 0.32359  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 13693 -- Train Loss: 0.32396  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 13694 -- Train Loss: 0.32298  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13695 -- Train Loss: 0.32428  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 13696 -- Train Loss: 0.32326  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 13697 -- Train Loss: 0.32361  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 13698 -- Train Loss: 0.32353  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 13699 -- Train Loss: 0.32341  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 13700 -- Train Loss: 0.32310  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 13701 -- Train Loss: 0.32297  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 13702 -- Train Loss: 0.32345  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 13703 -- Train Loss: 0.32356  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 13704 -- Train Loss: 0.32374  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 13705 -- Train Loss: 0.32355  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 13706 -- Train Loss: 0.32382  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 13707 -- Train Loss: 0.32295  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 13708 -- Train Loss: 0.32280  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 13709 -- Train Loss: 0.32312  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 13710 -- Train Loss: 0.32302  Validation Loss: 0.43715\n",
      "t: 10 EPOCH 13711 -- Train Loss: 0.32290  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 13712 -- Train Loss: 0.32266  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 13713 -- Train Loss: 0.32284  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 13714 -- Train Loss: 0.32322  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 13715 -- Train Loss: 0.32349  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 13716 -- Train Loss: 0.32316  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13717 -- Train Loss: 0.32238  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13718 -- Train Loss: 0.32285  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 13719 -- Train Loss: 0.32401  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13720 -- Train Loss: 0.32230  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 13721 -- Train Loss: 0.32285  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 13722 -- Train Loss: 0.32273  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 13723 -- Train Loss: 0.32314  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 13724 -- Train Loss: 0.32346  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 13725 -- Train Loss: 0.32316  Validation Loss: 0.43293\n",
      "t: 10 EPOCH 13726 -- Train Loss: 0.32285  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 13727 -- Train Loss: 0.32391  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 13728 -- Train Loss: 0.32271  Validation Loss: 0.43728\n",
      "t: 10 EPOCH 13729 -- Train Loss: 0.32246  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 13730 -- Train Loss: 0.32341  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 13731 -- Train Loss: 0.32253  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 13732 -- Train Loss: 0.32351  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 13733 -- Train Loss: 0.32367  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 13734 -- Train Loss: 0.32404  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 13735 -- Train Loss: 0.32326  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 13736 -- Train Loss: 0.32340  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 13737 -- Train Loss: 0.32298  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 13738 -- Train Loss: 0.32208  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13739 -- Train Loss: 0.32274  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 13740 -- Train Loss: 0.32373  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 13741 -- Train Loss: 0.32319  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 13742 -- Train Loss: 0.32298  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13743 -- Train Loss: 0.32357  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 13744 -- Train Loss: 0.32281  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 13745 -- Train Loss: 0.32293  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 13746 -- Train Loss: 0.32322  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 13747 -- Train Loss: 0.32338  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 13748 -- Train Loss: 0.32290  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 13749 -- Train Loss: 0.32256  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 13750 -- Train Loss: 0.32270  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 13751 -- Train Loss: 0.32263  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 13752 -- Train Loss: 0.32283  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 13753 -- Train Loss: 0.32337  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 13754 -- Train Loss: 0.32291  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 13755 -- Train Loss: 0.32304  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 13756 -- Train Loss: 0.32306  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 13757 -- Train Loss: 0.32378  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 13758 -- Train Loss: 0.32299  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 13759 -- Train Loss: 0.32236  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 13760 -- Train Loss: 0.32255  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 13761 -- Train Loss: 0.32285  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 13762 -- Train Loss: 0.32330  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 13763 -- Train Loss: 0.32320  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 13764 -- Train Loss: 0.32254  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 13765 -- Train Loss: 0.32293  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 13766 -- Train Loss: 0.32391  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 13767 -- Train Loss: 0.32302  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 13768 -- Train Loss: 0.32326  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 13769 -- Train Loss: 0.32387  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 13770 -- Train Loss: 0.32338  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 13771 -- Train Loss: 0.32311  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 13772 -- Train Loss: 0.32283  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 13773 -- Train Loss: 0.32364  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 13774 -- Train Loss: 0.32391  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 13775 -- Train Loss: 0.32266  Validation Loss: 0.43516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13776 -- Train Loss: 0.32404  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 13777 -- Train Loss: 0.32289  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 13778 -- Train Loss: 0.32331  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 13779 -- Train Loss: 0.32331  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 13780 -- Train Loss: 0.32399  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13781 -- Train Loss: 0.32355  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 13782 -- Train Loss: 0.32325  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 13783 -- Train Loss: 0.32363  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13784 -- Train Loss: 0.32299  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 13785 -- Train Loss: 0.32418  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 13786 -- Train Loss: 0.32344  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 13787 -- Train Loss: 0.32283  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 13788 -- Train Loss: 0.32355  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 13789 -- Train Loss: 0.32357  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 13790 -- Train Loss: 0.32330  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 13791 -- Train Loss: 0.32345  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 13792 -- Train Loss: 0.32301  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 13793 -- Train Loss: 0.32443  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 13794 -- Train Loss: 0.32380  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 13795 -- Train Loss: 0.32315  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 13796 -- Train Loss: 0.32382  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 13797 -- Train Loss: 0.32278  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 13798 -- Train Loss: 0.32340  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 13799 -- Train Loss: 0.32351  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 13800 -- Train Loss: 0.32396  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 13801 -- Train Loss: 0.32406  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 13802 -- Train Loss: 0.32316  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 13803 -- Train Loss: 0.32257  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 13804 -- Train Loss: 0.32398  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 13805 -- Train Loss: 0.32327  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 13806 -- Train Loss: 0.32346  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 13807 -- Train Loss: 0.32334  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 13808 -- Train Loss: 0.32398  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 13809 -- Train Loss: 0.32272  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 13810 -- Train Loss: 0.32467  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 13811 -- Train Loss: 0.32389  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 13812 -- Train Loss: 0.32381  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 13813 -- Train Loss: 0.32281  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 13814 -- Train Loss: 0.32382  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 13815 -- Train Loss: 0.32370  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 13816 -- Train Loss: 0.32364  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 13817 -- Train Loss: 0.32370  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 13818 -- Train Loss: 0.32291  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 13819 -- Train Loss: 0.32334  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 13820 -- Train Loss: 0.32293  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 13821 -- Train Loss: 0.32374  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 13822 -- Train Loss: 0.32256  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 13823 -- Train Loss: 0.32392  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 13824 -- Train Loss: 0.32279  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 13825 -- Train Loss: 0.32351  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 13826 -- Train Loss: 0.32406  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 13827 -- Train Loss: 0.32424  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 13828 -- Train Loss: 0.32350  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 13829 -- Train Loss: 0.32289  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 13830 -- Train Loss: 0.32379  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13831 -- Train Loss: 0.32347  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 13832 -- Train Loss: 0.32353  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 13833 -- Train Loss: 0.32286  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 13834 -- Train Loss: 0.32395  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 13835 -- Train Loss: 0.32263  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 13836 -- Train Loss: 0.32398  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 13837 -- Train Loss: 0.32342  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 13838 -- Train Loss: 0.32296  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13839 -- Train Loss: 0.32390  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 13840 -- Train Loss: 0.32342  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 13841 -- Train Loss: 0.32431  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 13842 -- Train Loss: 0.32255  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13843 -- Train Loss: 0.32344  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 13844 -- Train Loss: 0.32270  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 13845 -- Train Loss: 0.32314  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 13846 -- Train Loss: 0.32384  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 13847 -- Train Loss: 0.32292  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 13848 -- Train Loss: 0.32310  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13849 -- Train Loss: 0.32301  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 13850 -- Train Loss: 0.32282  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 13851 -- Train Loss: 0.32342  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 13852 -- Train Loss: 0.32295  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 13853 -- Train Loss: 0.32269  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 13854 -- Train Loss: 0.32247  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 13855 -- Train Loss: 0.32303  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 13856 -- Train Loss: 0.32274  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 13857 -- Train Loss: 0.32250  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 13858 -- Train Loss: 0.32339  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13859 -- Train Loss: 0.32345  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 13860 -- Train Loss: 0.32241  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 13861 -- Train Loss: 0.32285  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13862 -- Train Loss: 0.32325  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 13863 -- Train Loss: 0.32335  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 13864 -- Train Loss: 0.32268  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 13865 -- Train Loss: 0.32196  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 13866 -- Train Loss: 0.32279  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 13867 -- Train Loss: 0.32333  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 13868 -- Train Loss: 0.32287  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 13869 -- Train Loss: 0.32345  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 13870 -- Train Loss: 0.32358  Validation Loss: 0.43267\n",
      "t: 10 EPOCH 13871 -- Train Loss: 0.32345  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13872 -- Train Loss: 0.32353  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 13873 -- Train Loss: 0.32367  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 13874 -- Train Loss: 0.32340  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 13875 -- Train Loss: 0.32297  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 13876 -- Train Loss: 0.32278  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 13877 -- Train Loss: 0.32345  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 13878 -- Train Loss: 0.32309  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 13879 -- Train Loss: 0.32300  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 13880 -- Train Loss: 0.32414  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 13881 -- Train Loss: 0.32372  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 13882 -- Train Loss: 0.32284  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 13883 -- Train Loss: 0.32283  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 13884 -- Train Loss: 0.32326  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 13885 -- Train Loss: 0.32329  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 13886 -- Train Loss: 0.32368  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 13887 -- Train Loss: 0.32288  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 13888 -- Train Loss: 0.32271  Validation Loss: 0.43320\n",
      "t: 10 EPOCH 13889 -- Train Loss: 0.32331  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13890 -- Train Loss: 0.32248  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 13891 -- Train Loss: 0.32332  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 13892 -- Train Loss: 0.32332  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 13893 -- Train Loss: 0.32383  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 13894 -- Train Loss: 0.32316  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 13895 -- Train Loss: 0.32311  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 13896 -- Train Loss: 0.32320  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 13897 -- Train Loss: 0.32386  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 13898 -- Train Loss: 0.32300  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 13899 -- Train Loss: 0.32231  Validation Loss: 0.43411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 13900 -- Train Loss: 0.32262  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 13901 -- Train Loss: 0.32297  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 13902 -- Train Loss: 0.32291  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 13903 -- Train Loss: 0.32253  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 13904 -- Train Loss: 0.32345  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 13905 -- Train Loss: 0.32343  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 13906 -- Train Loss: 0.32354  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 13907 -- Train Loss: 0.32297  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 13908 -- Train Loss: 0.32254  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 13909 -- Train Loss: 0.32308  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 13910 -- Train Loss: 0.32281  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 13911 -- Train Loss: 0.32338  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 13912 -- Train Loss: 0.32244  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 13913 -- Train Loss: 0.32379  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13914 -- Train Loss: 0.32346  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 13915 -- Train Loss: 0.32350  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 13916 -- Train Loss: 0.32268  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 13917 -- Train Loss: 0.32391  Validation Loss: 0.43220\n",
      "t: 10 EPOCH 13918 -- Train Loss: 0.32349  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 13919 -- Train Loss: 0.32388  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 13920 -- Train Loss: 0.32286  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 13921 -- Train Loss: 0.32378  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 13922 -- Train Loss: 0.32368  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 13923 -- Train Loss: 0.32207  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 13924 -- Train Loss: 0.32284  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 13925 -- Train Loss: 0.32316  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 13926 -- Train Loss: 0.32351  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 13927 -- Train Loss: 0.32346  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 13928 -- Train Loss: 0.32344  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 13929 -- Train Loss: 0.32226  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 13930 -- Train Loss: 0.32344  Validation Loss: 0.43262\n",
      "t: 10 EPOCH 13931 -- Train Loss: 0.32388  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 13932 -- Train Loss: 0.32354  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 13933 -- Train Loss: 0.32368  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 13934 -- Train Loss: 0.32325  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13935 -- Train Loss: 0.32339  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 13936 -- Train Loss: 0.32390  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 13937 -- Train Loss: 0.32314  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13938 -- Train Loss: 0.32348  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 13939 -- Train Loss: 0.32337  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 13940 -- Train Loss: 0.32275  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 13941 -- Train Loss: 0.32395  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 13942 -- Train Loss: 0.32392  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 13943 -- Train Loss: 0.32332  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 13944 -- Train Loss: 0.32268  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 13945 -- Train Loss: 0.32306  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 13946 -- Train Loss: 0.32342  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 13947 -- Train Loss: 0.32392  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 13948 -- Train Loss: 0.32358  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 13949 -- Train Loss: 0.32386  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 13950 -- Train Loss: 0.32247  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 13951 -- Train Loss: 0.32331  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 13952 -- Train Loss: 0.32300  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 13953 -- Train Loss: 0.32212  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 13954 -- Train Loss: 0.32294  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 13955 -- Train Loss: 0.32325  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 13956 -- Train Loss: 0.32387  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 13957 -- Train Loss: 0.32333  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 13958 -- Train Loss: 0.32360  Validation Loss: 0.43325\n",
      "t: 10 EPOCH 13959 -- Train Loss: 0.32283  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 13960 -- Train Loss: 0.32356  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 13961 -- Train Loss: 0.32299  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13962 -- Train Loss: 0.32372  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 13963 -- Train Loss: 0.32227  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 13964 -- Train Loss: 0.32348  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 13965 -- Train Loss: 0.32292  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 13966 -- Train Loss: 0.32339  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 13967 -- Train Loss: 0.32319  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 13968 -- Train Loss: 0.32375  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 13969 -- Train Loss: 0.32306  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 13970 -- Train Loss: 0.32306  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 13971 -- Train Loss: 0.32282  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 13972 -- Train Loss: 0.32257  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 13973 -- Train Loss: 0.32294  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 13974 -- Train Loss: 0.32282  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 13975 -- Train Loss: 0.32289  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 13976 -- Train Loss: 0.32298  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 13977 -- Train Loss: 0.32315  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 13978 -- Train Loss: 0.32299  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 13979 -- Train Loss: 0.32265  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 13980 -- Train Loss: 0.32282  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 13981 -- Train Loss: 0.32277  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 13982 -- Train Loss: 0.32427  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 13983 -- Train Loss: 0.32290  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 13984 -- Train Loss: 0.32254  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 13985 -- Train Loss: 0.32342  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 13986 -- Train Loss: 0.32298  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 13987 -- Train Loss: 0.32338  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 13988 -- Train Loss: 0.32285  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 13989 -- Train Loss: 0.32382  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 13990 -- Train Loss: 0.32406  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 13991 -- Train Loss: 0.32304  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 13992 -- Train Loss: 0.32321  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 13993 -- Train Loss: 0.32319  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 13994 -- Train Loss: 0.32346  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 13995 -- Train Loss: 0.32292  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 13996 -- Train Loss: 0.32321  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 13997 -- Train Loss: 0.32235  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 13998 -- Train Loss: 0.32339  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 13999 -- Train Loss: 0.32294  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 14000 -- Train Loss: 0.32275  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 14001 -- Train Loss: 0.32349  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14002 -- Train Loss: 0.32298  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 14003 -- Train Loss: 0.32279  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 14004 -- Train Loss: 0.32307  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 14005 -- Train Loss: 0.32275  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 14006 -- Train Loss: 0.32329  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 14007 -- Train Loss: 0.32270  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 14008 -- Train Loss: 0.32373  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 14009 -- Train Loss: 0.32346  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 14010 -- Train Loss: 0.32305  Validation Loss: 0.43333\n",
      "t: 10 EPOCH 14011 -- Train Loss: 0.32319  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14012 -- Train Loss: 0.32324  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 14013 -- Train Loss: 0.32288  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 14014 -- Train Loss: 0.32325  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 14015 -- Train Loss: 0.32321  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 14016 -- Train Loss: 0.32354  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 14017 -- Train Loss: 0.32381  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 14018 -- Train Loss: 0.32359  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 14019 -- Train Loss: 0.32355  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 14020 -- Train Loss: 0.32326  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 14021 -- Train Loss: 0.32351  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 14022 -- Train Loss: 0.32344  Validation Loss: 0.43494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14023 -- Train Loss: 0.32369  Validation Loss: 0.43252\n",
      "t: 10 EPOCH 14024 -- Train Loss: 0.32280  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 14025 -- Train Loss: 0.32329  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 14026 -- Train Loss: 0.32294  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14027 -- Train Loss: 0.32312  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 14028 -- Train Loss: 0.32278  Validation Loss: 0.43329\n",
      "t: 10 EPOCH 14029 -- Train Loss: 0.32249  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 14030 -- Train Loss: 0.32305  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 14031 -- Train Loss: 0.32282  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 14032 -- Train Loss: 0.32305  Validation Loss: 0.43336\n",
      "t: 10 EPOCH 14033 -- Train Loss: 0.32378  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 14034 -- Train Loss: 0.32327  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 14035 -- Train Loss: 0.32377  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 14036 -- Train Loss: 0.32373  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 14037 -- Train Loss: 0.32317  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 14038 -- Train Loss: 0.32264  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 14039 -- Train Loss: 0.32290  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 14040 -- Train Loss: 0.32367  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 14041 -- Train Loss: 0.32338  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 14042 -- Train Loss: 0.32187  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 14043 -- Train Loss: 0.32293  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 14044 -- Train Loss: 0.32269  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 14045 -- Train Loss: 0.32400  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 14046 -- Train Loss: 0.32348  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 14047 -- Train Loss: 0.32261  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 14048 -- Train Loss: 0.32213  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 14049 -- Train Loss: 0.32337  Validation Loss: 0.43236\n",
      "t: 10 EPOCH 14050 -- Train Loss: 0.32362  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 14051 -- Train Loss: 0.32327  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 14052 -- Train Loss: 0.32293  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 14053 -- Train Loss: 0.32337  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 14054 -- Train Loss: 0.32231  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 14055 -- Train Loss: 0.32343  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 14056 -- Train Loss: 0.32343  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 14057 -- Train Loss: 0.32341  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14058 -- Train Loss: 0.32403  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 14059 -- Train Loss: 0.32275  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 14060 -- Train Loss: 0.32234  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 14061 -- Train Loss: 0.32371  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 14062 -- Train Loss: 0.32345  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 14063 -- Train Loss: 0.32327  Validation Loss: 0.43272\n",
      "t: 10 EPOCH 14064 -- Train Loss: 0.32273  Validation Loss: 0.43318\n",
      "t: 10 EPOCH 14065 -- Train Loss: 0.32238  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 14066 -- Train Loss: 0.32315  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 14067 -- Train Loss: 0.32361  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 14068 -- Train Loss: 0.32327  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 14069 -- Train Loss: 0.32352  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 14070 -- Train Loss: 0.32368  Validation Loss: 0.43263\n",
      "t: 10 EPOCH 14071 -- Train Loss: 0.32374  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 14072 -- Train Loss: 0.32335  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 14073 -- Train Loss: 0.32350  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14074 -- Train Loss: 0.32287  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 14075 -- Train Loss: 0.32336  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 14076 -- Train Loss: 0.32376  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 14077 -- Train Loss: 0.32317  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 14078 -- Train Loss: 0.32369  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 14079 -- Train Loss: 0.32280  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 14080 -- Train Loss: 0.32335  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 14081 -- Train Loss: 0.32280  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 14082 -- Train Loss: 0.32323  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 14083 -- Train Loss: 0.32322  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 14084 -- Train Loss: 0.32334  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 14085 -- Train Loss: 0.32345  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 14086 -- Train Loss: 0.32275  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 14087 -- Train Loss: 0.32259  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 14088 -- Train Loss: 0.32307  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14089 -- Train Loss: 0.32418  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 14090 -- Train Loss: 0.32289  Validation Loss: 0.43673\n",
      "t: 10 EPOCH 14091 -- Train Loss: 0.32323  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 14092 -- Train Loss: 0.32253  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 14093 -- Train Loss: 0.32361  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 14094 -- Train Loss: 0.32290  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 14095 -- Train Loss: 0.32241  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 14096 -- Train Loss: 0.32343  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 14097 -- Train Loss: 0.32237  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 14098 -- Train Loss: 0.32307  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 14099 -- Train Loss: 0.32188  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 14100 -- Train Loss: 0.32443  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 14101 -- Train Loss: 0.32296  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 14102 -- Train Loss: 0.32345  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 14103 -- Train Loss: 0.32170  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 14104 -- Train Loss: 0.32327  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 14105 -- Train Loss: 0.32337  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 14106 -- Train Loss: 0.32302  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 14107 -- Train Loss: 0.32362  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 14108 -- Train Loss: 0.32307  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 14109 -- Train Loss: 0.32262  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 14110 -- Train Loss: 0.32289  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 14111 -- Train Loss: 0.32272  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 14112 -- Train Loss: 0.32322  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 14113 -- Train Loss: 0.32323  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 14114 -- Train Loss: 0.32243  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 14115 -- Train Loss: 0.32257  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 14116 -- Train Loss: 0.32267  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 14117 -- Train Loss: 0.32288  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 14118 -- Train Loss: 0.32311  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 14119 -- Train Loss: 0.32318  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 14120 -- Train Loss: 0.32294  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 14121 -- Train Loss: 0.32278  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14122 -- Train Loss: 0.32317  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 14123 -- Train Loss: 0.32332  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 14124 -- Train Loss: 0.32358  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 14125 -- Train Loss: 0.32311  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 14126 -- Train Loss: 0.32312  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14127 -- Train Loss: 0.32284  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 14128 -- Train Loss: 0.32272  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 14129 -- Train Loss: 0.32338  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 14130 -- Train Loss: 0.32336  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 14131 -- Train Loss: 0.32339  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 14132 -- Train Loss: 0.32355  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 14133 -- Train Loss: 0.32267  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 14134 -- Train Loss: 0.32323  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 14135 -- Train Loss: 0.32260  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 14136 -- Train Loss: 0.32323  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 14137 -- Train Loss: 0.32269  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 14138 -- Train Loss: 0.32293  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 14139 -- Train Loss: 0.32284  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 14140 -- Train Loss: 0.32216  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 14141 -- Train Loss: 0.32319  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 14142 -- Train Loss: 0.32263  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 14143 -- Train Loss: 0.32236  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 14144 -- Train Loss: 0.32379  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 14145 -- Train Loss: 0.32386  Validation Loss: 0.43377\n",
      "t: 10 EPOCH 14146 -- Train Loss: 0.32241  Validation Loss: 0.43408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14147 -- Train Loss: 0.32361  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 14148 -- Train Loss: 0.32265  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 14149 -- Train Loss: 0.32327  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 14150 -- Train Loss: 0.32388  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 14151 -- Train Loss: 0.32363  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 14152 -- Train Loss: 0.32151  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 14153 -- Train Loss: 0.32256  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 14154 -- Train Loss: 0.32309  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14155 -- Train Loss: 0.32184  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 14156 -- Train Loss: 0.32323  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14157 -- Train Loss: 0.32227  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 14158 -- Train Loss: 0.32277  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 14159 -- Train Loss: 0.32285  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 14160 -- Train Loss: 0.32318  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 14161 -- Train Loss: 0.32329  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 14162 -- Train Loss: 0.32320  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 14163 -- Train Loss: 0.32279  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 14164 -- Train Loss: 0.32391  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 14165 -- Train Loss: 0.32298  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 14166 -- Train Loss: 0.32307  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 14167 -- Train Loss: 0.32375  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 14168 -- Train Loss: 0.32303  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14169 -- Train Loss: 0.32303  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 14170 -- Train Loss: 0.32304  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 14171 -- Train Loss: 0.32357  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 14172 -- Train Loss: 0.32301  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 14173 -- Train Loss: 0.32272  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 14174 -- Train Loss: 0.32319  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 14175 -- Train Loss: 0.32317  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 14176 -- Train Loss: 0.32331  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 14177 -- Train Loss: 0.32256  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 14178 -- Train Loss: 0.32272  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 14179 -- Train Loss: 0.32339  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 14180 -- Train Loss: 0.32369  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 14181 -- Train Loss: 0.32424  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 14182 -- Train Loss: 0.32299  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 14183 -- Train Loss: 0.32382  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 14184 -- Train Loss: 0.32266  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 14185 -- Train Loss: 0.32307  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 14186 -- Train Loss: 0.32276  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 14187 -- Train Loss: 0.32346  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 14188 -- Train Loss: 0.32361  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 14189 -- Train Loss: 0.32404  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 14190 -- Train Loss: 0.32367  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 14191 -- Train Loss: 0.32380  Validation Loss: 0.43611\n",
      "t: 10 EPOCH 14192 -- Train Loss: 0.32350  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 14193 -- Train Loss: 0.32323  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 14194 -- Train Loss: 0.32342  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 14195 -- Train Loss: 0.32284  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 14196 -- Train Loss: 0.32271  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 14197 -- Train Loss: 0.32419  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 14198 -- Train Loss: 0.32292  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 14199 -- Train Loss: 0.32330  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 14200 -- Train Loss: 0.32386  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 14201 -- Train Loss: 0.32292  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14202 -- Train Loss: 0.32425  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 14203 -- Train Loss: 0.32252  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 14204 -- Train Loss: 0.32393  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 14205 -- Train Loss: 0.32322  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 14206 -- Train Loss: 0.32341  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 14207 -- Train Loss: 0.32284  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 14208 -- Train Loss: 0.32325  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 14209 -- Train Loss: 0.32386  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 14210 -- Train Loss: 0.32277  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 14211 -- Train Loss: 0.32292  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 14212 -- Train Loss: 0.32399  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 14213 -- Train Loss: 0.32330  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 14214 -- Train Loss: 0.32283  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 14215 -- Train Loss: 0.32337  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 14216 -- Train Loss: 0.32344  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 14217 -- Train Loss: 0.32330  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 14218 -- Train Loss: 0.32261  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 14219 -- Train Loss: 0.32316  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 14220 -- Train Loss: 0.32333  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 14221 -- Train Loss: 0.32343  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 14222 -- Train Loss: 0.32375  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 14223 -- Train Loss: 0.32208  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 14224 -- Train Loss: 0.32350  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 14225 -- Train Loss: 0.32326  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 14226 -- Train Loss: 0.32285  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 14227 -- Train Loss: 0.32215  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 14228 -- Train Loss: 0.32316  Validation Loss: 0.43239\n",
      "t: 10 EPOCH 14229 -- Train Loss: 0.32295  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 14230 -- Train Loss: 0.32312  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 14231 -- Train Loss: 0.32248  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 14232 -- Train Loss: 0.32253  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 14233 -- Train Loss: 0.32218  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14234 -- Train Loss: 0.32254  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 14235 -- Train Loss: 0.32298  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 14236 -- Train Loss: 0.32293  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 14237 -- Train Loss: 0.32306  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 14238 -- Train Loss: 0.32274  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 14239 -- Train Loss: 0.32395  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 14240 -- Train Loss: 0.32226  Validation Loss: 0.43687\n",
      "t: 10 EPOCH 14241 -- Train Loss: 0.32277  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 14242 -- Train Loss: 0.32288  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 14243 -- Train Loss: 0.32332  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 14244 -- Train Loss: 0.32354  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 14245 -- Train Loss: 0.32337  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 14246 -- Train Loss: 0.32205  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 14247 -- Train Loss: 0.32296  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 14248 -- Train Loss: 0.32318  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 14249 -- Train Loss: 0.32203  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 14250 -- Train Loss: 0.32269  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 14251 -- Train Loss: 0.32182  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14252 -- Train Loss: 0.32249  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 14253 -- Train Loss: 0.32327  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 14254 -- Train Loss: 0.32142  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 14255 -- Train Loss: 0.32297  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 14256 -- Train Loss: 0.32173  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 14257 -- Train Loss: 0.32284  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 14258 -- Train Loss: 0.32267  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 14259 -- Train Loss: 0.32224  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 14260 -- Train Loss: 0.32269  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 14261 -- Train Loss: 0.32236  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14262 -- Train Loss: 0.32198  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 14263 -- Train Loss: 0.32317  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 14264 -- Train Loss: 0.32279  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 14265 -- Train Loss: 0.32271  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 14266 -- Train Loss: 0.32304  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 14267 -- Train Loss: 0.32232  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 14268 -- Train Loss: 0.32254  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 14269 -- Train Loss: 0.32264  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 14270 -- Train Loss: 0.32272  Validation Loss: 0.43274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14271 -- Train Loss: 0.32309  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 14272 -- Train Loss: 0.32311  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 14273 -- Train Loss: 0.32334  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 14274 -- Train Loss: 0.32319  Validation Loss: 0.43303\n",
      "t: 10 EPOCH 14275 -- Train Loss: 0.32281  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 14276 -- Train Loss: 0.32357  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 14277 -- Train Loss: 0.32301  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 14278 -- Train Loss: 0.32258  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 14279 -- Train Loss: 0.32246  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 14280 -- Train Loss: 0.32300  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 14281 -- Train Loss: 0.32223  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 14282 -- Train Loss: 0.32310  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 14283 -- Train Loss: 0.32218  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 14284 -- Train Loss: 0.32290  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 14285 -- Train Loss: 0.32271  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 14286 -- Train Loss: 0.32328  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 14287 -- Train Loss: 0.32276  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 14288 -- Train Loss: 0.32261  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14289 -- Train Loss: 0.32229  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 14290 -- Train Loss: 0.32345  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 14291 -- Train Loss: 0.32265  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 14292 -- Train Loss: 0.32304  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 14293 -- Train Loss: 0.32241  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 14294 -- Train Loss: 0.32318  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 14295 -- Train Loss: 0.32263  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 14296 -- Train Loss: 0.32225  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 14297 -- Train Loss: 0.32286  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 14298 -- Train Loss: 0.32245  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 14299 -- Train Loss: 0.32322  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 14300 -- Train Loss: 0.32269  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14301 -- Train Loss: 0.32346  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 14302 -- Train Loss: 0.32297  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 14303 -- Train Loss: 0.32177  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 14304 -- Train Loss: 0.32310  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 14305 -- Train Loss: 0.32252  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14306 -- Train Loss: 0.32388  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14307 -- Train Loss: 0.32284  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 14308 -- Train Loss: 0.32300  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 14309 -- Train Loss: 0.32209  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 14310 -- Train Loss: 0.32332  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 14311 -- Train Loss: 0.32279  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 14312 -- Train Loss: 0.32334  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 14313 -- Train Loss: 0.32280  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 14314 -- Train Loss: 0.32305  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14315 -- Train Loss: 0.32276  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 14316 -- Train Loss: 0.32298  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 14317 -- Train Loss: 0.32259  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 14318 -- Train Loss: 0.32240  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 14319 -- Train Loss: 0.32231  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 14320 -- Train Loss: 0.32330  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 14321 -- Train Loss: 0.32301  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 14322 -- Train Loss: 0.32179  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 14323 -- Train Loss: 0.32365  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 14324 -- Train Loss: 0.32317  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 14325 -- Train Loss: 0.32410  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14326 -- Train Loss: 0.32259  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 14327 -- Train Loss: 0.32174  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 14328 -- Train Loss: 0.32268  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 14329 -- Train Loss: 0.32313  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 14330 -- Train Loss: 0.32330  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 14331 -- Train Loss: 0.32328  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 14332 -- Train Loss: 0.32276  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 14333 -- Train Loss: 0.32191  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 14334 -- Train Loss: 0.32338  Validation Loss: 0.43280\n",
      "t: 10 EPOCH 14335 -- Train Loss: 0.32244  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 14336 -- Train Loss: 0.32271  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14337 -- Train Loss: 0.32283  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 14338 -- Train Loss: 0.32347  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14339 -- Train Loss: 0.32217  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 14340 -- Train Loss: 0.32258  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 14341 -- Train Loss: 0.32400  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 14342 -- Train Loss: 0.32286  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 14343 -- Train Loss: 0.32229  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 14344 -- Train Loss: 0.32204  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 14345 -- Train Loss: 0.32342  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 14346 -- Train Loss: 0.32323  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 14347 -- Train Loss: 0.32286  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 14348 -- Train Loss: 0.32236  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 14349 -- Train Loss: 0.32241  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 14350 -- Train Loss: 0.32346  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 14351 -- Train Loss: 0.32208  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 14352 -- Train Loss: 0.32258  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 14353 -- Train Loss: 0.32243  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 14354 -- Train Loss: 0.32257  Validation Loss: 0.43328\n",
      "t: 10 EPOCH 14355 -- Train Loss: 0.32267  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 14356 -- Train Loss: 0.32313  Validation Loss: 0.43366\n",
      "t: 10 EPOCH 14357 -- Train Loss: 0.32262  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14358 -- Train Loss: 0.32243  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 14359 -- Train Loss: 0.32396  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 14360 -- Train Loss: 0.32275  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 14361 -- Train Loss: 0.32322  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 14362 -- Train Loss: 0.32343  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 14363 -- Train Loss: 0.32216  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14364 -- Train Loss: 0.32295  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 14365 -- Train Loss: 0.32292  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 14366 -- Train Loss: 0.32289  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 14367 -- Train Loss: 0.32305  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 14368 -- Train Loss: 0.32375  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14369 -- Train Loss: 0.32335  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 14370 -- Train Loss: 0.32271  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 14371 -- Train Loss: 0.32195  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 14372 -- Train Loss: 0.32320  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 14373 -- Train Loss: 0.32312  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 14374 -- Train Loss: 0.32290  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 14375 -- Train Loss: 0.32197  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 14376 -- Train Loss: 0.32407  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 14377 -- Train Loss: 0.32176  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 14378 -- Train Loss: 0.32321  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 14379 -- Train Loss: 0.32326  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 14380 -- Train Loss: 0.32408  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 14381 -- Train Loss: 0.32291  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 14382 -- Train Loss: 0.32342  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 14383 -- Train Loss: 0.32288  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 14384 -- Train Loss: 0.32256  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 14385 -- Train Loss: 0.32238  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 14386 -- Train Loss: 0.32206  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 14387 -- Train Loss: 0.32259  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 14388 -- Train Loss: 0.32289  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 14389 -- Train Loss: 0.32298  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 14390 -- Train Loss: 0.32385  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 14391 -- Train Loss: 0.32279  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 14392 -- Train Loss: 0.32336  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 14393 -- Train Loss: 0.32357  Validation Loss: 0.43518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14394 -- Train Loss: 0.32390  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 14395 -- Train Loss: 0.32289  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 14396 -- Train Loss: 0.32200  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 14397 -- Train Loss: 0.32364  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 14398 -- Train Loss: 0.32360  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 14399 -- Train Loss: 0.32220  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 14400 -- Train Loss: 0.32297  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 14401 -- Train Loss: 0.32288  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 14402 -- Train Loss: 0.32339  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 14403 -- Train Loss: 0.32332  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 14404 -- Train Loss: 0.32300  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 14405 -- Train Loss: 0.32291  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 14406 -- Train Loss: 0.32366  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 14407 -- Train Loss: 0.32304  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 14408 -- Train Loss: 0.32354  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 14409 -- Train Loss: 0.32287  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 14410 -- Train Loss: 0.32284  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 14411 -- Train Loss: 0.32321  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 14412 -- Train Loss: 0.32250  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 14413 -- Train Loss: 0.32353  Validation Loss: 0.43285\n",
      "t: 10 EPOCH 14414 -- Train Loss: 0.32239  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 14415 -- Train Loss: 0.32312  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 14416 -- Train Loss: 0.32291  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 14417 -- Train Loss: 0.32311  Validation Loss: 0.43278\n",
      "t: 10 EPOCH 14418 -- Train Loss: 0.32320  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 14419 -- Train Loss: 0.32298  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14420 -- Train Loss: 0.32307  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 14421 -- Train Loss: 0.32326  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 14422 -- Train Loss: 0.32280  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 14423 -- Train Loss: 0.32290  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 14424 -- Train Loss: 0.32273  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 14425 -- Train Loss: 0.32310  Validation Loss: 0.43651\n",
      "t: 10 EPOCH 14426 -- Train Loss: 0.32297  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 14427 -- Train Loss: 0.32369  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 14428 -- Train Loss: 0.32290  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 14429 -- Train Loss: 0.32216  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 14430 -- Train Loss: 0.32271  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 14431 -- Train Loss: 0.32282  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 14432 -- Train Loss: 0.32286  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 14433 -- Train Loss: 0.32313  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 14434 -- Train Loss: 0.32232  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 14435 -- Train Loss: 0.32246  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 14436 -- Train Loss: 0.32246  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 14437 -- Train Loss: 0.32213  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 14438 -- Train Loss: 0.32311  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 14439 -- Train Loss: 0.32343  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 14440 -- Train Loss: 0.32259  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 14441 -- Train Loss: 0.32252  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14442 -- Train Loss: 0.32297  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 14443 -- Train Loss: 0.32238  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 14444 -- Train Loss: 0.32209  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14445 -- Train Loss: 0.32371  Validation Loss: 0.43323\n",
      "t: 10 EPOCH 14446 -- Train Loss: 0.32218  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 14447 -- Train Loss: 0.32339  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14448 -- Train Loss: 0.32181  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 14449 -- Train Loss: 0.32311  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 14450 -- Train Loss: 0.32225  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 14451 -- Train Loss: 0.32318  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 14452 -- Train Loss: 0.32292  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 14453 -- Train Loss: 0.32310  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 14454 -- Train Loss: 0.32295  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 14455 -- Train Loss: 0.32254  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 14456 -- Train Loss: 0.32314  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 14457 -- Train Loss: 0.32345  Validation Loss: 0.43708\n",
      "t: 10 EPOCH 14458 -- Train Loss: 0.32343  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 14459 -- Train Loss: 0.32333  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 14460 -- Train Loss: 0.32327  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 14461 -- Train Loss: 0.32265  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 14462 -- Train Loss: 0.32213  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 14463 -- Train Loss: 0.32239  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14464 -- Train Loss: 0.32250  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 14465 -- Train Loss: 0.32227  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 14466 -- Train Loss: 0.32268  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 14467 -- Train Loss: 0.32328  Validation Loss: 0.43691\n",
      "t: 10 EPOCH 14468 -- Train Loss: 0.32352  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 14469 -- Train Loss: 0.32283  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 14470 -- Train Loss: 0.32316  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 14471 -- Train Loss: 0.32225  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 14472 -- Train Loss: 0.32331  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 14473 -- Train Loss: 0.32340  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 14474 -- Train Loss: 0.32207  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 14475 -- Train Loss: 0.32341  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 14476 -- Train Loss: 0.32267  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 14477 -- Train Loss: 0.32372  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 14478 -- Train Loss: 0.32359  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 14479 -- Train Loss: 0.32346  Validation Loss: 0.43369\n",
      "t: 10 EPOCH 14480 -- Train Loss: 0.32278  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 14481 -- Train Loss: 0.32380  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 14482 -- Train Loss: 0.32262  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 14483 -- Train Loss: 0.32371  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14484 -- Train Loss: 0.32343  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 14485 -- Train Loss: 0.32334  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 14486 -- Train Loss: 0.32316  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 14487 -- Train Loss: 0.32379  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 14488 -- Train Loss: 0.32278  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 14489 -- Train Loss: 0.32340  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 14490 -- Train Loss: 0.32292  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 14491 -- Train Loss: 0.32233  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 14492 -- Train Loss: 0.32303  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 14493 -- Train Loss: 0.32303  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 14494 -- Train Loss: 0.32312  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 14495 -- Train Loss: 0.32356  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14496 -- Train Loss: 0.32241  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 14497 -- Train Loss: 0.32293  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 14498 -- Train Loss: 0.32200  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 14499 -- Train Loss: 0.32359  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 14500 -- Train Loss: 0.32236  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 14501 -- Train Loss: 0.32274  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 14502 -- Train Loss: 0.32217  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 14503 -- Train Loss: 0.32391  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 14504 -- Train Loss: 0.32246  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 14505 -- Train Loss: 0.32395  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 14506 -- Train Loss: 0.32297  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 14507 -- Train Loss: 0.32299  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 14508 -- Train Loss: 0.32300  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 14509 -- Train Loss: 0.32352  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 14510 -- Train Loss: 0.32244  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 14511 -- Train Loss: 0.32360  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 14512 -- Train Loss: 0.32278  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 14513 -- Train Loss: 0.32367  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 14514 -- Train Loss: 0.32295  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 14515 -- Train Loss: 0.32392  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 14516 -- Train Loss: 0.32250  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 14517 -- Train Loss: 0.32314  Validation Loss: 0.43461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14518 -- Train Loss: 0.32258  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 14519 -- Train Loss: 0.32255  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 14520 -- Train Loss: 0.32312  Validation Loss: 0.43699\n",
      "t: 10 EPOCH 14521 -- Train Loss: 0.32348  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 14522 -- Train Loss: 0.32305  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 14523 -- Train Loss: 0.32334  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 14524 -- Train Loss: 0.32428  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 14525 -- Train Loss: 0.32278  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 14526 -- Train Loss: 0.32379  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 14527 -- Train Loss: 0.32195  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 14528 -- Train Loss: 0.32300  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 14529 -- Train Loss: 0.32288  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 14530 -- Train Loss: 0.32292  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 14531 -- Train Loss: 0.32286  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 14532 -- Train Loss: 0.32307  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 14533 -- Train Loss: 0.32236  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 14534 -- Train Loss: 0.32351  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 14535 -- Train Loss: 0.32287  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 14536 -- Train Loss: 0.32237  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 14537 -- Train Loss: 0.32250  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 14538 -- Train Loss: 0.32202  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 14539 -- Train Loss: 0.32262  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 14540 -- Train Loss: 0.32306  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 14541 -- Train Loss: 0.32334  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 14542 -- Train Loss: 0.32168  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 14543 -- Train Loss: 0.32289  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 14544 -- Train Loss: 0.32291  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 14545 -- Train Loss: 0.32311  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 14546 -- Train Loss: 0.32237  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 14547 -- Train Loss: 0.32329  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 14548 -- Train Loss: 0.32276  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 14549 -- Train Loss: 0.32259  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 14550 -- Train Loss: 0.32294  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 14551 -- Train Loss: 0.32367  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 14552 -- Train Loss: 0.32300  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 14553 -- Train Loss: 0.32245  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 14554 -- Train Loss: 0.32345  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 14555 -- Train Loss: 0.32254  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 14556 -- Train Loss: 0.32267  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 14557 -- Train Loss: 0.32164  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 14558 -- Train Loss: 0.32321  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 14559 -- Train Loss: 0.32338  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 14560 -- Train Loss: 0.32292  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 14561 -- Train Loss: 0.32261  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 14562 -- Train Loss: 0.32331  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 14563 -- Train Loss: 0.32162  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 14564 -- Train Loss: 0.32269  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 14565 -- Train Loss: 0.32229  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 14566 -- Train Loss: 0.32201  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 14567 -- Train Loss: 0.32278  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 14568 -- Train Loss: 0.32246  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 14569 -- Train Loss: 0.32247  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 14570 -- Train Loss: 0.32324  Validation Loss: 0.43334\n",
      "t: 10 EPOCH 14571 -- Train Loss: 0.32267  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 14572 -- Train Loss: 0.32319  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 14573 -- Train Loss: 0.32283  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 14574 -- Train Loss: 0.32306  Validation Loss: 0.43351\n",
      "t: 10 EPOCH 14575 -- Train Loss: 0.32139  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 14576 -- Train Loss: 0.32195  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 14577 -- Train Loss: 0.32260  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 14578 -- Train Loss: 0.32161  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 14579 -- Train Loss: 0.32298  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 14580 -- Train Loss: 0.32246  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14581 -- Train Loss: 0.32270  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 14582 -- Train Loss: 0.32312  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 14583 -- Train Loss: 0.32273  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 14584 -- Train Loss: 0.32198  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14585 -- Train Loss: 0.32316  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 14586 -- Train Loss: 0.32290  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 14587 -- Train Loss: 0.32308  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 14588 -- Train Loss: 0.32262  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 14589 -- Train Loss: 0.32282  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 14590 -- Train Loss: 0.32314  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 14591 -- Train Loss: 0.32197  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 14592 -- Train Loss: 0.32249  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 14593 -- Train Loss: 0.32284  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 14594 -- Train Loss: 0.32272  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14595 -- Train Loss: 0.32331  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 14596 -- Train Loss: 0.32337  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 14597 -- Train Loss: 0.32228  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 14598 -- Train Loss: 0.32241  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 14599 -- Train Loss: 0.32289  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 14600 -- Train Loss: 0.32346  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 14601 -- Train Loss: 0.32228  Validation Loss: 0.43650\n",
      "t: 10 EPOCH 14602 -- Train Loss: 0.32243  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 14603 -- Train Loss: 0.32190  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 14604 -- Train Loss: 0.32256  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 14605 -- Train Loss: 0.32297  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 14606 -- Train Loss: 0.32324  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 14607 -- Train Loss: 0.32239  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 14608 -- Train Loss: 0.32311  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 14609 -- Train Loss: 0.32185  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 14610 -- Train Loss: 0.32167  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 14611 -- Train Loss: 0.32249  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 14612 -- Train Loss: 0.32256  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 14613 -- Train Loss: 0.32272  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 14614 -- Train Loss: 0.32212  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 14615 -- Train Loss: 0.32328  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 14616 -- Train Loss: 0.32222  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 14617 -- Train Loss: 0.32290  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 14618 -- Train Loss: 0.32339  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 14619 -- Train Loss: 0.32453  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 14620 -- Train Loss: 0.32246  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 14621 -- Train Loss: 0.32297  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 14622 -- Train Loss: 0.32228  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 14623 -- Train Loss: 0.32292  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 14624 -- Train Loss: 0.32223  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 14625 -- Train Loss: 0.32378  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 14626 -- Train Loss: 0.32344  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 14627 -- Train Loss: 0.32239  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 14628 -- Train Loss: 0.32379  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 14629 -- Train Loss: 0.32289  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 14630 -- Train Loss: 0.32385  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 14631 -- Train Loss: 0.32277  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 14632 -- Train Loss: 0.32298  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14633 -- Train Loss: 0.32343  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 14634 -- Train Loss: 0.32336  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 14635 -- Train Loss: 0.32148  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 14636 -- Train Loss: 0.32273  Validation Loss: 0.43693\n",
      "t: 10 EPOCH 14637 -- Train Loss: 0.32278  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14638 -- Train Loss: 0.32278  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 14639 -- Train Loss: 0.32370  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 14640 -- Train Loss: 0.32294  Validation Loss: 0.43705\n",
      "t: 10 EPOCH 14641 -- Train Loss: 0.32260  Validation Loss: 0.43546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14642 -- Train Loss: 0.32258  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 14643 -- Train Loss: 0.32291  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 14644 -- Train Loss: 0.32200  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 14645 -- Train Loss: 0.32333  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 14646 -- Train Loss: 0.32276  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 14647 -- Train Loss: 0.32383  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 14648 -- Train Loss: 0.32323  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 14649 -- Train Loss: 0.32256  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 14650 -- Train Loss: 0.32271  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 14651 -- Train Loss: 0.32325  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 14652 -- Train Loss: 0.32247  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 14653 -- Train Loss: 0.32304  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 14654 -- Train Loss: 0.32262  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 14655 -- Train Loss: 0.32277  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 14656 -- Train Loss: 0.32236  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 14657 -- Train Loss: 0.32276  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 14658 -- Train Loss: 0.32278  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 14659 -- Train Loss: 0.32254  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 14660 -- Train Loss: 0.32278  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 14661 -- Train Loss: 0.32203  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 14662 -- Train Loss: 0.32178  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 14663 -- Train Loss: 0.32351  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 14664 -- Train Loss: 0.32251  Validation Loss: 0.43682\n",
      "t: 10 EPOCH 14665 -- Train Loss: 0.32323  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 14666 -- Train Loss: 0.32267  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 14667 -- Train Loss: 0.32233  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 14668 -- Train Loss: 0.32271  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 14669 -- Train Loss: 0.32288  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 14670 -- Train Loss: 0.32329  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 14671 -- Train Loss: 0.32288  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 14672 -- Train Loss: 0.32274  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 14673 -- Train Loss: 0.32270  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 14674 -- Train Loss: 0.32220  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14675 -- Train Loss: 0.32250  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 14676 -- Train Loss: 0.32305  Validation Loss: 0.43721\n",
      "t: 10 EPOCH 14677 -- Train Loss: 0.32349  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 14678 -- Train Loss: 0.32209  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 14679 -- Train Loss: 0.32203  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 14680 -- Train Loss: 0.32244  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 14681 -- Train Loss: 0.32240  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 14682 -- Train Loss: 0.32323  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 14683 -- Train Loss: 0.32188  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 14684 -- Train Loss: 0.32230  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 14685 -- Train Loss: 0.32206  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 14686 -- Train Loss: 0.32258  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 14687 -- Train Loss: 0.32178  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 14688 -- Train Loss: 0.32291  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 14689 -- Train Loss: 0.32365  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 14690 -- Train Loss: 0.32331  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 14691 -- Train Loss: 0.32256  Validation Loss: 0.43733\n",
      "t: 10 EPOCH 14692 -- Train Loss: 0.32241  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 14693 -- Train Loss: 0.32249  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 14694 -- Train Loss: 0.32327  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 14695 -- Train Loss: 0.32278  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 14696 -- Train Loss: 0.32267  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 14697 -- Train Loss: 0.32257  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 14698 -- Train Loss: 0.32260  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 14699 -- Train Loss: 0.32314  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 14700 -- Train Loss: 0.32349  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 14701 -- Train Loss: 0.32292  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 14702 -- Train Loss: 0.32220  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 14703 -- Train Loss: 0.32163  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 14704 -- Train Loss: 0.32272  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 14705 -- Train Loss: 0.32254  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 14706 -- Train Loss: 0.32217  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 14707 -- Train Loss: 0.32226  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 14708 -- Train Loss: 0.32320  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 14709 -- Train Loss: 0.32237  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14710 -- Train Loss: 0.32294  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 14711 -- Train Loss: 0.32260  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 14712 -- Train Loss: 0.32349  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 14713 -- Train Loss: 0.32259  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 14714 -- Train Loss: 0.32313  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 14715 -- Train Loss: 0.32349  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 14716 -- Train Loss: 0.32266  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 14717 -- Train Loss: 0.32244  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 14718 -- Train Loss: 0.32343  Validation Loss: 0.43367\n",
      "t: 10 EPOCH 14719 -- Train Loss: 0.32259  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 14720 -- Train Loss: 0.32280  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 14721 -- Train Loss: 0.32313  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 14722 -- Train Loss: 0.32322  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 14723 -- Train Loss: 0.32371  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 14724 -- Train Loss: 0.32262  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14725 -- Train Loss: 0.32282  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 14726 -- Train Loss: 0.32319  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 14727 -- Train Loss: 0.32357  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 14728 -- Train Loss: 0.32259  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 14729 -- Train Loss: 0.32254  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 14730 -- Train Loss: 0.32209  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 14731 -- Train Loss: 0.32364  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14732 -- Train Loss: 0.32219  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 14733 -- Train Loss: 0.32305  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 14734 -- Train Loss: 0.32213  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 14735 -- Train Loss: 0.32349  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 14736 -- Train Loss: 0.32219  Validation Loss: 0.43344\n",
      "t: 10 EPOCH 14737 -- Train Loss: 0.32369  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 14738 -- Train Loss: 0.32272  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 14739 -- Train Loss: 0.32232  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 14740 -- Train Loss: 0.32246  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 14741 -- Train Loss: 0.32323  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 14742 -- Train Loss: 0.32265  Validation Loss: 0.43387\n",
      "t: 10 EPOCH 14743 -- Train Loss: 0.32290  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 14744 -- Train Loss: 0.32300  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 14745 -- Train Loss: 0.32263  Validation Loss: 0.43611\n",
      "t: 10 EPOCH 14746 -- Train Loss: 0.32338  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 14747 -- Train Loss: 0.32236  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 14748 -- Train Loss: 0.32320  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 14749 -- Train Loss: 0.32299  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 14750 -- Train Loss: 0.32340  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 14751 -- Train Loss: 0.32310  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 14752 -- Train Loss: 0.32294  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 14753 -- Train Loss: 0.32281  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 14754 -- Train Loss: 0.32314  Validation Loss: 0.43364\n",
      "t: 10 EPOCH 14755 -- Train Loss: 0.32298  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 14756 -- Train Loss: 0.32153  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 14757 -- Train Loss: 0.32250  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 14758 -- Train Loss: 0.32242  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 14759 -- Train Loss: 0.32246  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 14760 -- Train Loss: 0.32331  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 14761 -- Train Loss: 0.32350  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 14762 -- Train Loss: 0.32325  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 14763 -- Train Loss: 0.32231  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 14764 -- Train Loss: 0.32338  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 14765 -- Train Loss: 0.32269  Validation Loss: 0.43368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14766 -- Train Loss: 0.32372  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 14767 -- Train Loss: 0.32224  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 14768 -- Train Loss: 0.32311  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 14769 -- Train Loss: 0.32265  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 14770 -- Train Loss: 0.32265  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 14771 -- Train Loss: 0.32189  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 14772 -- Train Loss: 0.32251  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 14773 -- Train Loss: 0.32325  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 14774 -- Train Loss: 0.32333  Validation Loss: 0.43347\n",
      "t: 10 EPOCH 14775 -- Train Loss: 0.32313  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 14776 -- Train Loss: 0.32282  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 14777 -- Train Loss: 0.32328  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 14778 -- Train Loss: 0.32216  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 14779 -- Train Loss: 0.32259  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14780 -- Train Loss: 0.32188  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 14781 -- Train Loss: 0.32299  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 14782 -- Train Loss: 0.32211  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 14783 -- Train Loss: 0.32260  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 14784 -- Train Loss: 0.32237  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 14785 -- Train Loss: 0.32266  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 14786 -- Train Loss: 0.32283  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 14787 -- Train Loss: 0.32225  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 14788 -- Train Loss: 0.32292  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 14789 -- Train Loss: 0.32183  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 14790 -- Train Loss: 0.32283  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 14791 -- Train Loss: 0.32217  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 14792 -- Train Loss: 0.32287  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 14793 -- Train Loss: 0.32244  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 14794 -- Train Loss: 0.32243  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 14795 -- Train Loss: 0.32213  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 14796 -- Train Loss: 0.32251  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 14797 -- Train Loss: 0.32315  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 14798 -- Train Loss: 0.32279  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 14799 -- Train Loss: 0.32208  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 14800 -- Train Loss: 0.32285  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 14801 -- Train Loss: 0.32228  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 14802 -- Train Loss: 0.32266  Validation Loss: 0.43705\n",
      "t: 10 EPOCH 14803 -- Train Loss: 0.32256  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 14804 -- Train Loss: 0.32201  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 14805 -- Train Loss: 0.32286  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 14806 -- Train Loss: 0.32219  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 14807 -- Train Loss: 0.32193  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 14808 -- Train Loss: 0.32229  Validation Loss: 0.43338\n",
      "t: 10 EPOCH 14809 -- Train Loss: 0.32236  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14810 -- Train Loss: 0.32278  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 14811 -- Train Loss: 0.32293  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 14812 -- Train Loss: 0.32224  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14813 -- Train Loss: 0.32235  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 14814 -- Train Loss: 0.32252  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 14815 -- Train Loss: 0.32239  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 14816 -- Train Loss: 0.32258  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 14817 -- Train Loss: 0.32199  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 14818 -- Train Loss: 0.32289  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 14819 -- Train Loss: 0.32288  Validation Loss: 0.43674\n",
      "t: 10 EPOCH 14820 -- Train Loss: 0.32281  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 14821 -- Train Loss: 0.32197  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 14822 -- Train Loss: 0.32282  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 14823 -- Train Loss: 0.32162  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 14824 -- Train Loss: 0.32329  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 14825 -- Train Loss: 0.32220  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 14826 -- Train Loss: 0.32233  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 14827 -- Train Loss: 0.32186  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 14828 -- Train Loss: 0.32206  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 14829 -- Train Loss: 0.32154  Validation Loss: 0.43706\n",
      "t: 10 EPOCH 14830 -- Train Loss: 0.32317  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 14831 -- Train Loss: 0.32355  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 14832 -- Train Loss: 0.32188  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 14833 -- Train Loss: 0.32278  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 14834 -- Train Loss: 0.32282  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14835 -- Train Loss: 0.32240  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 14836 -- Train Loss: 0.32177  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 14837 -- Train Loss: 0.32218  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 14838 -- Train Loss: 0.32212  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 14839 -- Train Loss: 0.32305  Validation Loss: 0.43652\n",
      "t: 10 EPOCH 14840 -- Train Loss: 0.32264  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 14841 -- Train Loss: 0.32282  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 14842 -- Train Loss: 0.32267  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 14843 -- Train Loss: 0.32234  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 14844 -- Train Loss: 0.32232  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 14845 -- Train Loss: 0.32312  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 14846 -- Train Loss: 0.32204  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 14847 -- Train Loss: 0.32275  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 14848 -- Train Loss: 0.32304  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 14849 -- Train Loss: 0.32232  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 14850 -- Train Loss: 0.32229  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 14851 -- Train Loss: 0.32354  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 14852 -- Train Loss: 0.32304  Validation Loss: 0.43299\n",
      "t: 10 EPOCH 14853 -- Train Loss: 0.32232  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 14854 -- Train Loss: 0.32211  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 14855 -- Train Loss: 0.32265  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 14856 -- Train Loss: 0.32231  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 14857 -- Train Loss: 0.32206  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 14858 -- Train Loss: 0.32249  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 14859 -- Train Loss: 0.32296  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 14860 -- Train Loss: 0.32236  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14861 -- Train Loss: 0.32288  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 14862 -- Train Loss: 0.32182  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 14863 -- Train Loss: 0.32249  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 14864 -- Train Loss: 0.32304  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 14865 -- Train Loss: 0.32270  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 14866 -- Train Loss: 0.32285  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 14867 -- Train Loss: 0.32317  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14868 -- Train Loss: 0.32301  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 14869 -- Train Loss: 0.32163  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 14870 -- Train Loss: 0.32340  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 14871 -- Train Loss: 0.32224  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 14872 -- Train Loss: 0.32231  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 14873 -- Train Loss: 0.32246  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 14874 -- Train Loss: 0.32240  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 14875 -- Train Loss: 0.32191  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 14876 -- Train Loss: 0.32274  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 14877 -- Train Loss: 0.32269  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 14878 -- Train Loss: 0.32325  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 14879 -- Train Loss: 0.32149  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 14880 -- Train Loss: 0.32265  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 14881 -- Train Loss: 0.32201  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 14882 -- Train Loss: 0.32230  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 14883 -- Train Loss: 0.32227  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 14884 -- Train Loss: 0.32286  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 14885 -- Train Loss: 0.32260  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 14886 -- Train Loss: 0.32187  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 14887 -- Train Loss: 0.32194  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 14888 -- Train Loss: 0.32225  Validation Loss: 0.43666\n",
      "t: 10 EPOCH 14889 -- Train Loss: 0.32292  Validation Loss: 0.43492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 14890 -- Train Loss: 0.32284  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 14891 -- Train Loss: 0.32280  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 14892 -- Train Loss: 0.32284  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 14893 -- Train Loss: 0.32361  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 14894 -- Train Loss: 0.32244  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 14895 -- Train Loss: 0.32354  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 14896 -- Train Loss: 0.32185  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 14897 -- Train Loss: 0.32250  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 14898 -- Train Loss: 0.32226  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14899 -- Train Loss: 0.32254  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 14900 -- Train Loss: 0.32240  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 14901 -- Train Loss: 0.32287  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 14902 -- Train Loss: 0.32261  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 14903 -- Train Loss: 0.32327  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 14904 -- Train Loss: 0.32261  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 14905 -- Train Loss: 0.32218  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 14906 -- Train Loss: 0.32245  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 14907 -- Train Loss: 0.32322  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 14908 -- Train Loss: 0.32317  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 14909 -- Train Loss: 0.32305  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 14910 -- Train Loss: 0.32281  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 14911 -- Train Loss: 0.32279  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 14912 -- Train Loss: 0.32215  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 14913 -- Train Loss: 0.32233  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 14914 -- Train Loss: 0.32201  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 14915 -- Train Loss: 0.32253  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 14916 -- Train Loss: 0.32371  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 14917 -- Train Loss: 0.32232  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 14918 -- Train Loss: 0.32264  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 14919 -- Train Loss: 0.32248  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 14920 -- Train Loss: 0.32156  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14921 -- Train Loss: 0.32258  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 14922 -- Train Loss: 0.32201  Validation Loss: 0.43697\n",
      "t: 10 EPOCH 14923 -- Train Loss: 0.32300  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 14924 -- Train Loss: 0.32224  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 14925 -- Train Loss: 0.32203  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 14926 -- Train Loss: 0.32207  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 14927 -- Train Loss: 0.32253  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 14928 -- Train Loss: 0.32275  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 14929 -- Train Loss: 0.32233  Validation Loss: 0.43359\n",
      "t: 10 EPOCH 14930 -- Train Loss: 0.32225  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 14931 -- Train Loss: 0.32184  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 14932 -- Train Loss: 0.32176  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 14933 -- Train Loss: 0.32347  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 14934 -- Train Loss: 0.32126  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 14935 -- Train Loss: 0.32325  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 14936 -- Train Loss: 0.32224  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 14937 -- Train Loss: 0.32243  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 14938 -- Train Loss: 0.32223  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 14939 -- Train Loss: 0.32328  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 14940 -- Train Loss: 0.32191  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 14941 -- Train Loss: 0.32267  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 14942 -- Train Loss: 0.32225  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 14943 -- Train Loss: 0.32261  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 14944 -- Train Loss: 0.32244  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 14945 -- Train Loss: 0.32287  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 14946 -- Train Loss: 0.32281  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 14947 -- Train Loss: 0.32274  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 14948 -- Train Loss: 0.32316  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 14949 -- Train Loss: 0.32208  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 14950 -- Train Loss: 0.32196  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 14951 -- Train Loss: 0.32183  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 14952 -- Train Loss: 0.32298  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 14953 -- Train Loss: 0.32261  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 14954 -- Train Loss: 0.32177  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 14955 -- Train Loss: 0.32168  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 14956 -- Train Loss: 0.32284  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 14957 -- Train Loss: 0.32258  Validation Loss: 0.43332\n",
      "t: 10 EPOCH 14958 -- Train Loss: 0.32298  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 14959 -- Train Loss: 0.32226  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 14960 -- Train Loss: 0.32275  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 14961 -- Train Loss: 0.32281  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 14962 -- Train Loss: 0.32187  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 14963 -- Train Loss: 0.32231  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 14964 -- Train Loss: 0.32163  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 14965 -- Train Loss: 0.32242  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 14966 -- Train Loss: 0.32247  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 14967 -- Train Loss: 0.32233  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 14968 -- Train Loss: 0.32244  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 14969 -- Train Loss: 0.32301  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 14970 -- Train Loss: 0.32258  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 14971 -- Train Loss: 0.32313  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 14972 -- Train Loss: 0.32203  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 14973 -- Train Loss: 0.32283  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 14974 -- Train Loss: 0.32215  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 14975 -- Train Loss: 0.32316  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 14976 -- Train Loss: 0.32210  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 14977 -- Train Loss: 0.32268  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 14978 -- Train Loss: 0.32248  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 14979 -- Train Loss: 0.32359  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 14980 -- Train Loss: 0.32271  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 14981 -- Train Loss: 0.32314  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 14982 -- Train Loss: 0.32267  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 14983 -- Train Loss: 0.32320  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 14984 -- Train Loss: 0.32389  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 14985 -- Train Loss: 0.32246  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 14986 -- Train Loss: 0.32297  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 14987 -- Train Loss: 0.32342  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 14988 -- Train Loss: 0.32333  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 14989 -- Train Loss: 0.32263  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 14990 -- Train Loss: 0.32339  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 14991 -- Train Loss: 0.32311  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 14992 -- Train Loss: 0.32281  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 14993 -- Train Loss: 0.32218  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 14994 -- Train Loss: 0.32282  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 14995 -- Train Loss: 0.32279  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 14996 -- Train Loss: 0.32272  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 14997 -- Train Loss: 0.32240  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 14998 -- Train Loss: 0.32293  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 14999 -- Train Loss: 0.32283  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 15000 -- Train Loss: 0.32297  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 15001 -- Train Loss: 0.32295  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 15002 -- Train Loss: 0.32267  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 15003 -- Train Loss: 0.32259  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 15004 -- Train Loss: 0.32279  Validation Loss: 0.43383\n",
      "t: 10 EPOCH 15005 -- Train Loss: 0.32315  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 15006 -- Train Loss: 0.32339  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 15007 -- Train Loss: 0.32147  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 15008 -- Train Loss: 0.32318  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 15009 -- Train Loss: 0.32142  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 15010 -- Train Loss: 0.32334  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 15011 -- Train Loss: 0.32194  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 15012 -- Train Loss: 0.32328  Validation Loss: 0.43666\n",
      "t: 10 EPOCH 15013 -- Train Loss: 0.32169  Validation Loss: 0.43591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15014 -- Train Loss: 0.32306  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 15015 -- Train Loss: 0.32268  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 15016 -- Train Loss: 0.32262  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15017 -- Train Loss: 0.32221  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 15018 -- Train Loss: 0.32288  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 15019 -- Train Loss: 0.32280  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 15020 -- Train Loss: 0.32242  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 15021 -- Train Loss: 0.32219  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15022 -- Train Loss: 0.32164  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 15023 -- Train Loss: 0.32289  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 15024 -- Train Loss: 0.32162  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 15025 -- Train Loss: 0.32111  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 15026 -- Train Loss: 0.32198  Validation Loss: 0.43651\n",
      "t: 10 EPOCH 15027 -- Train Loss: 0.32272  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 15028 -- Train Loss: 0.32177  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 15029 -- Train Loss: 0.32314  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15030 -- Train Loss: 0.32134  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 15031 -- Train Loss: 0.32281  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 15032 -- Train Loss: 0.32240  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 15033 -- Train Loss: 0.32318  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 15034 -- Train Loss: 0.32167  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 15035 -- Train Loss: 0.32244  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 15036 -- Train Loss: 0.32239  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 15037 -- Train Loss: 0.32178  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15038 -- Train Loss: 0.32272  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 15039 -- Train Loss: 0.32168  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 15040 -- Train Loss: 0.32228  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 15041 -- Train Loss: 0.32243  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 15042 -- Train Loss: 0.32215  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 15043 -- Train Loss: 0.32287  Validation Loss: 0.43739\n",
      "t: 10 EPOCH 15044 -- Train Loss: 0.32154  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 15045 -- Train Loss: 0.32370  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 15046 -- Train Loss: 0.32194  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 15047 -- Train Loss: 0.32304  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 15048 -- Train Loss: 0.32279  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 15049 -- Train Loss: 0.32222  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 15050 -- Train Loss: 0.32238  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 15051 -- Train Loss: 0.32229  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 15052 -- Train Loss: 0.32230  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15053 -- Train Loss: 0.32294  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 15054 -- Train Loss: 0.32193  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 15055 -- Train Loss: 0.32267  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15056 -- Train Loss: 0.32218  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 15057 -- Train Loss: 0.32302  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 15058 -- Train Loss: 0.32180  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 15059 -- Train Loss: 0.32210  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15060 -- Train Loss: 0.32277  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 15061 -- Train Loss: 0.32241  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 15062 -- Train Loss: 0.32233  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15063 -- Train Loss: 0.32202  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15064 -- Train Loss: 0.32236  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 15065 -- Train Loss: 0.32241  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 15066 -- Train Loss: 0.32272  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 15067 -- Train Loss: 0.32340  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 15068 -- Train Loss: 0.32251  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 15069 -- Train Loss: 0.32364  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 15070 -- Train Loss: 0.32291  Validation Loss: 0.43341\n",
      "t: 10 EPOCH 15071 -- Train Loss: 0.32268  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 15072 -- Train Loss: 0.32189  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 15073 -- Train Loss: 0.32143  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15074 -- Train Loss: 0.32286  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 15075 -- Train Loss: 0.32184  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 15076 -- Train Loss: 0.32266  Validation Loss: 0.43671\n",
      "t: 10 EPOCH 15077 -- Train Loss: 0.32226  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 15078 -- Train Loss: 0.32263  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 15079 -- Train Loss: 0.32296  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15080 -- Train Loss: 0.32279  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 15081 -- Train Loss: 0.32334  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15082 -- Train Loss: 0.32181  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 15083 -- Train Loss: 0.32241  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 15084 -- Train Loss: 0.32171  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 15085 -- Train Loss: 0.32282  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 15086 -- Train Loss: 0.32217  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 15087 -- Train Loss: 0.32248  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 15088 -- Train Loss: 0.32324  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 15089 -- Train Loss: 0.32255  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 15090 -- Train Loss: 0.32368  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 15091 -- Train Loss: 0.32224  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 15092 -- Train Loss: 0.32275  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 15093 -- Train Loss: 0.32248  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 15094 -- Train Loss: 0.32279  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 15095 -- Train Loss: 0.32253  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 15096 -- Train Loss: 0.32275  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 15097 -- Train Loss: 0.32216  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 15098 -- Train Loss: 0.32313  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 15099 -- Train Loss: 0.32251  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 15100 -- Train Loss: 0.32174  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 15101 -- Train Loss: 0.32296  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 15102 -- Train Loss: 0.32195  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 15103 -- Train Loss: 0.32222  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 15104 -- Train Loss: 0.32254  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 15105 -- Train Loss: 0.32229  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 15106 -- Train Loss: 0.32295  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 15107 -- Train Loss: 0.32145  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 15108 -- Train Loss: 0.32293  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 15109 -- Train Loss: 0.32240  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 15110 -- Train Loss: 0.32246  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 15111 -- Train Loss: 0.32201  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 15112 -- Train Loss: 0.32157  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 15113 -- Train Loss: 0.32254  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 15114 -- Train Loss: 0.32300  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 15115 -- Train Loss: 0.32239  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 15116 -- Train Loss: 0.32262  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 15117 -- Train Loss: 0.32234  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 15118 -- Train Loss: 0.32201  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 15119 -- Train Loss: 0.32200  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 15120 -- Train Loss: 0.32268  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 15121 -- Train Loss: 0.32304  Validation Loss: 0.43705\n",
      "t: 10 EPOCH 15122 -- Train Loss: 0.32159  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 15123 -- Train Loss: 0.32200  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15124 -- Train Loss: 0.32259  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15125 -- Train Loss: 0.32264  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 15126 -- Train Loss: 0.32221  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15127 -- Train Loss: 0.32260  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 15128 -- Train Loss: 0.32364  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 15129 -- Train Loss: 0.32269  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 15130 -- Train Loss: 0.32241  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 15131 -- Train Loss: 0.32273  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 15132 -- Train Loss: 0.32204  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 15133 -- Train Loss: 0.32259  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 15134 -- Train Loss: 0.32324  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 15135 -- Train Loss: 0.32313  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 15136 -- Train Loss: 0.32210  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 15137 -- Train Loss: 0.32291  Validation Loss: 0.43501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15138 -- Train Loss: 0.32237  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 15139 -- Train Loss: 0.32349  Validation Loss: 0.43621\n",
      "t: 10 EPOCH 15140 -- Train Loss: 0.32222  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 15141 -- Train Loss: 0.32284  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 15142 -- Train Loss: 0.32268  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 15143 -- Train Loss: 0.32237  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 15144 -- Train Loss: 0.32226  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15145 -- Train Loss: 0.32326  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 15146 -- Train Loss: 0.32192  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 15147 -- Train Loss: 0.32226  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 15148 -- Train Loss: 0.32299  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 15149 -- Train Loss: 0.32257  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15150 -- Train Loss: 0.32163  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 15151 -- Train Loss: 0.32259  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 15152 -- Train Loss: 0.32198  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 15153 -- Train Loss: 0.32316  Validation Loss: 0.43306\n",
      "t: 10 EPOCH 15154 -- Train Loss: 0.32151  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 15155 -- Train Loss: 0.32234  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 15156 -- Train Loss: 0.32310  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 15157 -- Train Loss: 0.32181  Validation Loss: 0.43382\n",
      "t: 10 EPOCH 15158 -- Train Loss: 0.32265  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 15159 -- Train Loss: 0.32183  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 15160 -- Train Loss: 0.32204  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 15161 -- Train Loss: 0.32301  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 15162 -- Train Loss: 0.32224  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15163 -- Train Loss: 0.32233  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 15164 -- Train Loss: 0.32235  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 15165 -- Train Loss: 0.32234  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 15166 -- Train Loss: 0.32240  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 15167 -- Train Loss: 0.32216  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 15168 -- Train Loss: 0.32167  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 15169 -- Train Loss: 0.32227  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 15170 -- Train Loss: 0.32194  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 15171 -- Train Loss: 0.32233  Validation Loss: 0.43269\n",
      "t: 10 EPOCH 15172 -- Train Loss: 0.32192  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 15173 -- Train Loss: 0.32253  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 15174 -- Train Loss: 0.32189  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15175 -- Train Loss: 0.32312  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15176 -- Train Loss: 0.32168  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 15177 -- Train Loss: 0.32189  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 15178 -- Train Loss: 0.32190  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 15179 -- Train Loss: 0.32244  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 15180 -- Train Loss: 0.32192  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 15181 -- Train Loss: 0.32120  Validation Loss: 0.43693\n",
      "t: 10 EPOCH 15182 -- Train Loss: 0.32257  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 15183 -- Train Loss: 0.32259  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 15184 -- Train Loss: 0.32227  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 15185 -- Train Loss: 0.32248  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 15186 -- Train Loss: 0.32188  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 15187 -- Train Loss: 0.32114  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 15188 -- Train Loss: 0.32181  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 15189 -- Train Loss: 0.32242  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 15190 -- Train Loss: 0.32214  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 15191 -- Train Loss: 0.32192  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 15192 -- Train Loss: 0.32185  Validation Loss: 0.43687\n",
      "t: 10 EPOCH 15193 -- Train Loss: 0.32306  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 15194 -- Train Loss: 0.32231  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 15195 -- Train Loss: 0.32279  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 15196 -- Train Loss: 0.32246  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 15197 -- Train Loss: 0.32329  Validation Loss: 0.43775\n",
      "t: 10 EPOCH 15198 -- Train Loss: 0.32248  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 15199 -- Train Loss: 0.32332  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 15200 -- Train Loss: 0.32267  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 15201 -- Train Loss: 0.32299  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 15202 -- Train Loss: 0.32217  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 15203 -- Train Loss: 0.32312  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 15204 -- Train Loss: 0.32212  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 15205 -- Train Loss: 0.32292  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15206 -- Train Loss: 0.32280  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 15207 -- Train Loss: 0.32236  Validation Loss: 0.43389\n",
      "t: 10 EPOCH 15208 -- Train Loss: 0.32174  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 15209 -- Train Loss: 0.32323  Validation Loss: 0.43401\n",
      "t: 10 EPOCH 15210 -- Train Loss: 0.32178  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15211 -- Train Loss: 0.32284  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 15212 -- Train Loss: 0.32244  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 15213 -- Train Loss: 0.32350  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 15214 -- Train Loss: 0.32181  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15215 -- Train Loss: 0.32257  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 15216 -- Train Loss: 0.32273  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 15217 -- Train Loss: 0.32287  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 15218 -- Train Loss: 0.32151  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 15219 -- Train Loss: 0.32215  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 15220 -- Train Loss: 0.32218  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 15221 -- Train Loss: 0.32314  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 15222 -- Train Loss: 0.32243  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15223 -- Train Loss: 0.32245  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 15224 -- Train Loss: 0.32278  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 15225 -- Train Loss: 0.32333  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15226 -- Train Loss: 0.32114  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 15227 -- Train Loss: 0.32352  Validation Loss: 0.43340\n",
      "t: 10 EPOCH 15228 -- Train Loss: 0.32206  Validation Loss: 0.43666\n",
      "t: 10 EPOCH 15229 -- Train Loss: 0.32319  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 15230 -- Train Loss: 0.32219  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 15231 -- Train Loss: 0.32269  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 15232 -- Train Loss: 0.32300  Validation Loss: 0.43700\n",
      "t: 10 EPOCH 15233 -- Train Loss: 0.32305  Validation Loss: 0.43380\n",
      "t: 10 EPOCH 15234 -- Train Loss: 0.32254  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 15235 -- Train Loss: 0.32311  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 15236 -- Train Loss: 0.32282  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 15237 -- Train Loss: 0.32336  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 15238 -- Train Loss: 0.32316  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15239 -- Train Loss: 0.32373  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 15240 -- Train Loss: 0.32248  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 15241 -- Train Loss: 0.32294  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15242 -- Train Loss: 0.32367  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 15243 -- Train Loss: 0.32336  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 15244 -- Train Loss: 0.32228  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 15245 -- Train Loss: 0.32246  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 15246 -- Train Loss: 0.32312  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 15247 -- Train Loss: 0.32213  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 15248 -- Train Loss: 0.32287  Validation Loss: 0.43396\n",
      "t: 10 EPOCH 15249 -- Train Loss: 0.32309  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 15250 -- Train Loss: 0.32473  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 15251 -- Train Loss: 0.32264  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 15252 -- Train Loss: 0.32330  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 15253 -- Train Loss: 0.32287  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 15254 -- Train Loss: 0.32284  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 15255 -- Train Loss: 0.32238  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 15256 -- Train Loss: 0.32295  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 15257 -- Train Loss: 0.32177  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 15258 -- Train Loss: 0.32309  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 15259 -- Train Loss: 0.32236  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 15260 -- Train Loss: 0.32272  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 15261 -- Train Loss: 0.32203  Validation Loss: 0.43515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15262 -- Train Loss: 0.32299  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 15263 -- Train Loss: 0.32213  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 15264 -- Train Loss: 0.32227  Validation Loss: 0.43653\n",
      "t: 10 EPOCH 15265 -- Train Loss: 0.32173  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 15266 -- Train Loss: 0.32238  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 15267 -- Train Loss: 0.32204  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 15268 -- Train Loss: 0.32325  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 15269 -- Train Loss: 0.32303  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 15270 -- Train Loss: 0.32241  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 15271 -- Train Loss: 0.32280  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 15272 -- Train Loss: 0.32211  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 15273 -- Train Loss: 0.32277  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 15274 -- Train Loss: 0.32293  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 15275 -- Train Loss: 0.32291  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 15276 -- Train Loss: 0.32223  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 15277 -- Train Loss: 0.32350  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 15278 -- Train Loss: 0.32231  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 15279 -- Train Loss: 0.32221  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 15280 -- Train Loss: 0.32236  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15281 -- Train Loss: 0.32244  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 15282 -- Train Loss: 0.32283  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 15283 -- Train Loss: 0.32277  Validation Loss: 0.43339\n",
      "t: 10 EPOCH 15284 -- Train Loss: 0.32174  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 15285 -- Train Loss: 0.32186  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 15286 -- Train Loss: 0.32208  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15287 -- Train Loss: 0.32244  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 15288 -- Train Loss: 0.32182  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 15289 -- Train Loss: 0.32231  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 15290 -- Train Loss: 0.32197  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 15291 -- Train Loss: 0.32159  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 15292 -- Train Loss: 0.32212  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 15293 -- Train Loss: 0.32174  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15294 -- Train Loss: 0.32167  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 15295 -- Train Loss: 0.32176  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 15296 -- Train Loss: 0.32259  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 15297 -- Train Loss: 0.32197  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 15298 -- Train Loss: 0.32193  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 15299 -- Train Loss: 0.32165  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 15300 -- Train Loss: 0.32180  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 15301 -- Train Loss: 0.32242  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 15302 -- Train Loss: 0.32168  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15303 -- Train Loss: 0.32241  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 15304 -- Train Loss: 0.32132  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 15305 -- Train Loss: 0.32164  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 15306 -- Train Loss: 0.32186  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 15307 -- Train Loss: 0.32244  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 15308 -- Train Loss: 0.32167  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 15309 -- Train Loss: 0.32334  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 15310 -- Train Loss: 0.32265  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 15311 -- Train Loss: 0.32206  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15312 -- Train Loss: 0.32137  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 15313 -- Train Loss: 0.32231  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 15314 -- Train Loss: 0.32149  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 15315 -- Train Loss: 0.32212  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15316 -- Train Loss: 0.32248  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 15317 -- Train Loss: 0.32186  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 15318 -- Train Loss: 0.32259  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 15319 -- Train Loss: 0.32304  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 15320 -- Train Loss: 0.32356  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 15321 -- Train Loss: 0.32203  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 15322 -- Train Loss: 0.32298  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 15323 -- Train Loss: 0.32231  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 15324 -- Train Loss: 0.32208  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 15325 -- Train Loss: 0.32290  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 15326 -- Train Loss: 0.32179  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 15327 -- Train Loss: 0.32207  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15328 -- Train Loss: 0.32226  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 15329 -- Train Loss: 0.32154  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 15330 -- Train Loss: 0.32187  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 15331 -- Train Loss: 0.32222  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 15332 -- Train Loss: 0.32157  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 15333 -- Train Loss: 0.32231  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15334 -- Train Loss: 0.32199  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 15335 -- Train Loss: 0.32269  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 15336 -- Train Loss: 0.32191  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 15337 -- Train Loss: 0.32174  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 15338 -- Train Loss: 0.32282  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 15339 -- Train Loss: 0.32202  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 15340 -- Train Loss: 0.32081  Validation Loss: 0.43744\n",
      "t: 10 EPOCH 15341 -- Train Loss: 0.32205  Validation Loss: 0.43715\n",
      "t: 10 EPOCH 15342 -- Train Loss: 0.32232  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 15343 -- Train Loss: 0.32252  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 15344 -- Train Loss: 0.32201  Validation Loss: 0.43662\n",
      "t: 10 EPOCH 15345 -- Train Loss: 0.32171  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 15346 -- Train Loss: 0.32214  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 15347 -- Train Loss: 0.32149  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15348 -- Train Loss: 0.32214  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 15349 -- Train Loss: 0.32111  Validation Loss: 0.43670\n",
      "t: 10 EPOCH 15350 -- Train Loss: 0.32094  Validation Loss: 0.43357\n",
      "t: 10 EPOCH 15351 -- Train Loss: 0.32272  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 15352 -- Train Loss: 0.32240  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 15353 -- Train Loss: 0.32252  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 15354 -- Train Loss: 0.32231  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 15355 -- Train Loss: 0.32228  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 15356 -- Train Loss: 0.32295  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 15357 -- Train Loss: 0.32195  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 15358 -- Train Loss: 0.32122  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 15359 -- Train Loss: 0.32199  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15360 -- Train Loss: 0.32210  Validation Loss: 0.43372\n",
      "t: 10 EPOCH 15361 -- Train Loss: 0.32242  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 15362 -- Train Loss: 0.32225  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 15363 -- Train Loss: 0.32209  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 15364 -- Train Loss: 0.32290  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 15365 -- Train Loss: 0.32203  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 15366 -- Train Loss: 0.32224  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15367 -- Train Loss: 0.32218  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 15368 -- Train Loss: 0.32199  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 15369 -- Train Loss: 0.32224  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 15370 -- Train Loss: 0.32215  Validation Loss: 0.43314\n",
      "t: 10 EPOCH 15371 -- Train Loss: 0.32161  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 15372 -- Train Loss: 0.32222  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 15373 -- Train Loss: 0.32287  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 15374 -- Train Loss: 0.32167  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 15375 -- Train Loss: 0.32215  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 15376 -- Train Loss: 0.32199  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 15377 -- Train Loss: 0.32321  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15378 -- Train Loss: 0.32287  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 15379 -- Train Loss: 0.32262  Validation Loss: 0.43330\n",
      "t: 10 EPOCH 15380 -- Train Loss: 0.32207  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 15381 -- Train Loss: 0.32275  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 15382 -- Train Loss: 0.32256  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15383 -- Train Loss: 0.32229  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 15384 -- Train Loss: 0.32316  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 15385 -- Train Loss: 0.32220  Validation Loss: 0.43530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15386 -- Train Loss: 0.32322  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 15387 -- Train Loss: 0.32273  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 15388 -- Train Loss: 0.32282  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15389 -- Train Loss: 0.32191  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 15390 -- Train Loss: 0.32302  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15391 -- Train Loss: 0.32265  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 15392 -- Train Loss: 0.32308  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15393 -- Train Loss: 0.32184  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 15394 -- Train Loss: 0.32258  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 15395 -- Train Loss: 0.32251  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 15396 -- Train Loss: 0.32200  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 15397 -- Train Loss: 0.32189  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15398 -- Train Loss: 0.32169  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 15399 -- Train Loss: 0.32345  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 15400 -- Train Loss: 0.32230  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15401 -- Train Loss: 0.32313  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 15402 -- Train Loss: 0.32272  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 15403 -- Train Loss: 0.32281  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 15404 -- Train Loss: 0.32244  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 15405 -- Train Loss: 0.32148  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 15406 -- Train Loss: 0.32253  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 15407 -- Train Loss: 0.32311  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15408 -- Train Loss: 0.32328  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 15409 -- Train Loss: 0.32194  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15410 -- Train Loss: 0.32175  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 15411 -- Train Loss: 0.32189  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15412 -- Train Loss: 0.32232  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 15413 -- Train Loss: 0.32294  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 15414 -- Train Loss: 0.32209  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 15415 -- Train Loss: 0.32266  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 15416 -- Train Loss: 0.32375  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 15417 -- Train Loss: 0.32281  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 15418 -- Train Loss: 0.32215  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 15419 -- Train Loss: 0.32305  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 15420 -- Train Loss: 0.32228  Validation Loss: 0.43388\n",
      "t: 10 EPOCH 15421 -- Train Loss: 0.32225  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 15422 -- Train Loss: 0.32267  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15423 -- Train Loss: 0.32243  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 15424 -- Train Loss: 0.32212  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 15425 -- Train Loss: 0.32142  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 15426 -- Train Loss: 0.32255  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 15427 -- Train Loss: 0.32170  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 15428 -- Train Loss: 0.32314  Validation Loss: 0.43656\n",
      "t: 10 EPOCH 15429 -- Train Loss: 0.32169  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 15430 -- Train Loss: 0.32245  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 15431 -- Train Loss: 0.32174  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 15432 -- Train Loss: 0.32293  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 15433 -- Train Loss: 0.32226  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 15434 -- Train Loss: 0.32327  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 15435 -- Train Loss: 0.32257  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 15436 -- Train Loss: 0.32272  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 15437 -- Train Loss: 0.32230  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15438 -- Train Loss: 0.32256  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 15439 -- Train Loss: 0.32219  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 15440 -- Train Loss: 0.32145  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 15441 -- Train Loss: 0.32253  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 15442 -- Train Loss: 0.32111  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 15443 -- Train Loss: 0.32267  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 15444 -- Train Loss: 0.32292  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 15445 -- Train Loss: 0.32229  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 15446 -- Train Loss: 0.32284  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 15447 -- Train Loss: 0.32120  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15448 -- Train Loss: 0.32238  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 15449 -- Train Loss: 0.32238  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 15450 -- Train Loss: 0.32205  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15451 -- Train Loss: 0.32204  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 15452 -- Train Loss: 0.32191  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15453 -- Train Loss: 0.32291  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 15454 -- Train Loss: 0.32124  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 15455 -- Train Loss: 0.32248  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 15456 -- Train Loss: 0.32197  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15457 -- Train Loss: 0.32354  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 15458 -- Train Loss: 0.32230  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 15459 -- Train Loss: 0.32223  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 15460 -- Train Loss: 0.32181  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 15461 -- Train Loss: 0.32255  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 15462 -- Train Loss: 0.32241  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 15463 -- Train Loss: 0.32239  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 15464 -- Train Loss: 0.32340  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 15465 -- Train Loss: 0.32359  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 15466 -- Train Loss: 0.32211  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 15467 -- Train Loss: 0.32183  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 15468 -- Train Loss: 0.32235  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 15469 -- Train Loss: 0.32236  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 15470 -- Train Loss: 0.32134  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 15471 -- Train Loss: 0.32172  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 15472 -- Train Loss: 0.32186  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 15473 -- Train Loss: 0.32256  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 15474 -- Train Loss: 0.32201  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 15475 -- Train Loss: 0.32259  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 15476 -- Train Loss: 0.32194  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 15477 -- Train Loss: 0.32188  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 15478 -- Train Loss: 0.32223  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 15479 -- Train Loss: 0.32196  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 15480 -- Train Loss: 0.32274  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 15481 -- Train Loss: 0.32196  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15482 -- Train Loss: 0.32229  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 15483 -- Train Loss: 0.32248  Validation Loss: 0.43653\n",
      "t: 10 EPOCH 15484 -- Train Loss: 0.32213  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 15485 -- Train Loss: 0.32212  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 15486 -- Train Loss: 0.32198  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15487 -- Train Loss: 0.32293  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15488 -- Train Loss: 0.32117  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 15489 -- Train Loss: 0.32225  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 15490 -- Train Loss: 0.32282  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 15491 -- Train Loss: 0.32270  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 15492 -- Train Loss: 0.32191  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 15493 -- Train Loss: 0.32350  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 15494 -- Train Loss: 0.32231  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 15495 -- Train Loss: 0.32235  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 15496 -- Train Loss: 0.32241  Validation Loss: 0.43621\n",
      "t: 10 EPOCH 15497 -- Train Loss: 0.32207  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 15498 -- Train Loss: 0.32227  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 15499 -- Train Loss: 0.32236  Validation Loss: 0.43659\n",
      "t: 10 EPOCH 15500 -- Train Loss: 0.32276  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15501 -- Train Loss: 0.32294  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15502 -- Train Loss: 0.32269  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 15503 -- Train Loss: 0.32143  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 15504 -- Train Loss: 0.32281  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 15505 -- Train Loss: 0.32161  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 15506 -- Train Loss: 0.32233  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15507 -- Train Loss: 0.32258  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 15508 -- Train Loss: 0.32221  Validation Loss: 0.43556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15509 -- Train Loss: 0.32200  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 15510 -- Train Loss: 0.32260  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 15511 -- Train Loss: 0.32178  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 15512 -- Train Loss: 0.32216  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 15513 -- Train Loss: 0.32270  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 15514 -- Train Loss: 0.32269  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 15515 -- Train Loss: 0.32254  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 15516 -- Train Loss: 0.32257  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 15517 -- Train Loss: 0.32136  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 15518 -- Train Loss: 0.32248  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 15519 -- Train Loss: 0.32294  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 15520 -- Train Loss: 0.32364  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 15521 -- Train Loss: 0.32220  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 15522 -- Train Loss: 0.32331  Validation Loss: 0.43348\n",
      "t: 10 EPOCH 15523 -- Train Loss: 0.32174  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 15524 -- Train Loss: 0.32388  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15525 -- Train Loss: 0.32225  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 15526 -- Train Loss: 0.32285  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 15527 -- Train Loss: 0.32230  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 15528 -- Train Loss: 0.32290  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 15529 -- Train Loss: 0.32246  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 15530 -- Train Loss: 0.32286  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 15531 -- Train Loss: 0.32214  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 15532 -- Train Loss: 0.32202  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15533 -- Train Loss: 0.32182  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 15534 -- Train Loss: 0.32203  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 15535 -- Train Loss: 0.32247  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 15536 -- Train Loss: 0.32217  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 15537 -- Train Loss: 0.32256  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 15538 -- Train Loss: 0.32214  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15539 -- Train Loss: 0.32240  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 15540 -- Train Loss: 0.32308  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 15541 -- Train Loss: 0.32175  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 15542 -- Train Loss: 0.32186  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 15543 -- Train Loss: 0.32249  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 15544 -- Train Loss: 0.32214  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 15545 -- Train Loss: 0.32187  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15546 -- Train Loss: 0.32211  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 15547 -- Train Loss: 0.32260  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 15548 -- Train Loss: 0.32185  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 15549 -- Train Loss: 0.32183  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 15550 -- Train Loss: 0.32259  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 15551 -- Train Loss: 0.32206  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 15552 -- Train Loss: 0.32216  Validation Loss: 0.43342\n",
      "t: 10 EPOCH 15553 -- Train Loss: 0.32209  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 15554 -- Train Loss: 0.32178  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15555 -- Train Loss: 0.32168  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 15556 -- Train Loss: 0.32209  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 15557 -- Train Loss: 0.32181  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 15558 -- Train Loss: 0.32252  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 15559 -- Train Loss: 0.32271  Validation Loss: 0.43674\n",
      "t: 10 EPOCH 15560 -- Train Loss: 0.32291  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 15561 -- Train Loss: 0.32136  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 15562 -- Train Loss: 0.32246  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 15563 -- Train Loss: 0.32231  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 15564 -- Train Loss: 0.32129  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15565 -- Train Loss: 0.32221  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 15566 -- Train Loss: 0.32268  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 15567 -- Train Loss: 0.32174  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15568 -- Train Loss: 0.32162  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15569 -- Train Loss: 0.32201  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 15570 -- Train Loss: 0.32174  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 15571 -- Train Loss: 0.32189  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 15572 -- Train Loss: 0.32201  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 15573 -- Train Loss: 0.32175  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 15574 -- Train Loss: 0.32212  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 15575 -- Train Loss: 0.32216  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 15576 -- Train Loss: 0.32282  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15577 -- Train Loss: 0.32190  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 15578 -- Train Loss: 0.32241  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 15579 -- Train Loss: 0.32224  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 15580 -- Train Loss: 0.32229  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 15581 -- Train Loss: 0.32210  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 15582 -- Train Loss: 0.32124  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 15583 -- Train Loss: 0.32262  Validation Loss: 0.43668\n",
      "t: 10 EPOCH 15584 -- Train Loss: 0.32235  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15585 -- Train Loss: 0.32187  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 15586 -- Train Loss: 0.32178  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 15587 -- Train Loss: 0.32233  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 15588 -- Train Loss: 0.32154  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15589 -- Train Loss: 0.32193  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15590 -- Train Loss: 0.32210  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15591 -- Train Loss: 0.32153  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 15592 -- Train Loss: 0.32168  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 15593 -- Train Loss: 0.32128  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 15594 -- Train Loss: 0.32226  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 15595 -- Train Loss: 0.32168  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 15596 -- Train Loss: 0.32240  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 15597 -- Train Loss: 0.32116  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 15598 -- Train Loss: 0.32205  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15599 -- Train Loss: 0.32169  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 15600 -- Train Loss: 0.32216  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 15601 -- Train Loss: 0.32130  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 15602 -- Train Loss: 0.32233  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 15603 -- Train Loss: 0.32238  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15604 -- Train Loss: 0.32146  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 15605 -- Train Loss: 0.32205  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 15606 -- Train Loss: 0.32113  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 15607 -- Train Loss: 0.32193  Validation Loss: 0.43353\n",
      "t: 10 EPOCH 15608 -- Train Loss: 0.32121  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 15609 -- Train Loss: 0.32155  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 15610 -- Train Loss: 0.32206  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 15611 -- Train Loss: 0.32207  Validation Loss: 0.43716\n",
      "t: 10 EPOCH 15612 -- Train Loss: 0.32188  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 15613 -- Train Loss: 0.32173  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 15614 -- Train Loss: 0.32188  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 15615 -- Train Loss: 0.32214  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 15616 -- Train Loss: 0.32129  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 15617 -- Train Loss: 0.32295  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 15618 -- Train Loss: 0.32122  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 15619 -- Train Loss: 0.32239  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 15620 -- Train Loss: 0.32182  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 15621 -- Train Loss: 0.32041  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 15622 -- Train Loss: 0.32223  Validation Loss: 0.43662\n",
      "t: 10 EPOCH 15623 -- Train Loss: 0.32117  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 15624 -- Train Loss: 0.32236  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 15625 -- Train Loss: 0.32215  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 15626 -- Train Loss: 0.32308  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 15627 -- Train Loss: 0.32130  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 15628 -- Train Loss: 0.32255  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 15629 -- Train Loss: 0.32269  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 15630 -- Train Loss: 0.32173  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 15631 -- Train Loss: 0.32172  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 15632 -- Train Loss: 0.32253  Validation Loss: 0.43409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15633 -- Train Loss: 0.32165  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 15634 -- Train Loss: 0.32162  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15635 -- Train Loss: 0.32117  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 15636 -- Train Loss: 0.32187  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15637 -- Train Loss: 0.32235  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15638 -- Train Loss: 0.32231  Validation Loss: 0.43668\n",
      "t: 10 EPOCH 15639 -- Train Loss: 0.32249  Validation Loss: 0.43701\n",
      "t: 10 EPOCH 15640 -- Train Loss: 0.32200  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 15641 -- Train Loss: 0.32276  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 15642 -- Train Loss: 0.32203  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 15643 -- Train Loss: 0.32204  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 15644 -- Train Loss: 0.32160  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 15645 -- Train Loss: 0.32176  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 15646 -- Train Loss: 0.32182  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 15647 -- Train Loss: 0.32077  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 15648 -- Train Loss: 0.32176  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 15649 -- Train Loss: 0.32263  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 15650 -- Train Loss: 0.32171  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 15651 -- Train Loss: 0.32288  Validation Loss: 0.43684\n",
      "t: 10 EPOCH 15652 -- Train Loss: 0.32223  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 15653 -- Train Loss: 0.32272  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 15654 -- Train Loss: 0.32187  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 15655 -- Train Loss: 0.32215  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 15656 -- Train Loss: 0.32264  Validation Loss: 0.43703\n",
      "t: 10 EPOCH 15657 -- Train Loss: 0.32263  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 15658 -- Train Loss: 0.32231  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 15659 -- Train Loss: 0.32290  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 15660 -- Train Loss: 0.32166  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15661 -- Train Loss: 0.32164  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 15662 -- Train Loss: 0.32232  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 15663 -- Train Loss: 0.32209  Validation Loss: 0.43710\n",
      "t: 10 EPOCH 15664 -- Train Loss: 0.32202  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15665 -- Train Loss: 0.32159  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 15666 -- Train Loss: 0.32238  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 15667 -- Train Loss: 0.32280  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 15668 -- Train Loss: 0.32192  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 15669 -- Train Loss: 0.32231  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 15670 -- Train Loss: 0.32226  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 15671 -- Train Loss: 0.32278  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 15672 -- Train Loss: 0.32165  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15673 -- Train Loss: 0.32226  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 15674 -- Train Loss: 0.32194  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 15675 -- Train Loss: 0.32359  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 15676 -- Train Loss: 0.32276  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 15677 -- Train Loss: 0.32305  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15678 -- Train Loss: 0.32125  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 15679 -- Train Loss: 0.32197  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 15680 -- Train Loss: 0.32207  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15681 -- Train Loss: 0.32349  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 15682 -- Train Loss: 0.32218  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 15683 -- Train Loss: 0.32191  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 15684 -- Train Loss: 0.32256  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 15685 -- Train Loss: 0.32215  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15686 -- Train Loss: 0.32219  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 15687 -- Train Loss: 0.32281  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15688 -- Train Loss: 0.32235  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 15689 -- Train Loss: 0.32274  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 15690 -- Train Loss: 0.32212  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 15691 -- Train Loss: 0.32216  Validation Loss: 0.43671\n",
      "t: 10 EPOCH 15692 -- Train Loss: 0.32309  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 15693 -- Train Loss: 0.32277  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 15694 -- Train Loss: 0.32208  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15695 -- Train Loss: 0.32256  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 15696 -- Train Loss: 0.32257  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 15697 -- Train Loss: 0.32207  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 15698 -- Train Loss: 0.32244  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 15699 -- Train Loss: 0.32212  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 15700 -- Train Loss: 0.32262  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 15701 -- Train Loss: 0.32262  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 15702 -- Train Loss: 0.32224  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 15703 -- Train Loss: 0.32226  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 15704 -- Train Loss: 0.32296  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 15705 -- Train Loss: 0.32158  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 15706 -- Train Loss: 0.32165  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 15707 -- Train Loss: 0.32170  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15708 -- Train Loss: 0.32214  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 15709 -- Train Loss: 0.32209  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 15710 -- Train Loss: 0.32276  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 15711 -- Train Loss: 0.32184  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 15712 -- Train Loss: 0.32297  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 15713 -- Train Loss: 0.32347  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 15714 -- Train Loss: 0.32252  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 15715 -- Train Loss: 0.32213  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 15716 -- Train Loss: 0.32290  Validation Loss: 0.43308\n",
      "t: 10 EPOCH 15717 -- Train Loss: 0.32169  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 15718 -- Train Loss: 0.32224  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 15719 -- Train Loss: 0.32214  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 15720 -- Train Loss: 0.32214  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15721 -- Train Loss: 0.32256  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 15722 -- Train Loss: 0.32203  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 15723 -- Train Loss: 0.32252  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 15724 -- Train Loss: 0.32169  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 15725 -- Train Loss: 0.32232  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15726 -- Train Loss: 0.32220  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15727 -- Train Loss: 0.32301  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 15728 -- Train Loss: 0.32242  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 15729 -- Train Loss: 0.32263  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 15730 -- Train Loss: 0.32137  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 15731 -- Train Loss: 0.32208  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 15732 -- Train Loss: 0.32189  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 15733 -- Train Loss: 0.32198  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 15734 -- Train Loss: 0.32131  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 15735 -- Train Loss: 0.32272  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 15736 -- Train Loss: 0.32182  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 15737 -- Train Loss: 0.32210  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 15738 -- Train Loss: 0.32146  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15739 -- Train Loss: 0.32256  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 15740 -- Train Loss: 0.32230  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 15741 -- Train Loss: 0.32282  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 15742 -- Train Loss: 0.32278  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 15743 -- Train Loss: 0.32225  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15744 -- Train Loss: 0.32164  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 15745 -- Train Loss: 0.32240  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 15746 -- Train Loss: 0.32196  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 15747 -- Train Loss: 0.32245  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 15748 -- Train Loss: 0.32197  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 15749 -- Train Loss: 0.32214  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 15750 -- Train Loss: 0.32313  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 15751 -- Train Loss: 0.32214  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 15752 -- Train Loss: 0.32228  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 15753 -- Train Loss: 0.32175  Validation Loss: 0.43678\n",
      "t: 10 EPOCH 15754 -- Train Loss: 0.32204  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 15755 -- Train Loss: 0.32164  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 15756 -- Train Loss: 0.32176  Validation Loss: 0.43673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15757 -- Train Loss: 0.32182  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 15758 -- Train Loss: 0.32200  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 15759 -- Train Loss: 0.32184  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 15760 -- Train Loss: 0.32229  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 15761 -- Train Loss: 0.32138  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 15762 -- Train Loss: 0.32219  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 15763 -- Train Loss: 0.32252  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15764 -- Train Loss: 0.32145  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 15765 -- Train Loss: 0.32122  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 15766 -- Train Loss: 0.32222  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 15767 -- Train Loss: 0.32180  Validation Loss: 0.43386\n",
      "t: 10 EPOCH 15768 -- Train Loss: 0.32233  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 15769 -- Train Loss: 0.32145  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 15770 -- Train Loss: 0.32189  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 15771 -- Train Loss: 0.32175  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 15772 -- Train Loss: 0.32137  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 15773 -- Train Loss: 0.32167  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 15774 -- Train Loss: 0.32212  Validation Loss: 0.43439\n",
      "t: 10 EPOCH 15775 -- Train Loss: 0.32204  Validation Loss: 0.43294\n",
      "t: 10 EPOCH 15776 -- Train Loss: 0.32213  Validation Loss: 0.43701\n",
      "t: 10 EPOCH 15777 -- Train Loss: 0.32055  Validation Loss: 0.43652\n",
      "t: 10 EPOCH 15778 -- Train Loss: 0.32310  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 15779 -- Train Loss: 0.32226  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 15780 -- Train Loss: 0.32272  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 15781 -- Train Loss: 0.32116  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 15782 -- Train Loss: 0.32236  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 15783 -- Train Loss: 0.32194  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 15784 -- Train Loss: 0.32265  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 15785 -- Train Loss: 0.32199  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 15786 -- Train Loss: 0.32237  Validation Loss: 0.43385\n",
      "t: 10 EPOCH 15787 -- Train Loss: 0.32129  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15788 -- Train Loss: 0.32209  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 15789 -- Train Loss: 0.32167  Validation Loss: 0.43653\n",
      "t: 10 EPOCH 15790 -- Train Loss: 0.32109  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 15791 -- Train Loss: 0.32281  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 15792 -- Train Loss: 0.32231  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 15793 -- Train Loss: 0.32210  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 15794 -- Train Loss: 0.32138  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 15795 -- Train Loss: 0.32234  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 15796 -- Train Loss: 0.32186  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 15797 -- Train Loss: 0.32184  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15798 -- Train Loss: 0.32153  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 15799 -- Train Loss: 0.32171  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 15800 -- Train Loss: 0.32132  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 15801 -- Train Loss: 0.32196  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 15802 -- Train Loss: 0.32258  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 15803 -- Train Loss: 0.32136  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 15804 -- Train Loss: 0.32190  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 15805 -- Train Loss: 0.32116  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 15806 -- Train Loss: 0.32208  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 15807 -- Train Loss: 0.32166  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 15808 -- Train Loss: 0.32191  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 15809 -- Train Loss: 0.32221  Validation Loss: 0.43420\n",
      "t: 10 EPOCH 15810 -- Train Loss: 0.32197  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 15811 -- Train Loss: 0.32221  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 15812 -- Train Loss: 0.32293  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 15813 -- Train Loss: 0.32244  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 15814 -- Train Loss: 0.32192  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 15815 -- Train Loss: 0.32157  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 15816 -- Train Loss: 0.32210  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 15817 -- Train Loss: 0.32159  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 15818 -- Train Loss: 0.32245  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 15819 -- Train Loss: 0.32167  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 15820 -- Train Loss: 0.32287  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 15821 -- Train Loss: 0.32236  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 15822 -- Train Loss: 0.32239  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 15823 -- Train Loss: 0.32143  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 15824 -- Train Loss: 0.32187  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 15825 -- Train Loss: 0.32203  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 15826 -- Train Loss: 0.32190  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 15827 -- Train Loss: 0.32149  Validation Loss: 0.43404\n",
      "t: 10 EPOCH 15828 -- Train Loss: 0.32236  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 15829 -- Train Loss: 0.32237  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15830 -- Train Loss: 0.32226  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 15831 -- Train Loss: 0.32172  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 15832 -- Train Loss: 0.32195  Validation Loss: 0.43679\n",
      "t: 10 EPOCH 15833 -- Train Loss: 0.32191  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 15834 -- Train Loss: 0.32226  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 15835 -- Train Loss: 0.32184  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 15836 -- Train Loss: 0.32159  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 15837 -- Train Loss: 0.32222  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 15838 -- Train Loss: 0.32198  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 15839 -- Train Loss: 0.32263  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 15840 -- Train Loss: 0.32142  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 15841 -- Train Loss: 0.32220  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 15842 -- Train Loss: 0.32186  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 15843 -- Train Loss: 0.32175  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 15844 -- Train Loss: 0.32239  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 15845 -- Train Loss: 0.32189  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 15846 -- Train Loss: 0.32181  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 15847 -- Train Loss: 0.32176  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 15848 -- Train Loss: 0.32215  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 15849 -- Train Loss: 0.32226  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 15850 -- Train Loss: 0.32156  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 15851 -- Train Loss: 0.32146  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 15852 -- Train Loss: 0.32200  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 15853 -- Train Loss: 0.32152  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 15854 -- Train Loss: 0.32243  Validation Loss: 0.43669\n",
      "t: 10 EPOCH 15855 -- Train Loss: 0.32214  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 15856 -- Train Loss: 0.32240  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 15857 -- Train Loss: 0.32166  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 15858 -- Train Loss: 0.32233  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 15859 -- Train Loss: 0.32132  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 15860 -- Train Loss: 0.32261  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 15861 -- Train Loss: 0.32218  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 15862 -- Train Loss: 0.32207  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 15863 -- Train Loss: 0.32236  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 15864 -- Train Loss: 0.32189  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 15865 -- Train Loss: 0.32226  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 15866 -- Train Loss: 0.32238  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 15867 -- Train Loss: 0.32215  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 15868 -- Train Loss: 0.32249  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 15869 -- Train Loss: 0.32246  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 15870 -- Train Loss: 0.32161  Validation Loss: 0.43649\n",
      "t: 10 EPOCH 15871 -- Train Loss: 0.32254  Validation Loss: 0.43753\n",
      "t: 10 EPOCH 15872 -- Train Loss: 0.32198  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 15873 -- Train Loss: 0.32313  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 15874 -- Train Loss: 0.32192  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 15875 -- Train Loss: 0.32186  Validation Loss: 0.43680\n",
      "t: 10 EPOCH 15876 -- Train Loss: 0.32238  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 15877 -- Train Loss: 0.32175  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 15878 -- Train Loss: 0.32060  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 15879 -- Train Loss: 0.32117  Validation Loss: 0.43723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 15880 -- Train Loss: 0.32174  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 15881 -- Train Loss: 0.32208  Validation Loss: 0.43456\n",
      "t: 10 EPOCH 15882 -- Train Loss: 0.32224  Validation Loss: 0.43365\n",
      "t: 10 EPOCH 15883 -- Train Loss: 0.32181  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 15884 -- Train Loss: 0.32157  Validation Loss: 0.43309\n",
      "t: 10 EPOCH 15885 -- Train Loss: 0.32197  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 15886 -- Train Loss: 0.32278  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 15887 -- Train Loss: 0.32176  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 15888 -- Train Loss: 0.32228  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 15889 -- Train Loss: 0.32164  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 15890 -- Train Loss: 0.32179  Validation Loss: 0.43690\n",
      "t: 10 EPOCH 15891 -- Train Loss: 0.32129  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 15892 -- Train Loss: 0.32230  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 15893 -- Train Loss: 0.32228  Validation Loss: 0.43656\n",
      "t: 10 EPOCH 15894 -- Train Loss: 0.32132  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 15895 -- Train Loss: 0.32211  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 15896 -- Train Loss: 0.32147  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 15897 -- Train Loss: 0.32111  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 15898 -- Train Loss: 0.32110  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 15899 -- Train Loss: 0.32221  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 15900 -- Train Loss: 0.32126  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 15901 -- Train Loss: 0.32254  Validation Loss: 0.43672\n",
      "t: 10 EPOCH 15902 -- Train Loss: 0.32213  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 15903 -- Train Loss: 0.32276  Validation Loss: 0.43419\n",
      "t: 10 EPOCH 15904 -- Train Loss: 0.32265  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 15905 -- Train Loss: 0.32191  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 15906 -- Train Loss: 0.32217  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 15907 -- Train Loss: 0.32383  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 15908 -- Train Loss: 0.32148  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 15909 -- Train Loss: 0.32231  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 15910 -- Train Loss: 0.32165  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 15911 -- Train Loss: 0.32304  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 15912 -- Train Loss: 0.32119  Validation Loss: 0.43655\n",
      "t: 10 EPOCH 15913 -- Train Loss: 0.32259  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 15914 -- Train Loss: 0.32185  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 15915 -- Train Loss: 0.32255  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 15916 -- Train Loss: 0.32228  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 15917 -- Train Loss: 0.32212  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15918 -- Train Loss: 0.32087  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 15919 -- Train Loss: 0.32222  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 15920 -- Train Loss: 0.32253  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 15921 -- Train Loss: 0.32209  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 15922 -- Train Loss: 0.32166  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 15923 -- Train Loss: 0.32215  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 15924 -- Train Loss: 0.32217  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 15925 -- Train Loss: 0.32238  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 15926 -- Train Loss: 0.32168  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 15927 -- Train Loss: 0.32152  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 15928 -- Train Loss: 0.32260  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 15929 -- Train Loss: 0.32212  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 15930 -- Train Loss: 0.32189  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 15931 -- Train Loss: 0.32148  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 15932 -- Train Loss: 0.32199  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 15933 -- Train Loss: 0.32208  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 15934 -- Train Loss: 0.32157  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 15935 -- Train Loss: 0.32110  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 15936 -- Train Loss: 0.32157  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 15937 -- Train Loss: 0.32202  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 15938 -- Train Loss: 0.32159  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 15939 -- Train Loss: 0.32237  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 15940 -- Train Loss: 0.32134  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15941 -- Train Loss: 0.32170  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 15942 -- Train Loss: 0.32245  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 15943 -- Train Loss: 0.32166  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 15944 -- Train Loss: 0.32168  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 15945 -- Train Loss: 0.32222  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 15946 -- Train Loss: 0.32228  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15947 -- Train Loss: 0.32107  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 15948 -- Train Loss: 0.32211  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 15949 -- Train Loss: 0.32165  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 15950 -- Train Loss: 0.32156  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 15951 -- Train Loss: 0.32118  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 15952 -- Train Loss: 0.32209  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 15953 -- Train Loss: 0.32148  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 15954 -- Train Loss: 0.32217  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 15955 -- Train Loss: 0.32088  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 15956 -- Train Loss: 0.32208  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 15957 -- Train Loss: 0.32221  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 15958 -- Train Loss: 0.32153  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 15959 -- Train Loss: 0.32215  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 15960 -- Train Loss: 0.32230  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 15961 -- Train Loss: 0.32182  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 15962 -- Train Loss: 0.32250  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 15963 -- Train Loss: 0.32155  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 15964 -- Train Loss: 0.32162  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 15965 -- Train Loss: 0.32208  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 15966 -- Train Loss: 0.32193  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 15967 -- Train Loss: 0.32194  Validation Loss: 0.43679\n",
      "t: 10 EPOCH 15968 -- Train Loss: 0.32201  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 15969 -- Train Loss: 0.32171  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 15970 -- Train Loss: 0.32124  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 15971 -- Train Loss: 0.32267  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 15972 -- Train Loss: 0.32180  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 15973 -- Train Loss: 0.32175  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 15974 -- Train Loss: 0.32213  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 15975 -- Train Loss: 0.32230  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 15976 -- Train Loss: 0.32241  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 15977 -- Train Loss: 0.32145  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 15978 -- Train Loss: 0.32234  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 15979 -- Train Loss: 0.32201  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 15980 -- Train Loss: 0.32165  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 15981 -- Train Loss: 0.32106  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 15982 -- Train Loss: 0.32263  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 15983 -- Train Loss: 0.32137  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 15984 -- Train Loss: 0.32131  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 15985 -- Train Loss: 0.32171  Validation Loss: 0.43677\n",
      "t: 10 EPOCH 15986 -- Train Loss: 0.32170  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 15987 -- Train Loss: 0.32177  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 15988 -- Train Loss: 0.32230  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 15989 -- Train Loss: 0.32193  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 15990 -- Train Loss: 0.32178  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 15991 -- Train Loss: 0.32244  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 15992 -- Train Loss: 0.32179  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 15993 -- Train Loss: 0.32222  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 15994 -- Train Loss: 0.32192  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 15995 -- Train Loss: 0.32117  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 15996 -- Train Loss: 0.32145  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 15997 -- Train Loss: 0.32237  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 15998 -- Train Loss: 0.32135  Validation Loss: 0.43659\n",
      "t: 10 EPOCH 15999 -- Train Loss: 0.32175  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 16000 -- Train Loss: 0.32168  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 16001 -- Train Loss: 0.32172  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 16002 -- Train Loss: 0.32198  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 16003 -- Train Loss: 0.32133  Validation Loss: 0.43520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16004 -- Train Loss: 0.32169  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 16005 -- Train Loss: 0.32093  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 16006 -- Train Loss: 0.32113  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 16007 -- Train Loss: 0.32221  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 16008 -- Train Loss: 0.32133  Validation Loss: 0.43376\n",
      "t: 10 EPOCH 16009 -- Train Loss: 0.32117  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16010 -- Train Loss: 0.32125  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 16011 -- Train Loss: 0.32140  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 16012 -- Train Loss: 0.32095  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 16013 -- Train Loss: 0.32175  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 16014 -- Train Loss: 0.32131  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 16015 -- Train Loss: 0.32231  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 16016 -- Train Loss: 0.32116  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 16017 -- Train Loss: 0.32265  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 16018 -- Train Loss: 0.32062  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 16019 -- Train Loss: 0.32255  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 16020 -- Train Loss: 0.32139  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 16021 -- Train Loss: 0.32158  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 16022 -- Train Loss: 0.32193  Validation Loss: 0.43395\n",
      "t: 10 EPOCH 16023 -- Train Loss: 0.32193  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 16024 -- Train Loss: 0.32178  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 16025 -- Train Loss: 0.32203  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 16026 -- Train Loss: 0.32173  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 16027 -- Train Loss: 0.32169  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 16028 -- Train Loss: 0.32159  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 16029 -- Train Loss: 0.32205  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 16030 -- Train Loss: 0.32203  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 16031 -- Train Loss: 0.32199  Validation Loss: 0.43425\n",
      "t: 10 EPOCH 16032 -- Train Loss: 0.32218  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 16033 -- Train Loss: 0.32229  Validation Loss: 0.43363\n",
      "t: 10 EPOCH 16034 -- Train Loss: 0.32116  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 16035 -- Train Loss: 0.32225  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 16036 -- Train Loss: 0.32204  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 16037 -- Train Loss: 0.32253  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 16038 -- Train Loss: 0.32154  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 16039 -- Train Loss: 0.32237  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 16040 -- Train Loss: 0.32181  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 16041 -- Train Loss: 0.32166  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 16042 -- Train Loss: 0.32106  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 16043 -- Train Loss: 0.32166  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 16044 -- Train Loss: 0.32145  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 16045 -- Train Loss: 0.32210  Validation Loss: 0.43731\n",
      "t: 10 EPOCH 16046 -- Train Loss: 0.32122  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 16047 -- Train Loss: 0.32254  Validation Loss: 0.43358\n",
      "t: 10 EPOCH 16048 -- Train Loss: 0.32134  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 16049 -- Train Loss: 0.32155  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16050 -- Train Loss: 0.32132  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 16051 -- Train Loss: 0.32183  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 16052 -- Train Loss: 0.32136  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 16053 -- Train Loss: 0.32164  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16054 -- Train Loss: 0.32209  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 16055 -- Train Loss: 0.32139  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 16056 -- Train Loss: 0.32235  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 16057 -- Train Loss: 0.32100  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 16058 -- Train Loss: 0.32171  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 16059 -- Train Loss: 0.32237  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 16060 -- Train Loss: 0.32221  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 16061 -- Train Loss: 0.32206  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 16062 -- Train Loss: 0.32192  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 16063 -- Train Loss: 0.32127  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 16064 -- Train Loss: 0.32154  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 16065 -- Train Loss: 0.32269  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 16066 -- Train Loss: 0.32186  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 16067 -- Train Loss: 0.32270  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16068 -- Train Loss: 0.32144  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 16069 -- Train Loss: 0.32233  Validation Loss: 0.43430\n",
      "t: 10 EPOCH 16070 -- Train Loss: 0.32100  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 16071 -- Train Loss: 0.32117  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 16072 -- Train Loss: 0.32208  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16073 -- Train Loss: 0.32146  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16074 -- Train Loss: 0.32196  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 16075 -- Train Loss: 0.32130  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 16076 -- Train Loss: 0.32271  Validation Loss: 0.43352\n",
      "t: 10 EPOCH 16077 -- Train Loss: 0.32211  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 16078 -- Train Loss: 0.32104  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 16079 -- Train Loss: 0.32187  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 16080 -- Train Loss: 0.32220  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 16081 -- Train Loss: 0.32205  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 16082 -- Train Loss: 0.32189  Validation Loss: 0.43384\n",
      "t: 10 EPOCH 16083 -- Train Loss: 0.32218  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 16084 -- Train Loss: 0.32166  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 16085 -- Train Loss: 0.32186  Validation Loss: 0.43414\n",
      "t: 10 EPOCH 16086 -- Train Loss: 0.32193  Validation Loss: 0.43409\n",
      "t: 10 EPOCH 16087 -- Train Loss: 0.32135  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16088 -- Train Loss: 0.32248  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 16089 -- Train Loss: 0.32199  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 16090 -- Train Loss: 0.32144  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 16091 -- Train Loss: 0.32289  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 16092 -- Train Loss: 0.32287  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 16093 -- Train Loss: 0.32239  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16094 -- Train Loss: 0.32154  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16095 -- Train Loss: 0.32138  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 16096 -- Train Loss: 0.32244  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 16097 -- Train Loss: 0.32219  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 16098 -- Train Loss: 0.32223  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 16099 -- Train Loss: 0.32212  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 16100 -- Train Loss: 0.32168  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 16101 -- Train Loss: 0.32196  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 16102 -- Train Loss: 0.32135  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 16103 -- Train Loss: 0.32182  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 16104 -- Train Loss: 0.32113  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 16105 -- Train Loss: 0.32135  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 16106 -- Train Loss: 0.32219  Validation Loss: 0.43748\n",
      "t: 10 EPOCH 16107 -- Train Loss: 0.32171  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 16108 -- Train Loss: 0.32196  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 16109 -- Train Loss: 0.32214  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16110 -- Train Loss: 0.32186  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 16111 -- Train Loss: 0.32278  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 16112 -- Train Loss: 0.32225  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 16113 -- Train Loss: 0.32140  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 16114 -- Train Loss: 0.32171  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 16115 -- Train Loss: 0.32132  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 16116 -- Train Loss: 0.32163  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 16117 -- Train Loss: 0.32182  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 16118 -- Train Loss: 0.32251  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 16119 -- Train Loss: 0.32100  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 16120 -- Train Loss: 0.32172  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 16121 -- Train Loss: 0.32201  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 16122 -- Train Loss: 0.32193  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 16123 -- Train Loss: 0.32178  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 16124 -- Train Loss: 0.32093  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16125 -- Train Loss: 0.32190  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 16126 -- Train Loss: 0.32204  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 16127 -- Train Loss: 0.32194  Validation Loss: 0.43601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16128 -- Train Loss: 0.32218  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 16129 -- Train Loss: 0.32182  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 16130 -- Train Loss: 0.32105  Validation Loss: 0.43343\n",
      "t: 10 EPOCH 16131 -- Train Loss: 0.32154  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 16132 -- Train Loss: 0.32181  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 16133 -- Train Loss: 0.32152  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 16134 -- Train Loss: 0.32248  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 16135 -- Train Loss: 0.32151  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 16136 -- Train Loss: 0.32194  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 16137 -- Train Loss: 0.32181  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 16138 -- Train Loss: 0.32208  Validation Loss: 0.43651\n",
      "t: 10 EPOCH 16139 -- Train Loss: 0.32156  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16140 -- Train Loss: 0.32195  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 16141 -- Train Loss: 0.32272  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 16142 -- Train Loss: 0.32232  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 16143 -- Train Loss: 0.32180  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 16144 -- Train Loss: 0.32178  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 16145 -- Train Loss: 0.32265  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 16146 -- Train Loss: 0.32136  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16147 -- Train Loss: 0.32210  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 16148 -- Train Loss: 0.32210  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 16149 -- Train Loss: 0.32114  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 16150 -- Train Loss: 0.32232  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 16151 -- Train Loss: 0.32142  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 16152 -- Train Loss: 0.32186  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 16153 -- Train Loss: 0.32187  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 16154 -- Train Loss: 0.32111  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 16155 -- Train Loss: 0.32113  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 16156 -- Train Loss: 0.32235  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 16157 -- Train Loss: 0.32152  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 16158 -- Train Loss: 0.32099  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 16159 -- Train Loss: 0.32304  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16160 -- Train Loss: 0.32179  Validation Loss: 0.43374\n",
      "t: 10 EPOCH 16161 -- Train Loss: 0.32247  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 16162 -- Train Loss: 0.32152  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 16163 -- Train Loss: 0.32225  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 16164 -- Train Loss: 0.32169  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16165 -- Train Loss: 0.32220  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 16166 -- Train Loss: 0.32119  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 16167 -- Train Loss: 0.32235  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 16168 -- Train Loss: 0.32139  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 16169 -- Train Loss: 0.32182  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16170 -- Train Loss: 0.32213  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 16171 -- Train Loss: 0.32216  Validation Loss: 0.43669\n",
      "t: 10 EPOCH 16172 -- Train Loss: 0.32194  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16173 -- Train Loss: 0.32209  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 16174 -- Train Loss: 0.32144  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 16175 -- Train Loss: 0.32194  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 16176 -- Train Loss: 0.32199  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16177 -- Train Loss: 0.32181  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 16178 -- Train Loss: 0.32183  Validation Loss: 0.43345\n",
      "t: 10 EPOCH 16179 -- Train Loss: 0.32190  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 16180 -- Train Loss: 0.32158  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 16181 -- Train Loss: 0.32196  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 16182 -- Train Loss: 0.32144  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 16183 -- Train Loss: 0.32193  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 16184 -- Train Loss: 0.32130  Validation Loss: 0.43659\n",
      "t: 10 EPOCH 16185 -- Train Loss: 0.32269  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 16186 -- Train Loss: 0.32254  Validation Loss: 0.43462\n",
      "t: 10 EPOCH 16187 -- Train Loss: 0.32273  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 16188 -- Train Loss: 0.32190  Validation Loss: 0.43649\n",
      "t: 10 EPOCH 16189 -- Train Loss: 0.32199  Validation Loss: 0.43652\n",
      "t: 10 EPOCH 16190 -- Train Loss: 0.32160  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 16191 -- Train Loss: 0.32185  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 16192 -- Train Loss: 0.32190  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 16193 -- Train Loss: 0.32165  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 16194 -- Train Loss: 0.32218  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 16195 -- Train Loss: 0.32165  Validation Loss: 0.43316\n",
      "t: 10 EPOCH 16196 -- Train Loss: 0.32164  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 16197 -- Train Loss: 0.32175  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16198 -- Train Loss: 0.32156  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 16199 -- Train Loss: 0.32183  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 16200 -- Train Loss: 0.32303  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 16201 -- Train Loss: 0.32179  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 16202 -- Train Loss: 0.32309  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 16203 -- Train Loss: 0.32192  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 16204 -- Train Loss: 0.32165  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 16205 -- Train Loss: 0.32166  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 16206 -- Train Loss: 0.32217  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 16207 -- Train Loss: 0.32252  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 16208 -- Train Loss: 0.32234  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 16209 -- Train Loss: 0.32248  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 16210 -- Train Loss: 0.32145  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 16211 -- Train Loss: 0.32132  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 16212 -- Train Loss: 0.32159  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 16213 -- Train Loss: 0.32251  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 16214 -- Train Loss: 0.32132  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 16215 -- Train Loss: 0.32295  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16216 -- Train Loss: 0.32179  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16217 -- Train Loss: 0.32198  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 16218 -- Train Loss: 0.32193  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 16219 -- Train Loss: 0.32232  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 16220 -- Train Loss: 0.32108  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 16221 -- Train Loss: 0.32219  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 16222 -- Train Loss: 0.32227  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 16223 -- Train Loss: 0.32195  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 16224 -- Train Loss: 0.32126  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 16225 -- Train Loss: 0.32179  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 16226 -- Train Loss: 0.32188  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 16227 -- Train Loss: 0.32131  Validation Loss: 0.43674\n",
      "t: 10 EPOCH 16228 -- Train Loss: 0.32228  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 16229 -- Train Loss: 0.32048  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 16230 -- Train Loss: 0.32184  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 16231 -- Train Loss: 0.32105  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16232 -- Train Loss: 0.32111  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 16233 -- Train Loss: 0.32166  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 16234 -- Train Loss: 0.32142  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 16235 -- Train Loss: 0.32064  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16236 -- Train Loss: 0.32234  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 16237 -- Train Loss: 0.32136  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 16238 -- Train Loss: 0.32229  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 16239 -- Train Loss: 0.32142  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 16240 -- Train Loss: 0.32139  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 16241 -- Train Loss: 0.32143  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 16242 -- Train Loss: 0.32150  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 16243 -- Train Loss: 0.32091  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 16244 -- Train Loss: 0.32200  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 16245 -- Train Loss: 0.32157  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 16246 -- Train Loss: 0.32234  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 16247 -- Train Loss: 0.32190  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 16248 -- Train Loss: 0.32120  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 16249 -- Train Loss: 0.32194  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 16250 -- Train Loss: 0.32148  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 16251 -- Train Loss: 0.32118  Validation Loss: 0.43571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16252 -- Train Loss: 0.32121  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 16253 -- Train Loss: 0.32098  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 16254 -- Train Loss: 0.32260  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16255 -- Train Loss: 0.32124  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 16256 -- Train Loss: 0.32198  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 16257 -- Train Loss: 0.32227  Validation Loss: 0.43649\n",
      "t: 10 EPOCH 16258 -- Train Loss: 0.32157  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 16259 -- Train Loss: 0.32180  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 16260 -- Train Loss: 0.32129  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 16261 -- Train Loss: 0.32137  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 16262 -- Train Loss: 0.32249  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 16263 -- Train Loss: 0.32157  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 16264 -- Train Loss: 0.32128  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 16265 -- Train Loss: 0.32230  Validation Loss: 0.43292\n",
      "t: 10 EPOCH 16266 -- Train Loss: 0.32127  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 16267 -- Train Loss: 0.32227  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 16268 -- Train Loss: 0.32215  Validation Loss: 0.43300\n",
      "t: 10 EPOCH 16269 -- Train Loss: 0.32155  Validation Loss: 0.43392\n",
      "t: 10 EPOCH 16270 -- Train Loss: 0.32146  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 16271 -- Train Loss: 0.32113  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 16272 -- Train Loss: 0.32181  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 16273 -- Train Loss: 0.32164  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 16274 -- Train Loss: 0.32256  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 16275 -- Train Loss: 0.32218  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 16276 -- Train Loss: 0.32172  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16277 -- Train Loss: 0.32137  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 16278 -- Train Loss: 0.32171  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 16279 -- Train Loss: 0.32126  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 16280 -- Train Loss: 0.32186  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 16281 -- Train Loss: 0.32157  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 16282 -- Train Loss: 0.32120  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 16283 -- Train Loss: 0.32083  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 16284 -- Train Loss: 0.32166  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 16285 -- Train Loss: 0.32172  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 16286 -- Train Loss: 0.32212  Validation Loss: 0.43641\n",
      "t: 10 EPOCH 16287 -- Train Loss: 0.32013  Validation Loss: 0.43335\n",
      "t: 10 EPOCH 16288 -- Train Loss: 0.32159  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 16289 -- Train Loss: 0.32097  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 16290 -- Train Loss: 0.32213  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16291 -- Train Loss: 0.32101  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 16292 -- Train Loss: 0.32129  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16293 -- Train Loss: 0.32112  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 16294 -- Train Loss: 0.32141  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 16295 -- Train Loss: 0.32120  Validation Loss: 0.43418\n",
      "t: 10 EPOCH 16296 -- Train Loss: 0.32121  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 16297 -- Train Loss: 0.32194  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 16298 -- Train Loss: 0.32168  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 16299 -- Train Loss: 0.32211  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 16300 -- Train Loss: 0.32224  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 16301 -- Train Loss: 0.32205  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 16302 -- Train Loss: 0.32104  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 16303 -- Train Loss: 0.32087  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16304 -- Train Loss: 0.32091  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 16305 -- Train Loss: 0.32204  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 16306 -- Train Loss: 0.32102  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 16307 -- Train Loss: 0.32203  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 16308 -- Train Loss: 0.32207  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 16309 -- Train Loss: 0.32170  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 16310 -- Train Loss: 0.32140  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 16311 -- Train Loss: 0.32204  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 16312 -- Train Loss: 0.32232  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 16313 -- Train Loss: 0.32131  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 16314 -- Train Loss: 0.32196  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 16315 -- Train Loss: 0.32134  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 16316 -- Train Loss: 0.32103  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 16317 -- Train Loss: 0.32180  Validation Loss: 0.43671\n",
      "t: 10 EPOCH 16318 -- Train Loss: 0.32175  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 16319 -- Train Loss: 0.32144  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 16320 -- Train Loss: 0.32175  Validation Loss: 0.43651\n",
      "t: 10 EPOCH 16321 -- Train Loss: 0.32059  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16322 -- Train Loss: 0.32241  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16323 -- Train Loss: 0.32046  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 16324 -- Train Loss: 0.32205  Validation Loss: 0.43393\n",
      "t: 10 EPOCH 16325 -- Train Loss: 0.32077  Validation Loss: 0.43737\n",
      "t: 10 EPOCH 16326 -- Train Loss: 0.32227  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 16327 -- Train Loss: 0.32063  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 16328 -- Train Loss: 0.32276  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 16329 -- Train Loss: 0.32074  Validation Loss: 0.43724\n",
      "t: 10 EPOCH 16330 -- Train Loss: 0.32140  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 16331 -- Train Loss: 0.32218  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 16332 -- Train Loss: 0.32209  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 16333 -- Train Loss: 0.32137  Validation Loss: 0.43699\n",
      "t: 10 EPOCH 16334 -- Train Loss: 0.32125  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 16335 -- Train Loss: 0.32171  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 16336 -- Train Loss: 0.32189  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 16337 -- Train Loss: 0.32185  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 16338 -- Train Loss: 0.32208  Validation Loss: 0.43759\n",
      "t: 10 EPOCH 16339 -- Train Loss: 0.32187  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 16340 -- Train Loss: 0.32169  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 16341 -- Train Loss: 0.32207  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 16342 -- Train Loss: 0.32106  Validation Loss: 0.43684\n",
      "t: 10 EPOCH 16343 -- Train Loss: 0.32152  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 16344 -- Train Loss: 0.32237  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 16345 -- Train Loss: 0.32239  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 16346 -- Train Loss: 0.32181  Validation Loss: 0.43712\n",
      "t: 10 EPOCH 16347 -- Train Loss: 0.32114  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 16348 -- Train Loss: 0.32134  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16349 -- Train Loss: 0.32198  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 16350 -- Train Loss: 0.32172  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 16351 -- Train Loss: 0.32202  Validation Loss: 0.43722\n",
      "t: 10 EPOCH 16352 -- Train Loss: 0.32155  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16353 -- Train Loss: 0.32218  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 16354 -- Train Loss: 0.32075  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16355 -- Train Loss: 0.32197  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 16356 -- Train Loss: 0.32181  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 16357 -- Train Loss: 0.32096  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 16358 -- Train Loss: 0.32220  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 16359 -- Train Loss: 0.32144  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 16360 -- Train Loss: 0.32143  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 16361 -- Train Loss: 0.32115  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 16362 -- Train Loss: 0.32203  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 16363 -- Train Loss: 0.32001  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 16364 -- Train Loss: 0.32159  Validation Loss: 0.43671\n",
      "t: 10 EPOCH 16365 -- Train Loss: 0.32121  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 16366 -- Train Loss: 0.32139  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 16367 -- Train Loss: 0.32119  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 16368 -- Train Loss: 0.32262  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 16369 -- Train Loss: 0.32116  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 16370 -- Train Loss: 0.32139  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 16371 -- Train Loss: 0.32223  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 16372 -- Train Loss: 0.32115  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 16373 -- Train Loss: 0.32213  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 16374 -- Train Loss: 0.32217  Validation Loss: 0.43407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16375 -- Train Loss: 0.32258  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 16376 -- Train Loss: 0.32227  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 16377 -- Train Loss: 0.32199  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 16378 -- Train Loss: 0.32170  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 16379 -- Train Loss: 0.32204  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 16380 -- Train Loss: 0.32120  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 16381 -- Train Loss: 0.32226  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 16382 -- Train Loss: 0.32108  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 16383 -- Train Loss: 0.32201  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 16384 -- Train Loss: 0.32190  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 16385 -- Train Loss: 0.32135  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 16386 -- Train Loss: 0.32169  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 16387 -- Train Loss: 0.32164  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 16388 -- Train Loss: 0.32181  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 16389 -- Train Loss: 0.32164  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 16390 -- Train Loss: 0.32136  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 16391 -- Train Loss: 0.32238  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 16392 -- Train Loss: 0.32074  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 16393 -- Train Loss: 0.32135  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16394 -- Train Loss: 0.32173  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 16395 -- Train Loss: 0.32179  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 16396 -- Train Loss: 0.32068  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 16397 -- Train Loss: 0.32205  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16398 -- Train Loss: 0.32119  Validation Loss: 0.43715\n",
      "t: 10 EPOCH 16399 -- Train Loss: 0.32154  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16400 -- Train Loss: 0.32216  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 16401 -- Train Loss: 0.32126  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 16402 -- Train Loss: 0.32182  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 16403 -- Train Loss: 0.32200  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 16404 -- Train Loss: 0.32156  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 16405 -- Train Loss: 0.32225  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 16406 -- Train Loss: 0.32107  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 16407 -- Train Loss: 0.32166  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 16408 -- Train Loss: 0.32160  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 16409 -- Train Loss: 0.32227  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 16410 -- Train Loss: 0.32238  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 16411 -- Train Loss: 0.32178  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 16412 -- Train Loss: 0.32197  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16413 -- Train Loss: 0.32152  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 16414 -- Train Loss: 0.32215  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 16415 -- Train Loss: 0.32239  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 16416 -- Train Loss: 0.32179  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 16417 -- Train Loss: 0.32186  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 16418 -- Train Loss: 0.32234  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 16419 -- Train Loss: 0.32118  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 16420 -- Train Loss: 0.32202  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 16421 -- Train Loss: 0.32160  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 16422 -- Train Loss: 0.32137  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 16423 -- Train Loss: 0.32192  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 16424 -- Train Loss: 0.32138  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 16425 -- Train Loss: 0.32140  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 16426 -- Train Loss: 0.32188  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 16427 -- Train Loss: 0.32105  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 16428 -- Train Loss: 0.32178  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 16429 -- Train Loss: 0.32236  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 16430 -- Train Loss: 0.32181  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 16431 -- Train Loss: 0.32208  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 16432 -- Train Loss: 0.32162  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 16433 -- Train Loss: 0.32142  Validation Loss: 0.43407\n",
      "t: 10 EPOCH 16434 -- Train Loss: 0.32207  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 16435 -- Train Loss: 0.32146  Validation Loss: 0.43671\n",
      "t: 10 EPOCH 16436 -- Train Loss: 0.32238  Validation Loss: 0.43649\n",
      "t: 10 EPOCH 16437 -- Train Loss: 0.32149  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 16438 -- Train Loss: 0.32242  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 16439 -- Train Loss: 0.32159  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 16440 -- Train Loss: 0.32134  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 16441 -- Train Loss: 0.32236  Validation Loss: 0.43408\n",
      "t: 10 EPOCH 16442 -- Train Loss: 0.32191  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 16443 -- Train Loss: 0.32167  Validation Loss: 0.43720\n",
      "t: 10 EPOCH 16444 -- Train Loss: 0.32207  Validation Loss: 0.43390\n",
      "t: 10 EPOCH 16445 -- Train Loss: 0.32124  Validation Loss: 0.43399\n",
      "t: 10 EPOCH 16446 -- Train Loss: 0.32209  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 16447 -- Train Loss: 0.32099  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 16448 -- Train Loss: 0.32144  Validation Loss: 0.43691\n",
      "t: 10 EPOCH 16449 -- Train Loss: 0.32104  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 16450 -- Train Loss: 0.32129  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 16451 -- Train Loss: 0.32168  Validation Loss: 0.43668\n",
      "t: 10 EPOCH 16452 -- Train Loss: 0.32187  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 16453 -- Train Loss: 0.32194  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 16454 -- Train Loss: 0.32219  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16455 -- Train Loss: 0.32091  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 16456 -- Train Loss: 0.32185  Validation Loss: 0.43706\n",
      "t: 10 EPOCH 16457 -- Train Loss: 0.32224  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 16458 -- Train Loss: 0.32136  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 16459 -- Train Loss: 0.32106  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 16460 -- Train Loss: 0.32175  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 16461 -- Train Loss: 0.32173  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16462 -- Train Loss: 0.32107  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 16463 -- Train Loss: 0.32080  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 16464 -- Train Loss: 0.32202  Validation Loss: 0.43611\n",
      "t: 10 EPOCH 16465 -- Train Loss: 0.32145  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 16466 -- Train Loss: 0.32156  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 16467 -- Train Loss: 0.32208  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 16468 -- Train Loss: 0.32147  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 16469 -- Train Loss: 0.32168  Validation Loss: 0.43440\n",
      "t: 10 EPOCH 16470 -- Train Loss: 0.32174  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 16471 -- Train Loss: 0.32327  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 16472 -- Train Loss: 0.32140  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 16473 -- Train Loss: 0.32079  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 16474 -- Train Loss: 0.32151  Validation Loss: 0.43317\n",
      "t: 10 EPOCH 16475 -- Train Loss: 0.32129  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 16476 -- Train Loss: 0.32187  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 16477 -- Train Loss: 0.32253  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 16478 -- Train Loss: 0.32164  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 16479 -- Train Loss: 0.32184  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 16480 -- Train Loss: 0.32146  Validation Loss: 0.43662\n",
      "t: 10 EPOCH 16481 -- Train Loss: 0.32155  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 16482 -- Train Loss: 0.32101  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 16483 -- Train Loss: 0.32091  Validation Loss: 0.43354\n",
      "t: 10 EPOCH 16484 -- Train Loss: 0.32163  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 16485 -- Train Loss: 0.32253  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 16486 -- Train Loss: 0.32188  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 16487 -- Train Loss: 0.32232  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 16488 -- Train Loss: 0.32124  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 16489 -- Train Loss: 0.32258  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 16490 -- Train Loss: 0.32097  Validation Loss: 0.43720\n",
      "t: 10 EPOCH 16491 -- Train Loss: 0.32281  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16492 -- Train Loss: 0.32092  Validation Loss: 0.43663\n",
      "t: 10 EPOCH 16493 -- Train Loss: 0.32187  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 16494 -- Train Loss: 0.32129  Validation Loss: 0.43467\n",
      "t: 10 EPOCH 16495 -- Train Loss: 0.32277  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 16496 -- Train Loss: 0.32168  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16497 -- Train Loss: 0.32217  Validation Loss: 0.43443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16498 -- Train Loss: 0.32127  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 16499 -- Train Loss: 0.32273  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 16500 -- Train Loss: 0.32197  Validation Loss: 0.43312\n",
      "t: 10 EPOCH 16501 -- Train Loss: 0.32217  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 16502 -- Train Loss: 0.32179  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 16503 -- Train Loss: 0.32261  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 16504 -- Train Loss: 0.32122  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 16505 -- Train Loss: 0.32164  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 16506 -- Train Loss: 0.32115  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 16507 -- Train Loss: 0.32197  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 16508 -- Train Loss: 0.32192  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 16509 -- Train Loss: 0.32095  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16510 -- Train Loss: 0.32232  Validation Loss: 0.43656\n",
      "t: 10 EPOCH 16511 -- Train Loss: 0.32087  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 16512 -- Train Loss: 0.32173  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16513 -- Train Loss: 0.32117  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 16514 -- Train Loss: 0.32141  Validation Loss: 0.43685\n",
      "t: 10 EPOCH 16515 -- Train Loss: 0.32140  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 16516 -- Train Loss: 0.32115  Validation Loss: 0.43741\n",
      "t: 10 EPOCH 16517 -- Train Loss: 0.32159  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 16518 -- Train Loss: 0.32215  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 16519 -- Train Loss: 0.32148  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16520 -- Train Loss: 0.32163  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 16521 -- Train Loss: 0.32159  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 16522 -- Train Loss: 0.32239  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 16523 -- Train Loss: 0.32195  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 16524 -- Train Loss: 0.32209  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16525 -- Train Loss: 0.32177  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 16526 -- Train Loss: 0.32136  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 16527 -- Train Loss: 0.32097  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 16528 -- Train Loss: 0.32226  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 16529 -- Train Loss: 0.32124  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 16530 -- Train Loss: 0.32244  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 16531 -- Train Loss: 0.32147  Validation Loss: 0.43670\n",
      "t: 10 EPOCH 16532 -- Train Loss: 0.32171  Validation Loss: 0.43670\n",
      "t: 10 EPOCH 16533 -- Train Loss: 0.32136  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16534 -- Train Loss: 0.32135  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 16535 -- Train Loss: 0.32091  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 16536 -- Train Loss: 0.32197  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 16537 -- Train Loss: 0.32164  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 16538 -- Train Loss: 0.32203  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 16539 -- Train Loss: 0.32135  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 16540 -- Train Loss: 0.32195  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 16541 -- Train Loss: 0.32129  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 16542 -- Train Loss: 0.32169  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 16543 -- Train Loss: 0.32185  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 16544 -- Train Loss: 0.32077  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 16545 -- Train Loss: 0.32226  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 16546 -- Train Loss: 0.32111  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 16547 -- Train Loss: 0.32214  Validation Loss: 0.43449\n",
      "t: 10 EPOCH 16548 -- Train Loss: 0.32069  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 16549 -- Train Loss: 0.32214  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 16550 -- Train Loss: 0.32144  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 16551 -- Train Loss: 0.32251  Validation Loss: 0.43719\n",
      "t: 10 EPOCH 16552 -- Train Loss: 0.32111  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 16553 -- Train Loss: 0.32200  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 16554 -- Train Loss: 0.32199  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 16555 -- Train Loss: 0.32216  Validation Loss: 0.43662\n",
      "t: 10 EPOCH 16556 -- Train Loss: 0.32123  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 16557 -- Train Loss: 0.32085  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 16558 -- Train Loss: 0.32115  Validation Loss: 0.43674\n",
      "t: 10 EPOCH 16559 -- Train Loss: 0.32127  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 16560 -- Train Loss: 0.32203  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 16561 -- Train Loss: 0.32162  Validation Loss: 0.43655\n",
      "t: 10 EPOCH 16562 -- Train Loss: 0.32121  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16563 -- Train Loss: 0.32182  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16564 -- Train Loss: 0.32225  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 16565 -- Train Loss: 0.32232  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 16566 -- Train Loss: 0.32158  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 16567 -- Train Loss: 0.32196  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 16568 -- Train Loss: 0.32167  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 16569 -- Train Loss: 0.32174  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 16570 -- Train Loss: 0.32148  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 16571 -- Train Loss: 0.32125  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 16572 -- Train Loss: 0.32183  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16573 -- Train Loss: 0.32183  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 16574 -- Train Loss: 0.32157  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 16575 -- Train Loss: 0.32147  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16576 -- Train Loss: 0.32163  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 16577 -- Train Loss: 0.32150  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 16578 -- Train Loss: 0.32144  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 16579 -- Train Loss: 0.32143  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 16580 -- Train Loss: 0.32210  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 16581 -- Train Loss: 0.32142  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 16582 -- Train Loss: 0.32166  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 16583 -- Train Loss: 0.32117  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 16584 -- Train Loss: 0.32187  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 16585 -- Train Loss: 0.32225  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 16586 -- Train Loss: 0.32171  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 16587 -- Train Loss: 0.32195  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 16588 -- Train Loss: 0.32168  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 16589 -- Train Loss: 0.32141  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 16590 -- Train Loss: 0.32172  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 16591 -- Train Loss: 0.32096  Validation Loss: 0.43754\n",
      "t: 10 EPOCH 16592 -- Train Loss: 0.32254  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 16593 -- Train Loss: 0.32160  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16594 -- Train Loss: 0.32235  Validation Loss: 0.43677\n",
      "t: 10 EPOCH 16595 -- Train Loss: 0.32187  Validation Loss: 0.43752\n",
      "t: 10 EPOCH 16596 -- Train Loss: 0.32177  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 16597 -- Train Loss: 0.32163  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 16598 -- Train Loss: 0.32081  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 16599 -- Train Loss: 0.32150  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 16600 -- Train Loss: 0.32188  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 16601 -- Train Loss: 0.32061  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 16602 -- Train Loss: 0.32092  Validation Loss: 0.43445\n",
      "t: 10 EPOCH 16603 -- Train Loss: 0.32217  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 16604 -- Train Loss: 0.32146  Validation Loss: 0.43370\n",
      "t: 10 EPOCH 16605 -- Train Loss: 0.32179  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 16606 -- Train Loss: 0.32130  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 16607 -- Train Loss: 0.32201  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 16608 -- Train Loss: 0.32203  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 16609 -- Train Loss: 0.32206  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 16610 -- Train Loss: 0.32178  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 16611 -- Train Loss: 0.32152  Validation Loss: 0.43662\n",
      "t: 10 EPOCH 16612 -- Train Loss: 0.32180  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 16613 -- Train Loss: 0.32195  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 16614 -- Train Loss: 0.32127  Validation Loss: 0.43379\n",
      "t: 10 EPOCH 16615 -- Train Loss: 0.32120  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 16616 -- Train Loss: 0.32182  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 16617 -- Train Loss: 0.32130  Validation Loss: 0.43405\n",
      "t: 10 EPOCH 16618 -- Train Loss: 0.32249  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 16619 -- Train Loss: 0.32116  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 16620 -- Train Loss: 0.32095  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 16621 -- Train Loss: 0.32196  Validation Loss: 0.43535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16622 -- Train Loss: 0.32193  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 16623 -- Train Loss: 0.32164  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 16624 -- Train Loss: 0.32212  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 16625 -- Train Loss: 0.32151  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 16626 -- Train Loss: 0.32118  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 16627 -- Train Loss: 0.32120  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 16628 -- Train Loss: 0.32151  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 16629 -- Train Loss: 0.32127  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 16630 -- Train Loss: 0.32155  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16631 -- Train Loss: 0.32150  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 16632 -- Train Loss: 0.32257  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 16633 -- Train Loss: 0.32194  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 16634 -- Train Loss: 0.32071  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 16635 -- Train Loss: 0.32213  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 16636 -- Train Loss: 0.32118  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 16637 -- Train Loss: 0.32164  Validation Loss: 0.43764\n",
      "t: 10 EPOCH 16638 -- Train Loss: 0.32197  Validation Loss: 0.43297\n",
      "t: 10 EPOCH 16639 -- Train Loss: 0.32139  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 16640 -- Train Loss: 0.32064  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 16641 -- Train Loss: 0.32185  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 16642 -- Train Loss: 0.32176  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 16643 -- Train Loss: 0.32157  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 16644 -- Train Loss: 0.32163  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 16645 -- Train Loss: 0.32127  Validation Loss: 0.43650\n",
      "t: 10 EPOCH 16646 -- Train Loss: 0.32156  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 16647 -- Train Loss: 0.32192  Validation Loss: 0.43417\n",
      "t: 10 EPOCH 16648 -- Train Loss: 0.32176  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 16649 -- Train Loss: 0.32158  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 16650 -- Train Loss: 0.32149  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 16651 -- Train Loss: 0.32099  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 16652 -- Train Loss: 0.32152  Validation Loss: 0.43643\n",
      "t: 10 EPOCH 16653 -- Train Loss: 0.32137  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16654 -- Train Loss: 0.32204  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 16655 -- Train Loss: 0.32195  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 16656 -- Train Loss: 0.32049  Validation Loss: 0.43679\n",
      "t: 10 EPOCH 16657 -- Train Loss: 0.32138  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 16658 -- Train Loss: 0.32140  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 16659 -- Train Loss: 0.32151  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 16660 -- Train Loss: 0.32179  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 16661 -- Train Loss: 0.32080  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 16662 -- Train Loss: 0.32073  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16663 -- Train Loss: 0.32121  Validation Loss: 0.43313\n",
      "t: 10 EPOCH 16664 -- Train Loss: 0.32127  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 16665 -- Train Loss: 0.32121  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 16666 -- Train Loss: 0.32102  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 16667 -- Train Loss: 0.32101  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16668 -- Train Loss: 0.32138  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 16669 -- Train Loss: 0.32128  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16670 -- Train Loss: 0.32165  Validation Loss: 0.43655\n",
      "t: 10 EPOCH 16671 -- Train Loss: 0.32059  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 16672 -- Train Loss: 0.32132  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 16673 -- Train Loss: 0.32093  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 16674 -- Train Loss: 0.32202  Validation Loss: 0.43283\n",
      "t: 10 EPOCH 16675 -- Train Loss: 0.32224  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 16676 -- Train Loss: 0.32047  Validation Loss: 0.43477\n",
      "t: 10 EPOCH 16677 -- Train Loss: 0.32157  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 16678 -- Train Loss: 0.32201  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 16679 -- Train Loss: 0.32053  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 16680 -- Train Loss: 0.32133  Validation Loss: 0.43375\n",
      "t: 10 EPOCH 16681 -- Train Loss: 0.32149  Validation Loss: 0.43687\n",
      "t: 10 EPOCH 16682 -- Train Loss: 0.32134  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 16683 -- Train Loss: 0.32184  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 16684 -- Train Loss: 0.32188  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 16685 -- Train Loss: 0.32156  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 16686 -- Train Loss: 0.32043  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 16687 -- Train Loss: 0.32187  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 16688 -- Train Loss: 0.32049  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 16689 -- Train Loss: 0.32178  Validation Loss: 0.43682\n",
      "t: 10 EPOCH 16690 -- Train Loss: 0.32084  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 16691 -- Train Loss: 0.32164  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 16692 -- Train Loss: 0.32130  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 16693 -- Train Loss: 0.32083  Validation Loss: 0.43653\n",
      "t: 10 EPOCH 16694 -- Train Loss: 0.32033  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 16695 -- Train Loss: 0.32135  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 16696 -- Train Loss: 0.32078  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 16697 -- Train Loss: 0.32110  Validation Loss: 0.43740\n",
      "t: 10 EPOCH 16698 -- Train Loss: 0.32150  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 16699 -- Train Loss: 0.32175  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 16700 -- Train Loss: 0.32186  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 16701 -- Train Loss: 0.32119  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 16702 -- Train Loss: 0.32076  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 16703 -- Train Loss: 0.32116  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 16704 -- Train Loss: 0.32221  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 16705 -- Train Loss: 0.32201  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 16706 -- Train Loss: 0.32164  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 16707 -- Train Loss: 0.32115  Validation Loss: 0.43669\n",
      "t: 10 EPOCH 16708 -- Train Loss: 0.32175  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 16709 -- Train Loss: 0.32088  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 16710 -- Train Loss: 0.32131  Validation Loss: 0.43696\n",
      "t: 10 EPOCH 16711 -- Train Loss: 0.32184  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 16712 -- Train Loss: 0.32066  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16713 -- Train Loss: 0.32184  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 16714 -- Train Loss: 0.32113  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 16715 -- Train Loss: 0.32240  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 16716 -- Train Loss: 0.32167  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 16717 -- Train Loss: 0.32228  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 16718 -- Train Loss: 0.32071  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 16719 -- Train Loss: 0.32144  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 16720 -- Train Loss: 0.32182  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 16721 -- Train Loss: 0.32227  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 16722 -- Train Loss: 0.32108  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 16723 -- Train Loss: 0.32134  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 16724 -- Train Loss: 0.32236  Validation Loss: 0.43481\n",
      "t: 10 EPOCH 16725 -- Train Loss: 0.32074  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 16726 -- Train Loss: 0.32048  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 16727 -- Train Loss: 0.32086  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 16728 -- Train Loss: 0.32235  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 16729 -- Train Loss: 0.32040  Validation Loss: 0.43346\n",
      "t: 10 EPOCH 16730 -- Train Loss: 0.32237  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 16731 -- Train Loss: 0.31994  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 16732 -- Train Loss: 0.32148  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 16733 -- Train Loss: 0.32113  Validation Loss: 0.43397\n",
      "t: 10 EPOCH 16734 -- Train Loss: 0.32138  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 16735 -- Train Loss: 0.32127  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 16736 -- Train Loss: 0.32163  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 16737 -- Train Loss: 0.32191  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 16738 -- Train Loss: 0.32209  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 16739 -- Train Loss: 0.32099  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 16740 -- Train Loss: 0.32175  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 16741 -- Train Loss: 0.32162  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 16742 -- Train Loss: 0.32207  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 16743 -- Train Loss: 0.32113  Validation Loss: 0.43641\n",
      "t: 10 EPOCH 16744 -- Train Loss: 0.32165  Validation Loss: 0.43767\n",
      "t: 10 EPOCH 16745 -- Train Loss: 0.32174  Validation Loss: 0.43655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16746 -- Train Loss: 0.32136  Validation Loss: 0.43368\n",
      "t: 10 EPOCH 16747 -- Train Loss: 0.32085  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16748 -- Train Loss: 0.32178  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 16749 -- Train Loss: 0.32166  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 16750 -- Train Loss: 0.32165  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 16751 -- Train Loss: 0.32192  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 16752 -- Train Loss: 0.32196  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 16753 -- Train Loss: 0.32091  Validation Loss: 0.43662\n",
      "t: 10 EPOCH 16754 -- Train Loss: 0.32144  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 16755 -- Train Loss: 0.32128  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 16756 -- Train Loss: 0.32203  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 16757 -- Train Loss: 0.32159  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 16758 -- Train Loss: 0.32187  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 16759 -- Train Loss: 0.32115  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 16760 -- Train Loss: 0.32170  Validation Loss: 0.43731\n",
      "t: 10 EPOCH 16761 -- Train Loss: 0.32206  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 16762 -- Train Loss: 0.32199  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 16763 -- Train Loss: 0.32154  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 16764 -- Train Loss: 0.32250  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 16765 -- Train Loss: 0.32169  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 16766 -- Train Loss: 0.32168  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16767 -- Train Loss: 0.32182  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 16768 -- Train Loss: 0.32092  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16769 -- Train Loss: 0.32110  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16770 -- Train Loss: 0.32170  Validation Loss: 0.43349\n",
      "t: 10 EPOCH 16771 -- Train Loss: 0.32151  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 16772 -- Train Loss: 0.32152  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 16773 -- Train Loss: 0.32165  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16774 -- Train Loss: 0.32122  Validation Loss: 0.43687\n",
      "t: 10 EPOCH 16775 -- Train Loss: 0.32080  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16776 -- Train Loss: 0.32209  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 16777 -- Train Loss: 0.32169  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 16778 -- Train Loss: 0.32245  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 16779 -- Train Loss: 0.32037  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 16780 -- Train Loss: 0.32160  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 16781 -- Train Loss: 0.32151  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 16782 -- Train Loss: 0.32207  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 16783 -- Train Loss: 0.32180  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 16784 -- Train Loss: 0.32172  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16785 -- Train Loss: 0.32119  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 16786 -- Train Loss: 0.32166  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 16787 -- Train Loss: 0.32145  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 16788 -- Train Loss: 0.32225  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 16789 -- Train Loss: 0.32179  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 16790 -- Train Loss: 0.32171  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 16791 -- Train Loss: 0.32116  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 16792 -- Train Loss: 0.32231  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 16793 -- Train Loss: 0.32053  Validation Loss: 0.43706\n",
      "t: 10 EPOCH 16794 -- Train Loss: 0.32243  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 16795 -- Train Loss: 0.32221  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 16796 -- Train Loss: 0.32146  Validation Loss: 0.43350\n",
      "t: 10 EPOCH 16797 -- Train Loss: 0.32042  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 16798 -- Train Loss: 0.32143  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 16799 -- Train Loss: 0.32124  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 16800 -- Train Loss: 0.32209  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 16801 -- Train Loss: 0.32122  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 16802 -- Train Loss: 0.32067  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 16803 -- Train Loss: 0.32110  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 16804 -- Train Loss: 0.32063  Validation Loss: 0.43614\n",
      "t: 10 EPOCH 16805 -- Train Loss: 0.32248  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 16806 -- Train Loss: 0.32137  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 16807 -- Train Loss: 0.32248  Validation Loss: 0.43381\n",
      "t: 10 EPOCH 16808 -- Train Loss: 0.32169  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 16809 -- Train Loss: 0.32185  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 16810 -- Train Loss: 0.32156  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 16811 -- Train Loss: 0.32181  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 16812 -- Train Loss: 0.32205  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 16813 -- Train Loss: 0.32205  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 16814 -- Train Loss: 0.32235  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 16815 -- Train Loss: 0.32204  Validation Loss: 0.43422\n",
      "t: 10 EPOCH 16816 -- Train Loss: 0.32045  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 16817 -- Train Loss: 0.32118  Validation Loss: 0.43421\n",
      "t: 10 EPOCH 16818 -- Train Loss: 0.32138  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 16819 -- Train Loss: 0.32161  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 16820 -- Train Loss: 0.32158  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 16821 -- Train Loss: 0.32067  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 16822 -- Train Loss: 0.32049  Validation Loss: 0.43411\n",
      "t: 10 EPOCH 16823 -- Train Loss: 0.32157  Validation Loss: 0.43722\n",
      "t: 10 EPOCH 16824 -- Train Loss: 0.32197  Validation Loss: 0.43749\n",
      "t: 10 EPOCH 16825 -- Train Loss: 0.32155  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 16826 -- Train Loss: 0.32123  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 16827 -- Train Loss: 0.32198  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 16828 -- Train Loss: 0.32128  Validation Loss: 0.43679\n",
      "t: 10 EPOCH 16829 -- Train Loss: 0.32136  Validation Loss: 0.43406\n",
      "t: 10 EPOCH 16830 -- Train Loss: 0.32174  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 16831 -- Train Loss: 0.32162  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 16832 -- Train Loss: 0.32185  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 16833 -- Train Loss: 0.32158  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 16834 -- Train Loss: 0.32211  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 16835 -- Train Loss: 0.32193  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 16836 -- Train Loss: 0.32059  Validation Loss: 0.43441\n",
      "t: 10 EPOCH 16837 -- Train Loss: 0.32160  Validation Loss: 0.43738\n",
      "t: 10 EPOCH 16838 -- Train Loss: 0.32114  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 16839 -- Train Loss: 0.32077  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 16840 -- Train Loss: 0.32144  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16841 -- Train Loss: 0.32211  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 16842 -- Train Loss: 0.32179  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 16843 -- Train Loss: 0.32133  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 16844 -- Train Loss: 0.32174  Validation Loss: 0.43699\n",
      "t: 10 EPOCH 16845 -- Train Loss: 0.32121  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 16846 -- Train Loss: 0.32052  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 16847 -- Train Loss: 0.32214  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 16848 -- Train Loss: 0.32201  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 16849 -- Train Loss: 0.32143  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 16850 -- Train Loss: 0.32236  Validation Loss: 0.43402\n",
      "t: 10 EPOCH 16851 -- Train Loss: 0.32104  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 16852 -- Train Loss: 0.32167  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 16853 -- Train Loss: 0.32097  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 16854 -- Train Loss: 0.32140  Validation Loss: 0.43641\n",
      "t: 10 EPOCH 16855 -- Train Loss: 0.32193  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 16856 -- Train Loss: 0.32132  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 16857 -- Train Loss: 0.32051  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 16858 -- Train Loss: 0.32172  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 16859 -- Train Loss: 0.32164  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 16860 -- Train Loss: 0.32193  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 16861 -- Train Loss: 0.32066  Validation Loss: 0.43737\n",
      "t: 10 EPOCH 16862 -- Train Loss: 0.32252  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 16863 -- Train Loss: 0.32156  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 16864 -- Train Loss: 0.32195  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16865 -- Train Loss: 0.32123  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 16866 -- Train Loss: 0.32224  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 16867 -- Train Loss: 0.32155  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 16868 -- Train Loss: 0.32222  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 16869 -- Train Loss: 0.32130  Validation Loss: 0.43693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16870 -- Train Loss: 0.32152  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 16871 -- Train Loss: 0.32088  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 16872 -- Train Loss: 0.32124  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 16873 -- Train Loss: 0.32180  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 16874 -- Train Loss: 0.32281  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 16875 -- Train Loss: 0.32113  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 16876 -- Train Loss: 0.32251  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 16877 -- Train Loss: 0.32181  Validation Loss: 0.43747\n",
      "t: 10 EPOCH 16878 -- Train Loss: 0.32080  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 16879 -- Train Loss: 0.32105  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 16880 -- Train Loss: 0.32132  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 16881 -- Train Loss: 0.32081  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 16882 -- Train Loss: 0.32207  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 16883 -- Train Loss: 0.32116  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16884 -- Train Loss: 0.32169  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 16885 -- Train Loss: 0.32161  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16886 -- Train Loss: 0.32199  Validation Loss: 0.43517\n",
      "t: 10 EPOCH 16887 -- Train Loss: 0.32141  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 16888 -- Train Loss: 0.32142  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 16889 -- Train Loss: 0.32132  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 16890 -- Train Loss: 0.32131  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 16891 -- Train Loss: 0.32178  Validation Loss: 0.43713\n",
      "t: 10 EPOCH 16892 -- Train Loss: 0.32138  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 16893 -- Train Loss: 0.32103  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 16894 -- Train Loss: 0.32092  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16895 -- Train Loss: 0.32107  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 16896 -- Train Loss: 0.32165  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 16897 -- Train Loss: 0.32175  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 16898 -- Train Loss: 0.32126  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 16899 -- Train Loss: 0.32184  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 16900 -- Train Loss: 0.32219  Validation Loss: 0.43757\n",
      "t: 10 EPOCH 16901 -- Train Loss: 0.32147  Validation Loss: 0.43686\n",
      "t: 10 EPOCH 16902 -- Train Loss: 0.32101  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 16903 -- Train Loss: 0.32124  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 16904 -- Train Loss: 0.32187  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 16905 -- Train Loss: 0.32152  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 16906 -- Train Loss: 0.32147  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 16907 -- Train Loss: 0.32115  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 16908 -- Train Loss: 0.32160  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 16909 -- Train Loss: 0.32090  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 16910 -- Train Loss: 0.32122  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 16911 -- Train Loss: 0.32141  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 16912 -- Train Loss: 0.32008  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 16913 -- Train Loss: 0.32173  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 16914 -- Train Loss: 0.32049  Validation Loss: 0.43734\n",
      "t: 10 EPOCH 16915 -- Train Loss: 0.32193  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 16916 -- Train Loss: 0.32104  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 16917 -- Train Loss: 0.32166  Validation Loss: 0.43442\n",
      "t: 10 EPOCH 16918 -- Train Loss: 0.32078  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 16919 -- Train Loss: 0.32145  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 16920 -- Train Loss: 0.32156  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 16921 -- Train Loss: 0.32057  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 16922 -- Train Loss: 0.32074  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 16923 -- Train Loss: 0.32146  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 16924 -- Train Loss: 0.32152  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 16925 -- Train Loss: 0.32165  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 16926 -- Train Loss: 0.32132  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 16927 -- Train Loss: 0.32076  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 16928 -- Train Loss: 0.32082  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 16929 -- Train Loss: 0.32104  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 16930 -- Train Loss: 0.32050  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 16931 -- Train Loss: 0.32046  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 16932 -- Train Loss: 0.32114  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 16933 -- Train Loss: 0.32093  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 16934 -- Train Loss: 0.32045  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16935 -- Train Loss: 0.31982  Validation Loss: 0.43705\n",
      "t: 10 EPOCH 16936 -- Train Loss: 0.32118  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 16937 -- Train Loss: 0.32221  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 16938 -- Train Loss: 0.32121  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 16939 -- Train Loss: 0.32118  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 16940 -- Train Loss: 0.32102  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 16941 -- Train Loss: 0.32109  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 16942 -- Train Loss: 0.32100  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 16943 -- Train Loss: 0.32222  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 16944 -- Train Loss: 0.32122  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 16945 -- Train Loss: 0.32189  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 16946 -- Train Loss: 0.32174  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 16947 -- Train Loss: 0.32106  Validation Loss: 0.43699\n",
      "t: 10 EPOCH 16948 -- Train Loss: 0.32096  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 16949 -- Train Loss: 0.32079  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 16950 -- Train Loss: 0.32141  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 16951 -- Train Loss: 0.32196  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 16952 -- Train Loss: 0.32132  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 16953 -- Train Loss: 0.32137  Validation Loss: 0.43669\n",
      "t: 10 EPOCH 16954 -- Train Loss: 0.32065  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 16955 -- Train Loss: 0.32191  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 16956 -- Train Loss: 0.32140  Validation Loss: 0.43394\n",
      "t: 10 EPOCH 16957 -- Train Loss: 0.32082  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 16958 -- Train Loss: 0.32150  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 16959 -- Train Loss: 0.32241  Validation Loss: 0.43675\n",
      "t: 10 EPOCH 16960 -- Train Loss: 0.32148  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 16961 -- Train Loss: 0.32126  Validation Loss: 0.43625\n",
      "t: 10 EPOCH 16962 -- Train Loss: 0.32132  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 16963 -- Train Loss: 0.32153  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 16964 -- Train Loss: 0.32184  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 16965 -- Train Loss: 0.32196  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 16966 -- Train Loss: 0.32078  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 16967 -- Train Loss: 0.32155  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 16968 -- Train Loss: 0.32126  Validation Loss: 0.43437\n",
      "t: 10 EPOCH 16969 -- Train Loss: 0.32098  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 16970 -- Train Loss: 0.32172  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 16971 -- Train Loss: 0.32151  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 16972 -- Train Loss: 0.32156  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 16973 -- Train Loss: 0.32139  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 16974 -- Train Loss: 0.32087  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 16975 -- Train Loss: 0.32027  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 16976 -- Train Loss: 0.32097  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 16977 -- Train Loss: 0.32063  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 16978 -- Train Loss: 0.32177  Validation Loss: 0.43682\n",
      "t: 10 EPOCH 16979 -- Train Loss: 0.32178  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 16980 -- Train Loss: 0.32142  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 16981 -- Train Loss: 0.32125  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 16982 -- Train Loss: 0.32191  Validation Loss: 0.43458\n",
      "t: 10 EPOCH 16983 -- Train Loss: 0.32100  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 16984 -- Train Loss: 0.32168  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 16985 -- Train Loss: 0.32051  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 16986 -- Train Loss: 0.32152  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 16987 -- Train Loss: 0.32054  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 16988 -- Train Loss: 0.32103  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 16989 -- Train Loss: 0.32114  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 16990 -- Train Loss: 0.32194  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 16991 -- Train Loss: 0.32058  Validation Loss: 0.43452\n",
      "t: 10 EPOCH 16992 -- Train Loss: 0.32178  Validation Loss: 0.43790\n",
      "t: 10 EPOCH 16993 -- Train Loss: 0.32142  Validation Loss: 0.43553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 16994 -- Train Loss: 0.32148  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 16995 -- Train Loss: 0.32169  Validation Loss: 0.43378\n",
      "t: 10 EPOCH 16996 -- Train Loss: 0.32136  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 16997 -- Train Loss: 0.32148  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 16998 -- Train Loss: 0.32115  Validation Loss: 0.43774\n",
      "t: 10 EPOCH 16999 -- Train Loss: 0.32102  Validation Loss: 0.43373\n",
      "t: 10 EPOCH 17000 -- Train Loss: 0.32083  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 17001 -- Train Loss: 0.32155  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 17002 -- Train Loss: 0.32140  Validation Loss: 0.43435\n",
      "t: 10 EPOCH 17003 -- Train Loss: 0.32119  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 17004 -- Train Loss: 0.32074  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 17005 -- Train Loss: 0.32092  Validation Loss: 0.43641\n",
      "t: 10 EPOCH 17006 -- Train Loss: 0.32196  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 17007 -- Train Loss: 0.32138  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 17008 -- Train Loss: 0.32147  Validation Loss: 0.43472\n",
      "t: 10 EPOCH 17009 -- Train Loss: 0.32166  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 17010 -- Train Loss: 0.32158  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 17011 -- Train Loss: 0.32137  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 17012 -- Train Loss: 0.32142  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 17013 -- Train Loss: 0.32061  Validation Loss: 0.43550\n",
      "t: 10 EPOCH 17014 -- Train Loss: 0.32077  Validation Loss: 0.43782\n",
      "t: 10 EPOCH 17015 -- Train Loss: 0.32061  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 17016 -- Train Loss: 0.32150  Validation Loss: 0.43487\n",
      "t: 10 EPOCH 17017 -- Train Loss: 0.32184  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 17018 -- Train Loss: 0.32119  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 17019 -- Train Loss: 0.32211  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 17020 -- Train Loss: 0.32085  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 17021 -- Train Loss: 0.32094  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 17022 -- Train Loss: 0.32074  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17023 -- Train Loss: 0.32084  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 17024 -- Train Loss: 0.32074  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17025 -- Train Loss: 0.32097  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 17026 -- Train Loss: 0.32105  Validation Loss: 0.43652\n",
      "t: 10 EPOCH 17027 -- Train Loss: 0.32130  Validation Loss: 0.43621\n",
      "t: 10 EPOCH 17028 -- Train Loss: 0.32062  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 17029 -- Train Loss: 0.32144  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17030 -- Train Loss: 0.32005  Validation Loss: 0.43459\n",
      "t: 10 EPOCH 17031 -- Train Loss: 0.32090  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 17032 -- Train Loss: 0.32204  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 17033 -- Train Loss: 0.32057  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17034 -- Train Loss: 0.32224  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 17035 -- Train Loss: 0.32075  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 17036 -- Train Loss: 0.32164  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 17037 -- Train Loss: 0.32097  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 17038 -- Train Loss: 0.32259  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17039 -- Train Loss: 0.32083  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 17040 -- Train Loss: 0.31995  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 17041 -- Train Loss: 0.32099  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 17042 -- Train Loss: 0.32115  Validation Loss: 0.43616\n",
      "t: 10 EPOCH 17043 -- Train Loss: 0.32096  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 17044 -- Train Loss: 0.32082  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 17045 -- Train Loss: 0.32085  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 17046 -- Train Loss: 0.32164  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 17047 -- Train Loss: 0.32153  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 17048 -- Train Loss: 0.32217  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 17049 -- Train Loss: 0.32199  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 17050 -- Train Loss: 0.32101  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 17051 -- Train Loss: 0.32178  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 17052 -- Train Loss: 0.32132  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 17053 -- Train Loss: 0.32160  Validation Loss: 0.43733\n",
      "t: 10 EPOCH 17054 -- Train Loss: 0.32202  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 17055 -- Train Loss: 0.32222  Validation Loss: 0.43731\n",
      "t: 10 EPOCH 17056 -- Train Loss: 0.32122  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 17057 -- Train Loss: 0.32113  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 17058 -- Train Loss: 0.32142  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 17059 -- Train Loss: 0.32125  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 17060 -- Train Loss: 0.32206  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 17061 -- Train Loss: 0.32124  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 17062 -- Train Loss: 0.32157  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 17063 -- Train Loss: 0.32093  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 17064 -- Train Loss: 0.32200  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 17065 -- Train Loss: 0.32135  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 17066 -- Train Loss: 0.32166  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 17067 -- Train Loss: 0.32089  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 17068 -- Train Loss: 0.32229  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 17069 -- Train Loss: 0.32096  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 17070 -- Train Loss: 0.32136  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 17071 -- Train Loss: 0.32117  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 17072 -- Train Loss: 0.32153  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 17073 -- Train Loss: 0.32127  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 17074 -- Train Loss: 0.32143  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 17075 -- Train Loss: 0.32147  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 17076 -- Train Loss: 0.32137  Validation Loss: 0.43362\n",
      "t: 10 EPOCH 17077 -- Train Loss: 0.32160  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 17078 -- Train Loss: 0.32152  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 17079 -- Train Loss: 0.32094  Validation Loss: 0.43650\n",
      "t: 10 EPOCH 17080 -- Train Loss: 0.32163  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 17081 -- Train Loss: 0.32151  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 17082 -- Train Loss: 0.32135  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 17083 -- Train Loss: 0.32112  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 17084 -- Train Loss: 0.32109  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 17085 -- Train Loss: 0.32137  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 17086 -- Train Loss: 0.32196  Validation Loss: 0.43650\n",
      "t: 10 EPOCH 17087 -- Train Loss: 0.32111  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 17088 -- Train Loss: 0.32146  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 17089 -- Train Loss: 0.32145  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 17090 -- Train Loss: 0.32181  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 17091 -- Train Loss: 0.32198  Validation Loss: 0.43725\n",
      "t: 10 EPOCH 17092 -- Train Loss: 0.32157  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 17093 -- Train Loss: 0.32133  Validation Loss: 0.43664\n",
      "t: 10 EPOCH 17094 -- Train Loss: 0.32027  Validation Loss: 0.43679\n",
      "t: 10 EPOCH 17095 -- Train Loss: 0.32068  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 17096 -- Train Loss: 0.32052  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 17097 -- Train Loss: 0.32208  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 17098 -- Train Loss: 0.32214  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 17099 -- Train Loss: 0.32107  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 17100 -- Train Loss: 0.32015  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 17101 -- Train Loss: 0.32163  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 17102 -- Train Loss: 0.32128  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17103 -- Train Loss: 0.32016  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 17104 -- Train Loss: 0.32170  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 17105 -- Train Loss: 0.32108  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 17106 -- Train Loss: 0.32187  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 17107 -- Train Loss: 0.32086  Validation Loss: 0.43686\n",
      "t: 10 EPOCH 17108 -- Train Loss: 0.32217  Validation Loss: 0.43721\n",
      "t: 10 EPOCH 17109 -- Train Loss: 0.32086  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 17110 -- Train Loss: 0.32251  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 17111 -- Train Loss: 0.32165  Validation Loss: 0.43432\n",
      "t: 10 EPOCH 17112 -- Train Loss: 0.32201  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 17113 -- Train Loss: 0.32175  Validation Loss: 0.43738\n",
      "t: 10 EPOCH 17114 -- Train Loss: 0.32154  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 17115 -- Train Loss: 0.32145  Validation Loss: 0.43664\n",
      "t: 10 EPOCH 17116 -- Train Loss: 0.32146  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17117 -- Train Loss: 0.32155  Validation Loss: 0.43443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 17118 -- Train Loss: 0.32129  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 17119 -- Train Loss: 0.32229  Validation Loss: 0.43652\n",
      "t: 10 EPOCH 17120 -- Train Loss: 0.32152  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 17121 -- Train Loss: 0.32208  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 17122 -- Train Loss: 0.32092  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 17123 -- Train Loss: 0.32138  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 17124 -- Train Loss: 0.32023  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 17125 -- Train Loss: 0.32312  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 17126 -- Train Loss: 0.32128  Validation Loss: 0.43428\n",
      "t: 10 EPOCH 17127 -- Train Loss: 0.32108  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 17128 -- Train Loss: 0.32118  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 17129 -- Train Loss: 0.32170  Validation Loss: 0.43668\n",
      "t: 10 EPOCH 17130 -- Train Loss: 0.32051  Validation Loss: 0.43783\n",
      "t: 10 EPOCH 17131 -- Train Loss: 0.32267  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 17132 -- Train Loss: 0.32156  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 17133 -- Train Loss: 0.32154  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 17134 -- Train Loss: 0.32128  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 17135 -- Train Loss: 0.32190  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 17136 -- Train Loss: 0.32025  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 17137 -- Train Loss: 0.32142  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 17138 -- Train Loss: 0.32052  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 17139 -- Train Loss: 0.32221  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 17140 -- Train Loss: 0.32189  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 17141 -- Train Loss: 0.32098  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17142 -- Train Loss: 0.32040  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17143 -- Train Loss: 0.32173  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 17144 -- Train Loss: 0.32111  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 17145 -- Train Loss: 0.32260  Validation Loss: 0.43681\n",
      "t: 10 EPOCH 17146 -- Train Loss: 0.32076  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 17147 -- Train Loss: 0.32212  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 17148 -- Train Loss: 0.32171  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17149 -- Train Loss: 0.32203  Validation Loss: 0.43714\n",
      "t: 10 EPOCH 17150 -- Train Loss: 0.32072  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 17151 -- Train Loss: 0.32129  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 17152 -- Train Loss: 0.32210  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 17153 -- Train Loss: 0.32133  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 17154 -- Train Loss: 0.32192  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 17155 -- Train Loss: 0.32130  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 17156 -- Train Loss: 0.32183  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 17157 -- Train Loss: 0.32143  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 17158 -- Train Loss: 0.32092  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 17159 -- Train Loss: 0.32101  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 17160 -- Train Loss: 0.32154  Validation Loss: 0.43742\n",
      "t: 10 EPOCH 17161 -- Train Loss: 0.32144  Validation Loss: 0.43621\n",
      "t: 10 EPOCH 17162 -- Train Loss: 0.32124  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 17163 -- Train Loss: 0.32175  Validation Loss: 0.43544\n",
      "t: 10 EPOCH 17164 -- Train Loss: 0.32233  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 17165 -- Train Loss: 0.32200  Validation Loss: 0.43678\n",
      "t: 10 EPOCH 17166 -- Train Loss: 0.32202  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17167 -- Train Loss: 0.32145  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 17168 -- Train Loss: 0.32101  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 17169 -- Train Loss: 0.31995  Validation Loss: 0.43398\n",
      "t: 10 EPOCH 17170 -- Train Loss: 0.32210  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 17171 -- Train Loss: 0.32058  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 17172 -- Train Loss: 0.32113  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 17173 -- Train Loss: 0.32064  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 17174 -- Train Loss: 0.32213  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 17175 -- Train Loss: 0.32099  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 17176 -- Train Loss: 0.32100  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 17177 -- Train Loss: 0.32102  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 17178 -- Train Loss: 0.32216  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 17179 -- Train Loss: 0.32138  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 17180 -- Train Loss: 0.32140  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 17181 -- Train Loss: 0.32082  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 17182 -- Train Loss: 0.32157  Validation Loss: 0.43713\n",
      "t: 10 EPOCH 17183 -- Train Loss: 0.32144  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 17184 -- Train Loss: 0.32104  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 17185 -- Train Loss: 0.32194  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 17186 -- Train Loss: 0.32032  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 17187 -- Train Loss: 0.32201  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 17188 -- Train Loss: 0.32085  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 17189 -- Train Loss: 0.32090  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17190 -- Train Loss: 0.31995  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 17191 -- Train Loss: 0.32011  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 17192 -- Train Loss: 0.32130  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 17193 -- Train Loss: 0.32070  Validation Loss: 0.43478\n",
      "t: 10 EPOCH 17194 -- Train Loss: 0.32099  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 17195 -- Train Loss: 0.32059  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17196 -- Train Loss: 0.32150  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 17197 -- Train Loss: 0.32140  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 17198 -- Train Loss: 0.32089  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 17199 -- Train Loss: 0.32016  Validation Loss: 0.43446\n",
      "t: 10 EPOCH 17200 -- Train Loss: 0.32074  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 17201 -- Train Loss: 0.32159  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 17202 -- Train Loss: 0.32104  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 17203 -- Train Loss: 0.32117  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17204 -- Train Loss: 0.32165  Validation Loss: 0.43758\n",
      "t: 10 EPOCH 17205 -- Train Loss: 0.32048  Validation Loss: 0.43652\n",
      "t: 10 EPOCH 17206 -- Train Loss: 0.32185  Validation Loss: 0.43403\n",
      "t: 10 EPOCH 17207 -- Train Loss: 0.32090  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 17208 -- Train Loss: 0.32124  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 17209 -- Train Loss: 0.32185  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 17210 -- Train Loss: 0.32112  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 17211 -- Train Loss: 0.32102  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 17212 -- Train Loss: 0.32134  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 17213 -- Train Loss: 0.32091  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 17214 -- Train Loss: 0.32214  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 17215 -- Train Loss: 0.32102  Validation Loss: 0.43416\n",
      "t: 10 EPOCH 17216 -- Train Loss: 0.32106  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 17217 -- Train Loss: 0.31984  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 17218 -- Train Loss: 0.32044  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 17219 -- Train Loss: 0.32072  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 17220 -- Train Loss: 0.32138  Validation Loss: 0.43641\n",
      "t: 10 EPOCH 17221 -- Train Loss: 0.32098  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 17222 -- Train Loss: 0.32223  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 17223 -- Train Loss: 0.31987  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 17224 -- Train Loss: 0.32083  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17225 -- Train Loss: 0.32061  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 17226 -- Train Loss: 0.32179  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 17227 -- Train Loss: 0.32104  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 17228 -- Train Loss: 0.32113  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17229 -- Train Loss: 0.32053  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17230 -- Train Loss: 0.32176  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 17231 -- Train Loss: 0.32064  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 17232 -- Train Loss: 0.32058  Validation Loss: 0.43427\n",
      "t: 10 EPOCH 17233 -- Train Loss: 0.32032  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 17234 -- Train Loss: 0.32099  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17235 -- Train Loss: 0.32176  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 17236 -- Train Loss: 0.32110  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 17237 -- Train Loss: 0.32139  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 17238 -- Train Loss: 0.32084  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 17239 -- Train Loss: 0.32120  Validation Loss: 0.43695\n",
      "t: 10 EPOCH 17240 -- Train Loss: 0.32129  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 17241 -- Train Loss: 0.32071  Validation Loss: 0.43599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 17242 -- Train Loss: 0.32123  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 17243 -- Train Loss: 0.32105  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 17244 -- Train Loss: 0.32081  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 17245 -- Train Loss: 0.32081  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 17246 -- Train Loss: 0.32134  Validation Loss: 0.43611\n",
      "t: 10 EPOCH 17247 -- Train Loss: 0.32087  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 17248 -- Train Loss: 0.32088  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 17249 -- Train Loss: 0.32117  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 17250 -- Train Loss: 0.32137  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 17251 -- Train Loss: 0.32175  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 17252 -- Train Loss: 0.32133  Validation Loss: 0.43455\n",
      "t: 10 EPOCH 17253 -- Train Loss: 0.32112  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 17254 -- Train Loss: 0.32073  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 17255 -- Train Loss: 0.32115  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 17256 -- Train Loss: 0.32037  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 17257 -- Train Loss: 0.32136  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 17258 -- Train Loss: 0.32033  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 17259 -- Train Loss: 0.32130  Validation Loss: 0.43710\n",
      "t: 10 EPOCH 17260 -- Train Loss: 0.32017  Validation Loss: 0.43529\n",
      "t: 10 EPOCH 17261 -- Train Loss: 0.32171  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17262 -- Train Loss: 0.32158  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 17263 -- Train Loss: 0.32052  Validation Loss: 0.43757\n",
      "t: 10 EPOCH 17264 -- Train Loss: 0.32118  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 17265 -- Train Loss: 0.32108  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 17266 -- Train Loss: 0.32107  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 17267 -- Train Loss: 0.32051  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 17268 -- Train Loss: 0.32121  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 17269 -- Train Loss: 0.32142  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 17270 -- Train Loss: 0.32164  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 17271 -- Train Loss: 0.32072  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17272 -- Train Loss: 0.32050  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17273 -- Train Loss: 0.32077  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 17274 -- Train Loss: 0.32160  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 17275 -- Train Loss: 0.32107  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 17276 -- Train Loss: 0.32184  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 17277 -- Train Loss: 0.32161  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 17278 -- Train Loss: 0.32096  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 17279 -- Train Loss: 0.32100  Validation Loss: 0.43713\n",
      "t: 10 EPOCH 17280 -- Train Loss: 0.32194  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 17281 -- Train Loss: 0.32023  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 17282 -- Train Loss: 0.32172  Validation Loss: 0.43573\n",
      "t: 10 EPOCH 17283 -- Train Loss: 0.32117  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 17284 -- Train Loss: 0.32210  Validation Loss: 0.43796\n",
      "t: 10 EPOCH 17285 -- Train Loss: 0.32057  Validation Loss: 0.43521\n",
      "t: 10 EPOCH 17286 -- Train Loss: 0.32104  Validation Loss: 0.43371\n",
      "t: 10 EPOCH 17287 -- Train Loss: 0.32170  Validation Loss: 0.43436\n",
      "t: 10 EPOCH 17288 -- Train Loss: 0.32148  Validation Loss: 0.43729\n",
      "t: 10 EPOCH 17289 -- Train Loss: 0.32143  Validation Loss: 0.43628\n",
      "t: 10 EPOCH 17290 -- Train Loss: 0.32123  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 17291 -- Train Loss: 0.32135  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 17292 -- Train Loss: 0.32115  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 17293 -- Train Loss: 0.32054  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 17294 -- Train Loss: 0.32151  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 17295 -- Train Loss: 0.32152  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 17296 -- Train Loss: 0.32163  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17297 -- Train Loss: 0.32165  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 17298 -- Train Loss: 0.32115  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17299 -- Train Loss: 0.32085  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17300 -- Train Loss: 0.32099  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 17301 -- Train Loss: 0.32196  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 17302 -- Train Loss: 0.32106  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 17303 -- Train Loss: 0.32186  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 17304 -- Train Loss: 0.32138  Validation Loss: 0.43726\n",
      "t: 10 EPOCH 17305 -- Train Loss: 0.32167  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 17306 -- Train Loss: 0.31998  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 17307 -- Train Loss: 0.32116  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 17308 -- Train Loss: 0.32078  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 17309 -- Train Loss: 0.32149  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 17310 -- Train Loss: 0.32154  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 17311 -- Train Loss: 0.32119  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 17312 -- Train Loss: 0.32014  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 17313 -- Train Loss: 0.32102  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 17314 -- Train Loss: 0.32117  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 17315 -- Train Loss: 0.32187  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 17316 -- Train Loss: 0.32072  Validation Loss: 0.43498\n",
      "t: 10 EPOCH 17317 -- Train Loss: 0.32069  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 17318 -- Train Loss: 0.32054  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 17319 -- Train Loss: 0.32020  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 17320 -- Train Loss: 0.31996  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 17321 -- Train Loss: 0.32030  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17322 -- Train Loss: 0.32164  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 17323 -- Train Loss: 0.31998  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 17324 -- Train Loss: 0.32050  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 17325 -- Train Loss: 0.32105  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 17326 -- Train Loss: 0.32096  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17327 -- Train Loss: 0.32047  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 17328 -- Train Loss: 0.32073  Validation Loss: 0.43634\n",
      "t: 10 EPOCH 17329 -- Train Loss: 0.32157  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 17330 -- Train Loss: 0.32176  Validation Loss: 0.43423\n",
      "t: 10 EPOCH 17331 -- Train Loss: 0.32116  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17332 -- Train Loss: 0.32072  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17333 -- Train Loss: 0.32065  Validation Loss: 0.43664\n",
      "t: 10 EPOCH 17334 -- Train Loss: 0.32142  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 17335 -- Train Loss: 0.32160  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 17336 -- Train Loss: 0.32082  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 17337 -- Train Loss: 0.32065  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 17338 -- Train Loss: 0.32081  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 17339 -- Train Loss: 0.32164  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 17340 -- Train Loss: 0.32018  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 17341 -- Train Loss: 0.32079  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 17342 -- Train Loss: 0.31919  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 17343 -- Train Loss: 0.32160  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 17344 -- Train Loss: 0.32070  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 17345 -- Train Loss: 0.32084  Validation Loss: 0.43511\n",
      "t: 10 EPOCH 17346 -- Train Loss: 0.32083  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 17347 -- Train Loss: 0.32165  Validation Loss: 0.43690\n",
      "t: 10 EPOCH 17348 -- Train Loss: 0.32109  Validation Loss: 0.43527\n",
      "t: 10 EPOCH 17349 -- Train Loss: 0.32042  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 17350 -- Train Loss: 0.32050  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 17351 -- Train Loss: 0.32094  Validation Loss: 0.43641\n",
      "t: 10 EPOCH 17352 -- Train Loss: 0.32068  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 17353 -- Train Loss: 0.32116  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 17354 -- Train Loss: 0.32080  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 17355 -- Train Loss: 0.32158  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 17356 -- Train Loss: 0.32104  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 17357 -- Train Loss: 0.32171  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17358 -- Train Loss: 0.32084  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 17359 -- Train Loss: 0.32107  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 17360 -- Train Loss: 0.32122  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 17361 -- Train Loss: 0.31999  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17362 -- Train Loss: 0.32166  Validation Loss: 0.43488\n",
      "t: 10 EPOCH 17363 -- Train Loss: 0.32159  Validation Loss: 0.43526\n",
      "t: 10 EPOCH 17364 -- Train Loss: 0.32113  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 17365 -- Train Loss: 0.32128  Validation Loss: 0.43549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 17366 -- Train Loss: 0.32117  Validation Loss: 0.43533\n",
      "t: 10 EPOCH 17367 -- Train Loss: 0.32118  Validation Loss: 0.43468\n",
      "t: 10 EPOCH 17368 -- Train Loss: 0.32215  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 17369 -- Train Loss: 0.32119  Validation Loss: 0.43515\n",
      "t: 10 EPOCH 17370 -- Train Loss: 0.32234  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 17371 -- Train Loss: 0.32200  Validation Loss: 0.43361\n",
      "t: 10 EPOCH 17372 -- Train Loss: 0.32108  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17373 -- Train Loss: 0.32132  Validation Loss: 0.43747\n",
      "t: 10 EPOCH 17374 -- Train Loss: 0.32039  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 17375 -- Train Loss: 0.32119  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 17376 -- Train Loss: 0.32047  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 17377 -- Train Loss: 0.32163  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 17378 -- Train Loss: 0.32127  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 17379 -- Train Loss: 0.32134  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 17380 -- Train Loss: 0.32143  Validation Loss: 0.43633\n",
      "t: 10 EPOCH 17381 -- Train Loss: 0.32065  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 17382 -- Train Loss: 0.32198  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17383 -- Train Loss: 0.32143  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 17384 -- Train Loss: 0.32120  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 17385 -- Train Loss: 0.32056  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 17386 -- Train Loss: 0.32102  Validation Loss: 0.43704\n",
      "t: 10 EPOCH 17387 -- Train Loss: 0.32108  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17388 -- Train Loss: 0.32081  Validation Loss: 0.43465\n",
      "t: 10 EPOCH 17389 -- Train Loss: 0.32016  Validation Loss: 0.43627\n",
      "t: 10 EPOCH 17390 -- Train Loss: 0.32113  Validation Loss: 0.43676\n",
      "t: 10 EPOCH 17391 -- Train Loss: 0.32081  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 17392 -- Train Loss: 0.32211  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 17393 -- Train Loss: 0.32079  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 17394 -- Train Loss: 0.32128  Validation Loss: 0.43595\n",
      "t: 10 EPOCH 17395 -- Train Loss: 0.32172  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 17396 -- Train Loss: 0.32110  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 17397 -- Train Loss: 0.32190  Validation Loss: 0.43611\n",
      "t: 10 EPOCH 17398 -- Train Loss: 0.32083  Validation Loss: 0.43748\n",
      "t: 10 EPOCH 17399 -- Train Loss: 0.32091  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 17400 -- Train Loss: 0.32157  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 17401 -- Train Loss: 0.32046  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 17402 -- Train Loss: 0.32093  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 17403 -- Train Loss: 0.32006  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 17404 -- Train Loss: 0.32137  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 17405 -- Train Loss: 0.32070  Validation Loss: 0.43490\n",
      "t: 10 EPOCH 17406 -- Train Loss: 0.32185  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 17407 -- Train Loss: 0.32159  Validation Loss: 0.43528\n",
      "t: 10 EPOCH 17408 -- Train Loss: 0.32115  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 17409 -- Train Loss: 0.32136  Validation Loss: 0.43518\n",
      "t: 10 EPOCH 17410 -- Train Loss: 0.32127  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 17411 -- Train Loss: 0.32072  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 17412 -- Train Loss: 0.32091  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 17413 -- Train Loss: 0.32010  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 17414 -- Train Loss: 0.32120  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 17415 -- Train Loss: 0.32120  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 17416 -- Train Loss: 0.31985  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 17417 -- Train Loss: 0.32157  Validation Loss: 0.43499\n",
      "t: 10 EPOCH 17418 -- Train Loss: 0.32059  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 17419 -- Train Loss: 0.32116  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 17420 -- Train Loss: 0.32081  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 17421 -- Train Loss: 0.32153  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 17422 -- Train Loss: 0.32019  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 17423 -- Train Loss: 0.32087  Validation Loss: 0.43705\n",
      "t: 10 EPOCH 17424 -- Train Loss: 0.32087  Validation Loss: 0.43520\n",
      "t: 10 EPOCH 17425 -- Train Loss: 0.32162  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 17426 -- Train Loss: 0.32100  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 17427 -- Train Loss: 0.32068  Validation Loss: 0.43657\n",
      "t: 10 EPOCH 17428 -- Train Loss: 0.32115  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17429 -- Train Loss: 0.32011  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17430 -- Train Loss: 0.32081  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 17431 -- Train Loss: 0.32102  Validation Loss: 0.43675\n",
      "t: 10 EPOCH 17432 -- Train Loss: 0.32151  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 17433 -- Train Loss: 0.32017  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 17434 -- Train Loss: 0.32114  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 17435 -- Train Loss: 0.32117  Validation Loss: 0.43596\n",
      "t: 10 EPOCH 17436 -- Train Loss: 0.32112  Validation Loss: 0.43736\n",
      "t: 10 EPOCH 17437 -- Train Loss: 0.32010  Validation Loss: 0.43668\n",
      "t: 10 EPOCH 17438 -- Train Loss: 0.32088  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 17439 -- Train Loss: 0.31981  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 17440 -- Train Loss: 0.32105  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 17441 -- Train Loss: 0.32047  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 17442 -- Train Loss: 0.32089  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 17443 -- Train Loss: 0.32227  Validation Loss: 0.43650\n",
      "t: 10 EPOCH 17444 -- Train Loss: 0.32134  Validation Loss: 0.43666\n",
      "t: 10 EPOCH 17445 -- Train Loss: 0.32018  Validation Loss: 0.43675\n",
      "t: 10 EPOCH 17446 -- Train Loss: 0.32113  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 17447 -- Train Loss: 0.32081  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 17448 -- Train Loss: 0.32081  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 17449 -- Train Loss: 0.32043  Validation Loss: 0.43717\n",
      "t: 10 EPOCH 17450 -- Train Loss: 0.32049  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 17451 -- Train Loss: 0.32074  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 17452 -- Train Loss: 0.32127  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 17453 -- Train Loss: 0.32048  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 17454 -- Train Loss: 0.32048  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 17455 -- Train Loss: 0.32129  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17456 -- Train Loss: 0.32117  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 17457 -- Train Loss: 0.32031  Validation Loss: 0.43719\n",
      "t: 10 EPOCH 17458 -- Train Loss: 0.32056  Validation Loss: 0.43434\n",
      "t: 10 EPOCH 17459 -- Train Loss: 0.32131  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 17460 -- Train Loss: 0.32140  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 17461 -- Train Loss: 0.32111  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 17462 -- Train Loss: 0.32103  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 17463 -- Train Loss: 0.32052  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 17464 -- Train Loss: 0.32023  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17465 -- Train Loss: 0.32035  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 17466 -- Train Loss: 0.32184  Validation Loss: 0.43720\n",
      "t: 10 EPOCH 17467 -- Train Loss: 0.32133  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17468 -- Train Loss: 0.32035  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 17469 -- Train Loss: 0.32083  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 17470 -- Train Loss: 0.32093  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 17471 -- Train Loss: 0.32155  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 17472 -- Train Loss: 0.32142  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 17473 -- Train Loss: 0.32076  Validation Loss: 0.43659\n",
      "t: 10 EPOCH 17474 -- Train Loss: 0.32097  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 17475 -- Train Loss: 0.32076  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 17476 -- Train Loss: 0.32172  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 17477 -- Train Loss: 0.32146  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 17478 -- Train Loss: 0.32058  Validation Loss: 0.43755\n",
      "t: 10 EPOCH 17479 -- Train Loss: 0.32202  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 17480 -- Train Loss: 0.32108  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 17481 -- Train Loss: 0.32124  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 17482 -- Train Loss: 0.32080  Validation Loss: 0.43460\n",
      "t: 10 EPOCH 17483 -- Train Loss: 0.32156  Validation Loss: 0.43489\n",
      "t: 10 EPOCH 17484 -- Train Loss: 0.32077  Validation Loss: 0.43539\n",
      "t: 10 EPOCH 17485 -- Train Loss: 0.32157  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 17486 -- Train Loss: 0.32031  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 17487 -- Train Loss: 0.32114  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 17488 -- Train Loss: 0.32031  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 17489 -- Train Loss: 0.32148  Validation Loss: 0.43574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 17490 -- Train Loss: 0.32121  Validation Loss: 0.43677\n",
      "t: 10 EPOCH 17491 -- Train Loss: 0.32021  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 17492 -- Train Loss: 0.32197  Validation Loss: 0.43400\n",
      "t: 10 EPOCH 17493 -- Train Loss: 0.32087  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 17494 -- Train Loss: 0.32163  Validation Loss: 0.43675\n",
      "t: 10 EPOCH 17495 -- Train Loss: 0.32116  Validation Loss: 0.43508\n",
      "t: 10 EPOCH 17496 -- Train Loss: 0.32182  Validation Loss: 0.43426\n",
      "t: 10 EPOCH 17497 -- Train Loss: 0.32085  Validation Loss: 0.43747\n",
      "t: 10 EPOCH 17498 -- Train Loss: 0.32149  Validation Loss: 0.43581\n",
      "t: 10 EPOCH 17499 -- Train Loss: 0.32146  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 17500 -- Train Loss: 0.32200  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17501 -- Train Loss: 0.32150  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17502 -- Train Loss: 0.32089  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 17503 -- Train Loss: 0.32164  Validation Loss: 0.43683\n",
      "t: 10 EPOCH 17504 -- Train Loss: 0.32071  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 17505 -- Train Loss: 0.32141  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 17506 -- Train Loss: 0.32060  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17507 -- Train Loss: 0.32157  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 17508 -- Train Loss: 0.32177  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 17509 -- Train Loss: 0.32110  Validation Loss: 0.43551\n",
      "t: 10 EPOCH 17510 -- Train Loss: 0.32092  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 17511 -- Train Loss: 0.32109  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 17512 -- Train Loss: 0.32094  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 17513 -- Train Loss: 0.32229  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 17514 -- Train Loss: 0.32079  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 17515 -- Train Loss: 0.32111  Validation Loss: 0.43655\n",
      "t: 10 EPOCH 17516 -- Train Loss: 0.32172  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 17517 -- Train Loss: 0.32063  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 17518 -- Train Loss: 0.32150  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 17519 -- Train Loss: 0.32029  Validation Loss: 0.43530\n",
      "t: 10 EPOCH 17520 -- Train Loss: 0.32115  Validation Loss: 0.43707\n",
      "t: 10 EPOCH 17521 -- Train Loss: 0.32082  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 17522 -- Train Loss: 0.32141  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 17523 -- Train Loss: 0.32117  Validation Loss: 0.43450\n",
      "t: 10 EPOCH 17524 -- Train Loss: 0.32118  Validation Loss: 0.43696\n",
      "t: 10 EPOCH 17525 -- Train Loss: 0.32158  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17526 -- Train Loss: 0.32174  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 17527 -- Train Loss: 0.32033  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 17528 -- Train Loss: 0.32051  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 17529 -- Train Loss: 0.32131  Validation Loss: 0.43700\n",
      "t: 10 EPOCH 17530 -- Train Loss: 0.32077  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17531 -- Train Loss: 0.32079  Validation Loss: 0.43463\n",
      "t: 10 EPOCH 17532 -- Train Loss: 0.32147  Validation Loss: 0.43502\n",
      "t: 10 EPOCH 17533 -- Train Loss: 0.32125  Validation Loss: 0.43741\n",
      "t: 10 EPOCH 17534 -- Train Loss: 0.32087  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 17535 -- Train Loss: 0.32105  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17536 -- Train Loss: 0.32195  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 17537 -- Train Loss: 0.32060  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 17538 -- Train Loss: 0.32077  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 17539 -- Train Loss: 0.32122  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 17540 -- Train Loss: 0.32113  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 17541 -- Train Loss: 0.32095  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 17542 -- Train Loss: 0.32112  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17543 -- Train Loss: 0.31968  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 17544 -- Train Loss: 0.32080  Validation Loss: 0.43485\n",
      "t: 10 EPOCH 17545 -- Train Loss: 0.32078  Validation Loss: 0.43604\n",
      "t: 10 EPOCH 17546 -- Train Loss: 0.32122  Validation Loss: 0.43684\n",
      "t: 10 EPOCH 17547 -- Train Loss: 0.32100  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 17548 -- Train Loss: 0.32059  Validation Loss: 0.43537\n",
      "t: 10 EPOCH 17549 -- Train Loss: 0.32119  Validation Loss: 0.43640\n",
      "t: 10 EPOCH 17550 -- Train Loss: 0.32116  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 17551 -- Train Loss: 0.32108  Validation Loss: 0.43697\n",
      "t: 10 EPOCH 17552 -- Train Loss: 0.32084  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 17553 -- Train Loss: 0.32124  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 17554 -- Train Loss: 0.32069  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 17555 -- Train Loss: 0.32040  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 17556 -- Train Loss: 0.32172  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 17557 -- Train Loss: 0.32072  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 17558 -- Train Loss: 0.32151  Validation Loss: 0.43584\n",
      "t: 10 EPOCH 17559 -- Train Loss: 0.32143  Validation Loss: 0.43639\n",
      "t: 10 EPOCH 17560 -- Train Loss: 0.32129  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 17561 -- Train Loss: 0.32150  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 17562 -- Train Loss: 0.32032  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 17563 -- Train Loss: 0.32072  Validation Loss: 0.43721\n",
      "t: 10 EPOCH 17564 -- Train Loss: 0.32153  Validation Loss: 0.43454\n",
      "t: 10 EPOCH 17565 -- Train Loss: 0.32054  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 17566 -- Train Loss: 0.32181  Validation Loss: 0.43675\n",
      "t: 10 EPOCH 17567 -- Train Loss: 0.31993  Validation Loss: 0.43522\n",
      "t: 10 EPOCH 17568 -- Train Loss: 0.32024  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 17569 -- Train Loss: 0.32178  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 17570 -- Train Loss: 0.32104  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 17571 -- Train Loss: 0.32069  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 17572 -- Train Loss: 0.32056  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 17573 -- Train Loss: 0.32019  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 17574 -- Train Loss: 0.32083  Validation Loss: 0.43391\n",
      "t: 10 EPOCH 17575 -- Train Loss: 0.32064  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 17576 -- Train Loss: 0.32095  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 17577 -- Train Loss: 0.32061  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 17578 -- Train Loss: 0.32134  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 17579 -- Train Loss: 0.32030  Validation Loss: 0.43624\n",
      "t: 10 EPOCH 17580 -- Train Loss: 0.32050  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 17581 -- Train Loss: 0.32061  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 17582 -- Train Loss: 0.32145  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 17583 -- Train Loss: 0.32089  Validation Loss: 0.43672\n",
      "t: 10 EPOCH 17584 -- Train Loss: 0.32158  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17585 -- Train Loss: 0.32068  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 17586 -- Train Loss: 0.32100  Validation Loss: 0.43466\n",
      "t: 10 EPOCH 17587 -- Train Loss: 0.32058  Validation Loss: 0.43609\n",
      "t: 10 EPOCH 17588 -- Train Loss: 0.32155  Validation Loss: 0.43461\n",
      "t: 10 EPOCH 17589 -- Train Loss: 0.32150  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 17590 -- Train Loss: 0.32028  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 17591 -- Train Loss: 0.32122  Validation Loss: 0.43661\n",
      "t: 10 EPOCH 17592 -- Train Loss: 0.32069  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 17593 -- Train Loss: 0.32149  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 17594 -- Train Loss: 0.32073  Validation Loss: 0.43543\n",
      "t: 10 EPOCH 17595 -- Train Loss: 0.32069  Validation Loss: 0.43694\n",
      "t: 10 EPOCH 17596 -- Train Loss: 0.32086  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 17597 -- Train Loss: 0.32067  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 17598 -- Train Loss: 0.32155  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 17599 -- Train Loss: 0.32118  Validation Loss: 0.43592\n",
      "t: 10 EPOCH 17600 -- Train Loss: 0.32080  Validation Loss: 0.43424\n",
      "t: 10 EPOCH 17601 -- Train Loss: 0.32143  Validation Loss: 0.43583\n",
      "t: 10 EPOCH 17602 -- Train Loss: 0.32123  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 17603 -- Train Loss: 0.32138  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 17604 -- Train Loss: 0.32069  Validation Loss: 0.43493\n",
      "t: 10 EPOCH 17605 -- Train Loss: 0.32174  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 17606 -- Train Loss: 0.32209  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 17607 -- Train Loss: 0.32215  Validation Loss: 0.43541\n",
      "t: 10 EPOCH 17608 -- Train Loss: 0.32092  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 17609 -- Train Loss: 0.32189  Validation Loss: 0.43679\n",
      "t: 10 EPOCH 17610 -- Train Loss: 0.32108  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 17611 -- Train Loss: 0.32094  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 17612 -- Train Loss: 0.32070  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 17613 -- Train Loss: 0.32050  Validation Loss: 0.43500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 17614 -- Train Loss: 0.32085  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17615 -- Train Loss: 0.32189  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17616 -- Train Loss: 0.32126  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17617 -- Train Loss: 0.32125  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17618 -- Train Loss: 0.32197  Validation Loss: 0.43704\n",
      "t: 10 EPOCH 17619 -- Train Loss: 0.32088  Validation Loss: 0.43587\n",
      "t: 10 EPOCH 17620 -- Train Loss: 0.32118  Validation Loss: 0.43618\n",
      "t: 10 EPOCH 17621 -- Train Loss: 0.32047  Validation Loss: 0.43685\n",
      "t: 10 EPOCH 17622 -- Train Loss: 0.32105  Validation Loss: 0.43509\n",
      "t: 10 EPOCH 17623 -- Train Loss: 0.32147  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 17624 -- Train Loss: 0.32118  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 17625 -- Train Loss: 0.32064  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 17626 -- Train Loss: 0.32219  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 17627 -- Train Loss: 0.32106  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 17628 -- Train Loss: 0.32115  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 17629 -- Train Loss: 0.32115  Validation Loss: 0.43523\n",
      "t: 10 EPOCH 17630 -- Train Loss: 0.32244  Validation Loss: 0.43732\n",
      "t: 10 EPOCH 17631 -- Train Loss: 0.31986  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 17632 -- Train Loss: 0.32118  Validation Loss: 0.43731\n",
      "t: 10 EPOCH 17633 -- Train Loss: 0.32057  Validation Loss: 0.43610\n",
      "t: 10 EPOCH 17634 -- Train Loss: 0.32113  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 17635 -- Train Loss: 0.32183  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 17636 -- Train Loss: 0.32135  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 17637 -- Train Loss: 0.32178  Validation Loss: 0.43736\n",
      "t: 10 EPOCH 17638 -- Train Loss: 0.32145  Validation Loss: 0.43538\n",
      "t: 10 EPOCH 17639 -- Train Loss: 0.32098  Validation Loss: 0.43331\n",
      "t: 10 EPOCH 17640 -- Train Loss: 0.32019  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17641 -- Train Loss: 0.32075  Validation Loss: 0.43683\n",
      "t: 10 EPOCH 17642 -- Train Loss: 0.32119  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 17643 -- Train Loss: 0.32076  Validation Loss: 0.43745\n",
      "t: 10 EPOCH 17644 -- Train Loss: 0.32097  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17645 -- Train Loss: 0.32086  Validation Loss: 0.43726\n",
      "t: 10 EPOCH 17646 -- Train Loss: 0.32062  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17647 -- Train Loss: 0.32082  Validation Loss: 0.43483\n",
      "t: 10 EPOCH 17648 -- Train Loss: 0.32100  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17649 -- Train Loss: 0.32124  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 17650 -- Train Loss: 0.32037  Validation Loss: 0.43700\n",
      "t: 10 EPOCH 17651 -- Train Loss: 0.32105  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17652 -- Train Loss: 0.32098  Validation Loss: 0.43475\n",
      "t: 10 EPOCH 17653 -- Train Loss: 0.32188  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 17654 -- Train Loss: 0.32138  Validation Loss: 0.43752\n",
      "t: 10 EPOCH 17655 -- Train Loss: 0.32089  Validation Loss: 0.43413\n",
      "t: 10 EPOCH 17656 -- Train Loss: 0.32073  Validation Loss: 0.43678\n",
      "t: 10 EPOCH 17657 -- Train Loss: 0.32024  Validation Loss: 0.43496\n",
      "t: 10 EPOCH 17658 -- Train Loss: 0.32104  Validation Loss: 0.43824\n",
      "t: 10 EPOCH 17659 -- Train Loss: 0.32062  Validation Loss: 0.43665\n",
      "t: 10 EPOCH 17660 -- Train Loss: 0.32148  Validation Loss: 0.43690\n",
      "t: 10 EPOCH 17661 -- Train Loss: 0.32069  Validation Loss: 0.43438\n",
      "t: 10 EPOCH 17662 -- Train Loss: 0.32056  Validation Loss: 0.43588\n",
      "t: 10 EPOCH 17663 -- Train Loss: 0.32146  Validation Loss: 0.43714\n",
      "t: 10 EPOCH 17664 -- Train Loss: 0.32090  Validation Loss: 0.43650\n",
      "t: 10 EPOCH 17665 -- Train Loss: 0.32129  Validation Loss: 0.43431\n",
      "t: 10 EPOCH 17666 -- Train Loss: 0.32045  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 17667 -- Train Loss: 0.32055  Validation Loss: 0.43789\n",
      "t: 10 EPOCH 17668 -- Train Loss: 0.32025  Validation Loss: 0.43356\n",
      "t: 10 EPOCH 17669 -- Train Loss: 0.32056  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 17670 -- Train Loss: 0.32018  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 17671 -- Train Loss: 0.32048  Validation Loss: 0.43631\n",
      "t: 10 EPOCH 17672 -- Train Loss: 0.32109  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 17673 -- Train Loss: 0.32100  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 17674 -- Train Loss: 0.32107  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 17675 -- Train Loss: 0.32105  Validation Loss: 0.43734\n",
      "t: 10 EPOCH 17676 -- Train Loss: 0.32073  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 17677 -- Train Loss: 0.32096  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 17678 -- Train Loss: 0.32149  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 17679 -- Train Loss: 0.32183  Validation Loss: 0.43663\n",
      "t: 10 EPOCH 17680 -- Train Loss: 0.32009  Validation Loss: 0.43756\n",
      "t: 10 EPOCH 17681 -- Train Loss: 0.31977  Validation Loss: 0.43504\n",
      "t: 10 EPOCH 17682 -- Train Loss: 0.32153  Validation Loss: 0.43569\n",
      "t: 10 EPOCH 17683 -- Train Loss: 0.32047  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 17684 -- Train Loss: 0.32067  Validation Loss: 0.43586\n",
      "t: 10 EPOCH 17685 -- Train Loss: 0.32047  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 17686 -- Train Loss: 0.32083  Validation Loss: 0.43621\n",
      "t: 10 EPOCH 17687 -- Train Loss: 0.32182  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 17688 -- Train Loss: 0.32193  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 17689 -- Train Loss: 0.32094  Validation Loss: 0.43664\n",
      "t: 10 EPOCH 17690 -- Train Loss: 0.31980  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 17691 -- Train Loss: 0.32130  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 17692 -- Train Loss: 0.32138  Validation Loss: 0.43706\n",
      "t: 10 EPOCH 17693 -- Train Loss: 0.32063  Validation Loss: 0.43754\n",
      "t: 10 EPOCH 17694 -- Train Loss: 0.31980  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 17695 -- Train Loss: 0.32100  Validation Loss: 0.43482\n",
      "t: 10 EPOCH 17696 -- Train Loss: 0.32114  Validation Loss: 0.43762\n",
      "t: 10 EPOCH 17697 -- Train Loss: 0.32055  Validation Loss: 0.43632\n",
      "t: 10 EPOCH 17698 -- Train Loss: 0.32112  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 17699 -- Train Loss: 0.32040  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 17700 -- Train Loss: 0.32090  Validation Loss: 0.43492\n",
      "t: 10 EPOCH 17701 -- Train Loss: 0.32038  Validation Loss: 0.43673\n",
      "t: 10 EPOCH 17702 -- Train Loss: 0.31990  Validation Loss: 0.43676\n",
      "t: 10 EPOCH 17703 -- Train Loss: 0.32069  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 17704 -- Train Loss: 0.31986  Validation Loss: 0.43695\n",
      "t: 10 EPOCH 17705 -- Train Loss: 0.32056  Validation Loss: 0.43664\n",
      "t: 10 EPOCH 17706 -- Train Loss: 0.32038  Validation Loss: 0.43697\n",
      "t: 10 EPOCH 17707 -- Train Loss: 0.32036  Validation Loss: 0.43534\n",
      "t: 10 EPOCH 17708 -- Train Loss: 0.32016  Validation Loss: 0.43771\n",
      "t: 10 EPOCH 17709 -- Train Loss: 0.32157  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 17710 -- Train Loss: 0.31947  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 17711 -- Train Loss: 0.32104  Validation Loss: 0.43572\n",
      "t: 10 EPOCH 17712 -- Train Loss: 0.32067  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 17713 -- Train Loss: 0.32016  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 17714 -- Train Loss: 0.32084  Validation Loss: 0.43506\n",
      "t: 10 EPOCH 17715 -- Train Loss: 0.32009  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 17716 -- Train Loss: 0.32077  Validation Loss: 0.43601\n",
      "t: 10 EPOCH 17717 -- Train Loss: 0.32019  Validation Loss: 0.43659\n",
      "t: 10 EPOCH 17718 -- Train Loss: 0.32004  Validation Loss: 0.43531\n",
      "t: 10 EPOCH 17719 -- Train Loss: 0.32027  Validation Loss: 0.43607\n",
      "t: 10 EPOCH 17720 -- Train Loss: 0.31989  Validation Loss: 0.43682\n",
      "t: 10 EPOCH 17721 -- Train Loss: 0.32181  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17722 -- Train Loss: 0.32052  Validation Loss: 0.43701\n",
      "t: 10 EPOCH 17723 -- Train Loss: 0.32072  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 17724 -- Train Loss: 0.32020  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 17725 -- Train Loss: 0.32149  Validation Loss: 0.43660\n",
      "t: 10 EPOCH 17726 -- Train Loss: 0.32108  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 17727 -- Train Loss: 0.32098  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 17728 -- Train Loss: 0.32063  Validation Loss: 0.43575\n",
      "t: 10 EPOCH 17729 -- Train Loss: 0.32109  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 17730 -- Train Loss: 0.32048  Validation Loss: 0.43635\n",
      "t: 10 EPOCH 17731 -- Train Loss: 0.32138  Validation Loss: 0.43762\n",
      "t: 10 EPOCH 17732 -- Train Loss: 0.32027  Validation Loss: 0.43629\n",
      "t: 10 EPOCH 17733 -- Train Loss: 0.32130  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 17734 -- Train Loss: 0.32078  Validation Loss: 0.43474\n",
      "t: 10 EPOCH 17735 -- Train Loss: 0.32062  Validation Loss: 0.43845\n",
      "t: 10 EPOCH 17736 -- Train Loss: 0.32069  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 17737 -- Train Loss: 0.32123  Validation Loss: 0.43642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 17738 -- Train Loss: 0.32062  Validation Loss: 0.43532\n",
      "t: 10 EPOCH 17739 -- Train Loss: 0.32011  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 17740 -- Train Loss: 0.32106  Validation Loss: 0.43652\n",
      "t: 10 EPOCH 17741 -- Train Loss: 0.32083  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 17742 -- Train Loss: 0.32120  Validation Loss: 0.43512\n",
      "t: 10 EPOCH 17743 -- Train Loss: 0.32141  Validation Loss: 0.43535\n",
      "t: 10 EPOCH 17744 -- Train Loss: 0.32079  Validation Loss: 0.43448\n",
      "t: 10 EPOCH 17745 -- Train Loss: 0.32060  Validation Loss: 0.43676\n",
      "t: 10 EPOCH 17746 -- Train Loss: 0.32048  Validation Loss: 0.43516\n",
      "t: 10 EPOCH 17747 -- Train Loss: 0.32131  Validation Loss: 0.43667\n",
      "t: 10 EPOCH 17748 -- Train Loss: 0.32072  Validation Loss: 0.43641\n",
      "t: 10 EPOCH 17749 -- Train Loss: 0.32131  Validation Loss: 0.43655\n",
      "t: 10 EPOCH 17750 -- Train Loss: 0.32135  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 17751 -- Train Loss: 0.32119  Validation Loss: 0.43412\n",
      "t: 10 EPOCH 17752 -- Train Loss: 0.32060  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 17753 -- Train Loss: 0.32051  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 17754 -- Train Loss: 0.32087  Validation Loss: 0.43476\n",
      "t: 10 EPOCH 17755 -- Train Loss: 0.32140  Validation Loss: 0.43524\n",
      "t: 10 EPOCH 17756 -- Train Loss: 0.32026  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17757 -- Train Loss: 0.32142  Validation Loss: 0.43642\n",
      "t: 10 EPOCH 17758 -- Train Loss: 0.32057  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 17759 -- Train Loss: 0.32198  Validation Loss: 0.43457\n",
      "t: 10 EPOCH 17760 -- Train Loss: 0.32113  Validation Loss: 0.43681\n",
      "t: 10 EPOCH 17761 -- Train Loss: 0.32053  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 17762 -- Train Loss: 0.32104  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 17763 -- Train Loss: 0.32181  Validation Loss: 0.43689\n",
      "t: 10 EPOCH 17764 -- Train Loss: 0.32033  Validation Loss: 0.43503\n",
      "t: 10 EPOCH 17765 -- Train Loss: 0.32111  Validation Loss: 0.43722\n",
      "t: 10 EPOCH 17766 -- Train Loss: 0.32134  Validation Loss: 0.43666\n",
      "t: 10 EPOCH 17767 -- Train Loss: 0.32110  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 17768 -- Train Loss: 0.32058  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 17769 -- Train Loss: 0.32056  Validation Loss: 0.43548\n",
      "t: 10 EPOCH 17770 -- Train Loss: 0.32110  Validation Loss: 0.43603\n",
      "t: 10 EPOCH 17771 -- Train Loss: 0.32119  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 17772 -- Train Loss: 0.32102  Validation Loss: 0.43619\n",
      "t: 10 EPOCH 17773 -- Train Loss: 0.32070  Validation Loss: 0.43500\n",
      "t: 10 EPOCH 17774 -- Train Loss: 0.32087  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 17775 -- Train Loss: 0.32112  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 17776 -- Train Loss: 0.32074  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17777 -- Train Loss: 0.32122  Validation Loss: 0.43491\n",
      "t: 10 EPOCH 17778 -- Train Loss: 0.32094  Validation Loss: 0.43568\n",
      "t: 10 EPOCH 17779 -- Train Loss: 0.32195  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17780 -- Train Loss: 0.32078  Validation Loss: 0.43647\n",
      "t: 10 EPOCH 17781 -- Train Loss: 0.32162  Validation Loss: 0.43653\n",
      "t: 10 EPOCH 17782 -- Train Loss: 0.32026  Validation Loss: 0.43800\n",
      "t: 10 EPOCH 17783 -- Train Loss: 0.32059  Validation Loss: 0.43636\n",
      "t: 10 EPOCH 17784 -- Train Loss: 0.32093  Validation Loss: 0.43638\n",
      "t: 10 EPOCH 17785 -- Train Loss: 0.32137  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 17786 -- Train Loss: 0.32049  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 17787 -- Train Loss: 0.32085  Validation Loss: 0.43577\n",
      "t: 10 EPOCH 17788 -- Train Loss: 0.32057  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 17789 -- Train Loss: 0.32132  Validation Loss: 0.43513\n",
      "t: 10 EPOCH 17790 -- Train Loss: 0.32079  Validation Loss: 0.43507\n",
      "t: 10 EPOCH 17791 -- Train Loss: 0.32106  Validation Loss: 0.43705\n",
      "t: 10 EPOCH 17792 -- Train Loss: 0.32106  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 17793 -- Train Loss: 0.32111  Validation Loss: 0.43589\n",
      "t: 10 EPOCH 17794 -- Train Loss: 0.32038  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17795 -- Train Loss: 0.32116  Validation Loss: 0.43653\n",
      "t: 10 EPOCH 17796 -- Train Loss: 0.32090  Validation Loss: 0.43606\n",
      "t: 10 EPOCH 17797 -- Train Loss: 0.32073  Validation Loss: 0.43565\n",
      "t: 10 EPOCH 17798 -- Train Loss: 0.32151  Validation Loss: 0.43626\n",
      "t: 10 EPOCH 17799 -- Train Loss: 0.32114  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17800 -- Train Loss: 0.32167  Validation Loss: 0.43464\n",
      "t: 10 EPOCH 17801 -- Train Loss: 0.32087  Validation Loss: 0.43597\n",
      "t: 10 EPOCH 17802 -- Train Loss: 0.32048  Validation Loss: 0.43630\n",
      "t: 10 EPOCH 17803 -- Train Loss: 0.32125  Validation Loss: 0.43669\n",
      "t: 10 EPOCH 17804 -- Train Loss: 0.32126  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 17805 -- Train Loss: 0.32203  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17806 -- Train Loss: 0.32097  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 17807 -- Train Loss: 0.32157  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 17808 -- Train Loss: 0.32015  Validation Loss: 0.43674\n",
      "t: 10 EPOCH 17809 -- Train Loss: 0.32074  Validation Loss: 0.43536\n",
      "t: 10 EPOCH 17810 -- Train Loss: 0.32080  Validation Loss: 0.43560\n",
      "t: 10 EPOCH 17811 -- Train Loss: 0.32139  Validation Loss: 0.43617\n",
      "t: 10 EPOCH 17812 -- Train Loss: 0.32059  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 17813 -- Train Loss: 0.32122  Validation Loss: 0.43582\n",
      "t: 10 EPOCH 17814 -- Train Loss: 0.32051  Validation Loss: 0.43605\n",
      "t: 10 EPOCH 17815 -- Train Loss: 0.32126  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 17816 -- Train Loss: 0.32033  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 17817 -- Train Loss: 0.32128  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 17818 -- Train Loss: 0.32049  Validation Loss: 0.43484\n",
      "t: 10 EPOCH 17819 -- Train Loss: 0.32035  Validation Loss: 0.43542\n",
      "t: 10 EPOCH 17820 -- Train Loss: 0.32114  Validation Loss: 0.43663\n",
      "t: 10 EPOCH 17821 -- Train Loss: 0.32122  Validation Loss: 0.43726\n",
      "t: 10 EPOCH 17822 -- Train Loss: 0.32098  Validation Loss: 0.43501\n",
      "t: 10 EPOCH 17823 -- Train Loss: 0.32060  Validation Loss: 0.43770\n",
      "t: 10 EPOCH 17824 -- Train Loss: 0.32153  Validation Loss: 0.43650\n",
      "t: 10 EPOCH 17825 -- Train Loss: 0.32062  Validation Loss: 0.43692\n",
      "t: 10 EPOCH 17826 -- Train Loss: 0.32095  Validation Loss: 0.43613\n",
      "t: 10 EPOCH 17827 -- Train Loss: 0.32009  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 17828 -- Train Loss: 0.32099  Validation Loss: 0.43486\n",
      "t: 10 EPOCH 17829 -- Train Loss: 0.32042  Validation Loss: 0.43715\n",
      "t: 10 EPOCH 17830 -- Train Loss: 0.32074  Validation Loss: 0.43591\n",
      "t: 10 EPOCH 17831 -- Train Loss: 0.32096  Validation Loss: 0.43672\n",
      "t: 10 EPOCH 17832 -- Train Loss: 0.32106  Validation Loss: 0.43429\n",
      "t: 10 EPOCH 17833 -- Train Loss: 0.32048  Validation Loss: 0.43444\n",
      "t: 10 EPOCH 17834 -- Train Loss: 0.32072  Validation Loss: 0.43712\n",
      "t: 10 EPOCH 17835 -- Train Loss: 0.32048  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17836 -- Train Loss: 0.32022  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 17837 -- Train Loss: 0.32034  Validation Loss: 0.43480\n",
      "t: 10 EPOCH 17838 -- Train Loss: 0.32155  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 17839 -- Train Loss: 0.32110  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 17840 -- Train Loss: 0.32152  Validation Loss: 0.43558\n",
      "t: 10 EPOCH 17841 -- Train Loss: 0.32093  Validation Loss: 0.43599\n",
      "t: 10 EPOCH 17842 -- Train Loss: 0.32120  Validation Loss: 0.43556\n",
      "t: 10 EPOCH 17843 -- Train Loss: 0.32135  Validation Loss: 0.43566\n",
      "t: 10 EPOCH 17844 -- Train Loss: 0.32089  Validation Loss: 0.43510\n",
      "t: 10 EPOCH 17845 -- Train Loss: 0.32148  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 17846 -- Train Loss: 0.32093  Validation Loss: 0.43716\n",
      "t: 10 EPOCH 17847 -- Train Loss: 0.32087  Validation Loss: 0.43673\n",
      "t: 10 EPOCH 17848 -- Train Loss: 0.31981  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 17849 -- Train Loss: 0.32119  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 17850 -- Train Loss: 0.32028  Validation Loss: 0.43447\n",
      "t: 10 EPOCH 17851 -- Train Loss: 0.32014  Validation Loss: 0.43602\n",
      "t: 10 EPOCH 17852 -- Train Loss: 0.32051  Validation Loss: 0.43561\n",
      "t: 10 EPOCH 17853 -- Train Loss: 0.32198  Validation Loss: 0.43778\n",
      "t: 10 EPOCH 17854 -- Train Loss: 0.32143  Validation Loss: 0.43567\n",
      "t: 10 EPOCH 17855 -- Train Loss: 0.32064  Validation Loss: 0.43709\n",
      "t: 10 EPOCH 17856 -- Train Loss: 0.32026  Validation Loss: 0.43648\n",
      "t: 10 EPOCH 17857 -- Train Loss: 0.32079  Validation Loss: 0.43578\n",
      "t: 10 EPOCH 17858 -- Train Loss: 0.32038  Validation Loss: 0.43540\n",
      "t: 10 EPOCH 17859 -- Train Loss: 0.32048  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 17860 -- Train Loss: 0.32072  Validation Loss: 0.43469\n",
      "t: 10 EPOCH 17861 -- Train Loss: 0.32026  Validation Loss: 0.43525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 10 EPOCH 17862 -- Train Loss: 0.32055  Validation Loss: 0.43473\n",
      "t: 10 EPOCH 17863 -- Train Loss: 0.31996  Validation Loss: 0.43574\n",
      "t: 10 EPOCH 17864 -- Train Loss: 0.32090  Validation Loss: 0.43514\n",
      "t: 10 EPOCH 17865 -- Train Loss: 0.32094  Validation Loss: 0.43645\n",
      "t: 10 EPOCH 17866 -- Train Loss: 0.32100  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 17867 -- Train Loss: 0.32061  Validation Loss: 0.43471\n",
      "t: 10 EPOCH 17868 -- Train Loss: 0.32108  Validation Loss: 0.43686\n",
      "t: 10 EPOCH 17869 -- Train Loss: 0.32081  Validation Loss: 0.43685\n",
      "t: 10 EPOCH 17870 -- Train Loss: 0.32118  Validation Loss: 0.43505\n",
      "t: 10 EPOCH 17871 -- Train Loss: 0.32096  Validation Loss: 0.43579\n",
      "t: 10 EPOCH 17872 -- Train Loss: 0.32189  Validation Loss: 0.43615\n",
      "t: 10 EPOCH 17873 -- Train Loss: 0.32049  Validation Loss: 0.43705\n",
      "t: 10 EPOCH 17874 -- Train Loss: 0.32045  Validation Loss: 0.43451\n",
      "t: 10 EPOCH 17875 -- Train Loss: 0.32077  Validation Loss: 0.43470\n",
      "t: 10 EPOCH 17876 -- Train Loss: 0.32140  Validation Loss: 0.43734\n",
      "t: 10 EPOCH 17877 -- Train Loss: 0.32016  Validation Loss: 0.43745\n",
      "t: 10 EPOCH 17878 -- Train Loss: 0.32003  Validation Loss: 0.43598\n",
      "t: 10 EPOCH 17879 -- Train Loss: 0.32096  Validation Loss: 0.43546\n",
      "t: 10 EPOCH 17880 -- Train Loss: 0.31995  Validation Loss: 0.43612\n",
      "t: 10 EPOCH 17881 -- Train Loss: 0.31997  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 17882 -- Train Loss: 0.32096  Validation Loss: 0.43654\n",
      "t: 10 EPOCH 17883 -- Train Loss: 0.31948  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 17884 -- Train Loss: 0.32047  Validation Loss: 0.43622\n",
      "t: 10 EPOCH 17885 -- Train Loss: 0.32024  Validation Loss: 0.43497\n",
      "t: 10 EPOCH 17886 -- Train Loss: 0.32151  Validation Loss: 0.43570\n",
      "t: 10 EPOCH 17887 -- Train Loss: 0.32049  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 17888 -- Train Loss: 0.32023  Validation Loss: 0.43600\n",
      "t: 10 EPOCH 17889 -- Train Loss: 0.32024  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17890 -- Train Loss: 0.32075  Validation Loss: 0.43415\n",
      "t: 10 EPOCH 17891 -- Train Loss: 0.31984  Validation Loss: 0.43519\n",
      "t: 10 EPOCH 17892 -- Train Loss: 0.32071  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 17893 -- Train Loss: 0.32025  Validation Loss: 0.43433\n",
      "t: 10 EPOCH 17894 -- Train Loss: 0.32137  Validation Loss: 0.43682\n",
      "t: 10 EPOCH 17895 -- Train Loss: 0.32075  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17896 -- Train Loss: 0.32059  Validation Loss: 0.43655\n",
      "t: 10 EPOCH 17897 -- Train Loss: 0.32030  Validation Loss: 0.43646\n",
      "t: 10 EPOCH 17898 -- Train Loss: 0.32143  Validation Loss: 0.43697\n",
      "t: 10 EPOCH 17899 -- Train Loss: 0.31982  Validation Loss: 0.43783\n",
      "t: 10 EPOCH 17900 -- Train Loss: 0.32003  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17901 -- Train Loss: 0.32030  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 17902 -- Train Loss: 0.32102  Validation Loss: 0.43684\n",
      "t: 10 EPOCH 17903 -- Train Loss: 0.32074  Validation Loss: 0.43730\n",
      "t: 10 EPOCH 17904 -- Train Loss: 0.32004  Validation Loss: 0.43552\n",
      "t: 10 EPOCH 17905 -- Train Loss: 0.32003  Validation Loss: 0.43559\n",
      "t: 10 EPOCH 17906 -- Train Loss: 0.32048  Validation Loss: 0.43593\n",
      "t: 10 EPOCH 17907 -- Train Loss: 0.32083  Validation Loss: 0.43674\n",
      "t: 10 EPOCH 17908 -- Train Loss: 0.31999  Validation Loss: 0.43562\n",
      "t: 10 EPOCH 17909 -- Train Loss: 0.32024  Validation Loss: 0.43688\n",
      "t: 10 EPOCH 17910 -- Train Loss: 0.31942  Validation Loss: 0.43563\n",
      "t: 10 EPOCH 17911 -- Train Loss: 0.32015  Validation Loss: 0.43564\n",
      "t: 10 EPOCH 17912 -- Train Loss: 0.32141  Validation Loss: 0.43453\n",
      "t: 10 EPOCH 17913 -- Train Loss: 0.32104  Validation Loss: 0.43671\n",
      "t: 10 EPOCH 17914 -- Train Loss: 0.31997  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 17915 -- Train Loss: 0.31964  Validation Loss: 0.43700\n",
      "t: 10 EPOCH 17916 -- Train Loss: 0.32154  Validation Loss: 0.43545\n",
      "t: 10 EPOCH 17917 -- Train Loss: 0.32117  Validation Loss: 0.43554\n",
      "t: 10 EPOCH 17918 -- Train Loss: 0.32019  Validation Loss: 0.43571\n",
      "t: 10 EPOCH 17919 -- Train Loss: 0.31987  Validation Loss: 0.43555\n",
      "t: 10 EPOCH 17920 -- Train Loss: 0.32089  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 17921 -- Train Loss: 0.31957  Validation Loss: 0.43691\n",
      "t: 10 EPOCH 17922 -- Train Loss: 0.32083  Validation Loss: 0.43525\n",
      "t: 10 EPOCH 17923 -- Train Loss: 0.32052  Validation Loss: 0.43443\n",
      "t: 10 EPOCH 17924 -- Train Loss: 0.32103  Validation Loss: 0.43580\n",
      "t: 10 EPOCH 17925 -- Train Loss: 0.32026  Validation Loss: 0.43495\n",
      "t: 10 EPOCH 17926 -- Train Loss: 0.32142  Validation Loss: 0.43590\n",
      "t: 10 EPOCH 17927 -- Train Loss: 0.31976  Validation Loss: 0.43553\n",
      "t: 10 EPOCH 17928 -- Train Loss: 0.32073  Validation Loss: 0.43608\n",
      "t: 10 EPOCH 17929 -- Train Loss: 0.32091  Validation Loss: 0.43557\n",
      "t: 10 EPOCH 17930 -- Train Loss: 0.32160  Validation Loss: 0.43576\n",
      "t: 10 EPOCH 17931 -- Train Loss: 0.31968  Validation Loss: 0.43594\n",
      "t: 10 EPOCH 17932 -- Train Loss: 0.32077  Validation Loss: 0.43549\n",
      "t: 10 EPOCH 17933 -- Train Loss: 0.31949  Validation Loss: 0.43658\n",
      "t: 10 EPOCH 17934 -- Train Loss: 0.32099  Validation Loss: 0.43410\n",
      "t: 10 EPOCH 17935 -- Train Loss: 0.32066  Validation Loss: 0.43674\n",
      "t: 10 EPOCH 17936 -- Train Loss: 0.32133  Validation Loss: 0.43698\n",
      "t: 10 EPOCH 17937 -- Train Loss: 0.32010  Validation Loss: 0.43730\n",
      "t: 10 EPOCH 17938 -- Train Loss: 0.32182  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17939 -- Train Loss: 0.32043  Validation Loss: 0.43644\n",
      "t: 10 EPOCH 17940 -- Train Loss: 0.32099  Validation Loss: 0.43479\n",
      "t: 10 EPOCH 17941 -- Train Loss: 0.32038  Validation Loss: 0.43623\n",
      "t: 10 EPOCH 17942 -- Train Loss: 0.32110  Validation Loss: 0.43585\n",
      "t: 10 EPOCH 17943 -- Train Loss: 0.32089  Validation Loss: 0.43750\n",
      "t: 10 EPOCH 17944 -- Train Loss: 0.32083  Validation Loss: 0.43494\n",
      "t: 10 EPOCH 17945 -- Train Loss: 0.32090  Validation Loss: 0.43620\n",
      "t: 10 EPOCH 17946 -- Train Loss: 0.32204  Validation Loss: 0.43726\n",
      "t: 10 EPOCH 17947 -- Train Loss: 0.32118  Validation Loss: 0.43547\n",
      "t: 10 EPOCH 17948 -- Train Loss: 0.32093  Validation Loss: 0.43637\n",
      "t: 10 EPOCH 17949 -- Train Loss: 0.32088  Validation Loss: 0.43595\n",
      "t: 10 "
     ]
    }
   ],
   "source": [
    "losses, embedding_losses, final_state_losses, next_state_losses, val_losses = trainer.train(train=train, val=val, epochs=100000, batch_size=256, shuffle=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(data):\n",
    "    colors = {\n",
    "    1 : 'r',\n",
    "    10: 'g',\n",
    "    20: 'b',\n",
    "    30: 'y',\n",
    "    40: 'c',\n",
    "    50: 'm',\n",
    "    60: 'k',\n",
    "    70: 'tab:orange',\n",
    "    80: 'tab:purple',\n",
    "    90: 'tab:brown'\n",
    "    }\n",
    "    labels = []\n",
    "    for t in data.keys():\n",
    "        if t==1: continue\n",
    "        if t%10 == 0 or t==1:\n",
    "            labels.append(str(t))\n",
    "            plt.plot(data[t], colors[t])\n",
    "    plt.legend(labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(embedding_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd5wURfbAv48sIEFYgqwEFQMYUFfEhCiiwHmgh4mTExQPzzv0FPOhot6dopzhVM506mFExAAmUBH9mUCCiAKCgIoLSFRAcni/P6Zn6ZnpmemZ6Qm7+76fz362u6q6qnq6u17Vq1evRFUxDMMwDDdV8l0BwzAMo/Aw4WAYhmHEYMLBMAzDiMGEg2EYhhGDCQfDMAwjhmr5rkAQNG7cWFu3bp3vahiGYZQrZsyYsVpVi7ziKoRwaN26NdOnT893NQzDMMoVIvJDvDhfaiUR6S4i80VkoYjc4BE/RETmishsEZkkIq2c8A4i8pmIzHHiznNdM9jJT0WksStcROQBJ262iByZ2u0ahmEYmZJUOIhIVWAk0ANoB/QVkXZRyb4ASlT1MGAscLcTvgm4UFXbA92B+0WkgRP3CXAqEC25egBtnb9BwMOp3pRhGIaRGX5GDh2Bhaq6WFW3AaOB3u4EqjpZVTc5p1OAYid8gap+6xwvA1YCRc75F6r6vUd5vYGnNcQUoIGINE/91gzDMIx08SMcWgA/us5LnbB4DATejg4UkY5ADWBRwOUZhmEYARPohLSI9ANKgJOiwpsDzwD9VXVXQGUNIqR2omXLlkFkaRiGYTj4GTksBfZxnRc7YRGIyKnAUKCXqm51hdcD3gSGOmqiQMpT1cdUtURVS4qKPC2xDMMwjDTxIxymAW1FpI2I1ADOB8a7E4jIEcCjhATDSld4DeBVQnMIY33WaTxwoWO11AlYp6rLfV5rGIZhBEBS4aCqO4DBwERgHjBGVeeIyO0i0stJNgKoC7wkIrNEJCw8zgU6AwOc8Fki0gFARK4QkVJCI4PZIvJf55q3gMXAQuBx4M+B3GkaTP5uMvNXz89X8YZhGHlDKsJ+DiUlJZqNRXBymwCgw8r/b2QYhhGNiMxQ1RKvOPOtZBiGYcRgwsEwDMOIwYSDYRiGEYMJB8MwDCMGEw6GYRhGDCYcDMMwjBhMOBiGYRgxmHAwDMMwYjDhYFRKNm/fzBsL3sh3NQyjYDHhYFRKrpxwJb994bfMWDYj31UxKgiHPnwo/57y73xXIzBMOBiVkoU/LwTgly2/5LkmRkXh65Vfc+XEK/NdjcAw4WAYhmHEYMLBMAzDiMGEg2EYhhGDCYdyzMSFE9m8fXO+q2EYRhZZsGYB3675NuflmnDIAarKrmC2zi5j9orZdH+uO1e8fUWg+RpGZeRvk/7G3yb9LWflrd28lpr/qMkH33+QNO2BDx3IAQ8dkP1KRWHCIQccPPJgav+zdqB5/rz5ZwAWrF0QaL5G5WSX7uKVea94dmImLZ7E8189n4da5Y47P76TOz++M2flTVs6jW07t3HHR3fkrMxUMeGQA+avmc/WnVvzUvaEhRN4dvazeSm7PKDYLn8AT8x8gj5j+vD4jMdj4k595lQueOWCPNTKyCfV8l0BI7v0eK4HAP0O65fnmhQWguS7CgXFsg3LIv4b2UXE2YK4gDsnNnLIE7t0V0bzEIX8UhmGkZhw50Q18jveuWsnb3/7dkx4PvAlHESku4jMF5GFInKDR/wQEZkrIrNFZJKItHLCO4jIZyIyx4k7z3VNGxGZ6uT5oojUcMIHiMgqEZnl/F0S1M0WEgc8eAB17qiTcT7WA/bHnR/didxmv5WRG5ZvWI7cJrz2zWue8fFGDvd+di89n+/JuPnjsl7HZCQVDiJSFRgJ9ADaAX1FpF1Usi+AElU9DBgL3O2EbwIuVNX2QHfgfhFp4MTdBdynqvsDPwMDXfm9qKodnL//pnlvBc2inxexZceWfFej0vC39yMtUcrzyOum92/i/LHn57saRgJm/TQLgEemP+IZH2/ksPjnxUBIuOQbPyOHjsBCVV2sqtuA0UBvdwJVnayqm5zTKUCxE75AVb91jpcBK4EiCYnNUwgJEoBRwJmZ3oxhJGPjto1s37m97Lw8jrz++dE/eXHOi1nJO1dCc8uOLSxYU3Et7cIjg3TjCwE/wqEF8KPrvNQJi8dA4O3oQBHpCNQAFgGNgF9UdUecPPs4aqixIrKPjzpWOgpBJ5kOs36axZpNa/JWft0763LyqJPTvn7FryuYu2pugDUqDHLdWF007iIOfOhA1m9dn9Nyc015HqEGOiEtIv2AEmBEVHhz4BngItWks7CvA60dFdW7hEYVXmUNEpHpIjJ91apVmVe+nBLUR917dG+OePSIsvPnZj/HbR/cFkjebo549AiO+e8xgeebCp/8+EncuH99+i+Gfzw8bvx+D+xH+/+0z0a18kquOxvvf/c+QIVd4R9PbRRNIQsPP8JhKeDuvRc7YRGIyKnAUKCXqm51hdcD3gSGquoUJ3gN0EBEwqa0ZXmq6hrX9f8FjvKqlKo+pqolqlpSVFTk4zYqF6s3rU7pgx8/f3yZnhSg36v9uPXDW7NQs9B8S6YsXb+Ujds2ZpxP9Md57bvXcuOkG+Om37g98zILmUJRs63cuJJ+r/QL5BknI7ygNEiSmar6FR75xI9wmAa0dayLagDnA+PdCUTkCOBRQoJhpSu8BvAq8LSqhucX0NAvMhk42wnqD4xzrmnuyroXMC/Vmwqa9VvXI7cJD059MN9V8cU3q7+haEQRI6eNzHdVfLFuyzo2bN2Q0jXF9xXT+X+d0y4znUawdH1p2uWlwy7dxdYduV08qSjvf/c+Y+eOTZ44i9z8/s0899VzOVnAudfde2WcR3Qjn6zxD2Kdw9rNa1m6PqafHhhJhYMzLzAYmEiooR6jqnNE5HYR6eUkGwHUBV5yzE/DwuNcoDMwwGWa2sGJux4YIiILCc1BPOGEX+GYvn4JXAEMyPw2U8e9BiFsOfDQtIfyURVPEr1UYSddExdNzGodNm3fFIjPqAZ3NaDe8HopXzdz+cyMy04Fr9XD2eTKCVdS65+12LlrZ9bLcqsnuz7dlXNeOifrZSaikNUtXkwpnRJxnouRQ9N/NaX4vuK0r0+GrxXSqvoW8FZU2C2u41PjXPcs4Cn6VXUxIUuo6PAbgfjj+oBZtHYR+zbcN0Z3n29fMuu2rKNezXrJrR4CVgPIbcLXl32dNN26LetocFcDTmlzCpMunBRoHYwQYTPInbqTqlTNShnvLX6PgeMH0veQvlnJP1MSvf8L1y6kVrVaFNfLXgPpl03bN0Wc+x05ZMKOXTuSJ8qASr1CemrpVPZ/cH8env5wTFw29JB+mbdqHg3uasCTXzyZNK1XzyTTXtdb376VNM3qTauB3ROL+WLVxlX88//+mVEP7N7P7kVuk5hnvnbz2rL7rKhc/c7VLFm3hG/XZuYS+odffmDdlnUB1cpfj7rtg23Z5774xow/rvuRr1cm7+hkg0zVRoUwcqrUwiFsZ/1Z6Wd5rkkkYVPJtxa+FRMe1s1HjxhGfj4yZjVmoUwuevH2tzHWzmkxcPxAbpp8Ex8v+TjtPB6fGVIX/fTrTxHhje5uRNGI3cYO5cE23Q+qyve/fB9onq3/3ZoOj3ZInjBFMnmHW97fkkMfPjQmfNSsUVlfZOa33oUgBOJRqYVDqg8m35YF7f/Tnu7PdQ/VJarug98ezFkvnpWPaqXFYzMfCySfDdtCwjLdIXbP53qyZN0SIPgPdfvO7TECpxAYOW0kbf7dxnPOJpN3PGiBkw1WbVzFgHED6Pl8z0Dz9dtxeG72c6zcuDLjOYdctEWVWjj4Jfzgd2r2JwbdeL0An/74acR5NkYHfl70OavmJIx/5stneGfROymXvXbz2pSvyYTtu7aX6YuDVkEMemMQze9pnjc3Kcs3LPf8PT9a8hFATncX27x9c0EIj3AnIldC2/0NL9+wnH6v9uPM0WfGVTv5FTK3fnBrYHWMhwkHH4QfcNjvSdDs2LWDU0adwofffwiUD/VF79G9E8Zf+NqFnP7s6SnlOXP5TBrd3YjnZj+XSdXS5ryx5yWMT1UQvzLvFYCMzVHT7SXufe/eNLq7UcI00T3YbL17fcb0oc2/25Sdp7o4zD0y/L8f/q/gnSh6Nf4/bwnNaS3dsDTuyMHvs372q+yb+JpwSJEZy2ZE+OZxs3HbRmYsm5E0j0mLI617lm9YzuTvJ9Pv1WD2XMi3+itdvvzpSwDe++49AB76/CE6/bdTPquUV8pDJ8Evby/0nmPy44Po1XmvUv3v1ZmzMjRa9TIgKTSiG/8l65ZErKy3/RzKCc/Oftb3op+Sx0virqDt+3JfSh4vSWq1Eb3yuFqVkEVxtN5cUWYsm0GjuxuxaqO3i5CN2zcy8vPdi926/K9LmTrH/eFt27ktYZ0y4dMfP+XEp04MvIzL376cqUunJkxTHgRhITcA2WTGshlpqep+3fYrT3zxRNn5a/NDhhbTl03PqD4L1ixg73v3zigPv7gb/yYjmtDx8Uir/Xij0ELqEJhwcIhe9JPog56x3Ht0EG7IUtUxh4VDeEQSfnFWb1pNyeMlrN28NsZkNNwofr70cwa/Pbgs/MMfPuQ/0/8TkQbgzNG7nd6+Pv915DaJqyaL9+L+uO5HXp33akz4wPED+XjJxyxam7pbjHBv0M0r817hgakPpJRPNj+q8IR1qhSqtdiYOWPixqUjbOPtg1zyeImntVAybn7/5rLjdH9D96K0mctncsdHd0SM6oPsVKhqjPm3e+SwatMqVmxc4Vl29OK5Qurs2DahPkjU8Hyy5BNqV69N+ybpO2MrEw67ItVVicwzV25cGTfOi/Cw/t1F79JrdGhh+7Sl09i34b6+8zj2iWNZumEpOizzF3ja0mms3LiSQx4+JCZu/db1/HXCXzMuA0LbXhbVzsz3Vqv7W/HyuS8HUh8367aso36t+jHhm7dvZt7q1L3GjJ8/ns6tOtOgVoO4aVJZlHXdu9f5Wp099P2h/ivpA/eCsrmr5vL0l0+nnMexTxxbdnzUYyH3bC/0eSEm3Uc/fJRGDSMZ/fVo7vnsnoiwVNRGu3QXVSSyn/7juh/jvh+5olKPHBJJaT89ll26ixOeOoEjHzuSQ/4T28h5sW3ntpgJyvCLtH7rel/WOnNWzuH3r/w+aTqvD/6myTclvW7zDm9PmUs3BOfHZemGpRz+yOGB5efFpu2baHFvC/70xp9i4n7d9mtKeU1bOi2oagEhlUuDuxrw4tex+zIMGDeAox47KkZNt27Luhjz0wGvDUBuExatXUTv0b3p+3JwK51HfDqCe6fcW3a+ZN2SstHtWS+exQEPHpBxGV7foPu9dZefDS55PfONJr18biVrP9z36E4bDh/+yfC0Rl1BUqmFg1/iCZE3FrxRduxeYRqvt/De4veo+Y+aTFu2u6FZtmEZv3n+N2XnB488mDWbE+934HeTlHTVITdP3j2sz+aGLNkwJ6x6e1UGjgttKhgWAK8veD0m3dadqVsQpau68np/wvrzi8ZdxMdLPqb36N5lvfQYVYPzPvV4rkdZLzjMqC9DHu2vffdaIDWLOvd7Gq7jD+t+iJu+1f2tuPztywF47ZvXMlpVnei3zJY6Lh9qvrgjtTh1caf/cf2PnmlyhQmHDLho3EUR58lePq/hcd+X+0asXVi5cSV/fP2PgdTP7YLbCz9D3qBVBpnw5U9f8q9P/5UwzS7dxZOzQm5HwhP8YbVdrknUAIZViJt3bKbPmD6Mnz+eVZvi70uyc9fOhCv5054XiVrD88zsZxKmj2d1FCSJfrd3Fr2Tthvv6HznrZoXYwSycdvGMqs5N49Of9RzhPDUF08x6btY32JJHe9lOEeWC0FnwsEHb377pmd4qgu2vD68aIddRiwrfl3BbR/cRodHO5T1kP0Q/vCX/5q5q4SN2zcy7INhGefjRVjfnEjN+fnSzxPmkY5FlCB8s/obgJS867onXxNNboeZv3p+2fE9n95Ttp4nHvHmORb/vJjTnz09ZiTo16eTu0FdsXEF7f7TLmakdd7Y8+jwaIcIAbTi1xX86c0/RYzww+EXj7/Y0/txuCwvNx2Kejbuc1bO4d3F78at/5g5Y3I6YW0T0j6I9pmeTGpn4wEWkolbPC5941Ke7P1k4Kucm93TzFe66N89kUuNVHteD34euZfHiE9GsGDNAnod2IvfHvhbIKRqaVCrAV1ad4msV5KGO1yXeA308189z8GND44JdzeK4bmIpO+mqy7bd21P2bJOkIhG0mvh4KyfZkXMqx008qCy42vevQaARnuEFuct+nkRVatUpXHtxkBIMMRzrRJ2lRLNQ58/xNDOyUe4fr6h8C6B23Zuow51gN0qyGjHjIner7DQTKSmi8bLOMPNeWPPY2OvjVx0xEUJ0wWFCQcXpetLy9z/Zmqbvmn7JmpXrx1EtWLIRFB4Ca6g9nT+aMlHtH2wrWfcsg3LGDJxSCDlxOPRGY+WHa/4dUVWe1nXvXcdAP/94r/oMGXLji1lvq3C1lyJGuqw7h5cI4c479zA8QP59OJPY8KvmHBF3Pz99KbdjZvf3ypZYzf669EpTYof/+Tx1Kleh1//FpofyvcCN6/fISy0U/nuZq2Ir9KNfi/2+OcebB7qb7vUlRtXsn7r+hjLxmxgaiUXqbgcDrtGcBO2Zb5/yv3UuaMOyzYsC6xuboJs9KYvm07jEY3jxmeq2wzvQ339e9fz4pxYy5wgmfz95LLjZvc0Y8LCCVktL8yWHVsS6sG/Wf1Nwncr3OiEGyGv+QMvwbF+6/q4efYZ0ycmbMycMaz4dbe9faK9stPFr2BwG124t15Np6PityOXygZGXoIglW8hFWulrTu3pqTWqz+8ftpzTKlgwsEH0S/f8l+Xe358YUZ8OgII+bgvdJLpf70+vOgXM5GwuvXDW7M6r5JoT2f34sBogly13O2Zbp7hYVPU4588ngZ3xV974GfOwe/+IvPXhPT7X638Kub688aeF+GNNJwW4s+rlTeC2gAnPBeTDms3r41Zt+Am3pxDoVGphUN0A5GoJ+Ym2YsTztfP0C+dUUC6aqV3F70bYUYLu3XAqZDqvrXN/uVvziAdwiah3Z7pltJvmSxtKo7d4i1W9CuAwg1Jot7jGS+cERMWvX9HIsKeWL/7+Tvf1+SDL1fEWgr55YvlX1D979V9bVYVj/Azcy+iC/PDuh944avdC+nifYd9xvRJ+Rv1mz6Xc4+VWjhE414Q424A05XyJ/3vpIzrFCSnPXtaxLkfdxde9/7S3Jci0yR5YeNNJAZJqj3GXHxkft+bZBPSqTJscqRVlaqWedFdtzW43dqCZGrpVKYtncar38S6ZwmTTKCHTcLfXJD+KMjdQQyP1tzPMWwmnYjvf/k+5TYjVXcxucCEgwu3v/m7P707fxXxwP2y+fH86gc/q6W9uG/KfSlfUx6G0UETrfKaWurtRDBoD523/9/tEefJ1oYUAp2e6ESnJxJ74L1/6v05qk2Ip2Y9BaT+XARJufNx1cSrPMPDu0Imwj2PFCQmHPJMPCd+0Vz9ztVlx3d87O3orJDx07NP1Gv0Q/SIptCI1/iFbe2DdgYXJhe+//PNuG/Gla1DScV8NBFXv3N1jAp12YZltLi3Rc42SnK7+Y7HZW9elpWyfQkHEekuIvNFZKGI3OARP0RE5orIbBGZJCKtnPAOIvKZiMxx4s5zXdNGRKY6eb4oIjWc8JrO+UInvnUwt5qcTds3eTZiH/6QeNI2F+RrKX1Qbrhf+DrW6Vk0Xm4uskU6HmQT4bd3uWHrhqy6Tw/jXm1dSJ4+s4GqcuaLZ5ZZQAU5uf7OonciPBHPXTWXZRuWccsHt8S95rtfvku4C6KqBqrWzNYOlUmFg4hUBUYCPYB2QF8RaReV7AugRFUPA8YCYZ3MJuBCVW0PdAfuF5Gw2cZdwH2quj/wMzDQCR8I/OyE3+ekyxkTFk6IWdXot3efK4LSTfth3PxxQMVbyZ3NeZB5q+bFdWNdb3g9Th51ctbK9qK87CeR7nudze/h4vEXM+Sd2PU5o78eXTCq0mwJfz+L4DoCC1V1MYCIjAZ6A2XKMFWd7Eo/BejnhC9wpVkmIiuBIhFZB5wChF2LjgJuBR528r7VCR8LPCQiojnq/tw46Ub2rLFnLooqV9S5o06+q1BGKutRckW/V3bv4nf8k8eXbQnpRfQ+4GGyNVmcqgfa8sbYef426ioUMvFunEuB5Eet1AJw6zRKnbB4DARivHOJSEegBrAIaAT8oqphHY47z7LynPh1Tvro/AaJyHQRmb5qVXyHZYnwkjdfr/w6oYOzVPnbpL8FlpcRItGagXzh9q+T7ijr6MePDqo6EbgNLSoi6ew2FwSpuh5xk67ADq/MzwWBTkiLSD+gBBgRFd4ceAa4SDWYMaCqPqaqJapaUlSU2WYu2eTOj+/MdxUyxsvm200mC4YqIrlU+xn5I11rP4Ar3o7v+iRVsqU29CMclgL7uM6LnbAIRORUYCjQS1W3usLrAW8CQ1U17Kh+DdBARMJqLXeeZeU58fWd9EaeiN5fwEhMLvzeGPkn1d0Y3SRyz14o+BEO04C2jnVRDeB8YLw7gYgcATxKSDCsdIXXAF4FnlbVMsWgM38wGTjbCeoPjHOOxzvnOPHv52q+wTAMwy9+1iDEI0i/a9mah0gqHBy9/2BgIjAPGKOqc0TkdhHp5SQbAdQFXhKRWSISFh7nAp2BAU74LBHp4MRdDwwRkYWE5hSecMKfABo54UOAGNNZw6ioVDSrsIpMthxrpkq21Eq+XHar6lvAW1Fht7iOT41z3bOA5wocx/qpo0f4FsC/+0TDqEDc/uHtyRMZRg6o1Cuky4v9t1F5yHSVuGEERaUWDoZRaCxYsyB5IsNwka0pWRMOhmEY5ZjwNqZBY8LBMAyjHPPe4veykq8JB8MwDCMGEw6GYRhGDCYcDMMwjBhMOBiGYRgxmHAwDMMwYqjUwsFcNhmGYXhTqYWDYRiG4Y0JB8MwDCMGEw6GYRhGDCYcDMMwjBhMOBiGYRgxVGrhYC67DcMwvKnUwsEwDMPwxoSDYRiGEYMJB8MwDCMGEw6GYRhGDL6Eg4h0F5H5IrJQRG7wiB8iInNFZLaITBKRVq64CSLyi4i8EXXNKSIyU0S+FpFRIlLNCe8iIutEZJbzd0umN2kYhmGkRlLhICJVgZFAD6Ad0FdE2kUl+wIoUdXDgLHA3a64EcAfovKsAowCzlfVQ4AfgP6uJB+pagfn7/YU78kwDMPIED8jh47AQlVdrKrbgNFAb3cCVZ2sqpuc0ylAsStuErAhKs9GwDZVDe+m/i7QJ436G4ZhGFnAj3BoAfzoOi91wuIxEHg7SZ6rgWoiUuKcnw3s44o/VkS+FJG3RaS9VwYiMkhEpovI9FWrViUpzjAMw0iFQCekRaQfUEJIlRQXDfnKPh+4T0Q+JzSy2OlEzwRaqerhwIPAa3HyeExVS1S1pKioKKhbMAzDMPAnHJYS2asvdsIiEJFTgaFAL1XdmixTVf1MVU9U1Y7A/wELnPD1qvqrc/wWUF1EGvuoZ8rYfg6GYRje+BEO04C2ItJGRGoQ6vGPdycQkSOARwkJhpV+ChaRJs7/msD1wCPOeTMREee4o1PHNf5uxzAMwwiCaskSqOoOERkMTASqAk+q6hwRuR2YrqrjCamR6gIvOe36ElXtBSAiHwEHAXVFpBQYqKoTgWtF5AxCjf/Dqvq+U+TZwGUisgPYTMiiybr4hmEYOSSpcIAy9c5bUWG3uI5PTXDtiXHCrwWu9Qh/CHjIT70MwzCM7GArpA3DMIwYKrVwMJfdhmEY3lRq4WAYhmF4Y8LBMAzDiMGEg2EYhhGDCQfDMAwjBhMOhmEYRgwmHAzDMIwYTDgYhmEYMVRq4WBeOQzDMLyp1MLBMAzD8MaEg2EYhhGDCQfDMAwjBhMOhmEYRgyVWjjUrVE331UwDMMoSCq1cOjRtke+q2AYhlGQVGrhIEi+q2AYhlGQVGrhYBiGYXhTqYWDs9+1YRiGEUWlFg6GYRiGN76Eg4h0F5H5IrJQRG7wiB8iInNFZLaITBKRVq64CSLyi4i8EXXNKSIyU0S+FpFRIlLNCRcRecApa7aIHJnpTRqGYRipkVQ4iEhVYCTQA2gH9BWRdlHJvgBKVPUwYCxwtytuBPCHqDyrAKOA81X1EOAHoL8T3QNo6/wNAh5O8Z58YxPShmEY3vgZOXQEFqrqYlXdBowGersTqOpkVd3knE4Bil1xk4ANUXk2Arap6gLn/F2gj3PcG3haQ0wBGohI81RuyjAMw8gMP8KhBfCj67zUCYvHQODtJHmuBqqJSIlzfjawTyrlicggEZkuItNXrVqVpDhvbELaMAzDm0AnpEWkH1BCSJUUFw35yj4fuE9EPic0stiZSlmq+piqlqhqSVFRUbpVNgzDMDyo5iPNUnb36iGkMloanUhETgWGAiep6tZkmarqZ8CJzrWnAQekUp5hGIaRPfyMHKYBbUWkjYjUINTjH+9OICJHAI8CvVR1pZ+CRaSJ878mcD3wiBM1HrjQsVrqBKxT1eW+7sYwDMMIhKQjB1XdISKDgYlAVeBJVZ0jIrcD01V1PCE1Ul3gJUePv0RVewGIyEfAQUBdESkFBqrqROBaETmDkIB6WFXfd4p8C+gJLAQ2ARcFd7uGYRiGH6QibJVZUlKi06dPT/m69VvXU394/SzUyDAMI3fosPTacRGZoaolXnGVeoV0RRCMhmEY2aBSCwfDMAzDm0otHGydg2EYhjeVWjiYWskwDMObSi0cDCNIzm1/br6rYBiBYcLBMAJiv4b75bsKRiWkdvXaWcnXhINhBERxveLkiQwjYM444Iys5GvCwTAMo8B57IzH4sZla+7UhINhBIQZOBjZQsn9u2XCwTAMo8BJ1PHIlkm+CYcc8kKfF7j62KvzXQ0jS+Sjd2cUDnVr1M1a3m0atsla3vGo1MKhWhU/HsuDo4pUsa1JDaOC0qxus6zl3a4oemfm7FOphUOdGnXyXQXDMCoI+er4nbDPCVnJt1ILB6P88ddj/prR9f/u/u+AahJLvxx6o1sAAB6wSURBVMP6ZS1vI79kay1BEHQq7pSVfE045BjTS2fG/d3vz+j6K465IqCaxNKgVoOs5W3kFz+jglrVauWgJrnDhEOOKeQeiJE+3ffvHjfumbOeyWFNKh7ZWuQVNOPOH5e1vBMJp3o162WlTBMOOaZhrYb5rgL/6vavfFchL8Tr2bfdq23GeScyNTzroLMyzj8TDmx0YFbybbRHo5TSv3TOS2mVs3fdvdO6Lkj8mIvmw6LohuNv4MDG2Xm+Jhw8qF6lekrpV1yzwnfaQlArXX1c5TGnrSLJX/GmdZtmtQ61q9fOq1O+9/u/nzxRGqT6Lres3zIr9cgFr5z7Sl7L37Pmnp7h3fbrlrUyTTjkEDNjzT25+s2zLfSHdBqS9rV1qmfHKs+P4HWT7rMo2dtzF8ucceMJN/puhI9sfmRW6lCvZj1+vOrHmPBsrso34ZAh3/zlG98vvaKV0sXCW79/K99VAOJ/SEEIkPBk5F577JUw3eg+o9PKP98NpBcdmnVIKX06K3m/+cs3XHLkJSlfly/CAvOcdudknNdFHS6KOM+1Y0dfwkFEuovIfBFZKCI3eMQPEZG5IjJbRCaJSCtX3AQR+UVE3oi6pquIzBSRWSLysYjs74QPEJFVTvgsESnYN+MfJ/8ja/q+8kIyVcEzZz1Dj7Y9POPevzA76o5frv+l7DhXu/09/tvHAdh7T2/9eLY7BX8/+e8R503r7FaV7dJdWSkzVaHqlb5+zfoJrzmw8YHlasfGnvv3BODe0+/NOK9bTroFyJ/GIalwEJGqwEigB9AO6Csi0cv1vgBKVPUwYCxwtytuBPAHj6wfBi5Q1Q7A88BNrrgXVbWD8/df33eTJXod2MszfGjnoQmv+/n6nyPOs/GQj9vnuMDzjGblNSvjxhXVLkp4bePajePGxfvoLz3qUn8Vc7ity20R53vW3JODGx8MxPa+UqmHH/oc3AeAJnWa+ErvLqt9Ufu0y42eFxt6YuS7WFRn93MJUjgc1PigtK/1+p1/uuaniPNjWhxDjao1kubVsUXHtOuRTYZ1Gcbyq5cH0suvIlU444AzeOP3byRPnAX8jBw6AgtVdbGqbgNGA73dCVR1sqpuck6nAMWuuEnABo98FQjbYNUHlqVY96wRrT8+88Az08onF3bvbRoEayHRuVXnmDB3Q5MLmtVthg6L7Wn3bNvTM/11x18XcV5FqjD3L3PZcOMGHv7Nw4HWbf7g+Xx7+bdl56PPHs26G9YlvCae8Pnqsq98lxttQx+dZ/S5e6SSiXAYdeYo1l63Fgi9z6mqktz46Rz5EQyQ2IV1PqkiVQJ1o/F639fjvveQ3ZGxH+HQAnDPhJQ6YfEYCLztI99LgLdEpJTQyGK4K66Po6IaKyL7eF0sIoNEZLqITF+1apWP4tKnECyMckUm8wM3nnAjAP885Z9lYX4aBL8Tm2/+/k3P8HiLj+rWqEvVKlXLzuM9x5Lm/vX5BzQ6gP332r/svFqVamnbmUd/2Ins+XsfFNEfS0lNlYlwuPDwCwN7//02ZB8O+DBpGvc7M+ykYZ7h6XDTiTclTxQg4ZFnIRLohLSI9ANKCKmSknEV0FNVi4GngLCS7nWgtaOiehcY5XWxqj6mqiWqWlJUlNuerR/ijRoKXdD46bm9dt5rZcde9+PVcHnplsOC44SW2fEN45fhpw5PnigHJGrwq0gVXujzQlr5BuUtNFrQp/oue3UUvO7ZjzuImtVqxoTd0vkWHurxkGd6v25TEi1mzAZjzx1bdlxoK6z9CIelgLv3XuyERSAipwJDgV6qujVRhiJSBByuqlOdoBeB4wBUdY3r+v8CR/moY6Bkqi/86zF/jZlviObyjpczotsIXj735YzKyoewie7FhnF//Ce3PjkUVkCTiWcffLZnePWqsetaftP2N5x5UHrqRIBDmxya9rWZMrLnyLL3YuolU8scTNasGtugJmLw0YNjwvoe0jftevl5F/y+L+5OzMAjBrJvw30ZeORA+nfoT//D+0ekvarTVb7dphzf8nhPlWYuuKrTVRHnfkaH+TZlnQa0FZE2IlIDOB8Y704gIkcAjxISDPFnL3fzM1BfRA5wzrsB85y8mrvS9QqH55KhJw6lVf1WyRPGIa7JpOvFr1G1Btccd01ZIxpEWal+/NG8cu4rMQ3lnV3vTCsvtzonGdG/V7Ze+EfOeASIXNnrtb/GqDNH8cbv3+DV814tCxt64lCOaXGM77L+d+b/Is79CPGgBP2fj/5z2XF4jcPL577MnD/PSSmf6BGVovQ6sBfH73N8WvWKVvnsWcN7YZcf3O/6PvX3YdEVi2hZvyW1q9eO+e3DZNPpYhDc0fWOfFchgqTCQVV3AIOBiYQa6jGqOkdEbheRsBnPCKAu8JJjflomPETkI+AloKuIlIrI6U6efwReFpEvCc05XOtccoWIzHHCrwAGBHKnKVC9SvUIO+VkjVUqvePovOrXqs/Z7bx7tKmSilVD9/27x1jYnHVwrJuH89qfl1ZdwvfppUrIVCB6kUww1q1Rt0zwzf3LXC48/EIg9nm0L2pfFufmH6f8gymXTPFdn3h7hQRlseYlSJrXbe6RMsTvDv4d++21X1plBVXn6HxEJC2BeNZBZ6U06Rt+xtGjh0w9/AbFV5d95bnALd/4mnNQ1bdU9QBV3U9V/+mE3aKq453jU1W1qcv8tJfr2hNVtUhV91DVYlWd6IS/qqqHqurhqtpFVRc74Teqansn/GRV/Sb4207MHtX34Nrjr02eMAPCH0oVqcJL57xEiz0TzfF7s2DwggjB1LpB65g08fz6vH3B2zHmj5ni9aGH6+eu5/v9348YuosIT/V+ii6tu6Rd9pabtsSNm/7H6SwYvKDsvEmdJpzU6iQgdm4o3jqFVInXoGZTDTjlkikpjw4KjfDv5l6n4aZhrYY8fdbTaasr3aOX6E7KdcddF508JxzS5BBPVXauNyOLxlZIu2hetzl3n3o3Z7c727fdeqokaxwGdBjgO6+2jdrSrnFoyUk83z1he/9MScWE0atHmGj0paoM6DCgrMH2S7wGJJqj9j6K5ntG9qr7H96fkT1Hcv0J16dUpl+yIQSS9eBb1m+Z0x3Dop+p24rLC68GPd49zbx0puciybXXr81ogn3GoBllx9HPqJDmx57s9SQt6qXeYQwSEw4ualevzbXHX5vUHK5+zfpsHro5o7Ji7NKJr4aJ5rT9TiuzkQ/ns1/D/bxVOG3iq3BS0e3PGDSDnm17en6ww04axmcDP/PMN9H9xPsYo8PPbX+up9CcPmh62qa3VatU5c9H/9m3XX008Tydhu893juUiYomlYVfQczbpNpzdZswexG+93DHS4jtRISf/d577p3w3U2XDs06cFjTw9K6NnqiO1MSrY+56IjkizezTX7HLeWE6Be4apWqvs3OWtZvyZJ1S3bnFeejTaSjj+bvJ/+dQ5ockjTd5qGbMzaPC3+sVaRK3HUGt3a5FYDX579eFrZHtT2A1Cam4/Hi2S96hhfXKw7c34zf3uO8v8zzNuNNQcjHXJukQXe7hG5f1J4vV3yZNM9MesNhc9FwHuFnmijPW0+6lVs/vDXwugTJY2c8xnXvXZfyqDro0WC29mEIChs5JKBzq86e5oyp9MpmXTrLs6eSSQ/Sy2WFqtKyfkuOar7b8jeZYPBlQZPkXjs09VY3Pdn7SW7ufLPniutk9cinc8JoH0XxEBHP0UGZkE+wYjkI/LgFCYoGtRowvOtwPhjwQUR4zCpthGFdhhGP8Dsf7zfKFccUH8OHAz5Me9QY5oHuDzDm7DEB1So9Ml30lzDvrOVcDolupD4c8CGvnvdq2cuczqYtDfdoWKaLTUcgJNtbwp1n9arVmT5oOrd3uZ0R3bzXIQZtwz3yNyM9w5vUacLtJ9+e8OWNsV4pAJfmmfrsCa9GTuej9SOsx50/jsn9JweSVypcf8L1HNDogIiwdAVeeM7gzq535qQjkC0h1LFFR85pn5731XQX233/1+8jTHJPap3aPF0qmFqJkL31hm1e7p8iyfQlU7TsYZ6232lx07iZ95d57P9g4om+aG4+6eb0KpgGhbaqM12a120e0/ilw0mtTmL+mvkxVlBBNVBhJ5Bf/pRcpQSxAnf/vfZn4dqFGdUh3GFJ956qV61e1knZuG1jRnXxQ9i7aTJyOWJNd/OgVg1aRRiH2Mghi2y4cUNS+/XwxFi/Q/t5xqfS4+1U3IntN2+n675dI8Lj9fS8bNOz0RMadOSgwPN0k6gnm+pHmQ1LsmVXL4tRm6TDgz0fZN5f5sXY4Qe92vX4luktRHM7DUyXp896miGdhnBccXKPwFd0vILXznuN0/c7vSwsnUb4uuOuS8mS790/vAuEzFWz5QAzk+9wj+p7pF9ujkbYlV441K1RN+kCqv332h8dpmX683RfivBDTWQFkkvVivsjDa8ejiabeuF08545aCbv9HsnJnzZkGV5X0xUo2qNMrfWD3R/IEavneyeH+j+QEzYBYdeEBNWsncJW2+K76Umm73g4nrF3HP6Pb57rb0P6s2EfhP8uc+I8/7f1e0unur9lO86ptOjTla/VE2towl63UK2vT5XeuEAu1+KoD6o6F6ynxc1bDmR6iTZoKMG0W3fblzZ6cqUrssG4bUEqe7JnKp+vEW9Fp7bNjbfs3nOd8tKxOXHXJ6wAY9GUS4/5vKI/UOObH4kz/7uWc/0ft6VbAr33x38OwDa7tU27Tz2qL6HL6OFVMmGcLyow0UsG7KMo/c+OuVrT9vvNLbfvN3TX1WqhJ9ptte0mHDAZUWR5iResuse7PEgfzrqT/z2wN/GTfPyuS8z4YIJNKod8vtzZPMjfVlCNKrdiHf+8E7KDTIEP2l5WclljO4zmouPuDgmzqtHWAgT0Lki1w4Sc1HeoU0PRYcphzc7PO08qkiVCBfdQQuzRPmlWpaIRCymTEcAPdjzwYRGIX6Eh6mVyhHJXpJmdZvx8BkPJ+zpNdyjIafvf3qEZVS6lhCpclWnqwL5KKtWqcp5h5yX9iRZ2FKoUHf5yjbhZx9kr9erIfnyT18y9pyxHqnT49x2odX5mWwElA9a1W/FTSfexMAjBua7KmUkEx5usj2BbtZKLtL9sfPhKiEI8rGeYOagmWXHYR1seHFVj7Y9WDpkaWD+jQqJQholHdb0sLRXCXtxTvtz2NVul+8ORi5HUYnecRHh76f8neEfp7efR6Es6ssWNnLA/0MO+8WPXkafz0VbQZATQeQ0CO5Vvh1bdOS2LrdF6NQromCAyAbxntPuifDx45UmUw5vGlL1hN/ZbJPJZHOqacoLbrf/5bGNsJFDCtSqVouNf9sYY9sf5EcdbhyD3Ic2HpnU++HfPJzWhJj74xcR3zboFQVBGHLskKyX81TvpxjccXBBTdAHzWcDP2PZhsRbz+ezdz9j0Az+N+t/XPPuNYHmm6t7MuGQIrWr144Jy2SP3mguO/oymtZtWmYJEgTrb1hPveHx/bik87L9qeRPmVTJSEAqQrv7/t1p06BNTHidGnWSWgH9cv0vzF4xm87/C95aKF1SeRf9bCfqh6T7taS5PWqj2o04tGn2dgTMtnrOhIOLdH/sIIVDFakS2OY/Yfas6b3jVnkc6uaaSRdOSto79UO3fbvxyrxXOLBxpDfXTy7+hOOfTG9BG4T25UiX+rXqe+7FXFlJVaWVLxVYtI+qbGHCgcwfcq4b2XTqW7J3SVxProWq532n3zueGxjlklPanBJIPpcedSm/O/h3Mau7wwvm3HRu2Zk3Fvjf1S8IOjTrwKyfZmW1jIZ7NASIWC0dTdc2XePGpUI+9lbPFaZWygPpNvJBjhy8mPvnuWzftZ3DH0nfnnzaH6fFhLVtFFq8dHBRfNfF+RQcXgvdyisi4un2w/3OhY+vOe4a2jRswzkv5caUGZI7eAyCxrUb88OVPyQ0Orj++GA3X8p3xyds3vuXo/8SeN7ZFoBmrYRrhXRAaqWgRxIHFx0cqOlhmDMPOpPPL/k8xv3zxr9t9HQLngnhPblNjZEcEfGcR6gItKzfMrH7mHJgHnrlMSFvBH725G5Spwk6TOl9UO/AyrdFcDkkY7VSOR7CHt3i6JgPsnb12hk5BvPikTMeYeU1KyuMF9dskM/3KFtll+dvI8wZB5wRcX7BYRegw5S99tgrTzUKkW11ti/hICLdRWS+iCwUkRs84oeIyFwRmS0ik0SklStugoj8IiJvRF3TVURmisgsEflYRPZ3wmuKyItOWVNFpHVmt5h9wuqCfRvum+eaFC7VqlSjqE6woxEjc/KtdskWgflJG6Ycu8+xgeQVFLkaXSUVDiJSFRgJ9ADaAX1FJNrA/QugRFUPA8YCd7viRgB/8Mj6YeACVe0APA/c5IQPBH5W1f2B+4C7/N9OZmSyeYkO07LhZrbJhe36nV3vBFJ3omekT0W0Hsu38CkPaqp0KYQ5h47AQlVdrKrbgNFAhAJNVSer6ibndApQ7IqbBHjtpKNA2Pi+PhC2F+wNjHKOxwJdJctPuLy9QEHsy5yM3x/6e3SYmhooy8QzMw4vguy+X3o7huWT0qtKublz7jacypQurbsA6RtA5GIy302uBK4fa6UWgNtJfilwTIL0AwE/xteXAG+JyGZgPRBe0VJWnqruEJF1QCNgtftiERkEDAJo2bKlj+KyT3iXN699pw3DixpVazDpwkl0fbprRE+wRb0WLB2ylKZ1yt/IrUW9FjTao1G+q+GbY/c5lu03b4+YKH/2rGdp36S9r+u/GfwN81bNy1b14lIQcw5+EZF+QAkhVVIyrgJ6qmox8BRwbyplqepjqlqiqiVFRYWhyz6s6WHoMI3Z5S0o+h3mvROdUb6J1xPce8+9czJKrIh0Ku7Efg334x8n/8NX+mgLqgsOu8C3l9l9G+7Lbw74Tcp1TJdMrSv94kc4LAX2cZ0XO2ERiMipwFCgl6om3OFERIqAw1V1qhP0IhDec7CsPBGpRkjltMZHPdMmvKNS30P6ZrOYjHnmrGd8u/M1yh8Vcc4hX+xZc08WXrGQY4oTKTnKJ4WkVpoGtBWRNoQa7vOB37sTiMgRwKNAd1Vd6SPPn4H6InKAqi4AugHhcdl4oD/wGXA28L5m+aupW6Mu629YnzMPlobhprzNeRn5JbzSvEPT7O6fkVQ4OHr/wcBEoCrwpKrOEZHbgemqOp6QGqku8JLzoi9R1V4AIvIRcBBQV0RKgYGqOlFE/gi8LCK7CAmL8PZhTwDPiMhCYC0hYZR14k0MGoaRG/yqgCo7+zbcl08u/oQjmx+Z1XJ8uc9Q1beAt6LCbnEdn5rg2hPjhL8KvOoRvgXInd8AwygQ8rFgLLxrX6p7lweNqUtT47h9jkueKENshbRh5Jl8rgU4svmR3HjCjYzuMzpvdTAKE3O8Zxh55vBmh1NFqjD0xKE5L1tEuKPrHTkv1yh8TDgYRp5pUKsBO2/Zme9qGEYEplYyDAOAry77ijl/npPvahgFgo0cDMMAiLsZlFE5sZGDYRiGEYMJB8MwDCMGEw6GYRhGDCYcDMMInPMPOZ+2e7XlimOuyHdVjDSpsBPS27dvp7S0lC1btuS7KmlRq1YtiouLqV49t77iDSMImtZtyoLLF+S7GkYGVFjhUFpayp577knr1q3LnWMzVWXNmjWUlpbSpk3F3GjeMIzCpsKqlbZs2UKjRo3KnWCA0KrVRo0aldtRj2EY5Z8KKxygfLtCLs91Nwyj/FOhhYNhGIaRHiYcssjFF19MkyZNOOSQ3StP165dS7du3Wjbti3dunXj559/zmMNDcMwvDHhkEUGDBjAhAkTIsKGDx9O165d+fbbb+natSvDhw/PU+0MwzDiU2GtldxcOeFKZv00K9A8OzTrwP3d70+YpnPnznz//fcRYePGjeODDz4AoH///nTp0oW77ror0LoZhmFkio0ccsyKFSto3rw5AM2aNWPFihV5rpFhGEYslWLkkKyHny9ExKySDMMoSGzkkGOaNm3K8uXLAVi+fDlNmjTJc40MwzBi8SUcRKS7iMwXkYUicoNH/BARmSsis0Vkkoi0csVNEJFfROSNqGs+EpFZzt8yEXnNCe8iIutccbdkepOFRK9evRg1ahQAo0aNonfv3nmukWEYRixJ1UoiUhUYCXQDSoFpIjJeVee6kn0BlKjqJhG5DLgbOM+JGwHUBi5156uqJ7rKeBkY54r+SFXPSON+Coq+ffvywQcfsHr1aoqLi7ntttu44YYbOPfcc3niiSdo1aoVY8aMyXc1DSOC6lWqs33X9nxXw8gzfuYcOgILVXUxgIiMBnoDZcJBVSe70k8B+rniJolIl3iZi0g94BTgopRqXg544YUXPMMnTZqU45oYhn++uPQL3ln0Tr6rYeQZP8KhBfCj67wUOCZB+oHA2ynU4Uxgkqqud4UdKyJfAsuAa1Q1ZmNbERkEDAJo2bJlCsUZhpGI9k3a075J+3xXw8gzgU5Ii0g/oISQKskvfQF3F3sm0EpVDwceBF7zukhVH1PVElUtKSoqSrfKhmEYhgd+hMNSYB/XebETFoGInAoMBXqp6lY/hYtIY0JqqzfDYaq6XlV/dY7fAqo76VJGVdO5rCAoz3U3DKP840c4TAPaikgbEakBnA+MdycQkSOARwkJhpUplH828IaqlvmmFpFm4hj/i0hHp45rUsgTCG2Ws2bNmnLZyIb3c6hVq1a+q2IYRiUl6ZyDqu4QkcHARKAq8KSqzhGR24HpqjqekBqpLvCS064vUdVeEDJZBQ4C6opIKTBQVSc62Z8PRDsXOhu4TER2AJuB8zWNFr64uJjS0lJWrVqV6qUFQXgnOMMwjHwg5bFnHU1JSYlOnz4939UwDMMoV4jIDFUt8YqzFdKGYRhGDCYcDMMwjBhMOBiGYRgxVIg5BxFZBfyQ5uWNgdUBVqc8YPdcObB7rhxkcs+tVNVzoViFEA6ZICLT403IVFTsnisHds+Vg2zds6mVDMMwjBhMOBiGYRgxmHCAx/JdgTxg91w5sHuuHGTlniv9nINhGIYRi40cDMMwjBhMOBiGYRgxVGrhkGxv7PKCiOwjIpOdfbzniMhfnfC9RORdEfnW+d/QCRcRecC579kicqQrr/5O+m9FpH++7skvIlJVRL4I71HueA+e6tzbi44nYUSkpnO+0Ilv7crjRid8voicnp878YeINBCRsSLyjYjME5FjK/pzFpGrnPf6axF5QURqVbTnLCJPishKEfnaFRbYcxWRo0TkK+eaB8KerxOiqpXyj5CH2UXAvkAN4EugXb7rlea9NAeOdI73BBYA7Qjt5X2DE34DcJdz3JPQbn0CdAKmOuF7AYud/w2d44b5vr8k9z4EeJ6Q63eAMYQ8+QI8AlzmHP8ZeMQ5Ph940Tlu5zz7mkAb552omu/7SnC/o4BLnOMaQIOK/JwJ7UT5HbCH6/kOqGjPGegMHAl87QoL7LkCnztpxbm2R9I65ftHyePDOBaY6Dq/Ebgx3/UK6N7GAd2A+UBzJ6w5MN85fhTo60o/34nvCzzqCo9IV2h/hDaemkRoD/I3nBd/NVAt+hkTcjl/rHNczUkn0c/dna7Q/oD6TkMpUeEV9jmze5vivZzn9gZwekV8zkDrKOEQyHN14r5xhUeki/dXmdVKXntjt8hTXQLDGUYfAUwFmqrqcifqJ6Cpcxzv3svbb3I/cB2wyzlvBPyiqjucc3f9y+7NiV/npC9P99wGWAU85ajS/isidajAz1lVlwL/ApYAywk9txlU7OccJqjn2sI5jg5PSGUWDhUOEakLvAxcqarr3XEa6jJUGLtlETkDWKmqM/JdlxxSjZDq4WFVPQLYSEjdUEYFfM4Ngd6EBOPeQB2ge14rlQfy8Vwrs3DwtTd2eUFEqhMSDM+p6itO8AoRae7ENwfCW7jGu/fy9JscD/QSke+B0YRUS/8GGohIeIdDd/3L7s2Jr09o+9nydM+lQKmqTnXOxxISFhX5OZ8KfKeqq1R1O/AKoWdfkZ9zmKCe61LnODo8IZVZOCTdG7u84FgePAHMU9V7XVHjgbDFQn9CcxHh8Asdq4dOwDpn+DoROE1EGjo9ttOcsIJDVW9U1WJVbU3o2b2vqhcAkwltNQux9xz+Lc520qsTfr5j5dIGaEto8q7gUNWfgB9F5EAnqCswlwr8nAmpkzqJSG3nPQ/fc4V9zi4Cea5O3HoR6eT8hhe68opPvidh8jwB1JOQZc8iYGi+65PBfZxAaMg5G5jl/PUkpGudBHwLvAfs5aQXYKRz318BJa68LgYWOn8X5fvefN5/F3ZbK+1L6KNfCLwE1HTCaznnC534fV3XD3V+i/n4sOLI8712AKY7z/o1QlYpFfo5A7cB3wBfA88QsjiqUM8ZeIHQnMp2QiPEgUE+V6DE+f0WAQ8RZdTg9WfuMwzDMIwYKrNayTAMw4iDCQfDMAwjBhMOhmEYRgwmHAzDMIwYTDgYhmEYMZhwMAzDMGIw4WAYhmHE8P9eGwOgEIhg/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(final_state_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(next_state_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = range(1, len(losses) + 1)\n",
    "plt.clf()\n",
    "plt.plot(epoch_count, losses, 'r--')\n",
    "plt.plot(epoch_count, val_losses, 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss', 'Embedding Loss', 'Final State Loss', 'Next State Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(epoch_count, embedding_losses, 'y--')\n",
    "plt.legend(['Embedding Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(epoch_count, final_state_losses, 'g--')\n",
    "plt.plot(epoch_count, next_state_losses, 'b--')\n",
    "plt.legend(['Final State Loss', 'Next State Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(path=root+\"/../models/custom_rnn_uniform_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = seq_model.predict(x=X_test[n:n+1], a=A_test[n:n+1])\n",
    "Y = Y_test[n:n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 100, 21), (1, 100, 21))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_states(Y[0], Y_hat[0], overlap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3hcxdWH39muXfViVau4945tbKqxwQSICaEEA3EIJQFSCaGkl48EUkhP6CWQBEILNgaMCxgDtnHvtmTJtqze+2rrfH/cK1mSJavsSitL8z6PHu29d+beI1va3545Z84RUkoUCoVCMXwxhNoAhUKhUIQWJQQKhUIxzFFCoFAoFMMcJQQKhUIxzFFCoFAoFMMcU6gN6Avx8fEyMzMz1GYoFArFWcWOHTsqpJQJHc+flUKQmZnJ9u3bQ22GQqFQnFUIIU50dl4tDSkUCsUwRwmBQqFQDHOUECgUCsUwRwmBQqFQDHOUECgUCsUwRwmBQqFQDHOUECgUCsUwRwmBQqHoOcV7IXdDqK1QBJmzckOZQqEIAR4nvLwcpIR7D4TaGkUQUUKgUCh6xqd/gdqTIAzg84JRvX0MFdTSkEKh6J66Ivj4D2AJB+mHhpJQW6QIIkoIFApF96z7Gfh9sPhn2nFtYQiNUQQbJQQKheLMnNwGe1+Bc++BjAXaubqC0NqkCCpqkU+hUJyZTb8Hxwg4/17NKwDlEQwxlEegUCjOSOPxbey1zQZrBNiitDhBnRKCoYQSAoVC0TVNVTjcFawsieW9/cUgBESmQq1aGhpKKCFQKBRdUpm3E4CjpPOj/+2nutENUanKIxhiKCFQKBRdUpy9A4Brll5GTZOHn686oHsESgiGEkoIFApFl7gK91ElI7j83Gl8Y9EY/re7iFx3NDSWgdcVavMUQUIJgUKh6JLw2iMUWUdhNhm5+6IxjEsMZ+UxoV2sKwqtcYqgERQhEEIsFUIcEUIcFUI82Ml1qxDiFf36ViFEpn4+UwjhFELs1r8eD4Y9CoUicJpcbtI8J3DFTgTAYjIwKz2GPHe0NkDFCYYMAe8jEEIYgb8BS4ACYJsQYqWU8mCbYbcB1VLKMUKILwGPAjfo13KllDMCtUOhUASXw4f2M0u4cIyc1nrObjFx0BMDAhUnGEIEwyOYCxyVUuZJKd3Ay8CyDmOWAS/or18DLhFCiCA8W6FQ9BMlOdsBSJ0wp/Wc3WIk1x2lHajdxUOGYAhBKnCyzXGBfq7TMVJKL1ALxOnXsoQQu4QQG4UQ53f1ECHEnUKI7UKI7eXl5UEwW6FQnAlX4X78CCJGTm09Z7caaZQ2ZFiM8giGEKEOFhcD6VLKmcC9wL+FEJGdDZRSPimlnCOlnJOQkDCgRioUww2/XxJec5gqSypY7K3nHRZtNdkXnqJiBEOIYAhBITCyzXGafq7TMUIIExAFVEopXVLKSgAp5Q4gFxgXBJsUCkUA5FU0MMqfT3PshHbn7RYjAB5HivIIhhDBEIJtwFghRJYQwgJ8CVjZYcxKYIX++lpgg5RSCiES9GAzQohRwFggLwg2KRSKANiVW0SmKGkXKAZwWDWPoNmerGIEQ4iAhUBf8/8GsAY4BPxXSnlACPELIcTn9WHPAHFCiKNoS0AtKaYXAHuFELvRgshfl1JWBWqTYvjw5/U5rDmgmqQEm6Kc3RiFJDqrfUJfmO4RNIUlgrMa3E2hME8RZIJShlpK+Q7wTodzP2nzuhm4rpN5rwOvB8MGxfCjoLqJx9ZmMy4xnMsmJ4XanCGFq2gfACJxSrvzLTGCBqv+711XCPFjB9Q2RfAJdbBYoegz/9ulrVFnlzaQXVofYmuGDlWNbmIbjuIx2CAms921lhhBrWWEdkJVIR0SKCFQnJVIKXljZyETkiIwCHh7jyp3ECx2nKhmgsjHFTMODMZ211piBDUmXQhU5tCQQAmBIiScrGri09wKVu4p4tXtJ/H4/O2u1zd7uOWZrezMr+50/p6CWvIqGrl1YSbnjo5j1d5ipJQDYfqQZ8fxSqYb8rClzzrtmkP3CCoN+jYglTk0JFCtKhUDzqrdhfzi5Q8pJ7r1XIPLy60Ls1qPX9qSz6acCkwGwXO3zj3tHm/sLMBqMnD51GT8Eh56Yx8HiuqYkho1ID/DUKYsdzcRwgmZ5552za57BA1eo9a+UmUODQmUR6AYUHxeL7z9XbbZ7mbz9HdZ+825zM2K5e8f5tLs0frhNnt8PLspl6+Y17Ev+ygnKhvb3cPt9bNyTxGXTk4i0mZm6eQkTAbBqr1qeShQ3F4/jjKtBwEjTxfgMLPmETS6vVqDGuURDAmGnxCo5YPQ4XVT/OxNXOVdQ2XCXJKPvMjYt5bxw3ME5fUu/rU1H4BXt59kmnMLPzM+y12mVby05US723xwpIyaJg/XzEyBt+8lZu/TnDc2ntVqeShg9hfVMp1sXNY4iMk67brRILCZDTS5fVqDGhUjGBIMLyF48y74z5dCbcWgYUDeNH0eqMmH/C3I/9xIWtF7PGW7lZi73oflr0JDKdPfuZobR9bwjw9zqW/28MRHeXzbsQ6Aay1beG3bcZxuX+st39hZQHy4lQucG2D7M7DmIb4bvp6Caie7T9b0/880hNl5oppZIhvS5mr9iTvBYTHR5PbqQhB6L6zJ7W33+9Epzhoo2TcwBp2FDC8hMJrg5FblFQAVDS4u/O2HPPlRbr8948D/fo/vlyPgj1Ph2csgdwP3e+4g5XMPYDAIGHcp3PUJWBw8ZHieioZmbn1uGxE1h5nm2QPpC4jyVTHNvZu3dmufPJ/elMeaA6XcND0C47ofQ+ocmHgV0w88wg2mTby6Q61ZB8Lh3GOMMpRgHXV6fKAFu9VIk8sH4SPAVQee5gG08HTu/OcO7vn3zjMP2vBLeOoSaK4dGKPOMoaXECRP13ZDqtxnnv/kOPlVTfzqncOt+fjBZNPGdYzd9TBb/BN50HMHL455jJvDn2RX3FVcPqXN5q+IJLj4B0SWfsZ3U4+w/UQ13wlfjzTb4brnkWExfMWxmRc2n+C3aw7zf6sPcfmUJL7FK9BUCVc+Bl98BkZdxK9NT1C+7Y1++XmGA1JK5MnPtIOR87oc57CYtBhBuJ5C2lg2ANZ1TnWjm09zK/jkaAUubxdegZQ07H8XfC5k9pqBNfAsYXgJQdJ07XvJ3tDaMYBIKdlxorpdemZ9s4cXNh/n6nEWFmRF8/3X9vBpbkXQnrlmVx4pG75JvTGa0Xe/ivmcr/CTA0l8UmHnm5eM1byBtsxaAQkT+br7edIMlSz2bURMvxEiEhFTvsj5vq2cLC7hbx/kcuPcdP56kcC441mYe6cm7iYr3PAvSJnBn6yP86fX1vHZMVWppLecrHIyxnUAnzBBcte9osIsRi1G4NCFoCF0ZeE3Zpfjl+Dy+tlX0Pmn/QP7dxHu1D4cNOz+30Cad9YwvIQgcTIIAxTvCbUlA8aHR8r54j8+5Rer9IZxzmp2v/F7/un/AX/Mv5YXXd/k6xGf8I0Xt/DQG/u47fltLPvbJ7y4+XifnvdRdjmVb9xHlijGfsPTJCWl8surp7DynvP40RUTuWJq8umTjCZY+ius9flsTPwDRr8H5t+lXZt+Iya/izvi9vKtRWP41dJUjKu+BeGJcPEPT93DGo7huucJMxv5s+0f3PXPrRwsqtPiIM6akL5ZnS3syK9iliEHd8JUMNu6HOewmGh0eSFcLwcfQo9g/eEyIm1aSuvWTsS/qtHNe2/9C4BNvinYTmwAj3NAbTwbGF5CYLFD3FgoHiIegd8PjZVnHLJ6XzEAW7Z+Qt4zX0X+bjznZ/+aeIsXLrgfozWc7zX/lTXiW4Tt+xfFNU24PD5+/NYBXt6SC3tehqLdPTZp8zsvsty4Hu+8ewgbv6j1/NS0KG4/fxTGjt5AC6MXwdjLMFbnwdhLT9WvSZ0NcWP4dvxO7p1tQjy9GCqOwOf/ArYOrStiMhBXPsZU3yG+yv/43J8/4oGf/pi630yh/ImrevwzDFd25ZUxXeRizeo6PgBamYn2HkFohMDr87PxSBmXTk5ifGLEaULg80u+/fIuZrp34o5IZ3XEtZh9Tsj7MCT2DmaGlxAAJE8765aG9hfW8t9tJ9ufPP4xPHkh/G4srPtZpwE7j8/PloN5vB33Z9Za7yc5fxXbopdyheth8m9YB4t+CHduhJvfICFtDD+R/+CdyEdYeUM83x6Zx5x3roQ3vwarvtUjO/OLS/ly9V+ocIzFsuQn3U/oyGUPQ3Q6nP+9U+eEgGlfghMfw9OXaDGeFau0QHNnTLsepl7H3bzKp6l/4TeGv2CTTuz1x3tvzzCj5thObMKDIb3r+ABoZSY0IdA9ghAJwc78GuqavSyaMIK5WbHsOF6Ft80S6NOb8tiSU8L55kNYxi8hcsIi6qQd74GOVfIVw1AIpmu5z918ku4WfzfpakHk8Y253P/6Xl7cckJb4njlFnj+CvxNldRlXQ4f/wEeXwgnNrebtzWviivca5jSuIWmhQ/wRdtTXF94A6bUGSwYE68NEgLGXAK3vgef/yuUH8LyxAK+W/4j7GbBSv9CbSmt7HC3dpat+jnJogqu/IO2bt9b4sfCd/ZB+vz256ddry3p2ePg9nWnX+/IFb9HRKaSUrMLlvyCzWm34cCJdDX03qZhQmWDi/hq3fM7Q6AYWjwCr7Z8ZI0K2dLQhsNlmAyC88bGMzcrlka3j4PFdYC2Me6pTce4dWSJ5gWMuYTzJ6awwT8D/+F3wecNic2DleEnBEl6o42SAOIEhTvg0UzY+2pQTOqOo2XaG9jPVh6g+K2fQPZ7VM69j6vkH5l2cDk5l70IXjc8f0W7Za81+wv4smkdvvTzsC/5Ab/58sWMjA3je5eOR3TMETcYYNYt8I3tsPDbcPlvcXx3G/+MuAMfBuTe/57RRn/xfmYU/YcPHJcTP7HL1tN9IyYDvvYR3LEB4kZ3P94WpQnGt3ZqP0tkCgANFaHPeR+sfJpbySxDNq7wVIjsJI7TBrvFSKNL/yAUnhAyj+CDw2WckxlLZPUhFto1j7klSeDd/cVUNLi4KT4XDCbIPJ9zMmP5gLlY3NWQv/lMt+4RUkp++OY+th0/+xMThqEQ6I24A4kT7P63lj/9v7sg94Pg2NUFXp+fvPJGbpqXztgEBzLnfY7HLuSCLedQ0iSID7dw345Y/HduBGsErP85oPWcbdr/DqmiHOP8OwGYkhrFpvsXccG4M/R8dsTDkp/DvDuJCndwy5K5fOybQvPOl7WYRGf4/TS++W3qpJ2mC34U7H8CjaSp2ht8T4lIhKg0AMzRmhDUVqi04a7YnFPCucbDmDupL9QRu8WE0+PD55danKBx4APxhTVOjpTWs2RsBLz0RWL/cwW3Ru1iS572pvzi5hNkxNlJr96seTi2SGxmI67MRbgxw+G3A7ahvEHbDf/794+cdu3h1Qd5c9fZ8/s2/ITAHgtR6X2PE/h9+A68RU7EPDyxY+CVm/s1Cym/qgm3z8+MkdE8f1UkKVTwRNEoxiVF8Pa3zuOhyyeyp6CW1w81amvrR9fBsU3szK/mavdqnGFJMP6KPj//c1OT2WC5mLCmwq4/Re1+iYiy7Twmb+bimRM6HxNCwmJSAWiqVPsLusKds544ajFMvrrbsQ6rVm/I6dE3lYXAI9hwWHvmVd612tJU3Gh+7PodI4/9l/2FtWw/Uc2dM8MRJXu1RASd+RPS2eibqsUJAtxYeqJS6862Ja+KYxWn6mHtL6zlqU3HeP6T4wHdfyAJihAIIZYKIY4IIY4KIR7s5LpVCPGKfn2rECKzzbWH9PNHhBCXBcOebkme1uc3b9/xTzE2lfOnyrnc0nw/fls0vHRt7zapbfwNHH6n+3FAjr4sNDYxgqSyjwGYeuG1vHLnuSRHhfGFmanMTI/m0feOUD/9Vm3b/7qfsm3bFs437sdwzm1aemYfMRsNjFx4PY3SSvWWl04fUH4E+e6DbJOTcE35EnbL4CtoGxGvCYG7Ri0NdUZ+ZRPnN22g2RylZWx1Q8v/cVPLprIQxAg+OFzG2FgT8Xsfh4zz4I4PKBtxHj/lCUpevJ07LGu41vWmNnjMJa3zLhw/go3+6ZgaiqD2ZBd37xnH27z5v7wtv/X105u0tuv7i+pocJ0dsYiAhUBvPv834HJgEnCjEGJSh2G3AdVSyjHAH4BH9bmT0JrdTwaWAn9vaWbfH/z63UPc/PRWVpYl4K/MZfWOnF7f48C6F2iWZlLOWcbO6jDutfwY6W6Et+/t2SeMgh3wwcOw6tvgbux2eEt8YMyIcMhZCwkTWX7pAiwm7b/OYBD87KrJVDS4+MtHBXDRQ1C4g0sPPoAHM9Z5X+31z9iR6+aPZz1zsWWvbJ+d5G6E/67ALax8w3U3X5g9MuBn9Qcx8Yl4pBF/nept3BlbDh3nMsM2XOOW9SjI3+IRNLn0FNLmWvC6+tvMVnx+yWfHqvhmzBZEfTFc+H2w2PFc9xKveC/iPOcH/NDwAtZtf9P2m7RsJAUy4+yUh0/UDgKsPXSisgmjQXDJhBG8vqMAt9dPUY2TVXuLmZwcgc8v2Xmi834ag41geARzgaNSyjwppRt4GVjWYcwy4AX99WvAJUKLVi4DXpZSuqSUx4Cj+v36BYGg0e1lqzMNA5LnXl/FjhMdAj17Xoa/zIbs90+bv+NYBUmFazkccS4PXT2Hx26YzluFEbwacQvkrIFDbdLSyrPhr3Nhx/Ptb7LxETA7tE9Rnz3Vrc05pfWkRNkIp1lbmhm7+LQx00dGc93sNJ78KI/Jb8aQRxqjZT6FqZdra/4BEmU3Uzv2C4T5G6jdu1o7KSWs/h6y/DA/s9yLJTaV+VlxAT+rP4hx2KggCkMINz4NZlz73sQmPETOv6VH41s8Aq3MRMumst7HCbJL6/tU+DC7tB6Xq5nFVf/W1v+zLgQgLT6KPzm+xQTX8xy5ZbeWGn3bWi0RQkcIQdqE2fikwFsUWBr58cpG0mLCuHl+BhUNbtYdLOLDd1/lEePjrGy4kR+bXzprdrgHQwhSgbY+VoF+rtMxUkovUAvE9XBu0Hjw8gm8efdCHr5rOQDn2gt54PV9p2qU+Lyw4WGozIV/XwcrvwkurRfuyaomnnv5P4wQNYxbdDNCCK6clsJPrpzEQ0ULyTWOwvP2fdBci6w6RvOzV0LFEfzv3A/lejCpcAfkvA8XfA/GLIFP/thtEaycsgbGJEbAsY/A59bmdcJPPz+ZH10xkZvOHc3GjG/iERZGXPrd4PzDARdcdi1lMpqw1ffAExfAS9fAnv+wa9TX+E/FKH5w+cTTS0cMEgwGQZUhFrNTCUFH/H7J+NLVlFnSEGnn9GhOS9/iQDaV7cyv5tI/fMSHR3ovIDvzq/mi8SPszhK44P7WKqlCCK6ZlcYVU1MYPzoLUmZoGWcdmD4qheMyiab8Xb1+dltOVDaREefggnEJTI1sYupbS1l+5Jtcad6G0R7LF02fsC3v7NjRftYEi4UQdwohtgshtpeXB/iPG5EM9nhuTK/haFkDf/9Ar8B5aCXU5sO1z8DCbyN3vkjzn+fzuyee4sLffsA85yb8Riv2yZ9rvdWtC7P48/Jz+Dlfw9hYzu7Hb6Pkr0tpbmrgZvdDNEkrvHGnVo55428gLIb78+fzD+OXtM1Rm//epZk+v+RoWQNjR4TD0bVgCYf0zrM6wq0mbj9/FD/43ERuvfXrmH9YgD3j9FaDfSUjIYrXMn7Ky57zKPFFQPUJnJNuYMXRC7lofAJL2xaSG4TUmeKwu4NXT2mocPToIeZygIqsq7ssO92RVo/A1bbwXO/+JlsEoKtWpGfiQF4h3zG/iUyZ2W79H+C+y8bzt5vO/Hs/OSWSgzIDQ+n+Xj+7BSklxysbyYyzY3RW8bzpYWK9ZXzHfTdHv7wLFv+UaFkLhdtbGy4NZoIhBIVA28XhNP1cp2OEECYgCqjs4VwApJRPSinnSCnnJCScIf2xJwgBydNIqdnFNdMT+PuHR8kuqYNP/4KMHc3B6EU84l3OXZaHKa73cF/xfbyW/gbLI3ZjGLtES9NswxXTkvnL925jc/w1zKhZS5S/hu3nPc3IOVfwkOd2KN4Nr98G2e9RPuV2/ruvhkf3hPGpZQH+zX/VPk2d3AYf/Q4Orz71j1btxOX1MzbBATnrNBfYZOnZz9iXDV3d8NVbVvDuyPtYWHAPaxe/y33er+P2C37++cmn70sYZDgtcUR4AtxEOASp2aLV4Uk478s9ntMaIwhgd/EnRzVR3lfY+7LQ5+b+kRFUIy7/bY/Fqy1ZcQ5yRJZWiM7Zt/4V1U0e6pu9jImS8NI1xLqKuNNzH0UZn2dqZhKMWYxfmLiY7ew5C3pkBEMItgFjhRBZQggLWvC34x7ulcAK/fW1wAapLQ6uBL6kZxVlAWOBz4JgU/fM/gpU5fIr83OEW4w88sSzULSTH5ddyOf++ilPbcrDlXwOBz7/Dt65X2dW6esYG0thUufpdVF2Mwvv+COuyTdgXfEGi5d8jqumJ7PKM4eC9GVw8C2wRfOifylGg+DX10zlkeZrwN2I/P0EeGaxVjP99Tta/6hyyrRlqam2Us1T6SQ+MJDYzEaeWjGHKSmR3P2vHazeW8w9F48hI84RUrt6gidshPYJzecJtSmDBylJzV/JPuMkEkaO7/E0R2vWkO+UR9BQ2uP5dc0edp+sQQgt1bI3cYK6A2u5yruGPSNvhpE9W8rqiMEgaIzV81n66BUcr2wEJFcevA9K9yNueJFblt/Cr6/R9ymFReNLX8hiw46zYsNZwLl+UkqvEOIbwBrACDwrpTwghPgFsF1KuRJ4BnhRCHEUqEITC/Rx/wUOAl7gHinlwPhRk5bBBfdj++g3vDozg8YjH9LgiiJu7goeiY9lyaRE4sJbPlU/CpOXwaFVMOEMOfm2SKzXPdl6ODczlliHhT9b7uA3qQX4p9/Ea+truWBsPDfOTeeczC/x+NMHiHedZMGSa0jLGAvPLtWWkK74XWvq6KjqTdoNu4gPDCThVhPP3zqXG5/ags8v+dqFo0JtUo/whydCBciGMkRUv4Whzip2fLaJ2d58dqd/n6m9mHcqRuAFcxhYInq1NLQ1rwqfX3L5lCTe3V9CaZ2LpKiuq5224qrHvPpb5PqT8V7wUC8sPh1r2nSoAX/xXgyZ5/V6/onKRkaLImLLtsCSX8K4y1jaYYx50pWMOfF9TmTvhUVjA7K3vwlK0reU8h3gnQ7nftLmdTNwXRdzHwYeDoYdveaih6D8MGN2PQJIuPBBvntxF3XYMxZoX73AZDRw6aRE3t5bzC9/vJZd+TUU1W7hgcu1TVdjRkTguOfXfOFvn/LYR/DmPVNJnv0V2PEczL+LnNIGzg0vJezTxyB9AUQPjvTMGIeFVd88D69PYjX1W7ZvUDFEaDGMpqpCHEoI2H68ih2rn2aGwcD5y27v1dxTMYK+lZnYnFPCbZa1fLdyK8fEl9lfWNszIVj7U2xNxTzo+xkvZib2yuaOZGRkUb4vClv+biK630x9Gscrmphn0OtvdfXhcPzl8O73SSxaj9f3BUzGwRuSHbyWDQQGA3zhca18gSkM5t4R9EcsnZJEg8vLxzkV/G9XIXaLkSWTTv0SJ0eF8dyt59Do8nLrc9uon38vGC2w4f8oLSnkT/JRLUh87TNBty0QzEYDYZazQwQALNFa/Zz6CrW7+EBRLbc+/xlXGbfgy7iAyLjeBfptZgNC6B4BaLn6PfUIcjfw5T038WPDcziqD3G36a2exQncjbDrRdbZL8eVPAebObDfvckpURz0Z+DvYwrpicpGLrYe0RJPYrvwiqNHUhs1kQvYzoGiugCs7X+GtxAAWBxw6zta79wg5Nx3ZMHoeCJsJt7aXcTqfcUsnZx02u7bicmRPH7LbI6WNXDPyiLk/LvhwBv8qPJBYv1V8KV/tRZOU/QNe6z279dcNbyFwOPz89XntzHXfJwUWYplRqeO+hkRQujNaXSPwNFDj+D4J/DiF8Dr5v2pjyHm380Vxq0U5R/tfu6JT8Hn5uX6mcxKj+m1zR0ZlxjBETJw1B3VCjb2khOVjczhIGQsPGPA2jTxCmaLbPYe6cHPGEKUEICWBdSTqpZ9wGIysGRiIiv3FFHf7OXqmZ0vSywcE8/Pl03mo+xynvJfhc8WywRxgs+m/gTS5vSLbcOJljITnpriEFsycPj9pwdhj5TUU1rn4qGMQ2AwnznmdQZaS1FDz8tMHPwfXoONy92/Ju3c62De1xDAlMJXup+buwG/0crHnrHMyghcCCwmA9WREzBJD1Rk93q+rMwlxl8F3cQXHNM/j1FIfEfe66upA4ISggGgJcc+PtzKgtFd775dPjedq6an8OgHRbw+6hd833Mnppk3DZSZQ5r46HAqZQSyfniUmcgrb2DyT9ewJa99yuyeghoEfjJL3tdy8MP69qba2pwGtE1lzuozZ2RJCdlrOGKfiSM8kglJERCTwYmEi1nmW0tZVTepvbkfUBI9ExcWZqVH98nmjhiStRC57GUBylqnhwkufU53geakaVSZRpBV9XFfTBwwlBAMABeMSyDGbuaLs1PPGDASQvCrL0xhZEwY9++M5VXfRdpmMkXAxNotlMtoDE1nx07PQPnv9gKcHh/rD7VP69xzsoYLw45pRdemfLHP92/vEfSgzERFNtScYGXTVBaMjm/dhd40606iRSPVn77Y9dy6Iig/xGeGGSRGWkmNDuuz3W0ZkTkZp7TQlN/zVqygFembbzhIsy0B4sacebAQlEVNI9Obi9vbRRn3QYASggHAZjay4XsXcd+l3edqR9jM/HX5LCxGA/HhFmIcPdxApjgjJqOBakMs1mFQZsLnl6218DvWutlbUMtyxw4w2bSslj7SrjlNT8pMZK8BYFXTFM4bcyoWlz5jEXv9WSQceK7rfhd6j+E3a8cxKz0maJsXJ6XFckSOxFXQu0rExysamGc4jDt1fo82tPkTJpIhyjhZOnh/95QQDBAxDgvmHqaPTUmN4k9fmsG9S3q+yUfRPQ3mOOzuob+7+KOcckrrXExIimB/UZ1WCgItyyentJYFrk3QyQ753mC3mNrHCODMHkHO+1SFj6WIeBaMObU8GhFmYRQlYRgAACAASURBVFXY1cQ6j8OxjZ3Pzd2AJyyej+pGsGjCiD7b3JGJyVqpCXvVwV71JqgpPEKyqMI29sIejbeP1Loilh3tv74lgaKEYJBy+dRkls9LD7UZQwqnLZ5IX1XADUkGO6/tKCAmzMT/zaoHv7e1ns/+wjqSqSDcUwmjL+nmLmfGYTXS6G6TNQRdewTNtZC/mS2mOaTH2kmLsbe7XJWub5Qs3H76XL8f8j5kv3UWVrOJy6eeuY1mbwi3miizj8PmrYPq4z2eZy3UGjRZRl/Qo/EJo7XaR87CwKqd9idKCBTDBm/YCMx4oWnwb/nvK7VNHtYeKOWBrFzmbFjOFcatrctDe07WME7oDZRGTAzoOXaLCWeLEHRXZiJ3A/i9/KdmYqfJEuNHJlEkY3GVHD59bul+aCzn9ZqxXDY5iXBrcBsfNSTN01505Y10QlLVdmoM0RA/rkfjHSNG0YQNU8Whvpg4ICghUAwbZLi+ka8XdXHONlbuLcLr83J19XMAXBRZfEoICmqYbdc/tScE1lLUYTFq/QhA24tjdnS9NJT9Pl5rNJ80j+LcToRgSkoUuf4UXCWdpHHmaT3B32+exDWz0gKyuTPiMqdRImNoPLSuZxOkZFzzXk6Ez+x5wTuDgUJzJtH1vW+EhdcFpQd7P6+XKCFQDBuMUdqygrN66G4qe21HAV+L3YWtOhuMVqabC9h1sgaX16cJQViJths2LLAUzDCLSetQ1kJXZSb8fsh5n2PR5+LHwLmjTheCySlR5MoUbLW5py/b5W6g0JyJjEhi4RlSr/vKVTNS2Mo0/Lkf4vF0X5CwIXsjSVRQndi7uhS1EWNJ8xxDdhUQ74rd/4LHF0JVXu/m9RIlBIphgy1a213cOETLTBwta+DAyQq+Lv8LiVNhyjWkubS0xQ+PlHOyyskoTgbsDYDmEbh9/lMpkeGJnW8qK9oFTRWs885gzIhwRkSeXlMoym6mwpqOxdcIbfd5eN3I/C283zyRZdNT+qVWT1qMnfRzriBC1vPS/1adebDfj2v1gxTKOGIWrDjz2A74EiYSSz2VZb3obQ5ap0Ppb1eevj9QQqAYNjji9DIT1UOzif2aAyV80biJKOdJWPRDSJqK1VVBPLU8s+kYAj9xTccDjg8A2PW1emfbgHFDJ0tD+mat18rTzriZ0h+nV+dsu8u37CDC28x239h+WRZqYeZFXwCgfPd7fHCk6xRPufdl4uoO8UrkV5me1bv6TGFp2ua1spydvTOu5oT2/dDbvZvXS5QQKIYNMTGxNEgb3tqhWWZi48EC7rP+D1LnwLilkDgFgEtiy/jseBUjRTlGnzNoHgFwKk7QVZmJhlIkghPuiDMKgT1FEydfeRshKNJaSTbGTWVSSmTANndJ+Aj8IyZzadghvvffPRyraDx9jLsJ95qfsds/isyLet7Ep4URY/TMoYJ9vZrXXK4tCcmTW3vd/Kc3KCFQDBsSIqyUyeh+/YMKFRUNLiKLPiLBXw4XPqAFMnUhuChKC45fGK3voQiiR9BaZiI8UcvG6lhmor4EpzkanzAxL6trIUhLH02jtFJ38lRgtDl/BzXSwZwZXZSGDyKG0Rcz3X8Ym3Rx/RObyS6tbz9g81+xOkv5i/lWrpje+zLmIxJTtZ3tFb0I/EqJqMnnU98kBLJfl4eUECiGDbEOC+VEY2oaellDGw6XMUdk4zdYIEvPb3fEQUQyU0zauvT8iJaMocA3KjraNqcBiEgCZPs1foCGUsplNBOTIs+4S358ciR5MhlP2ZHWc+78nez1j2Le6OBXBT6N0Rcj/G5e+5xEADc8sZn9hbXQWAEf/wH/psd41zeXSfMu61MPDoNBcNKc1bvMIWc1Vn8T6/yzKTclw+H+Wx5SQqAYNpiNBmoMMdhcQ6/e0PpDpSwwZyNSZ4K5TUA2cQpJzqNYjAYmm4sgMhVsUQE/r6UXRWuZiQi9THp9+2U3f10JJ9yRZ1wWAhidEE6eTMVak6ud8DTjqD3CQUYxNTVwe7slfQEYLaRUbuHVr5/LWFM5x59cjvd3E2DdzzgZNpGHfV8OaJNnTcRYUtwnwN+zJozN5dq/Rakhkbdcs5B5G6G5f/oaKCFQDCuqLSlEu0rA4wy1KUGj2eNja04Rk8hDjJzX/mLSFMxVOWy6byEZvvygxAegbd9i3SOI1Hf81rUPxHtqiyj1R7UrK9EZFpOBGnsmUe4ScDdB2QGM0ktd7NSAm9D0CIsd0ufD0XVk7Podr/i+wyWGHbzkWcQS929YXPV9pk+eTHJU3wve+eInYMVNc2nPehOcyNU2oF0wbw7veucg/B7Ieb/Pzz8TAQmBECJWCLFWCJGjf++0pq0QYoU+JkcIsaLN+Q+FEEeEELv1r+AVElEoOuFk+DRMeKFwR6hNCRpb8ioZ48nRauunz29/MXEK+D0kNh9DVGQHTwisLcHiM3gEfj8mZznlRPeomYyvJXOo8iiek1p2jSNrAHtxjLoYyg/Dx48hJl9D2L27WXLfC1yx6GImJUdy98WB9Syx6ZlD5bm7ejS+PF8LnC9dOA9n4myqRUy/LQ8F6hE8CKyXUo4F1uvH7RBCxAI/BeYBc4GfdhCMm6SUM/SvoRfFUwwqKmJnAuDKG9z14XvDukOlnGvWP2V29Aj0gDGH3wFvM4wIjhC0dNlr0gvaYY8Fo7W9R+Cswih9uKwJRNu7r6LrSNFsayo6RM3Rz6iQkYwbG3hgu8fMWA4zboKvvg/XPAERSaRGh/GdxeN46xvnMTklsCWqhKzp+KWgqWCv1hXtxKdQ1HUJbFf5MWpFBFExsVwzeyTvembiz34fPM0B2dEZgQrBMuAF/fULwNWdjLkMWCulrJJSVgNrgaUBPleh6BPTx2Zx2D+SHR+9w5/W5XCsopEPj5Tx5AeHee3t1cizrCCdlJINh8pYHJ4HcWNPb7caN0Z7g97/mnacEJw31lNLQ7pHIIQWMG7rEeiBY1tcz9qsJmZOwi8F1fkHEMW72OfPYnZmbFDs7RERSXD13yF9Xvdj+0BmcjwnZCLpR1+CRzPhucvh2aVQdnoNIp9fYm04SYNN+7f7/IwU1so5uKQRKvtQqqIbAhWCRClly/98CZDYyZhU4GSb4wL9XAvP6ctCPxZnKDQuhLhTCLFdCLG9vHzoBfsUA8PyeenET7qQWSKbP687xMW/+5CvPLeNpvWPsmzbLVR31ylrkHGwuI7i2iYmeA6dviwEYDRpXkCl7jEEIWMITgWLW2MEoPXVrjslBO4azTuIGTGyR/cclzaCAhmPv2gPMY25FIRNIHYI9eOwmY1stJxPtSEGZt4EX3xGKwX+6le0uEgbDpfUkSzLICYDgBERNsToRSwxPIN/xJSg29atEAgh1gkh9nfytaztOKl9lOrtx6mbpJRTgfP1r1u6GiilfFJKOUdKOSchIaGXj1EoThE/+WJs0snaG2N4+AtTeOWOeXw14jPMwkdT/dlVmXRnfg2jRDFWT23nQgBauQmAyDSwBWdjlsVkwGwUp2IEoHsEp5aGSou0XbFJqZk9umdylI18QyrJFZ9gxI8/uf/3Dww0WzLu4hLno3wy7gGYeq22BFV+BN57oN24HccrSRMVRCSd6oB29ewMCuo87C+qDbpd3QqBlHKxlHJKJ19vAaVCiGQA/Xtna/yFQNuPBGn6OaSULd/rgX+jxRAUiv4lYwEAo5r2ctO8DOZZ8oh0arn2zqb6M80cdBwqruMCq75UkN5FIbTEydr3IMUHWrBbTKdiBKAFjOuKWwvHVZVqCwGZmaN6dD8hBDX2TC3oDcSN60LYzmJ+sWwy6bF2bn1+G+sOlsLoRXgXfAd2/pOtK59sXZo8kpuLVXiISDoVoL50UiKb7r+YaWnB6dnclkCXhlYCLVlAK4C3OhmzBrhUCBGjB4kvBdYIIUxCiHgAIYQZuBLYH6A9CkX3RKZAdIYWrAPY+9/WS66mhhAZ1TcOF9dxYVge2OMhtos33CR9KSFIGUMtaKWo23gEkcngdUJzDQDOqiLqZRjpiT3fEOaL1TKHSmU0U8YPvQ59IyJtvHznfCYmRfD1l3Zwz792MufTuWz3j2Pcjp/zm9X7kVJSka9trBMxma1zbWYjI2PtXdw5MAIVgkeAJUKIHGCxfowQYo4Q4mkAKWUV8Etgm/71C/2cFU0Q9gK70byEpwK0R6HoGRkLIH+LVhLhwJt4bNqblfssEgK/X3KkpJ6pPj0+0FWILXm69ml91EVBfb7d2qY5DWjlraE1TiDrS6g1xbU2qu8JYXrNoSOGMWTE9c+bXqiJcVh46fZ5zMmM4cMjZSyalILtonuJEQ3s/XQ13355N2GNeoVcPUbQ3wTU7kdKWQmc1vNOSrkduL3N8bPAsx3GNAKzA3m+QtFn0s+FPf+Bz56CpgrqZ95D7K6/4Wo+e4SgoNqJ3V1JnKEQ0u/qeqAtCr4X/O5Y9rbNaUDztADqi5AjJmJpLsft6F08L3HUVPxbBTWxU4PWpH4wEmEz8+/b5+P1SywmA3jGIzffy3cSsrluz1S+adRX2aN6FmgPFLWzWDE8yVioff/w12CLxjfhKgC8zrNHCA6V1DHD0MX+gQHAbjG2b07TxiMorHES569GRPauXPPorFHcwY/xzLkziJYOTgwGoYkAgDkMMXoRc5o3851LxjArsg4ZntS+XEg/EtwGoArF2ULcaK2GfmM5zFqBLUIrgeBznT1CcLi4ntEGPUsnyOv/PcFhMVFS12ZzU4sQ1BdzqKiOhaKG+tie7SFoIdxq4s8/+DZ2ywCUlRhsTLgScfhtvjOpEQqd4BuYZSFQHoFiuCLEqSybadcTZg8HwO/qpBb9IOVwSR3TbBVaCeggpYX2BrvVdGpDGWifXsNioa6I3IJi7MJFdGLvi7Q5rKYhvSzUJeMuA2HUyk3XnNASGgYI5REohi+zVoDRAukLMLk1T+DsEoJ6vmcq1XYUhwCHxUhj2/RR0OIE9SWUNB8HwBrdO49gWGOP1ZIYDr4FtYUwTXkECkX/M3YxXPsMGAxgcQAgz5KqpE1uL8crG0nxFWrLXCFgRKSNigZXezGISIb6ImrK9GIC4Z0VG1B0yYQrtBIS0jegHoESAoUCwGDEhRnhaep+7ADx5q4C7vlX5z1uj5TUEyEbsXuqtHpCIWBWejR+CXtO1pw6GZmMv64Yf73e/Ceid8HiYc/4z516PUCpo6CEQKFoxSVsg0YI6ps9/GLVQVbvK6au2XPa9cMl9WQJva5PiIRgpl5aeseJ6lMnI1IQjeWkUKEdK4+gd8RkQJJeEkR5BArFwOMWNozewSEET206RnWTJgDHO2mmfri4jglmPdc8REIQFWZmXGI4O/LbCEFkMgLJZMNxpNEWlG5ow45pN2g7xSN73xu5ryghUCh0PAYbRl/oYwQVDS6e3pTH5BQtE+hYJ0JwqKSe2eGVIAzQpgzBQDM7I4Zd+TX4/Xq9Sb1BzUzTcYhI7Hq3s6Jr5t8D39mnVY4dIJQQKBQ6HmMYJl/wm370lr9uOIrL6+f3109HCMgrby8EUkrNI7CUacsHptCVap6VHkOt00NehZZ11WTTmgymyRKEig/0DYNBa505kI8c0KcpFIMYnykMsz+0HsHJqib+tfUE189JY0JSJGkxYad5BMW1zdQ1e0n1F4ZsWaiF2Rnt4wSflLURJRUfOGtQQqBQ6PiMYVj8ofUI/rExF4MQfOsSbW9AVnz4aUJwuKQOkEQ35YdcCLLiHcTYza1C8O5RFy7M2kUlBGcNSggUCh1ptmOTzfj8oWlX6fb62bLnIF8fU01yVBgAo+IdHKtobNdCc19BHYmiRgtsh2gPQQtCCGZnxLDjRDVen58N2eU0mPWy0xFKCM4WlBAoFDrSbMcuXO0rag4gHx8t507vv/nu8bvg31+CqmNkxTtocHkpb3C1jttTUMN5MXrufog9AtDSSHPLG1l3qJSaJg+ipQppuIoRnC0oIVAodITZThiu08smDBCr9hSTaapEhsXCsY/gb/M4v+zfABzTA8ZSSvacrGF+lJ6yGR+a8hJtaYkT/O79bCwmA5Ej9PpCKlh81qCEQKHQEVY7YbhDIgROt4/3D5SQZa1HZCyAb26H0RczavejjBJFrXGCgmonlY1uJlvLwBTWmq4ZSqanRWM0CI6WNbBwdBymaD3/XcUIzhqUECgUOgarA7tw0dDJTt7+5oMjZTS6fcTKau2TdGQKXPVnpMHMLeb1rUKwWy/nkObXawwZQv8nHGYxtu55WDwpUdvXIAwDuiFKERgB/RYJIWKFEGuFEDn695guxr0nhKgRQrzd4XyWEGKrEOKoEOIVIUToEqIVwx6TVStF3dQ48D0JVu0pIsUhMLtrT62tRyQiJn2e6wwfUVCmlWzYc7IGq8lARMOJkAeK29KyPLR4YiLMvBluWwuOuBBbpegpgX6ceBBYL6UcC6zXjzvjt8AtnZx/FPiDlHIMUA3cFqA9CkWfMdk0IWhurB/Q59Y3e9hwuIzrJ+ifg9pm25xzO+E0MqrkPUDzCKanOBA1xwdFoLiFuy8awwtfnUtipA3MYZA2J9QmKXpBoEKwDHhBf/0CcHVng6SU64F2f11C6zyxCHitu/kKxUBgsWmlqF3OgRWCtQdLcXn9LM3UT7TNtkk/l7Kw0VzuXEWz28v+olouSHCC3zuohCAhwsqF43rXn1gxeAhUCBKllHoJREqA3kSH4oAaKWVLZK4AUIuKipBhsUcA4BlgIVh/qIzkKBvjHfrGsbYegRDkj17OJHGCXZvX0uzxs8CSo10bREKgOLvptqqREGId0Fke2A/bHkgppRCi33biCCHuBO4ESE/vffs7haI7rLoQuJsHtktZUa2T0QnhiIY87UTH/Ptp11O/73fEbf4Vr1jczNp1WGsAM2LigNqpGLp0KwRSysVdXRNClAohkqWUxUKIZKCsF8+uBKKFECbdK0gDCs9gx5PAkwBz5swJzdZPxZDGEqYtDXmbBzZYXNHgIiPdDvUlWraNI77d9YzkRF73nc9Xmt+nyJCAvPRhxKwvgzViQO1UDF0CXRpaCazQX68A3urpRKntmf8AuLYv8xWKYCP0dpV+18D2JKhscBMfboWGEnCMAIOx3fX4cAt/N97Mje4f8qP0FxELvhGSZvWKoUugQvAIsEQIkQMs1o8RQswRQjzdMkgIsQl4FbhECFEghLhMv/QAcK8Q4ihazOCZAO1RKPqOWRMCn2vgPIImt5cmt4+4cCvUl3Zan0cIQVJCHJv9k5mWrlIyFcEnoM4HUspK4JJOzm8Hbm9zfH4X8/OAuYHYoFAEDbNW6E26B84jqGxwA9qnfhpKutwpnBXvYG9BLdNHRg+YbYrhQ+i3JSoUgwV9aWgghaClmFz8GTwCgHGJERgNgulpSggUwWfgeqEpFIMds9YVaiAb2FfU60JgN0JjeZcVO1csyGThmHhiHWrzvSL4KI9AoWjBHIYfgWEAG9hXNmpLQyOMWrOZrjyCcKuJGWpZSNFPKCFQKFoQAo+wYfQOXLvKFo8gxl+lnVA1/BUhQAmBQtEGj9GGyTdwQlDZ6CbSZsLSVK6dUDX8FSFACYFC0Qav0YbZ52zXGrI/KW9wndpDAKqGvyIkKCFQKNrgM9qx4sLl9Q/I8yrqXacyhkAJgSIkKCFQKNrgN4VhH8B2lZWNbuIjLNBQCmGxYFJZQYqBRwmBQtEGabYTJlw0unwD8ryKBhdxDqsmBCo+oAgRSggUirZY7NhxUe/q/3aVHp+fmiaPvjRUopaFFCFDCYFC0QZhcRDGwHgEVfoegrhwi/IIFCFFCYFC0QZhsWMXAxMjKG/ZVezQhUB5BIoQoUpMKBRtMFodmHDRMABC0LKrOMnSBD638ggUIUMJgULRBpMtHMsAZQ217CpOoEY7oTwCRYhQS0MKRRvMtnCswkujs7nfn1WhVx6NlS3lJZQQKEKDEgKFog3msHAA3M7+71tc2ejGajJga1blJRShRQmBQtEGo1XrSeBpru/3Z7XsKhYNalexIrQoIVAo2qL3JPAMQAP7ikY38RF6eQlLOFjD+/2ZCkVnBCQEQohYIcRaIUSO/j2mi3HvCSFqhBBvdzj/vBDimBBit/41IxB7FIqA0YXA29z/S0MV9S4tdbS+WHkDipASqEfwILBeSjkWWK8fd8ZvgVu6uPZ9KeUM/Wt3gPYoFIFh0YTANxBC0FJ5tGQfxI/r9+cpFF0RqBAsA17QX78AXN3ZICnleqD/F10VikAxazECv7t/hcDvl1Q1ukmzNkFVLoyc26/PUyjORKBCkCilLNZflwB98W8fFkLsFUL8QQhh7WqQEOJOIcR2IcT28vLyPhmrUHSL7hHg6V8hqHV68PolE7xHtBMj5/Xr8xSKM9GtEAgh1gkh9nfytaztOKl18uhtN4+HgAnAOUAs8EBXA6WUT0op50gp5yQkJPTyMQpFD9E9AuHu377FlY3aHoIM534wmCBlZr8+T6E4E93uLJZSLu7qmhCiVAiRLKUsFkIkA2W9eXgbb8IlhHgOuK838xWKoGMO0773c9/i8nqtvERi7R5ImnrKE1EoQkCgS0MrgRX66xXAW72ZrIsHQgiBFl/YH6A9CkVg6G/IBk//egQVDS6M+Iio3KuWhRQhJ1AheARYIoTIARbrxwgh5gghnm4ZJITYBLwKXCKEKBBCXKZf+pcQYh+wD4gH/i9AexSKwNCXhky+Zvz+/utbXNngYoLIx+B1Qto5/fYchaInBFR0TkpZCVzSyfntwO1tjs/vYv6iQJ6vUAQdkwW/MGEXzTS6vUTYzP3ymIoGN+cYc7QD5REoQozaWaxQdMBrbOlb3H/NaSoaXMw350JEMkSl9dtzFIqeoIRAoeiAzxRGWD/3JKhocDNDHNH2DwjRb89RKHqCEgKFogPSFEaYcON0959H4KopJMlfBmlqI5ki9CghUCg64DdrDeyb3P3jEfj9kpgKvZqKig8oBgFKCBSKjpjthNFMUz95BEW1TibLI/iEGZKn9cszFIreoIRAoeiAsDiwC1e/CUFOWQOzDTk446eCqcuqKgrFgKGEQKHogLDYCevHpaFjRZVMFXmYMhf0y/0Vit6imtcrFB0wWB16jKB/PILm/O1YhRdGL+yX+ysUvUV5BApFB0xWB2HC3W9CEFG2XXuhAsWKQYISAoWiA0argzBcOPthaUhKSXrjXsqsmeCIC/r9FYq+oIRAoeiAsDiw00xTP2woK6tzMkMepiZhdtDvrVD0FSUECkVHLHaMQuJyBV6K+rdrDrP2YGnrcWH2LqJEEyJ9fsD3ViiChQoWKxQd0SuQ+lwNAd3G75c8+VEeE5IiWTJJa97XnPsJALETLwzMRoUiiCiPQKHoiN6cxu8KrF1leYMLj0+yr7CW/Eqtv0FYyTbKiSY2dWzAZioUwUIJgULREYfWCtXWHFhv7MKaU0tLq/dpzfhS63Zz1DoFYVB/eorBg/ptVCg6kjAegHjnsYBuU1itCUGsw8I7+4qhtpAR/jIq4mYFbKJCEUyUECgUHYnJxCPMJLlPBHSbFo/g5vkZ7Cus5diu9QD40lSgWDG4CEgIhBCxQoi1Qogc/XtMJ2NmCCE2CyEOCCH2CiFuaHMtSwixVQhxVAjxihDCEog9CkVQMBgps6ST6s0P6DZFNU4ibSaun6M1nsndsY5GaSVmlPIIFIOLQD2CB4H1UsqxwHr9uCNNwJellJOBpcAfhRDR+rVHgT9IKccA1cBtAdqjUASFClsmI30nA7pHYbWT1Bg7aTF2po+MJrl2N7v8YxibFN39ZIViAAlUCJYBL+ivXwCu7jhASpktpczRXxcBZUCCEEIAi4DXzjRfoQgF1Y4sUmQ5uPueOVRY4yQ12gbAsklRTBD57DeMJznKFiwzFYqgEKgQJEopi/XXJUDimQYLIeYCFiAXiANqpJQt2zcLgNQzzL1TCLFdCLG9vDywbA6FojvqwkdjEBJZkd3ne2hCoKWiXplQhlFIyqOmIlRrSsUgo1shEEKsE0Ls7+RrWdtxUkoJyDPcJxl4EbhVSunvraFSyiellHOklHMSEhJ6O12h6BWNUWMA8JQe6dP8umYP9c1eUmM0IRhRux+A1MnnBcdAhSKIdLuzWEq5uKtrQohSIUSylLJYf6Mv62JcJLAa+KGUcot+uhKIFkKYdK8gDSjs9U+gUPQDnshMvNKAt+QQfclgKNIzhlJ0j4DC7RCdzlcvUz2KFYOPQJeGVgIr9NcrgLc6DtAzgd4E/imlbIkHtHgQHwDXnmm+QhEKbGFhHJdJUH64T/NbhCC1VQh2QuqcYJmnUASVQIXgEWCJECIHWKwfI4SYI4R4Wh9zPXAB8BUhxG79a4Z+7QHgXiHEUbSYwTMB2qNQBAW7xchRmYqpKqdP81s2k6VGh0F9KdSehFRVcVQxOAmo6JyUshK4pJPz24Hb9dcvAS91MT8PUL6yYtBhtxg5IFO5rHYneF297i1cWNOMxWggPtwK2XojmjTlESgGJ2pnsULRCXaLiRx/KkL6oDK31/MLa5wkR9swGAQU7gBhhOTp/WCpQhE4SggUik6wW4zkSj2buaL3mUNFbVJHKdgOiZNbq5oqFIMNJQQKRSdoQpCMREB574WgsNqpZQz5/VC0Sy0LKQY1SggUik4Is5hoxkqjPbXXmUOe5kZK65s1j6AiG1x1KmNIMahRHcoUik5wWIwAVNmzCC/vZnexlLDp93DiUyg7hLm+iKdMM6l3/A0Kd2tjVMaQYhCjhECh6IQwXQgqbFmkF28FnxeMXfy5lOyFDb+E+HGQdQFF7jAuPPRPvJuXQ+IYsEZq1xSKQYoSAoWiEyxGA0aDoMSaAT43VB+H+DGdD85eAwj4ymoIH8HmHQX8Z89IXvb9A46ug6wLQXUkUwxi1G+nQtEJQgjsFiOlhiTtRF1B14Oz39OWfsJHAFrq6HY5Ae9tG2D8FTDrywNgsULRd5RHqPfb9wAADp1JREFUoFB0gd1ipEpGagcNXVS8bSjT9glc/KPWU0U1TuLDrdji0uHGfw+ApQpFYCiPQKHoArvFRBlR2kFjF0KQ8772fdxlracKa5ytVUcVirMBJQQKRReEmY1UemxgMHUtBNnvQUQKJE1tPdW2IY1CcTaghECh6AKH1UijR4I9/jQhaHB5Wf74RjzZ65HjLgO92czukzUUVDlJi7GHwmSFok8oIVAouiDMYqLJ4wNHwmlCcKSkHkP+Zsy+Jp4vH4/L6+Ot3YVc/8RmRkRauWleeoisVih6jwoWKxRdYDcbKal1QvzpQlBc6+QSw07cwsKj2Yk8+9hGTlY5mZsVy+M3zybW0Zd2NgpFaFAegULRBXarkUZX5x5BcbUmBGLUhfzx5nOpbfKwfF46L902T4mA4qxDeQQKRRfYLUacrUtDFe2uNZYfI91Qjhx3KUunJHPppCSt5LRCcRYyZITA4/FQUFBAc3NzqE0ZUGw2G2lpaZjN5lCbMuSwW0w0ub2aEHiawNUA1nAA/FXHARAJ4wGUCCjOaoaMEBQUFBAREUFmZiZCDI8/SikllZWVFBQUkJWVFWpzhhxhZiPNHj9+e7y2htpY3ioEhpadxlFpIbNPoQgWAcUIhBCxQoi1Qogc/XtMJ2NmCCE2CyEOCCH2CiFuaHPteSHEsU56Gfea5uZm4uLiho0IgFYGIS4ubth5QQOFw6oVnvv/9u49tsr6DOD49+lpe3rhUloKtJQJC2SAZQNW8AJbppB4GZuXEOOCKFYkxJnBsjkxXTo1WcIWtuF02WJ2qcxlKp1ThpM4AeNiBKyDDApOnaJCL9QiSGmBlj774/2dcuh6SvG87Wnf9/kkJ7y3c87zy4+cp7/fe3lORwu8DXHTQ9HWBm9hRPFAh2WM75I9WbwG2KqqU4Ctbr27VuB2Vb0UuBZYLyJ5cfvvU9WZ7rUnmWDClARiwtjmgZKd6Q2Y26L53gZ3wvh0x1lGnmmgNWOUVR0zgZBsIrgBeMItPwHc2P0AVX1bVd9xy3XAEaAwye81pt/lZHgjgtZ0N9A9eQSAxuOnKZajnMopSlVoxvgq2UQwVlXr3XIDMLa3g0VkLpAJxFcD/7GbMvqFiER7ee8KEakRkZqmpgS3+xvjo9jU0Ik0N4B1I4K6420Uy8fo8PGpCs0YX10wEYjIyyKyr4fXDfHHqaoC2svnFAF/BO5U1U63+QFgKjAHyAfuT/R+VX1cVctUtayw0AYUpv/FpoZaNd0rLuPOEdQfb6NIjhIZNSGV4RnjmwteNaSqCxPtE5FGESlS1Xr3Q38kwXEjgBeAClXdEffZsdHEaRH5A/D9i4o+gYf+Vsv+uk/9+Kgu04tH8KNvXJpwf2VlJfn5+axevRqAiooKxowZw6pVq3yNwwycHFelrPXM+TeVffxxE8OljfbCS1IZnjG+SXZqaBNwh1u+A3i++wEikgn8FdigqtXd9hW5fwXv/MK+JONJmfLycjZs2ABAZ2cnTz31FLfddluKozLJyM7olghavL9z2po+ACAj30YEJhiSvY9gLfCMiNwFfADcAiAiZcBKVV3utn0VKBCRZe59y9wVQn8SkUJAgD3AyiTjAej1L/f+MnHiRAoKCti9ezeNjY3MmjWLgoKCAY/D+Cc36qaGznRA7mho9k5tnT0Wu4fAEoEJhqQSgao2Awt62F4DLHfLTwJPJnj/1cl8/2CzfPlyqqqqaGhooLy8PNXhmCSdNzU0bAx86M1qRk4c9g4YYSeLTTDYQ+d8dNNNN7FlyxbeeOMNrrnmmgu/wQxq2S4RtMWmhlqb4WwH2W31nCUCw8elOEJj/BGYR0wMBpmZmVx11VXk5eURiURSHY5JUuw+gpOnz8KIQkA5efwIBWebaM0pZHia9bEJBksEPurs7GTHjh1s3Lgx1aEYH6RH0shMT6O13T14DmhuPESxNHMm1x4tYYLDpoZ8sn//fiZPnsyCBQuYMmVKqsMxPsnJjJybGgKONdVTRDNq5wdMgNiIwCfTp0/nvffeS3UYxmc5GZFzl48CrUcPM1WaOVVgpShNcFgiMKYXOdH0c5ePApGmA2TKWdLsZjITIDY1ZEwvcjLdiCB7FKSlk3esFoD0PLuHwASHJQJjepEdmxoSgdxCilv/4+0YaecITHBYIjCmF7nRdO9kMUDuaHK1xVu2u4pNgFgiMKYX2ZkRTp7pAEBzxwDQLlFvqsiYgLBEMMBeeeUVFi1adFHvqaqqoq6urp8iMr3JyYh0jQjas7xnR53MLvKmiowJiGBeNfTiGmjY6+9njpsB16319zP7qKqqitLSUoqL7SamgdZ1shj4REYyFmgfZv1ggsVGBD6prKxk/fr1XesVFRU88sgjPR7b0tLC4sWLmTp1KkuWLMGr6QMPP/wwc+bMobS0lBUrVqCqVFdXU1NTw5IlS5g5cyZtbW0D0h7j6bp8FHi90XukxIixE1MYkTH+C+aIIAV/uZeXl3PzzTezevXqrnoEu3bt6vHY3bt3U1tbS3FxMfPmzeO1115j/vz53HvvvVRWVgKwdOlSNm/ezOLFi3nsscdYt24dZWVlA9kkgzc11H5W2V/3Kf+sgxszIJpvN5OZYLERgU/i6xG89NJLvdYjmDt3LiUlJaSlpTFz5kwOHjwIwPbt27nsssuYMWMG27Zto7a2dgBbYHoSewLp2i1v0RJxtYvt0lETMMEcEaRIX+sRRKPRruVIJEJHRwenTp3innvuoaamhgkTJvDggw9y6tSpgQjb9CJWnObVt5tYc+UVcCAfxn85xVEZ4y8bEfgomXoEsR/90aNH09LSQnX1uaqew4cP58SJE77GavomVpxmWDSdWxdeCfe/D2MHvgKeMf0p6RGBiOQDTwMTgYPALar6SbdjLsGrW5wGZACPqupv3L4vA1VANvB3YJXGzp4OMcnUI8jLy+Puu++mtLSUcePGMWfOnK59y5YtY+XKlWRnZ/P666+TnZ3td+gmgVjd4jvnTSQvJzPF0RjTPyTZ31wR+SlwVFXXisgaYJSq3t/tmEz3XadFZBhekforVbVORHYB3wF24iWCX6rqi719Z1lZmdbU1Jy37cCBA0ybNi2ptiSrs7OT2bNns3HjxgF9FPVgaHtQHW9t59Ft7/CdhVMYkZWR6nCMSYqIvKmq/3fViR9TQzcAT7jlJ4Abux+gqmdU9bRbjca+V0SKgBGqusONAjb09P6hwOoRBNPInAx+uGi6JQETaH6cLB6rqvVuuQEY29NBIjIBeAGYDNznRgNlwKG4ww4BPV6SISIrgBUAn/vc4Lt8r3s9gr1797J06dLzjolGo+zcuXOgQzPGmF71KRGIyMtAT5W6K+JXVFVFpMe5JlX9CPiiiBQDz4lIdU/HJaKqjwOPgzc1lOAYZJDc+j9jxgz27NnT798zRE+nGGMGkT4lAlVdmGifiDSKSJGq1rupniMX+Kw6EdkHfAV4DSiJ210CHO5LTN1lZWXR3NxMQUHBoEkG/U1VaW5uJisrK9WhGGOGMD+mhjYBdwBr3b/Pdz9AREqAZlVtE5FRwHzgFy55fCoil+OdLL4dePSzBFFSUsKhQ4doamr6rO0YkrKysigpKbnwgcYYk4AfiWAt8IyI3AV8ANwC4Ob/V6rqcmAa8DM3bSTAOlWNPRXuHs5dPvqie120jIwMJk2alEw7jDEmlJK+fDQVerp81BhjTO/68/JRY4wxQ5glAmOMCbkhOTUkIk145yM+i9HAxz6GM1SEsd1hbDOEs93W5r65RFULu28ckokgGSJS09McWdCFsd1hbDOEs93W5uTY1JAxxoScJQJjjAm5MCaCx1MdQIqEsd1hbDOEs93W5iSE7hyBMcaY84VxRGCMMSaOJQJjjAm5UCUCEblWRP4jIu+6amqBIyITRGS7iOwXkVoRWeW254vIP0TkHffvqFTH6jcRiYjIbhHZ7NYnichO199Pu0p5gSIieSJSLSJvicgBEbki6H0tIt91/7f3icifRSQriH0tIr8XkSPuac2xbT32rXh+6dr/bxGZfTHfFZpEICIR4FfAdcB04FsiMj21UfWLDuB7qjoduBz4tmvnGmCrqk4Btrr1oFkFHIhb/wneU24nA58Ad6Ukqv71CLBFVacCX8Jrf2D7WkTG45W2LVPVUiAC3Eow+7oKuLbbtkR9ex0wxb1WAL++mC8KTSIA5gLvqup7qnoGeAqvzGagqGq9qv7LLZ/A+2EYTx9Kig5l7lHnXwd+69YFuBqIFUAKYptHAl8FfgddJWGPEfC+xntqcraIpAM5QD0B7GtVfRU42m1zor69Adignh1AnqsP0ydhSgTjgY/i1hOWxQwKEZkIzMKr9dCnkqJD2HrgB0CnWy8Ajqlqh1sPYn9PApqAP7gpsd+KSC4B7mtVPQysAz7ESwDHgTcJfl/HJOrbpH7fwpQIQkVEhgF/AVar6qfx+9S7Zjgw1w2LyCLgiKq+mepYBlg6MBv4tarOAk7SbRoogH09Cu+v30lAMZDL/0+fhIKffRumRHAYmBC3/pnLYg52IpKBlwT+pKrPus2NsaFiX0qKDjHzgG+KyEG8Kb+r8ebO89z0AQSzvw8Bh1R1p1uvxksMQe7rhcD7qtqkqu3As3j9H/S+jknUt0n9voUpEbwBTHFXF2TinWDalOKYfOfmxn8HHFDVn8ftipUUhQQlRYcqVX1AVUtUdSJev25T1SXAdmCxOyxQbQZQ1QbgIxH5gtu0ANhPgPsab0rochHJcf/XY20OdF/HSdS3m4Db3dVDlwPH46aQLkxVQ/MCrgfeBv4LVKQ6nn5q43y84eK/gT3udT3enPlW4B3gZSA/1bH2U/u/Bmx2y58HdgHvAhuBaKrj64f2zgRqXH8/B4wKel8DDwFvAfuAPwLRIPY18Ge88yDteKO/uxL1LV4J4F+537a9eFdV9fm77BETxhgTcmGaGjLGGNMDSwTGGBNylgiMMSbkLBEYY0zIWSIwxpiQs0RgjDEhZ4nAGGNC7n+rKLeZBNpWwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_velocity_curve(true=Y[0, :, 0], pred=Y_hat[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_velocity_curve(true=Y[0, :, 1], pred=Y_hat[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_velocity_curve(true=Y[0, :, 2], pred=Y_hat[0, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(path=root+\"/../models/custom_rnn_uniform.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = seq_model.foresee(x=X_test[n:n+1], a=A_test[n:n+1], lookahead=1)\n",
    "Y = Y_test[n:n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 21)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_states(Y[0], Y_hat[0], overlap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_velocity_curve(true=Y[0, :, 0], pred=Y_hat[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3xbd7n/30fLkrz3dmzHzt6zI23SmU7S0rLaAqXQ0ttboHChhcv9MQpcSuFCC6XQQveCttC9R9ImaXazE9uJHSfeS7Zla1jr/P74Hg3bki3Hsh3H5/165SVbOtL5ypHO833W55FkWUZFRUVFZeqimegFqKioqKhMLKohUFFRUZniqIZARUVFZYqjGgIVFRWVKY5qCFRUVFSmOLqJXsDJkJGRIRcXF0/0MlRUVFQmFbt27WqXZTlz4P2T0hAUFxezc+fOiV6GioqKyqRCkqTj4e5XQ0MqKioqUxzVEKioqKhMcVRDoKKiojLFmZQ5gnC43W7q6+txOp0TvZRxxWg0UlBQgF6vn+ilqKioTFJOG0NQX19PYmIixcXFSJI00csZF2RZpqOjg/r6ekpKSiZ6OSoqKpOU0yY05HQ6SU9PnzJGAECSJNLT06ecF6SiohJbThtDAEwpI+BnKr5nFRWV2HJaGQIVFRWV0wmLzcWTW2o50WEf0/OcNjkCFRUVldONf+6o4zdvVwAHWVGSxrVLC7h8fi7xcbG9dKsegYpKLGjeD241V6MSW4629pKRYOD7F8+graePO1/cR0OXI+bnUQ1BjPjJT37CfffdF/j9xz/+Mffff/8Erkhl3HB0wsNrYO9zE70SldOM6rZeyrMSuf38cj78r9W8/q1VzMhOjPl5TsvQ0M9fO8ihRmtMX3NOXhI/vXJuxMdvuukmPvvZz3LHHXfg8/n4xz/+wfbt22O6BpVTlK468HnA3jHRK1E5jZBlmeq2XtYtygNEYci8/OQxOddpaQgmguLiYtLT09m9ezctLS0sXryY9PT0iV6WynjQ0yRuPWpoSCV2tPX20eP0MD0zYczPdVoagqF27mPJN77xDR5//HGam5u56aabJmQNKhOAtVHcumMfu1WZutS02QDGxRCoOYIYcvXVV/P222+zY8cO1q5dO9HLURkvVEOgMgZUt/UCMD1L9QgmFQaDgfPOO4+UlBS0Wu1EL0dlvOhRDIEaGlKJIdWtNkx6LblJxjE/l2oIYojP52Pr1q288MILE70UlfHEquQIVI9AJYZUt/VSmhmPRjP26gFqaChGHDp0iLKyMi644ALKy8snejkq44lV9QhUYk91W++45AdA9Qhixpw5c6ipqZnoZahMBD1qjkAltjjdXhq6HFy7tGBczqd6BCoqo8FlA2e3+Fk1BCrD0dcLzuF7nI6125Dl8akYAtUQqKiMDn9+AMCjGgKVYXj1W/DCjcMeFqgYUg2BisokwB8WMqWqWkMqw9NWAd11wx5W3WpDkqAkIz54p8cFFW+ALMd8WaohUFEZDX6PIG266hGoDE9PU1Shoeq2XvJTTJgMIWXoH/8W/nEd1O+M+bJUQ6CiMhqsDeI2rUT1CFSGxu0QAoV9PcMeOqhiqOFT2Ph/sPBLULg85ktTDcE4s2HDBq644ooRPefxxx+nsbFxjFakMip6miAuGeIz1WSxytD4NancNvB5Ix7m88nUtNmChsDthJduhYRsuOSeMVmaaggmAaohOIWxNkJSLuiMamhIZWhCCwv6IoeHmq1OHG4vpZlKfmD9r6C9Ej7zJzCljMnSTs8+grd+KAaFxJKc+XBpZGv8k5/8hLS0NO644w5AzCPIysriO9/5zqBje3t7ufbaazlw4ABLly7l6aefRpIk7r77bl577TUcDgdnnXUWDz30EP/617/YuXMn119/PSaTiS1btmAymWL73lROHmsjJOaC3iSkqL0e0J6eXyuVUdITagh6RIFBGPwVQ/MMzbD+WfjkT7D0Rii/cMyWpnoEMeKmm27iySefBAjMI7jhhhvCHrt7927uu+8+Dh06RE1NDZs3bwbg9ttvZ8eOHRw4cACHw8Hrr7/Otddey7Jly3jmmWfYs2ePagRONXqaIClfeASgegUqkQk1BEMkjLuPbOFdww9Y9OrF8NE9ULoGLv7lmC7t9Ny6DLFzHytGMo9gxYoVFBSIjsFFixZRW1vLqlWrWL9+Pffeey92ux2LxcLcuXO58sorx/NtqIwErwd6W0RoSK8YaLcT4mI/QUrlNMA6wCOIQNqJdymVmpAvvRdp9pWQlDfmS4uJIZAk6RLgfkAL/F2W5XsGPB4HPAksBTqAL8iyXCtJUjFwGKhUDt0qy/KtsVjTRBDtPIK4uLjAz1qtFo/Hg9Pp5LbbbmPnzp0UFhbys5/9DKdTrUI5peltAdknQkM65f/UbZ/YNamcuvSE5PmGyBHIji56pERSV35zHBYlGHVoSJIkLfBn4FJgDvAlSZLmDDjs60CnLMtlwB+A34Q8Vi3L8iLl36Q1AjC6eQT+i35GRga9vb28+OKLgccSExPp6Rm+5ExlnPG7+kl5IaEh1XirRMDaBPFZ4uchPAJNXxd27fh0FPuJhUewAjgqy3INgCRJ/wDWAYdCjlkH/Ez5+UXgAUmSxl5bdZwZzTyClJQUbr75ZubNm0dOTg7LlwdrhW+88UZuvfVWNVl8quFXHU3Kg+568bNaQqoSiZ4myJwJttYhPQK920qffmxmE0ciFoYgHwjtma4HVkY6RpZljyRJ3YA/gF4iSdJuwAr8jyzLG8OdRJKkW4BbAIqKimKw7NgTzTyCNWvWsGbNmsDvDzzwQODnX/7yl/zyl4OTQtdccw3XXHNNTNeqEgP8hiAxD2zt4mfVI1AJhyxDTzOUXwS1G4dMFps8PXjjs8dxcRNfNdQEFMmyvBj4HvCsJElJ4Q6UZflhWZaXybK8LDMzc1wXGQ3qPIJJjtshujdHQk8jaPRgTg9JFqsegUoY7Bbw9gkpEkkbMTRkd3lIkHuRjZPPI2gACkN+L1DuC3dMvSRJOiAZ6JBlWQb6AGRZ3iVJUjUwA4i9mMYYM3Aewf79+/nyl7/c75i4uDi2bds23ktTiYbdT8Nbd8Gd1RHruwdhbRIVQxqNaghUhqYnJIwYlxgxNNRq7SNFstFujvIzGCNiYQh2AOWSJJUgLvhfBK4bcMyrwFeBLcC1wIeyLMuSJGUCFlmWvZIklQLlwElPd5FlmVMl9TB//nz27Nkz5ueRx0CJcEpibQDZK8I90RqCniYRFgLQKYZA7SOIGW6vj521nczJSyLZpJ/o5YwOf+loYi7EJUX0CFqtDoqwY01IG8fFxcAQKDH/24F3EOWjj8qyfFCSpLuBnbIsvwo8AjwlSdJRwIIwFgDnAndLkuQGfMCtsixbTmYdRqORjo4O0tPTTxljMNbIskxHRwdG49gPtz7tsXeI255myJ4b3XOsDZC7UPysV/4PVOG5UVPRbOWfO+p4dU8jHTYX3zy3lB9dNnuilzU6AhVmuWCMbAgslnY0kowxMXwP0lgRkz4CWZbfBN4ccN9PQn52Ap8L87x/Af+KxRoKCgqor6+nra0tFi83aTAajYHmNJWTx93Tjh6gtzW6J8iy2OXNuFT8rnoEMaG3z8OVf9qEhMRFc7I52NjN7rquiV7W6PEbgoQcERryT7UbgLVTFB3EJ09CQ3AqoNfrKSkpmehljJy+HtDogjFmlQmho7WJHMDR2UhU/xPOLnHR93d9qh5BTKjvtOP2ytz/xYWsW5TP/7y8n5d3N+LzyWg0k9jTtzYKhVqdQRiCCBuO3m6xkTWPsyGY6KqhqY3XDX87H/755eGPVRlTdH0iIunpjlLl1V8umqA0COnN4lZNFo+Kxi7x9ytME3/P+fnJ9PZ5OG6Z5B3bPU2QmCN+jkuKmCzus4rPoRRtnipGqIZgItn1OLRXwdH3Rl66qBJTjG4l/NDTEt0TXEIhEoMiFazVi7JANTQ0Khq7hEeVlyz8srl5ooxyf0P4UMqkIbSwIC4xYo7A1aukSI1jIzcdCdUQTBR9vfDRvVCwHIzJsOn3E72iqYvPi9krvpiSLcocgcsmbg0hM2X1JjU0NEoauxzoNBKZiUK7aUZ2IgathoOT3RD4S41BJIsjNJT5HJ3ihzGaOxAJ1RBMFFsfFK3ma38NK74Jh1+D1oqJXtXUxNmNBh8AWlu0HoESqjCEaMKow2lGTWOXg5xkI1qNBLKMYcPdrEuvm9wegacP7O39PQJvn7h/IA7lfaoewRTA1g6b/wizrhDzR1feKmLMm++b6JVNTZTS0XY5Cb0jyqozf2jInxsA1SOIAY1dTvJSlHR9837Y9Ae+Ir3BgYbuydsz09Msbv0eQZwintDX2+8wp9tLnMeKV9L29zTHAdUQTAQf3Svmll6gVNjGp4sJRPueh87jE7q0qUifVYSDKn2F6Dy2QV/QsPjlpgeFhiZ5UnOCaex2kJesVGDtF5pdM+yf0ut0Ud85Sb2tnpBmMggxBP29nLaePpKx4dYnwzj3QqmGYDzxuOCN/4LtD8GSrwolQj9n3g6SBrY8EPn5KmOCtUOEgyplRSmlN4rwULgcgc6ois6NAq9Pprlb8Qh8PjjwLzAkEOe2MleqHdfwkN3l4Z63Kvj7xho+qmqj1TqK/9dBhkAZXDQgYdza00ey1Isvbnx1huA06iM45bE2wfNfgfrt4qJ/4c/7P56cDzPWwtH3J2Z9Uxh7t/AIKkINQfr0oZ80sGoIFI9gku5aTwHaevrw+GRhCE5sEZ3ba38N7/yIc7UHONBwEZfNzx2Xtbx3qIW/flTd774nblrB6hknIXhpDZlbASJZDIMSxq1WJ8nYxj1RDKpHMD54PfDoWmg5CNc+Cmt/FX7Aed4isNQMKVGrEnv6FENQ5VMMgT+mOxQuu/DgdCHyHqpHMCoalB6C/BSTCAvpzbD0q5A9j4uMh8bVI9haYyExTsf2H1/AczefQbxBy/uHoiwkGEhPI2jjghpWQ3oENnTjLDgHqiEYH+q2Qddx+MwfYd4QcwVyFN2aloPjsy4VQMhLOGQDx2WlOSwamQmXDfTx/WO5qkcwKpq6xd8uL1ELh16GmZcJj6t0DfO8h6luaBu3hPG2mg6Wl6SRlWjkzOnprCxNZ9PR9pN7MX/pqP+zEsgRDPAIepykSDb04yw4B6ohGB8q3wStQYR+hiJnvrht3tf/fksNHHlvbNamgmzvwEIidl0SXkkHvVF4BG7b4MoO1RCMikBXcedWcHTCfEWerHQNOtlNqfMATd1j73G1Wp3UtNs4ozR4QT67LINj7TbqO0+iGKCnKZgfgBBDMMAjsPaRLNmR1NDQaYgsQ8UbUHJu0CWMRGIOmDMGG4L3fgrPXAtV74zdGt//Oaz/NdTvEom6KYTOYaFHSiLRaKBHlxZdd7HLBgZz//t0pvEJDfU0w6b7wOcd+3ONI41dThLjdJgrXxJhlOnniwemnYVPo2eVZv+4hIe2HhPdvWeUBvV+zinPAOCTox0jezGfD1oOQMaM4H2B0NDAHIGDRGzj3kMAqiEYe9oqoPMYzLp8+GMlCXIXQFOIIfD5xGg7gH/fDB3V4Z87Go5vFp3NH90Dfz8fflcOh16N/XlOUfQuC3ZdCiaDlm5tWvRVQ4M8AuP4eAT7X4D3fwpH3h37c40jDV0OpiXrxMZpzjoh0AZgiEcuWMEqzQEOjIchqOkgIU7HnNzgsMTyrASyEuPYONLwUHuVUBotDJneqzeKCMGAXGBvtwUNsposPi2peF3c+uWKhyNnvjAeHpf4vfWgcJPX/DcgCYE6f+lirNj+sNiBffcgfPbv4HXBkTHyPk5BzO5u+gwpmPU6OjUjMAT6AYZgvDwCizK7adfjY3+ucaSp28H8hE7Ri1F0Vr/HtGXnMU9TS0drlKKAo2BbTQfLi1PRaYOXR0mSWFWWwSdH2/H5RpCnqFMmEhYOGOMeRm8ooDM0zoJzoBqCsafiTchfGuwqHI6cBeJC3F4pfj/2sbhdfANc+wi0HoJ/3QxddbFZX3cDHH4dFn8ZkgtgwecgKT+iXvrpSIKvG48xDZNBi0VKibJqaAiPYKwTmpZj4vbIu9BdP7bnGkcau5zMilNCL2kDJOVLzwMgp2NsR7229jipbrP1CwsB4PNxdlkGHTYXFc3hBePCUrcdTGmDy5EHKJC6vT58DkX4UA0NTRCyLCShY421CRo/FdUP0ZKzQNw27xe3xzaKgdfJ+VB2IVz8C5F8vn8BPHcdHP9kdGvc9RjIPlj+9eB9xmRwnAbDQKJA9rhIxA7mNMwGLe2kCl2Y4T4Pbnv4ZLHsHZvPUiidtZC/THxuP31qbM81TjhcXiw2F6UapWIrdYAhyFuMXRNPSe/uMV3HthqxK18Zagg6quGeQtYYjwCw6egIhl/VbRPewMBO4QEeQZtSOgqooaEJ46PfwB+XhBeBGg2VytC2aPIDwPM76njhmEHUTzftE/0HxzdDyTnBg876FnxnL5z9HajbCk9cKYZenAyePhFemHEJpBYH7zelTBmPoFvpKtbGZ2A2aGmRlS+hbZgveziPYDymlHk90F0HpatFMnX3U+K+SU6jUjqaKzeLkFt8Rv8DNFpazeUUuk96pHlUbDvWQbxBy7y8YH6AHY+Aq5d0y27KsxLYFG3C2NYBHUegcMXgxwbMLW5V5CUA1SOYEGQZ9v4Duk+IJFWM8Plkqj7+J87EaZA5a9jjW6xO/ueVA/zv21XIWXOFR9C8V7iPJef2Pzh1Glz4M7jxDfB5Tj5peOgVccFbcXP/+43JU8YQdHWIMJAhKROTQUezT2nvHy485OoNHxqCsRWe664T/+epJUKfytpwWnSjNylzCNJdjSIsFEZrx5pUznS5Dqdr7Azf1hoLy0vSgvkBtxP2Pit+tlRzdlkG24910OeJomKrfoe4HZgfgEFS1K1Wp+oRTCj+qh6AT5+I2cvWNzcxzbqLF3sX0NIzvKfx4PqjuDw+Ou1u2hJmCENQ85F4sPic8E/KnAXJRSdfVrr9YUgvC8RfA0whQ9BjER6BOSULs15Lo0fZCQ6XMHbZ+yuPwvh4BP7PaloJzLwUErJPi6Sxv4cgwVbX3zsNwZU2m0TJgaVxDCrnEOGZo629rCwJCQsdekUUa8QlQUcNq8oycLp97DreOfwL1m8XY2jzFg9+LC6xX45A9QgmGn9Vz7KboGZDMBE3EFkOjieMAuvOF4iTPDzft5JvP7cbjzdybX5Tt4Pnttdx+fxcdBqJT12FQplwz7OQOTs4DnEgkiSa1Go2RN6Fdp2Av5wt+gNCOfq+2LGsuAU0Az4GfkMwBfoJ7N3igp+Ulo3JoKUuGkPg9Qg9+dBZBDA+HoH/85laIqaiLb5BVHhFO1ntFKWhy4FG8qGznohoCKScuQDY6/ePyRq21IiQT2gjGbseEzm62VdCx1GWl4jH9tVHsVGq2y6qAAf2m8CgZLHfI5A1unGXoAbVEChVPcvgnO8L7ZjdYZJvTXvhscvgt2Ww++moXjb16L854svn81deybZjFv74wZGIx/55/VFkZH546SxWlKTxRqsSH+040j8/EI4Za0XisnZT+McP/Es0tLzyn8GSVK8b3v4RpJWK8MJAjCmADK4RVEdMUlxWYdxTMnMxG7Q0uJRmn6EurO4wyqMQMrd4DKWoO48J3Rp/p2rxKpHst4zNLnm8aOxyMCfBjuTtG1wxpGDKF4bA1zw2EiwbKlpJNetZUKDsyFsPC/G7pTcKz9nWSrLkINWsp264GcpeNzTsGhQW2l/fzc5aSzBZrFSYbT1modDUh2RMGXcJapjqhsDaKKp6Zl2mVOVcBLufCSbf7BZ49dvw0GpRzpm/BF79Fhz499Cva6kh37qHDcbzueHMYq5dWsCf1h/lrx9VB1xgP/Wddv65o47PLSukMM3M+bOyeLcjA1lS/msG5gcGUnyOuABFqvuveFPUJbcdhs33i/u2/000uqz9X9DFDX6OUYmTT4HwkLdXGIL4lCzMBi0OnxbZlDa0zERAgnpgaEjxCMayl8ByTOyY/V5cvKKGOQJv9VSksdvBwngl3DKwYkghIyOTejkDffvhmJ/f65PZUNXG6hmZYjoawM7HROPXouuD5Z+WGorSzJwYzhC0HBAbgpBEsSzLfOu5T/nGkztx6eJFrsftoKatl+3HLMxO8U1IfgCmugx1oKrnCnG79Kvwj+uCF9XX7gCHBc64DVbfKT4UT18jOnz1Zph5SfjX3fc8PiRq88Xr3r1uLicsdu55q4J73qpgYUEypZkirHC0tRcJif88rwyAC2dn88s3DHSZi0m1HYNpZw/9HvRGKFkNVW/Dpff23030torwz5ofCUPw8b1QfDZsuAemXyCqhcIxhQwB9g56MZOgi8NkEF8HX3w22qE8gnBjKkGUj8LYdhd31vbfMZsV73G4KqdTnKYuJ5eYI/QQKKTHx/GRr5D51qqYn39vfRcWm4vzZilhWJddFJHMWScGR6UphqDjKIVppcN3ONdtF7chHsGu453UdojPzqctPs4A6OvhnzssaDUSRWYXeCbGEExtj6DiDeHy+XVAytdCQg68crswCAnZcMsGuOR/haU2mOG6f4q43/NfgYZPB7+mLOPb8xyfeOeQWyg+PGaDjue/eSYf/tdq7rpkFhqNxM7jFnYd78TqdPPtC8qE9C5QnBFPaWY8n2iWiPJAcxRKhDPWilxAW2X/+yvfAmTh8Vx6rzBeT3xGhDYu+XVkF9RvCKZAL4HO2UmvVuQFzAYtAB5z1tA5gnBjKmHsPQJZVjyCUEOgJDbtI9TAOYWQZZmGLgcl2laQtJBcGPY4rUbihL6YNHttMMwZI9ZXtKKRCM4bOPKuyNMt+Yr4Pa1U3CoeQX2nA+9QHcZ120RjZnJB4K4Xd9VjNmiZl5/Eu9XCq3TZu/nXp/VcMCsLg9s6YR7B1DUEzm7RrDXzMtZXtnH3a4fEjIDlXxePnXsn3PxhUBHUjzEJbvi3qHN+6ZuDd39129B01fKS9xxmh2iVAJRmJvAfa6bz0m1ns/HO8/n4zvP46Afncfv55f2Ou3B2NndYrqH3889H917KLxa3VW/3v7/yTVFVlD1PJJwv/iX43CJBHDodbSD+D+MU8AjiXJ04dOL9+g2By5QxjCGIlCMYY4/A1iaMeOiOWWcQhnsSh4Y6bC76PD7RQ5BcIJLgEWg1TUeLFzqOxnQNH1a0snRaKilmRd/oyLsiV+aXujCYxYW9o5rCNDMenxyQzR6ExyWuLSFhIYfLy+v7mrhsfi63n1dGba/wPndW1tLe6+JLK4pEddIEVAzBVDYER94TF8VZV/Do5mM8uvkY3Xa3SBp//wic/+Og6NVAzGmw7gERZ//gF/0f2/scHq2Rt33LmTXAEETLBbOycHtlNlZF6e4n5wuDFdpP4LKJaqJZlwV3/otvgK++LnoQhmIKhYbM3m5ccULbxaQXhsAZlykMQSSpCPcEhYZCK4ZCMWdM6tDQx8rnPMfTFDEs5MeapGyaWg/F7PwtVicHG62smamEhXw+8V0qu6D/AKm0Uug4SlGa8AQj5gkOvwq2Vlj4pcBdbx9sorfPw7VLC7hoTg4JSeIzt/FADTlJRs6dkSk8cNUjGEea9sIHd0NCDs7sxWxXZGf3NXSJJFx8+jAvgAjbLL8Ztv5ZWH+vR4SaDrzE/qTVaI2JwSHcI2TptFSSTXo+qBh6QEqdxc6mI8pOsHwtnNgKLcoXpHq9CFGEyltIkqhCCpcgDmWkhmDbQ0Luwm6J7vhThD6Pl2TZis8owm9mJUdgj8sUek+OCLXigTGVkfoIxig0FNpDEEp8hpDFmKS8ureRglQTZnt9xNJRP97UMjxoYzq8aUOl+J6d788PNO0WhrV8wPyQ9DKwVAcMQcTKoe0PC2NddlHgrhd31VOYZmJFcRpajcTFS0Q4uqa+ic8vK0CLLL5vqkcwDsiyqAT4+0WivOsLT7OrzkqfR9TLR1UbHMpFPxe7hH99Q2j//OM6MJh5iiuZlZuEdJJlYDqtRlQPHWzG4RrcwVjT1sv3X9jLmt9t4IZHtlHbbhOJ7oQsePwykbuofFNc0KedFeYMw+AfnOGMIkfg6BJeUeUb8Pjlwfmsk4D2Xhep9CApht+khIZsumFkJgLJ4kidxWPpEUiQUtT//vjMSRsa6ujtY+ORdq6Zm4Rk74hYMeQnPTmRGl8ucgwNwYcVreQmG5mVo5QOV70LSELbq9/Jp4Ojk1yDA61Gos7iGCzv0bhH5AdW3Byo7KrvtPNJdQfXLClAo1QkXbRYFIckSg4+t6xQ6SmYGAlqmEqGQJbh1dvh9TtE5cytG6FwORuPtKPXSuQmG9lXP8LkqCEern5Y/CdmzIAvPI3vO/t5pyOzn5b5yfCF5YVYnR5e39dfR+j5HXVc8PuPeG1vI9csyQfg/cMt4uLwtbdEffITnxGKouVrh4y3RkSjFcYgGo9g5yOi32Dtr0XC+tGLx2ZmwhjQ3tlNvNSHLkFU3vhzBHZJCflEmh3tzxGEk6GGsfUIkgsGe3Tm9ElrCN7c34TXJ3NVsZL8HSY0lJkYR4VciK9lFKGhqnfg0UvB00efx8umI+2cNysruHE78g4ULB8cGUgXF29d1zHyU0y0trXBH+bCy7cFhwRtf1gUESy6PvC0lz5tQJbhmiXBxHFcvLjgXz4jnsI0c3DTpXoEY4wkQdZcoet//YsBUavNR9tZXJTK8uI09g/hEbg8PjYdaR/cIVy4HP67Eb7yMsy+krpuFzaXN7i7OElWlqRRlpXAM9tOBO6zuzzc+04FS4pS2XTX+dx77UJmZCfwwWElhJRWAje9IySv+7pFfuBkMUYhPOd2wta/ijDZmbfBV18TF8mnrh57KeYY0NUuegWMySIk4DcEPZJyge+L8P4DoaEBhkCrE5ICY+kRhAudxGeKqqFJ2An+yp5GZmYnUqJRvK9hPIKsxDgqfIVorXWRDfVwbHsITnwCtRvZWmPB5vJyvj8/0NMCjbthxsWDnxdSQlqUZqao+R3Rb7LnGVFp2NsK+18UuYGQnf3bB5tZUZwmLvh+lCll5xUrmwd/hZ7qEYwDZ94Ga+4SO16g0+biQGM3q8oyWFCQTGO3k7YIuinprh0AACAASURBVEC/faeCGx7ZxlUPbh5cQxwSAjrcJLpxB1YMjRRJkrh+ZRF76roC53tyy3Hae13892WzyEwUu8ILZ2ezvdYiEt0ASXnCM7j8/4L9ESdDNHpDe58VSbFV3xW/5y+BC34CXccnhVdg6xKVQfGp2UAwNBQwBJHev9sOSMHkcCh689gZgs5j4XfM8RlC/jpSKM/rhhdvErmxU4j6Tjs7j3fymUV5IYnw4iGfk5UUR5WslJe2VYz8pHYLHBMaXnLFm/z+vSoyEuI4u0zpxziqzAYvD2MIUouF+oBSObSq9x3ImCk2l3ufhb9fKKRHVtwSeIrb66OqpYfF0wZc4LV64UH6ZSZOB49AkqRLJEmqlCTpqCRJPwzzeJwkSf9UHt8mSVJxyGM/Uu6vlCRpmOnuseWT6g5kWQymnp8vEqT7GwZ/mfbVd/HIpmOsKsugubuPzzywiV+9cShs/P5wkxWNBDOyR+cRAHx2cQFGvYZnt5+gt8/DQx9Vs3pGJkunBXsLLpidrXRFhiSW4zNg+TdOLizkZ7iZBD4vbP4j5C3pL4pXoJTM1W8/+XOPE1ZFcC4xze8RiGSxVVZ2bpEMgV+COlwOSGccG9G5vh6Rswh3oQw0lUUID3XXCamRj38b+3WNgtf2inzSZxbmCSNnThfl2UOQmWCkwm8ITiZPUPmm6OhNK8Vx4HX21nXyo0tnBTYBVL0j5Dv8c0FC0RlECNZSzQJjK4uopG/+l8TmcvVdYgNUshqygmrDNW023F45fKg4VIF0snsEkiRpgT8DlwJzgC9JkjRnwGFfBzplWS4D/gD8RnnuHOCLwFzgEuBB5fXGhU1H20mM07GwIJl5+clI0uCEsdvr44f/2k9GQhx/vn4JH/zXar64ooi/bTzGFX/aOMg7qGi2UpwRH/xgjYJks54rF+Txyu4G/rz+KJ12N9+9aEa/YxYVppAebwiGh2LFcB7BoVfEl3fVHf0viJmzRH7BL8F7iiLLMlU1tQDoEkQTkb98tMun7PSHyhFEEgbTG8dGdK6zVtyGC534tfsjVQ75LzKVb0U3fW2ceGVPA0uKUkTIZGCjXAQyE+NokDNwac0jKiHtsrvYWtOBfOgVSC7CccYdmJ0tXJvbztWLRa4Nj0tU25VfFLnZMm26EJ/reguPrOF4wZXi/jU/gs89AZ/5Y7/DDzeJz9CsnDCGIHQ4zWngEawAjsqyXCPLsgv4B7BuwDHrAL/G84vABZLIzKwD/iHLcp8sy8eAo8rrjQubjrZxxvR0dFoN8XE6yjITBhmCRzYd41CTlbvXzSXZpCfZpOd/r57P019fia3Py1V/3syf1x+lzmLH65M53NTD7HD/6SfJ9WdMw+by8pcN1VwwK4tFhf0/KFqNxPmzslhf2Yp7CIXTETPccJodj4iKqYHhJ41GjOasO7UNwe66roDOkL87V6uRiNNp6PHoRax/KI9gYFexH51pbDwCS4TSUQgagkhVTv4yWJ9HxLNPAY609FDR3CO8ARCGbpiwEIjwXUKcgSZjefjO/gjc+04ltzz8Ad4jH9JVcikPNpThlSV+UFwTqOSh+kNR+DCwbDSU9OnQUcO0+lfZ4FvIMadSWCBJMPeqQe/hcLMVvVaiNDPMxiFUinqyewRAPhA6QLdeuS/sMbIse4BuID3K544JJzrs1FkcrCoLTkKaX5DMvvpuZCXRebzDxh/eq+LiOdlcMq//zOFV5Rm8fcc5rJ2bw2/fqeSce9cz+/+9zQmLndm5ow8L+VlYkMxcZVrSQG/AzwWzs+lxethRG8M6/qE8Alu7SLbNuxY0Wl7d28hv3wmJ1xaugNaDg4Zzn0q89GkDWdoeZKR+uzCzQYvd7Rv6/btsg5vJ/IyVR9B1XNxGShZD5NCQf7eZlA+7njglksov72lAq5G4fEGeyGF01w9bMeQnMymOSsNskfOIIh8jyzIbKlr5UspBdHi4eWcBD+7o5kT8fLIbPxQHeVzw3v+DlGmDy0ZDSS8DVw96ewsveFcPq0Ja0dRDWVYiem2YS61/Sll3g1Aq1egif67GmEmTLJYk6RZJknZKkrSzrW30XZQblbmjq8qDhmBhQQrtvX00W53IssyP/r0fvVbD3evmhX2NFLOBB65bzEu3ncVvrpnP11YVs25RHlcsyBv1+vxIksTd6+byi6vmMU/JYwzknPIMDFpNbMNDxmSxOwo3BrHqbSF9POtyZFnmd+9U8pcN1VhsSglgwQrx+Ah2bOOJy+Pj9X2NLEuxISXl9eseNRt02F3eoctn3UOFhsxjI0NtaxPy0+FCB369oUiGwO8RnHm7MCg162O/vuNbhFJvFBpAsizzyp5Gzi7LEEUPLQdEslspzxyOrMQ4dsszhTJAFJ+xo629NHY7+XLSHryJ+eTPXUVRmpms5VdDy35R9rxFUQq47LfBfpBwKJVDsjmd7YYVw6qQVjRbI28M4xJFCPUPc0Q3ctGZEyJBDbFRH20AQlWiCpT7wh1TL0mSDkgGOqJ8LgCyLD8MPAywbNmyUdcmvn2gmfwUE6UZwS/0/AJxod1b181GZzufVHfwy6vmkTNEh7AkSSwuSmVxUepolxSRpdPS+iWIBxIfp+OssnTeO9TCFQty0Wk0uH0+atpsHGnpobWnjx9fPpuMhGE6ikPxdxf3WQcL31W8IYTBchfy6YmuwJfho6pWrl5cAAVLxXH128Vs3VOMj6ra6LS7mZFuAdO0fo+ZDFocbo94/31D5AiM4Y0yOmOwvDSW2DvE/0O4C4VWL9YzXI5g8Q2w8XdiolnZBbFd38F/iwl/8RmicmwIPj3RRX2ng+9eqHi4u58WRm5GdLUimYlGNncppZx1W0Vf0BB8VNVGAnbyO7YgLf86912yRDzQXgAf/VzU/u94RIQ5h1uDIkctzf88eUeShjQEFpuLFmtf5FDxrCuERzD9fHHeKEbajhWxMAQ7gHJJkkoQF/EvAtcNOOZV4KvAFuBa4ENZlmVJkl4FnpUk6fdAHlAOjHm5SUWzlY1H2vnB2pn9un/n5Cah1Uh8WNHCOwdbWF6cynUrioZ4pVOHtXNz+NG/93P1g5/0u1+vlXB7ZZZMS+XLZ0yL8Oww+Heezq7+hsBlE7HUpTeCJPHS7nqMeg3xBh0fVrQJQ2BKFWV1p2ie4KXd9aTHG0jpa4Tc/oN/zAat8AiGDA3ZRZluOPSmsWnusneCaQgl2qG6i51dIndhTIJF18HWv4h6+cTs2K2vUwldbfqDkFaYdmbEQ1/d00CcTsPFc7PF33LfC0Lu2RTdZiorMY4PeuMgsxxObBv2+I+q2rgh5SCSs0+cx0+Gojz8yZ/E3+eSXw9/8rQSuOovMOMSijqOUdUSOfxZ4U8UR/IIFn1J/DsFGLUhkGXZI0nS7cA7gBZ4VJblg5Ik3Q3slGX5VeAR4ClJko4CFoSxQDnueeAQ4AH+U5blKKZCj46/bzyGSa/l+pX9L/JGvZYZ2Yk8v7Meg1bDrz+7IJhIOsX53NICitPjcXq8eLwyElCSGc+0NDOrfrOebTUdIzQEEfSGjn4gOmdnXa6EWJq4eE4ORr2Gtw804/b6RDy0cLkYiiPLE+buhqPb4eb9w618eVku0t4mSB3gEegVQ5CSBO0RFEhdtsFdxX7GqnzUYRlaknwo4TlHZzAJueRGceH79AkxYyNWdNaK2dedx+ClW+DWzWFLQd1e8Zm5cHY2iUY97HlRNO4t/WrUp8pKjMPu8uLOX4G+6g2R81DkHE502Ont8zBHyas5XF5qjx3lQdOTkF4eLG/2M/NSERJafedg6Y5ILBL73KK0Fj6oaMXnk8NeJw43x6anaDyISY5AluU3ZVmeIcvydFmWf6Xc9xPFCCDLslOW5c/Jslwmy/IKWZZrQp77K+V5M2VZfisW6xmKFquTV/Y08PllBUHJ2RAWKuGhb19QRlnWxCRuTgadVsOZ09M5b2YWF83J5sI52UzPTECn1bCyNI1txyyBJHhUhJlJ0G134z70WkCe96OqNrrsbq5enM/5s7KxOj3Bod4Fy8XFy1IT5sUnjrf2N+Hy+Li2XBJ5jAFffuERKKGhSOWjQ+YITGOTLPaHhiIRnxF5JoGjK7jbzigTA4m2Phi7ZL4si9xD9lwhudJdD2/dFfbQzUfb6bC5WLdI8ag+fVLE3YcbwBSCv5myK32J8Hbag4NqfvrqAT7/0BZarOL/YPvRRv6k+R1m2QFfeGrwfO4VtwjJ+TNvH8EbFhSmmXF5fLRGaEI93GQlIyFuZCHZCWLSJItjxROf1OLxydy0KnyFwueWFfDF5YXccu70cV7Z2LGyJJ22nj6Otduif1IYj+A/n9qG/cCbWKddCFpdIMSyqjyDVeUZ6LUSH/oVU/07r7pTq7Hsjf1NlGTEM8uoGKxBhkBJFg8lsaH0EbQqRQX90JvGJllstwRCQ26vjyMDQxLxGUOEhgaoWp57p/ASdjwSm7X1tggvMbUYilbC2d8RnbZhNgGv7mkkyahj9cxMaKsS1WdLvjIirzErUeTsGpMWijvqtgYeO9zUQ2+fR8wXkWWS37+TRZoavOv+ClmzB79YcsHQkvNDMJwc9ZCJ4lOMKWUIbH0entl2gkvm5jAtPfyObum0NO65ZgEG3enzp1lZKi4gfrntqBgwnMbt9aGp30Iyvfz8SCk7ay28f7iVKxfmoddqSIjTcUZpOh8cVsIpgcayU8cQWJ1uttZ0cPGcbCR/OWZKmGSxv2rIbROljaH4vOBxYpPjOOPXH/DghgFSGjpj7EXnZFlcuBWP4PmddVz0h4/ZUh3iAZgzIusNhYaGQCTzp18gQkSuEWwOBtDtcFPRbA3mB/ylrYu/LG6PvN9/GS4v7xxs5rL5ucTptLD7SVEyuWhgSnFospLEDvuElCcqppQ8QbfDzbLe9Txn/h1frPgW3Q+sZpHlTV5OvgHD/IGtTaNnKEPg8fqoaukdtebYeHH6XO2i4IWddXQ73HzjnNKJXsq4UpoRT0ZCHNtGYggGeARVLT2cJ+/ArYlju2YRn39oCy6PL9iVidBzr26zcbzDdko2ln1c1YbbK3PhnGxRMihpRW19CP2SxTA4fKJcOG3E4ZPh/veP9E8Y6k2itj2WonvOblFeqXgEfgPwk1cOBJsI4zMj6w2Fhob8rL5LVBntevykl/X7dyu55L6N/O01pRzVb1TTp4su4aP9DcEHB+u43Ps+txjfh20Pw55nRYw+IWtE581UQi2tvS4oPCPgEdQf2srv9Q+y0NhCmt7NUYuHv3quoHP59076PQ5FXooJjST6jQZS22HD5fFNivwATDFD8P5hMY5u6bSxK/U8FZEkiZUlaWyr6Yg+T2BIEAJbiiE40NDNmZpDuAvP5slb15CdZGRmdiILCoJllP7BHoHwUNEZorFsqEHw48h7h1pIjzewpChVGILk/P4TqAjxCAKGcMCFVTEELknIULi8Pn7w4r7g/FqdEZDFYJtY4Y/9m9ORZZmdtZ0UpJo40trLE5/Uisfih9AbCjcCsWgllJwLm+8/aZG8A41WMhPjcLYKr+je7XZ8/r9D2YVQu7FfvsSy6THu1f+N0h0/h7d+IN7X8ptHfN4Usx6DViMEIotWihBU53EKPvw2nSTSef27WK9/i2scP+Yez3WsnhnD6qgQDDoNhWlmasKEXA8p4pNhpSVOQaaUIXjiphX85folE72MCWFlaRqN3U7qO6P80kuSkjAVF8IDdR1M1zRiKlhISUY8731vNf+45Yx+5bfT0uMpy0oIGoJ514iE7J6nY/12Rozb62N9RSvnz8pCq5FEcjNlcBWVWa/D5fXhNSgu/cA8gRL/d2qEIfjCskL21nXx6CZFAmIsxlX6G8LMaTR0OWi2Orn5nFLOn5XFfe8fEYnRQFPZgMohr1uEuMKVZp57p4jv73l2xEuSZZmq5h4unZfDN+Zp6dZl8ODGBv7wvpK4LbtQ/K1ObAHEAJqFba/RapoOP6gR/35Yd1J9JpIkkZkYR6vVKTwCgOe+RLKthh/Lt5Gbm8+Z09O5bmURc3KTKMmIkNiPAaUZ8VS3Du4bqWiyotNITM8au3PHkillCLQaiaykkxsfOdlZUSLCCiMLDwUTpp0nDqPHi5Qt9AQT4nSkxg9OsJ0/K4utNR2i8iajXCiT7no8OLhjgthxzILV6RFhIRAeQThDoIgFOnURhtMozWJOSXyOPr+8gAtnZ/O7dyvFpLixMAT+EaCmNHbWCqOwrDiVn145B5fXx/++eTgoMzGwqWwoDZviVcLYn4Scc1O3k54+D+XZiZh660jKLeMLywr504dHeXl3gxiJqjUEwkObP/mYhZpq5MU3iIEv8cMrjQ7F9KwEDjR2Q94i0YzWepC346+iLXtVoJTzV1fN441vrzrpSYFRrSMzgdoOW9ATUqho7mF6ZoLIhUwCppQhmMrMyEokxaxnW02EEsNwKE1Vbq8PbYdysRim+/Hc8kzcXpltNcrFa9lN4qJb/eFJrjw2vHuohTidhnPKM0S4oqcpbN24XzXWqY3gESihIb8hiNNp+cVVc+nz+HjzQFPIlLJYegTK39Kcxo5aCwlxOmblJDEtPZ5bzy3llT2NHHMoG5yBHoHfmwgnTSFJYr0nYbT8eZGZ2YnQdRwptZhfXDWPlSVp3PniPnY19YkxqYohkHY/hRsd2WdH3y8wFCtL0qhq6cXSJ4nzZM7mF87PMyOk5FuSpDE1AgClmQk43T4au/v/DQ83WSM3kp2CqIZgiqDRSKwoTht5wtjZTVVLD6VyHTIa0Yk5BMuKU4nTafioSrkgzbpC7FZ3PjqK1Y8OWZZ571AL55RniJkD3fXigdTIHkFwXOVAQyBCQw7Ehdeo15CbbCLZpKepyxkyt3gElUMeV3AOcjgCOYI0dh3vZHFRighvAZ9Vxh9u8atL2wYYen+OI1LXrt4InvB18EPhNwQzMgxgbYDUaRh0Gv56w1LyUozc8uQu2nPOgbYK6o/uZ5X9A05knjd4/ONJsrIkpBLuC09jue5NGmyxmQMyEvyqojVtwTyBxeaiqdsZEIucDKiGYAqxsjSdExY7Td1R7gCV4TQHGrqZIdXhTikeWpAL0Z29sjSdjUcUQ6AziHLCqreDF+Bx5nBTDw1dDi6c7Q8L1YrbMB6B3xD0Sv6ZBAMNgQgN2RGVK37XPzfZSFO38+Q8gte+I2Y9R1IFtVtA0tDtM1PZ0sPy4mBj2bR0M2nxBnbV2cSufyShITjpTujK5l6yk+JIcbWIPJBSOpoab+DRG5cjSfCt7eKi7339v0iVekk5+6YRnycSCwpSMOo1bDvWAXEJVHWK0MyMcS7XDBqCYJ7gYKP4zMzNi6BHdQqiGoIpxJml4ov53//eT0dvFLtAZSbB/oZuZmka0OcMnDcUnnPLM6hus9HQpVxgln5VlFN++tTJLn1UvH+4BUkSct2ACFVB2ByBSZlSZsMMSIOF55RksV32ewTCEOQkG2m2OgZ5BN96bjf/3HGCIWneB837B5VbBnBYwJTKp3XdyLLwuvxIksSSohR2n+hUmspGEBoCYQhOohO6qqVH7L7D9GOUZibw1NdXcsiTR4uUzrSubbRrM0lfELsBhAadhiVFqYEQZMBDyR5fNYDMhDgS43T9KocONorPjOoRqJySzMlL4mdXzmHz0Q7W3reRDZXDyFYroaGK+namSc1IWVEaghkicbnRHx5KLRZVJDv+Du/+P/jkgaAO0Tiw+0QnM7MTA9IEdB4HjR4ScwYdGwgNueXwUtT+PgJZvJZRL75CuclGmrudwYE1bgdur4839jXy8u7GyIuT5aBh+uSP4Y+xd4hE8XELOo00aDjR4qJUatptuI3pg8tHhw0NmUbcAOfzyRxpVQxBoJmsv1GdnZvEk19fyce+RQC0lF4TmBUeK1aWpHO42Uq3w01VSw+JRh0541wMIkli6ExoaOhAQzf5KaawEjanKqohmGLceHYJr9x+Nmnxem58bAev7Amr+i0wJouwQfMBNPj6zWIdivKsBHKSjGw8EnJRWvVdMJhh21/h3R/DP74EdcMrR8aChi6HGIfop+uEkBYIc2Hyj6sUTWXhDIEIAfT4/IbAHxoy0d7rwiUpX36Pg6YuJz4Z9jd0B/sMBuLoFF5HyjRRd9+4Z/AxdguY09lR28ncvKTAbGU/SxQJ9E4pabDeUMAjiCSbHTdiQ1DXacfp9olEcWetqA5KzB103MLCFBZc+nV6tKkUX/QfIzpHNKwoSUOWYWethaqWXmZkJ455cjgcpZkJVIeEhg41WgOid5MF1RBMQWbnJvHq7auYn5/Mb9+pxOWJEJtWwgkLZaViKEqPQJIkzinPYNPR9uAFsPhsuGM//E8rfO+wkBaoHHONQWRZpqHTQX6KKXhn1/GwiWIIegSBmQSDykftgITNp0cjgU5J2vpnVrQ7la+U20l9pwgj9fZ5+sWQ++H3BlbfBYZEMSBlII5OfKZU9tZ1sax4sPDcwsJktBqJJldCmNBQl/BstBGEhnUj9wgqFVXN8uwE8bdMLoy42595xuUk/r9a4rOKR3SOaFhclIJBq2HbMYsSqpoYkcjpmfE0dTuxuzzY+jwc67BNqrAQqIZgymLUa/nexTOo73Tw4q4ISVzFECzTVCJrdIHpTNFwzoxMuh1u9tUP6MyVJCzaDE4kLsJX+fbJLj9qrA4PNpeXgtRQQ3AiouSwf7cdcSaBMq/Y6ZEx6rWBHWiuYgha/MU/Hgd1ncFKoL31EQTs/DH2nHkil3Lg34OT6nYLFjmBPo+P5cWDQzxmg47ZuYnUOEyD9YacXUMPRD+J0ZpHlAaqcr9HEMWs4bHAqNeyqDCFN/c30WV3j3vFkJ/STGGAatpsHG6yIsswbxIlikE1BFOaNTMyWVyUwgMfHqHPE6bhSwknLNdUCS33ESg0rirLQJLoHx5SePyTWh5vn42mvSI4lH2MqO8SF+OAR+CyiV1zmEQxBPsIHJHGVSoS1E6PNxAWgqAhaHYooQm36OLWSBBv0LK3LowGEARj7CnTYOWt4udtfw0+Lstg7+CE0icQaVLdkqJUDncbRAWPPxwEiuDcEBelkxDJq2zuoSDVREKcTqw/gnc1HqwsTQt0y0+cIVAqh9ptwURxvuoRqEwSJEniexfNoLHbyT931A0+QDEEGVI3UpT5AT9p8Qbm5SUHy0gVZFnm1T0NfOBbLO6oeuek1h4tDcpFIs9vCLqU9xnBEASSxX6PoC+MR2Aw43T7MIYo1OYki9dvsPkNgZ06i53cZBMLClLYO9Az8tN1QpzHlAIphTDrcjGxy4/bDt4+tjXDGaVpwYT3AJYUpdLsUUIjoSWk4QTnQjkJQ1DV0iPyA06rqGiK8LccD/wd8zBxhqA4PR5JEiWkBxu7SYs3jHvSerSohmCKs6osgxXFafx5/VGc7v5eQbMrxAOIMj8QyuoZmXx6oovGrmCd+t76bmo77DRqcqnTFIj+gljx0b2w87F+d/nPne8PDXWFr3Lxo9dq0GulIUJDdjAk4HT39wgS4nQkGnU09Cg5EbeD+k4HhWkmFhamcLjJOujvG1hPSJhqn1wGvc3I/vp/RV6i1mHkK2cWR3zrS4pSaUfZhfaGVIMNGxoa2SAdt9dHdVuvCAsF/paR1zXWLJ2Wik4jkWrWk5EwMVU6Rr2W/BQTNW3CI5iblzQhSevRoBqCKY4kSXz3ohm0WPt4dlv/eve3q0MuECcxWPuLKwqRgIc+Cmr2v7KnAYNOw1fPLOYt10Lk2k2xmZQlyyLRuu/5fnc3dDkw6jWk+3WRAj0EkccSmvRaHC6PUjVk7R9zd/WCIZ4+j2/QzIrcZCON1j6RPG2vpL7TQUGqmUWFybi9Moebwkw86wyK3+06buHP+8UFZNNWZdiKIi8hm1K5aE5kFc3CNBNWU6H4xRIyI2HgLIKB6OJG1FB2vMOG2yszMychYunoeGI26FhWnMqCgpQJvfiWZiZQ2dxDVUvPpKsYAtUQqABnTk9nRXEaf99YE9C3l2WZFw6EXKDDTXcahoJUM9csKeC5HXW0Wp14fTKv7W3i/JlZrJ2XwwfeJUg+d2x0iLqOi917T/+a/YYuB3kppuBForNWiJQlRL6oBqeUJQMyuEL+Dv5k8QCPAER4qKnbCUVnIJ/YSkuPg4JU4REAg/ME/h6ClGl02V1869nd9CaKWRkfbNpEb5+HlmZR3rtsdpmYBR0BSZLIKyrDiQHajwRff9jQkAl8HvB6Ih8TQmWzSBTP8CeKYUI9AoCHbljGH7+0eELXUJoRT2VLD26vPKk6iv2ohkAFgG+uLqWx28lre8WF9FCTlYNtLrySXlw4U8OP9hyO286bjtcn8/DHNXxS3U57bx9XLc5jYUEKh3SzcGgTY5MnaNorbq1N/RrVBpWO+qtchtg9mg1a7O7QmQQhO3m3XXgEbl+gmcxPbpIxYAiknibyaaMw1UxOkpGsxDj2DawcsrWBx4GcUsT3X9hHW28fd123FlnSkdFXx/3vV/HJfnFRP3/J8B7Z4mnpVPtycbUo5b5uB3j7hq8agqjzBJUtPWgkobpJd70oeR3K0IwDyWY9ySb9hK5hemZQbnqylY6CaghUFM6bmcWM7AQe+qgGWZZ5eXcDeq0GyZQihOYi1aEPw7T0eNYtzOOZbSd4bHMtiUYda2ZmYdBpWFySxRZpsTAEkXR2osVvCLx9/apmGroGGALLMUgb2qj1G1cJ/fMESmhoYNUQiF6C9t4+3PkrAVguVVKQKryRhYUp7BmYMFbCVOtbTLx/uIUfXTqbBUWZSGnFrE7v5NHNtRyqrgUgI3Nww9ZAFhYmUy3n4W2tVNY9TFcxKIN0iNoQHO+wkZ9qEu+9zzp02GkKMV0pITUbtJREGIN7KqMaAhVAqJN+89zpVLb08MHhVl7Z08iamVloMsph2pmjeu3bzivD6fHyYUUrl87LCVxAz5qezsv2+aLK5amrRHz/+bnY/AAAIABJREFUZGfoNu0L/tzTBIDT7aW91xU0BLKseARDGwIxrtIzaFwnoCSL40VoaIDWfF6KEVmGFmMJLl0iyzWVFCgdzYsKU6hps9HtCJmBrIRW3qw3MCc3ia+dXSzuTy9ntr6VRKMOk0fxRqLYdRemmqn25WHsrRfewHCCczBiQ+BweYn3dzYrRlEl2EswOzcpMA9hMqEaApUAVy7MIzfZyA//vZ/Wnj4xj/grr8DaX4/qdcuyErh8vtjRrlsUnBF81vR03vCdweFZ34LOY/Dvm+F3M+HTJ/n0RCdrfruev2yoHn68pixD055gw5tVGIJBFUO9raIPIG3omdUmg67/uMpQ4TmXLZAsjhsQGvKXkDZbXdQlzGe5pjJQRugf6bk/NDykVN3s602iPDshmMfIKEPXWcM9V89hZbaMHJcE2uFDHznJRqrJQ0KGjurhBecgZJBOdIZAvG/FAPb1ipGmKmQnxZGRYGBJ0eT0kFRDoBLAoNPw9VUltPf2kRinEzOIdYaTDguF8uPLZ3PXJbMCCqggZHrNxjie0H8evr0XbnwT8pfAq9+i+pGb6LT28Ju3K/jhv/YHh7SHo6dZxNtnXKL8LvIcfvXTgEdgqRG3w4SGzPoBA+z9HoHPKyps9OE9An9TWWO3k0O6OZRrGtA6xcV4Qb6SMA4ND3WdQDZnUNMt9Q9fpZeDt49LCjycna9BModvIhuIXquhy6S8t/aqKENDSl9ClJVDLo+POH/SWjGKKiJZ/+rtq/juRUPP6zhVUQ2BSj++uKKI9HgD6xbnDYqBj4bcZBP/sWZ6P7dZq5E4ozSdT6o7QKNBnnYW7y39K3/xXcXnpA/Zmfd/3LUqlX/urONrj+2gx+kO/+L+/MAMReZY8Qj8zWQBj6BT6WIexiMQoaEwhkCRoBahocHJYr/eUHO3g62ecnGnIqyXbNZTnG7mQEOIR9B5HHdiAR6fHFwjBIf/tB8VfQSm6AwBgDu1BB+SqByKKjTkn58Q3XCaPo836Am5bKpHEEJeimmQIOBkQTUEKv1IiNPx3vdW8z+Xj7yB7GQ4UxmWc+n9G1nw83e5+endvJ19C71XP4m+/RD/wQv89toFbKnp4HfvVIZ/kaa9gMSG3gIhxdwTDA1pJMj2d3laakDSiDr/ITAZtDjcocliJTTkz18YwpePJsbpiDdoaep2sqGnEI+kCwxvx+fj59LDzGsI6XPoOk6vSYTK+nkEGYoR6TgitIOi9AgAMlJTaJayoL0yytCQf35CdB5Bn8dHnL9/Qs0RnDaohkBlEGnxhph6A0NxybwcFhelkJ0Ux9WL8/nplXN45hsrSVi4DhZdB7uf4XMzDXx2cT7/3FmHxeYa/CJNe5HTy/jeKzUcdyUFDEF9l4OcJGOw/t5yTMhPD6OZFEgW6wxivoA/xKIYAlkf3z9WriBJErkpJmrbbTTYoC1hDpxQpLY3/4HVvW9yo/1xZEenqJLqqqNDL2Yi9BPFM6eLi3f7EdFQZo5+vGN+iokj3lxkf2hI0gQNWjhGmCx2hTbSuXohTvUITgdUQ6AyoeSlmHjptrN5/GsruHvdPL52dokQMwM469vgdcG2v3LLuaU43T6e2nJ88Is076M7ZQ4Wm4sT7mScFqHe2dDp6B9y6Tw2bFgIRLLY6fbh8w0YTqMYArdWVALF6QZ/fXKTjew6LnbiPdlLofFTOPYxfPgrWlIWES85sW15VBgrn5sGsgJ/hwCSJLyC9iqwd44oNJSbbOSIL1cJK3WI8JZmiK/5CA2B8AgUA6jmCE4bVEOgcuqSPh3mrIMdf6c82ccFs7J4YkutqOjxY+uA7joOy8UANMup+LqDyeL+PQQ1UTXGBWcSDNAbat4PQF+8COeE85pykoxYnaJLVyo6UxiyZ78IyQVUXvAom71zMex8GDqOAnDMk0FavGFwbDm9HFoPi67mEYSG8lJMVMt5SB4HtBwcvux0xFVDXgxajUicu+1qjuA0QTUEKqc2q+4Q5Zs7H+OWc0ux2Fy8+GmIXn+zSBSvt+YyMzsRKTkPs9uC191Hc7czuNN2dImYeRQewWAFUiVHcOhlSCnCnj4XYFCyGIKVQwBJM1aJH7x9cO1jFObm8DfvZRjszbD5PgAqnKn9jZWfjLKgiugIOnfzU0wc9Skluo17hs4PwMlVDek1IfkS1RCcDqiGQOXUJm8xlK6BrQ+yotDMwsIU/r6xJjj5TKkYeqk5g1XlGeQViAv9gcqq/tU4gYqh4T0C/7hKR+i4SkcXVK+HOetwKhPdBpaPQrCXwKDVkJmVB0tvhMt/DwVLyU8xsYlFtJtKAvpK+3qTwhuC9PLgzyPIEeQmG6mW88Qv3r7hO39HXDWkJIsDhkANDZ0OqIZA5dRn1XehtwXpkwe49dxSjnfYeftAs3isaS/O+ALaPGZWlWcwa4YovXxny24gTA9BFKGhRKMI0/T0uYOhoco3weeGOVfjdCuGIExoKDdFeAT5qSZRKnvl/WLyGKJPIy8lnneSrgVATsihtsvbP4/hJyOkHn0EoaG0eAM2XTJ2rZIgHjY0NPKqIYNO9QhON1RDoHLqU7Ia5n4W1v+StfbXKc2M5//eq8RzYjvUbKDWUIZBq2FlSRrZ+eJCf7xWxOAD1TiW6D2CRKPo4u1xhswtPvgyJBdB/pLANLdIyeJ+5x3AtHQzL3nOgvhMPMnTcLi94T2CtBJR8QMjShZLkkR+ipkmvVIiO2xoyJ8sHt4j8Hh9eH2ySBb7FVlVj+C0YFSGQJKkNEmS3pMk6YhyG3b7IUnSV5VjjkiS9NWQ+zdIklQpSdIe5V/WaNajcpoiSfDZh2HGpWje+j4PzDzA+Zbn0Tx2KRgSud9zDUumpYiEa6IIi2QhdPwDOQLLMSE9HcWFK+AROD2iasjRKUI5cz4DkjS0R5AkzjeUIThi8cB1z1O74ucA4T0CXVxw8tcIPAIQXskxlDzBcB6BVg+SNqocgUvp7u4XGlLLR08LRusR/BD4QJblcuAD5fd+SJKUBvwUWAmsAH46wGBcL8vyIuVf68Dnq6gA4oL1ucdh+vnM2flj/kf/DOvlJdRc8yZvtaVzTnmmOM6chk8bR7bURapZH6zGibJ0FEI9AiU0JHtFWGju1QCBSWPhksVJJh0Xz8nmglnh5x0Up8fT7XDTlTqPam0xQHiPAIKNZSPwCADykk0cdivnj0YdVBfdAPs+xQAa1BzBacdo+6HXAWuUn58ANgB3DThmLfCeLMsWAEmS3gMuAZ4b5blVphp6I3zhGXjrTprjZ3LzByUUPy+mcZ1TniGOkSSkxBymS1YKU8zB51qOiaRzFPTzCPwyE8mFkL8UCDUEgz0CSZJ4+CvLIr52kaJGWtthDwxdj+Q9kLuQ/9/evQfHdVcHHP+efa/ekq3YkmzJJjEkIYHYMUl4hLSxwyNQTKe0NNA07cCkzHQKLdAShn8KpTMwdJqWocM0DY/AAKUJtAlhJpCYtMlMhyTOg8RJnNh5WH7I8VPyQ9ZKu3v6x713tVrdlXa9Wm33t+czo/Heu3e1v5vfZo9+5/fi4JOQaAt/vozBnjRPTa2COIunhsD771rBPILZFkHUm0wG1kfgiFoDwSpVHfMfHwLC/gwaAop3Rt/vnwt8R0RywE+AL2uZpSZF5GbgZoDh4fLbDBrHJdpg2zdYDXz45DP86NFRetric3aFks4B3pqe5rzrL/FOzJz1FqKroH8AigPBDHT6v/fibYXNbDLZohRJldat9P6C3nvsDPtPnKU9ES2/qcrVn4HL/7Tq9xjsSfGD3Plk+9YQG3jT4i+IpSsKBEGLIBmLeCuPggUCRyz6SRaRB0RkZ8jPtuLr/C/wRdYLnuejqnopcLX/c2O5C1X1NlXdrKqb+/v7q3wb46JPX/d6OpIxrt7QT7R4DfiuAToyhwtbRBa2VKwwNZSMRUnEIl6LoG+9l0O/9PcLzy/UIlhM0CLYe2zSm/DWmy6/1248Dd1D4c8tYLAnzVG6efx3H/JaFYuJJSsaNTSd8+7bUkPuWbRFoKpbyz0nIq+JyICqjonIABCW4z/AbPoIYA1eCglVPeD/e0pEfojXh/C9iktvWlp/Z5Kf/cU75v9F3TkIL/7S26dAZHbEUBXbbXalYt4M4aHL4ZbROZ2iwTyC0v0IKpGKRxnoTvHqsTPzt9FcIkEH+cGJCjelj6crGjU0NRPSWWyBwAm1dhbfAwSjgG4C7g655hfAu0Sk1+8kfhfwCxGJichKABGJA+8HdtZYHtNi1q9sp6+9ZBG5rgFvA5pgRnCF+xAU60jGZpe9LhkZk6mhRQBeq6C4RbDUBv1JbQfHvXRPLq/c/vDLHD5ZJv0TS1U0aqiQEov7w0ejyYo2zDH//9UaCL4CXCciu4Gt/jEisllEbgfwO4n/DnjM//mSfy6JFxCeBp7Cazn8W43lMQY6/f19/X0JOP6y1+lbxTDMzlSc05ls6HOF1FDIzOJKrFvRzouHTjFxdoahnuo6giuRTkTpbYsXdmi7/7lDfPnnz/PTJw+Ev6DCUUPTfiBIRP0WgQ0ddUZNncWqegzYEnJ+B/DxouNvA98uueYMcHkt729MqCAQnDoI7Sth510wXN2+y52pmNdHECKTzSMC8ei57U07srKNU36QqUeLALz00MHxs6gq//qQ1yLae2wy/OJ4ytsAZxGFiXTBWkOWFnJGc26nY8xCuoJAcAie/U/vS+u6L1X1KzpTMY4ePRP6XLBNZdlO3kWM9M1+gdajjwC8HeH2n5jk8b0neHJ0HBEYPR5+P15qqIJRQ8WjpTKnbMSQQ2yJCeOeoEWw6+fwxPfhyk9A/xuq+xWpeNkWQdg2ldUYWTGbDio7h6BGQz0pDoyf5baHXqa3Lc51F63i1aNlWgSxVGWjhrIlncUWCJxhgcC4J572llbYdS90nAfXlM5xXNxCqaGwbSqrEQSCRDRCf0fynH/PQgZ70pyayvLL517jxqtGuHB1J2MTZwvpnTniqYpGDc22CKKWGnKMBQLjpqBVsPWL3lLS1b7c7ywuLHddZCqbrykQdKbirOxIMNCT8lYorYMBP+WUiEW48a3rGFnRTl4pzGaeI5aucNRQyTwCCwTOsD4C46ahTdDeD2/68Dm9vMufXXw6k503TyEzkzunWcXFLhroquu+0EP+cti/t2kN/Z3JQitk9Ngk5/eXpHRiyapGDXmpIesjcIkFAuOmD3zDm1C20H69CyheZqI0EEyFbFxfrW98ZBPn2NdckUuGuvmTt63jz67xZlOPrPD+en/1WEiHcdxfYiKYgFfGvNSQDR91hgUC4yaRBb/UFjNnT4IS3qih2loEZdcXWiLJWJS//cAbC8crOxK0J6LhQ0hjKUC9/ZVj5fss5q0+aqkhZ1gfgTEh5qxAWiJTY2dxI4gIwyva2RvWIihsTrNwemg6lyMWEaKa86611JAzLBAYE6IjWbQCaYlah482yroVbew9HtIiKGxXuXAgyMwE+xXbyqOuab5PszHLIEgNhS0zkcnmvDx5kxle0ca+45PzR0IVNrBfeOTQ/P2KLTXkCgsExoQIRg2dDO0jaNYWQTszOWWsdFXSoF9gkbkE09l8yaY0Fghc0XyfZmOWwZztKktMZZuvjwBgpGgvhDnifotgkdnFmWzOX2fIUkOusUBgTIhUPEIsIuVHDTVjICjsjlYSCCrsLM5k87Mrj4INH3WIBQJjQoiIv8zE3BaBqnqpoRqHjzbC6q4UiWhk/sihSkcNZfOzK4+CpYYc0nyfZmOWSdjCc4UN3JuwRRCNCGv70iGpoQpHDQV9BLZfsXMsEBhTRtjCc3O2a2xCIyva588urnDU0HQhNWSBwDXN+Wk2ZhmEpYZq3aay0UZWtDF6fBLVoiGkFY4amu0sttSQaywQGFNGWGooaBE0bSDoa2NyOseR00Vf+hWPGiptEVggcIUFAmPKCE0NZYMWQXP+rxOMHBot7ieoqrPYn0cQS0OkOYOhma85P83GLIOuVJyT81JDRStwNqF1hVVIqw8EXmexbVzvIgsExpTRkYxxOpOdk09v9hbBUE+aeFTYffjU7MlYpaOGct4SE5nTlhZyTHN+mo1ZBp2pGKpwZnp2e8epJu8sTsQiXDzYzZOj47MnIxGIJitaa8j2K3aTBQJjyghbZqLQWdykqSGATcM9PL1/nBl/TgTgtQoWHTVUtNaQtQicYoHAmDLC9iQIWgTJJk0NAWwc7mVqJs8Lh4rSQ/HUgqOGVNWbR2AtAic176fZmDor3q4yEGzX2OwtAoAnRk/MnowlF+wsLsyoDvYjsBaBUywQGFNGkBo6GdIiaNbOYvA6jM/rTM7tJ4ilFwwEmTkb11uLwDXN+2k2ps66FkwNNW+LQETYONwzt0UQTy04aigzU9IisOGjTrFAYEwZYZ3FhdRQE7cIADYN97L32CRHgxnGsVSFqaGoDR91UHN/mo2po7DO4sxMDhG8pRaa2KaRXgCeCtJDiwSCwhpL0SzkZywQOKa5P83G1FFbIko0InOHj/pj6UWkgSWr3aVD3cQiMpseiqcXHDUUtITa1A8W1kfgFAsExpQhInQkY/P6CJp1MlmxVDzKxYNds4EgllxwHsF0EAjwg4UFAqdYIDBmAaGBoImHjhbbNNzL0/snyOby/qihxVsEqUKLwFJDLqkpEIhIn4jcLyK7/X97y1x3n4iMi8i9JefXi8gjIrJHRH4sIolaymPMUitdgXRqJt/0HcWBjcM9TE7neOG1U4uPGgrWWFJrEbio1k/0LcB2Vd0AbPePw3wNuDHk/FeBW1X1AuAE8LEay2PMkupKxUtGDeWaduXRUpuGvb/bnhgdX3SJiSA1lMr7gcCGjzql1kCwDbjDf3wH8MGwi1R1O3Cq+Jx4vW3XAnct9npjGsXlFsGa3jTd6Ti7xk76gWDx1FAi7y9fbakhp9T6iV6lqmP+40PAqipeuwIYV9Xg/7L9wFC5i0XkZhHZISI7jhw5cm6lNaZKnakYpzLFi87lmnoyWTERYbAnzdjElDdqKDcN+VzotUFqKJG3UUMuii12gYg8AKwOeeoLxQeqqiKiIdctCVW9DbgNYPPmzXV7H2OKlW5XOZXN052ON7BES2uwO8XBiam5+xYn2uZdF6SGEjlrEbho0UCgqlvLPScir4nIgKqOicgAcLiK9z4G9IhIzG8VrAEOVPF6Y+ouSA2pKiJCZiZHqjPZ6GItmdXdKR4fPeGNGgJvUllIIAhSQ/FssHG9tQhcUmtq6B7gJv/xTcDdlb5QvW2fHgQ+dC6vN2Y5dKbi5PLKWX9mbSbYt9cRgz1pxidnmA4G7JWZVBa0CGJBiyA+P1iY5lVrIPgKcJ2I7Aa2+seIyGYRuT24SEQeBu4EtojIfhF5t//U54BPi8gevD6Db9VYHmOWVOkyE948Ajc6iwEGur1tKsdn/Hsqs8xE0CKIZc9CvN3b1cw4Y9HU0EJU9RiwJeT8DuDjRcdXl3n9y8AVtZTBmHoq3pNgVVfKmZnFgdV+IDieiXIelA8EfosoMmMrj7rIwroxC1jR7vUHvHrUS4m4NHwUYLDb6xs4mvHvqcykskzOX2Pp7AlIdi5X8cwycecTbUwdXLG+jxXtCX68Yx+qylTWzRbBET/1X75F4G9cf/ApWHXJMpXOLBcLBMYsIBGL8AdvWcv2519j9Pgkqv7mLI5IxaP0tSc4dNZfTbXMpLJMNs9gdAImRmHtlctYQrMc3PlEG1MnH7liGAW++7+vAjjVIgCvw/hQ0CIokxqazua5PLLbO1hr3XqusUBgzCLW9rVxzev7+Y/H9gHNvU1lmIHuNAdP+3M0y44ayvFmXoBoEla/aRlLZ5aDBQJjKvBHV45wZtpfgdOh1BB4LYJ9p7zhoQsNH70k/wIMboSYLRLsGrc+0cbUyW9feB6Dfseqc6mhnhRHp/x7KhMI8jNTbMjtsbSQoywQGFOBaES44YphwK3OYvCGkGbw108q00cwePYF4mQtEDiqpgllxrSSj141wu7Dp7lsuKfRRVlSq7tTTOGne8qMGnrd1HPegzUWCFxkgcCYCvW1J/j6DRsbXYwlN9idZoYoeSJEymxOsyHzHEdiq+nvrGaledMs3GrjGmOqtqo7CQi5SCJ80TlVLszu4pW0TSRzlQUCY1pcMhZlZUeCaUmGdxZP7GOlHme0zQKBqywQGGMY6E57/QRhLYJ9jwJwsPPSZS6VWS4WCIwxDHSn2Mugt5ZQqX2PMkmS4x0XLH/BzLKwQGCMYaA7xX/nLoHDz8LJsblPvvI//EY3EI/bRDJXWSAwxjDQk+b+jN8H8NKvZp84ugeO7OKXuctJxtyaSGdmWSAwxjDQnWKXriWb7p8bCHb9DID7sptJODaRzsyymjXGMNCdRolwbNXb4eUHIe+vPbTr5+RWv5kxVjg3o9rMspo1xhT2Ln6l50qYPAaHfuP1Fex/jOkLrgfcW1rDzLKZxcYYVnWlEIHfJDZxFcCe7ZDuBeDM+vcAB0hYH4GzLBAYY0jEIqzsSPLSZNrbb+ClX0EsCX3nM9m9AThgLQKHWc0aYwBY25tm/4mzcMEW2PcIvPIwXPg+MjmvvyAZt68LV1nNGmMAGO5rY/T4JJx/LeSzkJ+Bi36HTNYLBImofV24ymrWGAN4geDg+FlmBt8C8XboWAVDmwuBwLUtOs0s6yMwxgDe3sx5hYOn84y887OQ7oFIhEzW26LTWgTuskBgjAG8QAAwenySkas/XTg/2yKwQOAqq1ljDOClhsALBMWmg0Bgo4acZTVrjAG8uQSJaIR9x+cuRZ2xQOA8q1ljDADRiLCmN82+khZBZsbrI7BF59xlgcAYU7A2GEJaZDpnLQLXWc0aYwqGQwJBZsafR2CBwFlWs8aYguG+NibOzjAxOVM4N9tHYKkhV1kgMMYUrO1LA7DvxGyrIBg1ZC0Cd9VUsyLSJyL3i8hu/9/eMtfdJyLjInJvyfnvisgrIvKU/3NZLeUxxtRmbcgQ0kw2RywiRCPSqGKZOqs1xN8CbFfVDcB2/zjM14Abyzz316p6mf8TsnO2MWa5hAeCvHUUO67W2t0G3OE/vgP4YNhFqrodOFXjexlj6qwrFae3LT4nEExn87bOkONqDQSrVHXMf3wIWHUOv+PvReRpEblVRJLlLhKRm0Vkh4jsOHLkyDkV1hizuOG+tjlzCTLZnK0z5LhFa1dEHhCRnSE/24qvU1UFtMr3/zxwIfAWoA/4XLkLVfU2Vd2sqpv7+/urfBtjTKXWzgsEeVtnyHGLLjqnqlvLPScir4nIgKqOicgAcLiaNy9qTWRE5DvAZ6t5vTFm6Q33tXHfzkPk8ko0Il5qyPoInFZr7d4D3OQ/vgm4u5oX+8EDERG8/oWdNZbHGFOj4b42snllbMJbcyiTzdvQUcfVWrtfAa4Tkd3AVv8YEdksIrcHF4nIw8CdwBYR2S8i7/af+oGIPAM8A6wEvlxjeYwxNSoeOfTswQl+/fIx1vS0NbhUpp5q2o9AVY8BW0LO7wA+XnR8dZnXX1vL+xtjll6wHPWOV0/ww0dG6UnH+dK2Nza4VKaebGMaY8wcA90pohHh1gdepC0e5c5PvI3zulKNLpapI0v8GWPmiEUjDPV4S018/YaNXDzY1eASmXqzFoExZp5PbtlAPCpsuehcpgaZZmOBwBgzz4cuX9PoIphlZKkhY4xpcRYIjDGmxVkgMMaYFmeBwBhjWpwFAmOMaXEWCIwxpsVZIDDGmBZngcAYY1qcePvJNBcROQLsPceXrwSOLmFxmkUr3ncr3jO05n3bPVdmRFXn7ezVlIGgFiKyQ1U3N7ocy60V77sV7xla877tnmtjqSFjjGlxFgiMMabFtWIguK3RBWiQVrzvVrxnaM37tnuuQcv1ERhjjJmrFVsExhhjilggMMaYFtdSgUBE3iMiL4jIHhG5pdHlqQcRWSsiD4rIcyLyrIh8yj/fJyL3i8hu/9/eRpd1qYlIVESeFJF7/eP1IvKIX98/FpFEo8u41ESkR0TuEpFdIvK8iLzV9boWkb/yP9s7ReRHIpJysa5F5NsiclhEdhadC61b8Xzdv/+nRWRTNe/VMoFARKLAvwDvBS4GbhCRixtbqrrIAp9R1YuBq4A/9+/zFmC7qm4AtvvHrvkU8HzR8VeBW1X1AuAE8LGGlKq+/hm4T1UvBN6Md//O1rWIDAGfBDar6iVAFPhD3Kzr7wLvKTlXrm7fC2zwf24GvlnNG7VMIACuAPao6suqOg38O7CtwWVacqo6pqpP+I9P4X0xDOHd6x3+ZXcAH2xMCetDRNYA7wNu948FuBa4y7/ExXvuBt4JfAtAVadVdRzH6xpvi920iMSANmAMB+taVR8CjpecLle324DvqefXQI+IDFT6Xq0UCIaAfUXH+/1zzhKRdcBG4BFglaqO+U8dAlzblfyfgL8B8v7xCmBcVbP+sYv1vR44AnzHT4ndLiLtOFzXqnoA+AdgFC8ATACP435dB8rVbU3fb60UCFqKiHQAPwH+UlVPFj+n3phhZ8YNi8j7gcOq+nijy7LMYsAm4JuquhE4Q0kayMG67sX763c9MAi0Mz990hKWsm5bKRAcANYWHa/xzzlHROJ4QeAHqvpT//RrQVPR//dwo8pXB28HPiAir+Kl/K7Fy533+OkDcLO+9wP7VfUR//guvMDgcl1vBV5R1SOqOgP8FK/+Xa/rQLm6ren7rZUCwWPABn90QQKvg+meBpdpyfm58W8Bz6vqPxY9dQ9wk//4JuDu5S5bvajq51V1jaquw6vXX6nqR4EHgQ/5lzl1zwCqegjYJyJv8E9tAZ7D4brGSwldJSJt/mc9uGen67pIubq9B/hjf/TQVcBEUQppcaraMj/A9cCLwEvAFxpdnjrd4zvwmotPA0/5P9fj5cy3A7uBB4C+Rpe1Tvf/W8C9/uPXAY8Ce4A7gWSjy1eH+70M2OHX938Bva7XNfDkXf/yAAAAYElEQVRFYBewE/g+kHSxroEf4fWDzOC1/j5Wrm4BwRsV+RLwDN6oqorfy5aYMMaYFtdKqSFjjDEhLBAYY0yLs0BgjDEtzgKBMca0OAsExhjT4iwQGGNMi7NAYIwxLe7/ADchg1AZa4PlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_velocity_curve(true=Y[0, :, 1], pred=Y_hat[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_velocity_curve(true=Y[0, :, 2], pred=Y_hat[0, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
